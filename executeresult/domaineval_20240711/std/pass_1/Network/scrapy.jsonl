{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "curl_to_request_kwargs", "method_path": "../srcdata/Network/scrapy/scrapy/utils/curl.py", "method_code_mask": "import argparse\nimport warnings\nfrom http.cookies import SimpleCookie\nfrom shlex import split\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import NoReturn\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Union\nfrom urllib.parse import urlparse\n\n\nclass CurlParser(argparse.ArgumentParser):\n\n    def error(self, message: str) ->NoReturn:\n        error_msg = f'There was an error parsing the curl command: {message}'\n        raise ValueError(error_msg)\n\n\ncurl_parser = CurlParser()\n\n\ndef curl_to_request_kwargs(curl_command: str, ignore_unknown_options: bool=True\n    ) ->Dict[str, Any]: [MASK]\n", "response": "import argparse\nimport warnings\nfrom http.cookies import SimpleCookie\nfrom shlex import split\nfrom typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import NoReturn\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Union\nfrom urllib.parse import urlparse\nclass CurlParser(argparse.ArgumentParser):\n\n    def error(self, message: str) ->NoReturn:\n        error_msg = f'There was an error parsing the curl command: {message}'\n        raise ValueError(error_msg)\ncurl_parser = CurlParser()\ndef curl_to_request_kwargs(curl_command: str, ignore_unknown_options: bool=True\n    ) ->Dict[str, Any]:\n    \"\"\"Convert a cURL command syntax to Request kwargs.\n    :param str curl_command: string containing the curl command\n    :param bool ignore_unknown_options: If true, only a warning is emitted when\n                                        cURL options are unknown. Otherwise\n                                        raises an error. (default: True)\n    :return: dictionary of Request kwargs\n    \"\"\"\n    curl_args = split(curl_command)\n    if curl_args[0] != 'curl':\n        raise ValueError('A curl command must start with \"curl\"')\n    parsed_args, argv = curl_parser.parse_known_args(curl_args[1:])\n    if argv:\n        msg = f\"Unrecognized options: {', '.join(argv)}\"\n        if ignore_unknown_options:\n            warnings.warn(msg)\n        else:\n            raise ValueError(msg)\n    url = parsed_args.url\n    parsed_url = urlparse(url)\n    if not parsed_url.scheme:\n        url = 'http://' + url\n    method = parsed_args.method or 'GET'\n    result: Dict[str, Any] = {'method': method.upper(), 'url': url}\n    headers, cookies = _parse_headers_and_cookies(parsed_args)\n    if headers:\n        result['headers'] = headers\n    if cookies:\n        result['cookies'] = cookies\n    if parsed_args.data:\n        result['body'] = parsed_args.data\n        if not parsed_args.method:\n            result['method'] = 'POST'\n    return result"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "build_from_settings", "method_path": "../srcdata/Network/scrapy/scrapy/utils/misc.py", "method_code_mask": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\nT = TypeVar('T')\n\n\ndef build_from_settings(objcls: Type[T], settings: BaseSettings, /, *args:\n    Any, **kwargs: Any) ->T: [MASK]\n", "response": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\nT = TypeVar('T')\ndef build_from_settings(objcls: Type[T], settings: BaseSettings, /, *args:\n    Any, **kwargs: Any) ->T:\n    \"\"\"Construct a class instance using its ``from_settings`` constructor.\n    ``*args`` and ``**kwargs`` are forwarded to the constructor.\n    Raises ``TypeError`` if the resulting instance is ``None``.\n    \"\"\"\n    if hasattr(objcls, 'from_settings'):\n        instance = objcls.from_settings(settings, *args, **kwargs)\n        method_name = 'from_settings'\n    else:\n        instance = objcls(*args, **kwargs)\n        method_name = '__new__'\n    if instance is None:\n        raise TypeError(f'{objcls.__qualname__}.{method_name} returned None')\n    return cast(T, instance)"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "set_environ", "method_path": "../srcdata/Network/scrapy/scrapy/utils/misc.py", "method_code_mask": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\n\n\n@contextmanager\ndef set_environ(**kwargs: str) ->Iterator[None]: [MASK]\n", "response": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\n@contextmanager\ndef set_environ(**kwargs: str) ->Iterator[None]:\n    \"\"\"Temporarily set environment variables inside the context manager and\n    fully restore previous environment afterwards\n    \"\"\"\n    original_env = {k: os.environ.get(k) for k in kwargs}\n    os.environ.update(kwargs)\n    try:\n        yield\n    finally:\n        for k, v in original_env.items():\n            if v is None:\n                del os.environ[k]\n            else:\n                os.environ[k] = v"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "build_from_crawler", "method_path": "../srcdata/Network/scrapy/scrapy/utils/misc.py", "method_code_mask": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\nT = TypeVar('T')\n\n\ndef build_from_crawler(objcls: Type[T], crawler: Crawler, /, *args: Any, **\n    kwargs: Any) ->T: [MASK]\n", "response": "from __future__ import annotations\nimport ast\nimport hashlib\nimport inspect\nimport os\nimport re\nimport warnings\nfrom collections import deque\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom importlib import import_module\nfrom pkgutil import iter_modules\nfrom typing import IO\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Deque\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import List\nfrom typing import Optional\nfrom typing import Type\nfrom typing import TypeVar\nfrom typing import Union\nfrom typing import cast\nfrom types import ModuleType\nT = TypeVar('T')\ndef build_from_crawler(objcls: Type[T], crawler: Crawler, /, *args: Any, **\n    kwargs: Any) ->T:\n    \"\"\"Construct a class instance using its ``from_crawler`` constructor.\n    ``*args`` and ``**kwargs`` are forwarded to the constructor.\n    Raises ``TypeError`` if the resulting instance is ``None``.\n    \"\"\"\n    if hasattr(objcls, 'from_crawler'):\n        instance = objcls.from_crawler(crawler, *args, **kwargs)\n        method_name = 'from_crawler'\n    elif hasattr(objcls, 'from_settings'):\n        instance = objcls.from_settings(crawler.settings, *args, **kwargs)\n        method_name = 'from_settings'\n    else:\n        instance = objcls(*args, **kwargs)\n        method_name = '__new__'\n    if instance is None:\n        raise TypeError(f'{objcls.__qualname__}.{method_name} returned None')\n    return cast(T, instance)"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "guess_scheme", "method_path": "../srcdata/Network/scrapy/scrapy/utils/url.py", "method_code_mask": "import re\nfrom typing import TYPE_CHECKING\nfrom typing import Iterable\nfrom typing import Optional\nfrom typing import Type\nfrom typing import Union\nfrom typing import cast\nfrom urllib.parse import ParseResult\nfrom urllib.parse import urldefrag\nfrom urllib.parse import urlparse\nfrom urllib.parse import urlunparse\n\n\ndef guess_scheme(url: str) ->str: [MASK]\n", "response": "import re\nfrom typing import TYPE_CHECKING\nfrom typing import Iterable\nfrom typing import Optional\nfrom typing import Type\nfrom typing import Union\nfrom typing import cast\nfrom urllib.parse import ParseResult\nfrom urllib.parse import urldefrag\nfrom urllib.parse import urlparse\nfrom urllib.parse import urlunparse\ndef guess_scheme(url: str) ->str:\n    \"\"\"Add an URL scheme if missing: file:// for filepath-like input or\n    http:// otherwise.\"\"\"\n    if _is_filesystem_path(url):\n        return any_to_uri(url)\n    return add_http_if_no_scheme(url)"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "sitemap_urls_from_robots", "method_path": "../srcdata/Network/scrapy/scrapy/utils/sitemap.py", "method_code_mask": "from typing import Any\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import Optional\nfrom typing import Union\nfrom urllib.parse import urljoin\nimport lxml.etree\n\n\ndef sitemap_urls_from_robots(robots_text: str, base_url: Optional[str]=None\n    ) ->Iterable[str]: [MASK]\n", "response": "from typing import Any\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import Iterator\nfrom typing import Optional\nfrom typing import Union\nfrom urllib.parse import urljoin\nimport lxml.etree\ndef sitemap_urls_from_robots(robots_text: str, base_url: Optional[str]=None\n    ) ->Iterable[str]:\n    \"\"\"Return an iterator over all sitemap urls contained in the given\n    robots.txt file\n    \"\"\"\n    for line in robots_text.splitlines():\n        if line.lstrip().lower().startswith('sitemap:'):\n            url = line.split(':', 1)[1].strip()\n            yield urljoin(base_url or '', url)"}
{"result": "passed", "model_name": "std", "repository": "scrapy", "full_method_name": "add_http_if_no_scheme", "method_path": "../srcdata/Network/scrapy/scrapy/utils/url.py", "method_code_mask": "import re\nfrom typing import TYPE_CHECKING\nfrom typing import Iterable\nfrom typing import Optional\nfrom typing import Type\nfrom typing import Union\nfrom typing import cast\nfrom urllib.parse import ParseResult\nfrom urllib.parse import urldefrag\nfrom urllib.parse import urlparse\nfrom urllib.parse import urlunparse\n\n\ndef add_http_if_no_scheme(url: str) ->str: [MASK]\n", "response": "import re\nfrom typing import TYPE_CHECKING\nfrom typing import Iterable\nfrom typing import Optional\nfrom typing import Type\nfrom typing import Union\nfrom typing import cast\nfrom urllib.parse import ParseResult\nfrom urllib.parse import urldefrag\nfrom urllib.parse import urlparse\nfrom urllib.parse import urlunparse\ndef add_http_if_no_scheme(url: str) ->str:\n    \"\"\"Add http as the default scheme if it is missing from the url.\"\"\"\n    match = re.match('^\\\\w+://', url, flags=re.I)\n    if not match:\n        parts = urlparse(url)\n        scheme = 'http:' if parts.netloc else 'http://'\n        url = scheme + url\n    return url"}
