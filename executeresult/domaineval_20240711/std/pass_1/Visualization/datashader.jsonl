{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "isfixed", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/predicates.py", "method_code_mask": "import numpy as np\n\n\ndef isfixed(ds): [MASK]\n", "response": "import numpy as np\ndef isfixed(ds):\n    \"\"\" Contains no variable dimensions\n\n    >>> isfixed('10 * int')\n    True\n    >>> isfixed('var * int')\n    False\n    >>> isfixed('10 * {name: string, amount: int}')\n    True\n    >>> isfixed('10 * {name: string, amounts: var * int}')\n    False\n    \"\"\"\n    ds = dshape(ds)\n    if isinstance(ds[0], TypeVar):\n        return None\n    if isinstance(ds[0], Var):\n        return False\n    if isinstance(ds[0], Record):\n        return all(map(isfixed, ds[0].types))\n    if len(ds) > 1:\n        return isfixed(ds.subarray(1))\n    return True"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "lex", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/lexer.py", "method_code_mask": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport re\nimport ast\nimport collections\nToken = collections.namedtuple('Token', 'id, name, span, val')\n\n\ndef _str_val(s):\n    return ast.parse('u' + s).body[0].value.value\n\n\n_tokens = [('BOOLEAN', 'True|False', ast.literal_eval), ('NAME_LOWER',\n    '[a-z][a-zA-Z0-9_]*', lambda x: x), ('NAME_UPPER', '[A-Z][a-zA-Z0-9_]*',\n    lambda x: x), ('NAME_OTHER', '_[a-zA-Z0-9_]*', lambda x: x), (\n    'ASTERISK', '\\\\*'), ('COMMA', ','), ('EQUAL', '='), ('COLON', ':'), (\n    'LBRACKET', '\\\\['), ('RBRACKET', '\\\\]'), ('LBRACE', '\\\\{'), ('RBRACE',\n    '\\\\}'), ('LPAREN', '\\\\('), ('RPAREN', '\\\\)'), ('ELLIPSIS', '\\\\.\\\\.\\\\.'),\n    ('RARROW', '->'), ('QUESTIONMARK', '\\\\?'), ('INTEGER',\n    '0(?![0-9])|-?[1-9][0-9]*', int), ('STRING', \n    '(?:\"(?:[^\"\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\[\"bfnrt]))*\")|' +\n    \"(?:'(?:[^'\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\['bfnrt]))*')\",\n    _str_val)]\n_tokens_re = re.compile('|'.join('(' + tok[1] + ')' for tok in _tokens), re\n    .MULTILINE)\n_whitespace = '(?:\\\\s|(?:#.*$))*'\n_whitespace_re = re.compile(_whitespace, re.MULTILINE)\n\n\ndef lex(ds_str): [MASK]\n", "response": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport re\nimport ast\nimport collections\nToken = collections.namedtuple('Token', 'id, name, span, val')\ndef _str_val(s):\n    return ast.parse('u' + s).body[0].value.value\n_tokens = [('BOOLEAN', 'True|False', ast.literal_eval), ('NAME_LOWER',\n    '[a-z][a-zA-Z0-9_]*', lambda x: x), ('NAME_UPPER', '[A-Z][a-zA-Z0-9_]*',\n    lambda x: x), ('NAME_OTHER', '_[a-zA-Z0-9_]*', lambda x: x), (\n    'ASTERISK', '\\\\*'), ('COMMA', ','), ('EQUAL', '='), ('COLON', ':'), (\n    'LBRACKET', '\\\\['), ('RBRACKET', '\\\\]'), ('LBRACE', '\\\\{'), ('RBRACE',\n    '\\\\}'), ('LPAREN', '\\\\('), ('RPAREN', '\\\\)'), ('ELLIPSIS', '\\\\.\\\\.\\\\.'),\n    ('RARROW', '->'), ('QUESTIONMARK', '\\\\?'), ('INTEGER',\n    '0(?![0-9])|-?[1-9][0-9]*', int), ('STRING',\n    '(?:\"(?:[^\"\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\[\"bfnrt]))*\")|' +\n    \"(?:'(?:[^'\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\['bfnrt]))*')\",\n    _str_val)]\n_tokens_re = re.compile('|'.join('(' + tok[1] + ')' for tok in _tokens), re\n    .MULTILINE)\n_whitespace = '(?:\\\\s|(?:#.*$))*'\n_whitespace_re = re.compile(_whitespace, re.MULTILINE)\ndef lex(ds_str):\n    \"\"\"A generator which lexes a datashape string into a\n    sequence of tokens.\n    Example\n    -------\n        import datashape\n        s = '   -> ... A... \"string\" 1234 Blah _eil(# comment'\n        print('lexing %r' % s)\n        for tok in datashape.lexer.lex(s):\n            print(tok.id, tok.name, tok.span, repr(tok.val))\n    \"\"\"\n    pos = 0\n    m = _whitespace_re.match(ds_str, pos)\n    if m:\n        pos = m.end()\n    while pos < len(ds_str):\n        m = _tokens_re.match(ds_str, pos)\n        if m:\n            id = m.lastindex\n            tokinfo = _tokens[id - 1]\n            name = tokinfo[0]\n            span = m.span()\n            if len(tokinfo) > 2:\n                val = tokinfo[2](ds_str[span[0]:span[1]])\n            else:\n                val = None\n            pos = m.end()\n            yield Token(id, name, span, val)\n        else:\n            raise error.DataShapeSyntaxError(pos, '<nofile>', ds_str,\n                'Invalid DataShape token')\n        m = _whitespace_re.match(ds_str, pos)\n        if m:\n            pos = m.end()"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "calc_res", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef calc_res(raster): [MASK]\n", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef calc_res(raster):\n    \"\"\"Calculate the resolution of xarray.DataArray raster and return it as the\n    two-tuple (xres, yres). yres is positive if it is decreasing.\n    \"\"\"\n    h, w = raster.shape[-2:]\n    ydim, xdim = raster.dims[-2:]\n    xcoords = raster[xdim].values\n    ycoords = raster[ydim].values\n    xres = (xcoords[-1] - xcoords[0]) / (w - 1)\n    yres = (ycoords[0] - ycoords[-1]) / (h - 1)\n    return xres, yres"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "apply", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef apply(func, args, kwargs=None): [MASK]\n", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef apply(func, args, kwargs=None):\n    if kwargs:\n        return func(*args, **kwargs)\n    else:\n        return func(*args)"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "isnumeric", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/predicates.py", "method_code_mask": "import numpy as np\n\n\ndef isnumeric(ds): [MASK]\n", "response": "import numpy as np\ndef isnumeric(ds):\n    \"\"\" Has a numeric measure\n\n    >>> isnumeric('int32')\n    True\n    >>> isnumeric('3 * ?real')\n    True\n    >>> isnumeric('string')\n    False\n    >>> isnumeric('var * {amount: ?int32}')\n    False\n    \"\"\"\n    ds = launder(ds)\n    try:\n        npdtype = to_numpy_dtype(ds)\n    except TypeError:\n        return False\n    else:\n        return isinstance(ds, Unit) and np.issubdtype(npdtype, np.number)"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "orient_array", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef orient_array(raster, res=None, layer=None): [MASK]\n", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef orient_array(raster, res=None, layer=None):\n    \"\"\"\n    Reorients the array to a canonical orientation depending on\n    whether the x and y-resolution values are positive or negative.\n\n    Parameters\n    ----------\n    raster : DataArray\n        xarray DataArray to be reoriented\n    res : tuple\n        Two-tuple (int, int) which includes x and y resolutions (aka \"grid/cell\n        sizes\"), respectively.\n    layer : int\n        Index of the raster layer to be reoriented (optional)\n\n    Returns\n    -------\n    array : numpy.ndarray\n        Reoriented 2d NumPy ndarray\n    \"\"\"\n    if res is None:\n        res = calc_res(raster)\n    array = raster.data\n    if layer is not None:\n        array = array[layer - 1]\n    r0zero = np.timedelta64(0, 'ns') if isinstance(res[0], np.timedelta64\n        ) else 0\n    r1zero = np.timedelta64(0, 'ns') if isinstance(res[1], np.timedelta64\n        ) else 0\n    xflip = res[0] < r0zero\n    yflip = res[1] > r1zero\n    array = _flip_array(array, xflip, yflip)\n    return array"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "optionify", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/promote.py", "method_code_mask": "from __future__ import absolute_import\nimport numpy as np\nfrom datashader import datashape\n\n\ndef optionify(lhs, rhs, dshape): [MASK]\n", "response": "from __future__ import absolute_import\nimport numpy as np\nfrom datashader import datashape\ndef optionify(lhs, rhs, dshape):\n    \"\"\"Check whether a binary operation's dshape came from\n    :class:`~datashape.coretypes.Option` typed operands and construct an\n    :class:`~datashape.coretypes.Option` type accordingly.\n\n    Examples\n    --------\n    >>> from datashader.datashape import int32, int64, Option\n    >>> x = Option(int32)\n    >>> x\n    Option(ty=ctype(\"int32\"))\n    >>> y = int64\n    >>> y\n    ctype(\"int64\")\n    >>> optionify(x, y, int64)\n    Option(ty=ctype(\"int64\"))\n    \"\"\"\n    if hasattr(dshape.measure, 'ty'):\n        return dshape\n    if hasattr(lhs, 'ty') or hasattr(rhs, 'ty'):\n        return datashape.Option(dshape)\n    return dshape"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "isreal", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef isreal(dt): [MASK]\n", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef isreal(dt):\n    \"\"\"Check if a datashape is numeric and real.\n\n    Example\n    -------\n    >>> isreal('int32')\n    True\n    >>> isreal('float64')\n    True\n    >>> isreal('string')\n    False\n    >>> isreal('complex64')\n    False\n    \"\"\"\n    dt = datashape.predicates.launder(dt)\n    return isinstance(dt, datashape.Unit) and dt in datashape.typesets.real"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "rgb", "method_path": "../srcdata/Visualization/datashader/datashader/colors.py", "method_code_mask": "from __future__ import annotations\n\n\ndef rgb(x): [MASK]\n", "response": "from __future__ import annotations\ndef rgb(x):\n    \"\"\"Return a triple representing rgb color.\n\n    Can convert colors by name or hexcode. Passing in a valid rgb tuple is\n    idempotent.\n\n    Example\n    -------\n    >>> rgb('plum')\n    (221, 160, 221)\n    >>> rgb('#FFFFFF')\n    (255, 255, 255)\n    >>> rgb((255, 255, 255))\n    (255, 255, 255)\n    \"\"\"\n    if isinstance(x, str):\n        if x.startswith('#'):\n            return hex_to_rgb(x)\n        elif x in color_lookup:\n            return hex_to_rgb(color_lookup[x])\n        else:\n            raise ValueError(\"Unknown color: '{0}'\".format(x))\n    elif isinstance(x, tuple) and len(x) == 3:\n        if min(x) < 0 or max(x) > 255:\n            raise ValueError('Invalid RGB tuple')\n    else:\n        raise TypeError(\"Don't know how to convert {0} to RGB\".format(x))\n    return x"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "compute_chunksize", "method_path": "../srcdata/Visualization/datashader/datashader/resampling.py", "method_code_mask": "from __future__ import annotations\nfrom itertools import groupby\nfrom math import floor\nfrom math import ceil\nimport dask.array as da\nimport numpy as np\nfrom dask.delayed import delayed\nfrom numba import prange\n\n\ndef compute_chunksize(src, w, h, chunksize=None, max_mem=None): [MASK]\n", "response": "from __future__ import annotations\nfrom itertools import groupby\nfrom math import floor\nfrom math import ceil\nimport dask.array as da\nimport numpy as np\nfrom dask.delayed import delayed\nfrom numba import prange\ndef compute_chunksize(src, w, h, chunksize=None, max_mem=None):\n    \"\"\"\n    Attempts to compute a chunksize for the resampling output array\n    that is as close as possible to the input array chunksize, while\n    also respecting the maximum memory constraint to avoid loading\n    to much data into memory at the same time.\n\n    Parameters\n    ----------\n    src : dask.array.Array\n        The source array to resample\n    w : int\n        New grid width\n    h : int\n        New grid height\n    chunksize : tuple(int, int) (optional)\n        Size of the output chunks. By default the chunk size is\n        inherited from the *src* array.\n    max_mem : int (optional)\n        The maximum number of bytes that should be loaded into memory\n        during the regridding operation.\n\n    Returns\n    -------\n    chunksize : tuple(int, int)\n        Size of the output chunks.\n    \"\"\"\n    start_chunksize = src.chunksize if chunksize is None else chunksize\n    if max_mem is None:\n        return start_chunksize\n    sh, sw = src.shape\n    height_fraction = float(sh) / h\n    width_fraction = float(sw) / w\n    ch, cw = start_chunksize\n    dim = True\n    nbytes = src.dtype.itemsize\n    while ch * height_fraction * (cw * width_fraction) * nbytes > max_mem:\n        if dim:\n            cw -= 1\n        else:\n            ch -= 1\n        dim = not dim\n    if ch == 0 or cw == 0:\n        min_mem = height_fraction * width_fraction * nbytes\n        raise ValueError(\n            'Given the memory constraints the resampling operation could not find a chunksize that avoids loading too much data into memory. Either relax the memory constraint to a minimum of %d bytes or resample to a larger grid size. Note: A future implementation could handle this condition by declaring temporary arrays.'\n             % min_mem)\n    return ch, cw"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "expand_varargs", "method_path": "../srcdata/Visualization/datashader/datashader/macros.py", "method_code_mask": "import re\nimport copy\nimport inspect\nimport ast\nimport textwrap\nimport astor\n\n\ndef expand_varargs(expand_number): [MASK]\n", "response": "import re\nimport copy\nimport inspect\nimport ast\nimport textwrap\nimport astor\ndef expand_varargs(expand_number):\n    \"\"\"\n    Decorator to expand the variable length (starred) argument in a function\n    signature with a fixed number of arguments.\n\n    Parameters\n    ----------\n    expand_number: int\n        The number of fixed arguments that should replace the variable length\n        argument\n\n    Returns\n    -------\n    function\n        Decorator Function\n    \"\"\"\n    if not isinstance(expand_number, int) or expand_number < 0:\n        raise ValueError('expand_number must be a non-negative integer')\n\n    def _expand_varargs(fn):\n        fn_ast = function_to_ast(fn)\n        fn_expanded_ast = expand_function_ast_varargs(fn_ast, expand_number)\n        return function_ast_to_function(fn_expanded_ast, stacklevel=2)\n    return _expand_varargs"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "parse", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/parser.py", "method_code_mask": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\ndef parse(ds_str, sym): [MASK]\n", "response": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\ndef parse(ds_str, sym):\n    \"\"\"Parses a single datashape from a string.\n\n    Parameters\n    ----------\n    ds_str : string\n        The datashape string to parse.\n    sym : TypeSymbolTable\n        The symbol tables of dimensions, dtypes, and type constructors for each.\n\n    \"\"\"\n    dsp = DataShapeParser(ds_str, sym)\n    ds = dsp.parse_datashape()\n    if ds is None:\n        dsp.raise_error('Invalid datashape')\n    if dsp.pos != dsp.end_pos:\n        dsp.raise_error('Unexpected token in datashape')\n    return ds"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "calculate_zoom_level_stats", "method_path": "../srcdata/Visualization/datashader/datashader/tiles.py", "method_code_mask": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\n\n\ndef calculate_zoom_level_stats(super_tiles, load_data_func, rasterize_func,\n    color_ranging_strategy='fullscan'): [MASK]\n", "response": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\ndef calculate_zoom_level_stats(super_tiles, load_data_func, rasterize_func,\n    color_ranging_strategy='fullscan'):\n    if color_ranging_strategy == 'fullscan':\n        stats = []\n        is_bool = False\n        for super_tile in super_tiles:\n            agg = _get_super_tile_min_max(super_tile, load_data_func,\n                rasterize_func)\n            super_tile['agg'] = agg\n            if agg.dtype.kind == 'b':\n                is_bool = True\n            else:\n                stats.append(np.nanmin(agg.data))\n                stats.append(np.nanmax(agg.data))\n        if is_bool:\n            span = 0, 1\n        else:\n            b = db.from_sequence(stats)\n            span = dask.compute(b.min(), b.max())\n        return super_tiles, span\n    else:\n        raise ValueError('Invalid color_ranging_strategy option')"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "gen_super_tiles", "method_path": "../srcdata/Visualization/datashader/datashader/tiles.py", "method_code_mask": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\n\n\ndef gen_super_tiles(extent, zoom_level, span=None): [MASK]\n", "response": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\ndef gen_super_tiles(extent, zoom_level, span=None):\n    xmin, ymin, xmax, ymax = extent\n    super_tile_size = min(2 ** 4 * 256, 2 ** zoom_level * 256)\n    super_tile_def = MercatorTileDefinition(x_range=(xmin, xmax), y_range=(\n        ymin, ymax), tile_size=super_tile_size)\n    super_tiles = super_tile_def.get_tiles_by_extent(extent, zoom_level)\n    for s in super_tiles:\n        st_extent = s[3]\n        x_range = st_extent[0], st_extent[2]\n        y_range = st_extent[1], st_extent[3]\n        yield {'level': zoom_level, 'x_range': x_range, 'y_range': y_range,\n            'tile_size': super_tile_def.tile_size, 'span': span}"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "unite_base", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/discovery.py", "method_code_mask": "from __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom datetime import date\nfrom datetime import time\nfrom datetime import timedelta\nfrom itertools import chain\nimport re\nfrom textwrap import dedent\nfrom types import MappingProxyType\nfrom warnings import warn\nfrom dateutil.parser import parse as dateparse\nimport numpy as np\nfrom unittest.mock import Mock\n\n\ndef unite_base(dshapes): [MASK]\n", "response": "from __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom datetime import date\nfrom datetime import time\nfrom datetime import timedelta\nfrom itertools import chain\nimport re\nfrom textwrap import dedent\nfrom types import MappingProxyType\nfrom warnings import warn\nfrom dateutil.parser import parse as dateparse\nimport numpy as np\nfrom unittest.mock import Mock\ndef unite_base(dshapes):\n    \"\"\" Performs lowest common dshape and also null aware\n\n    >>> unite_base([float64, float64, int64])\n    dshape(\"3 * float64\")\n\n    >>> unite_base([int32, int64, null])\n    dshape(\"3 * ?int64\")\n    \"\"\"\n    dshapes = [unpack(ds) for ds in dshapes]\n    bynull = groupby(isnull, dshapes)\n    try:\n        good_dshapes = bynull[False]\n    except KeyError:\n        return len(dshapes) * null\n    if all(isinstance(ds, Unit) for ds in good_dshapes):\n        base = lowest_common_dshape(good_dshapes)\n    elif (all(isinstance(ds, Record) for ds in good_dshapes) and ds.names ==\n        dshapes[0].names for ds in good_dshapes):\n        names = good_dshapes[0].names\n        base = Record([[name, unite_base([ds.dict.get(name, null) for ds in\n            good_dshapes]).subshape[0]] for name in names])\n    if base:\n        if bynull.get(True):\n            base = Option(base)\n        return len(dshapes) * base"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "draw_segment", "method_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py", "method_code_mask": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\n_draw_segment = _build_draw_segment(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols, 0, False)\n\n\ndef draw_segment(x0, y0, x1, y1, i, segment_start, agg): [MASK]\n", "response": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n_draw_segment = _build_draw_segment(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols, 0, False)\ndef draw_segment(x0, y0, x1, y1, i, segment_start, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    buffer = np.empty(0)\n    _draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start,\n        False, x0, x1, y0, y1, 0.0, 0.0, buffer, agg)"}
{"result": "passed", "model_name": "std", "repository": "datashader", "full_method_name": "draw_trapezoid", "method_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py", "method_code_mask": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\n_draw_trapezoid = _build_draw_trapezoid_y(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols)\n\n\ndef draw_trapezoid(x0, x1, y0, y1, y2, y3, i, trapezoid_start, stacked, agg): [\n    MASK]\n", "response": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n_draw_trapezoid = _build_draw_trapezoid_y(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols)\ndef draw_trapezoid(x0, x1, y0, y1, y2, y3, i, trapezoid_start, stacked, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    _draw_trapezoid(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, x0, x1, y0,\n        y1, y2, y3, trapezoid_start, stacked, agg)"}
