{"result": "passed", "model_name": "std", "repository": "altair", "full_method_name": "eval_block", "method_path": "../srcdata/Visualization/altair/altair/utils/execeval.py", "method_code_mask": "import ast\nimport sys\n\n\nclass _CatchDisplay:\n    \"\"\"Class to temporarily catch sys.displayhook\"\"\"\n\n    def __init__(self):\n        self.output = None\n\n    def __enter__(self):\n        self.old_hook = sys.displayhook\n        sys.displayhook = self\n        return self\n\n    def __exit__(self, type, value, traceback):\n        sys.displayhook = self.old_hook\n        return False\n\n    def __call__(self, output):\n        self.output = output\n\n\ndef eval_block(code, namespace=None, filename='<string>'): [MASK]\n", "response": "import ast\nimport sys\nclass _CatchDisplay:\n    \"\"\"Class to temporarily catch sys.displayhook\"\"\"\n\n    def __init__(self):\n        self.output = None\n\n    def __enter__(self):\n        self.old_hook = sys.displayhook\n        sys.displayhook = self\n        return self\n\n    def __exit__(self, type, value, traceback):\n        sys.displayhook = self.old_hook\n        return False\n\n    def __call__(self, output):\n        self.output = output\ndef eval_block(code, namespace=None, filename='<string>'):\n    \"\"\"\n    Execute a multi-line block of code in the given namespace\n    If the final statement in the code is an expression, return\n    the result of the expression.\n    \"\"\"\n    tree = ast.parse(code, filename='<ast>', mode='exec')\n    if namespace is None:\n        namespace = {}\n    catch_display = _CatchDisplay()\n    if isinstance(tree.body[-1], ast.Expr):\n        to_exec, to_eval = tree.body[:-1], tree.body[-1:]\n    else:\n        to_exec, to_eval = tree.body, []\n    for node in to_exec:\n        compiled = compile(ast.Module([node], []), filename=filename, mode=\n            'exec')\n        exec(compiled, namespace)\n    with catch_display:\n        for node in to_eval:\n            compiled = compile(ast.Interactive([node]), filename=filename,\n                mode='single')\n            exec(compiled, namespace)\n    return catch_display.output"}
{"result": "passed", "model_name": "std", "repository": "altair", "full_method_name": "deprecated", "method_path": "../srcdata/Visualization/altair/altair/utils/deprecation.py", "method_code_mask": "from __future__ import annotations\nimport sys\nimport warnings\nfrom typing import TYPE_CHECKING\nfrom typing_extensions import deprecated as _deprecated\nfrom typing_extensions import LiteralString\n\n\ndef _format_message(version: LiteralString, alternative: (LiteralString |\n    None), message: (LiteralString | None), /) ->LiteralString:\n    output = f'Deprecated in `altair={version}`.'\n    if alternative:\n        output = f'{output} Use {alternative} instead.'\n    return f'{output}\\n{message}' if message else output\n\n\nclass AltairDeprecationWarning(DeprecationWarning):\n    ...\n\n\ndef deprecated(*, version: LiteralString, alternative: (LiteralString |\n    None)=None, message: (LiteralString | None)=None, category: (type[\n    AltairDeprecationWarning] | None)=AltairDeprecationWarning, stacklevel:\n    int=1): [MASK]\n", "response": "from __future__ import annotations\nimport sys\nimport warnings\nfrom typing import TYPE_CHECKING\nfrom typing_extensions import deprecated as _deprecated\nfrom typing_extensions import LiteralString\ndef _format_message(version: LiteralString, alternative: (LiteralString |\n    None), message: (LiteralString | None), /) ->LiteralString:\n    output = f'Deprecated in `altair={version}`.'\n    if alternative:\n        output = f'{output} Use {alternative} instead.'\n    return f'{output}\\n{message}' if message else output\nclass AltairDeprecationWarning(DeprecationWarning):\n    ...\ndef deprecated(*, version: LiteralString, alternative: (LiteralString |\n    None)=None, message: (LiteralString | None)=None, category: (type[\n    AltairDeprecationWarning] | None)=AltairDeprecationWarning, stacklevel:\n    int=1):\n    \"\"\"Indicate that a class, function or overload is deprecated.\n    When this decorator is applied to an object, the type checker\n    will generate a diagnostic on usage of the deprecated object.\n    Parameters\n    ----------\n    version\n        ``altair`` version the deprecation first appeared.\n    alternative\n        Suggested replacement class/method/function.\n    message\n        Additional message appended to ``version``, ``alternative``.\n    category\n        If the *category* is ``None``, no warning is emitted at runtime.\n    stacklevel\n        The *stacklevel* determines where the\n        warning is emitted. If it is ``1`` (the default), the warning\n        is emitted at the direct caller of the deprecated object; if it\n        is higher, it is emitted further up the stack.\n        Static type checker behavior is not affected by the *category*\n        and *stacklevel* arguments.\n    References\n    ----------\n    [PEP 702](https://peps.python.org/pep-0702/)\n    \"\"\"\n    msg = _format_message(version, alternative, message)\n    return _deprecated(msg, category=category, stacklevel=stacklevel)"}
{"result": "passed", "model_name": "std", "repository": "altair", "full_method_name": "update_nested", "method_path": "../srcdata/Visualization/altair/altair/utils/core.py", "method_code_mask": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\n\n\ndef update_nested(original: t.MutableMapping[Any, Any], update: t.Mapping[\n    Any, Any], copy: bool=False) ->t.MutableMapping[Any, Any]: [MASK]\n", "response": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\ndef update_nested(original: t.MutableMapping[Any, Any], update: t.Mapping[\n    Any, Any], copy: bool=False) ->t.MutableMapping[Any, Any]:\n    \"\"\"Update nested dictionaries\n\n    Parameters\n    ----------\n    original : MutableMapping\n        the original (nested) dictionary, which will be updated in-place\n    update : Mapping\n        the nested dictionary of updates\n    copy : bool, default False\n        if True, then copy the original dictionary rather than modifying it\n\n    Returns\n    -------\n    original : MutableMapping\n        a reference to the (modified) original dict\n\n    Examples\n    --------\n    >>> original = {'x': {'b': 2, 'c': 4}}\n    >>> update = {'x': {'b': 5, 'd': 6}, 'y': 40}\n    >>> update_nested(original, update)  # doctest: +SKIP\n    {'x': {'b': 5, 'c': 4, 'd': 6}, 'y': 40}\n    >>> original  # doctest: +SKIP\n    {'x': {'b': 5, 'c': 4, 'd': 6}, 'y': 40}\n    \"\"\"\n    if copy:\n        original = deepcopy(original)\n    for key, val in update.items():\n        if isinstance(val, Mapping):\n            orig_val = original.get(key, {})\n            if isinstance(orig_val, MutableMapping):\n                original[key] = update_nested(orig_val, val)\n            else:\n                original[key] = val\n        else:\n            original[key] = val\n    return original"}
{"result": "passed", "model_name": "std", "repository": "altair", "full_method_name": "infer_vegalite_type_for_pandas", "method_path": "../srcdata/Visualization/altair/altair/utils/core.py", "method_code_mask": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\n\n\ndef infer_vegalite_type_for_pandas(data: object) ->(InferredVegaLiteType |\n    tuple[InferredVegaLiteType, list[Any]]): [MASK]\n", "response": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\ndef infer_vegalite_type_for_pandas(data: object) ->(InferredVegaLiteType |\n    tuple[InferredVegaLiteType, list[Any]]):\n    \"\"\"\n    From an array-like input, infer the correct vega typecode\n    ('ordinal', 'nominal', 'quantitative', or 'temporal')\n\n    Parameters\n    ----------\n    data: object\n    \"\"\"\n    from pandas.api.types import infer_dtype\n    typ = infer_dtype(data, skipna=False)\n    if typ in {'floating', 'mixed-integer-float', 'integer',\n        'mixed-integer', 'complex'}:\n        return 'quantitative'\n    elif typ == 'categorical' and hasattr(data, 'cat') and data.cat.ordered:\n        return 'ordinal', data.cat.categories.tolist()\n    elif typ in {'string', 'bytes', 'categorical', 'boolean', 'mixed',\n        'unicode'}:\n        return 'nominal'\n    elif typ in {'datetime', 'datetime64', 'timedelta', 'timedelta64',\n        'date', 'time', 'period'}:\n        return 'temporal'\n    else:\n        warnings.warn(\n            f\"I don't know how to infer vegalite type from '{typ}'.  Defaulting to nominal.\"\n            , stacklevel=1)\n        return 'nominal'"}
{"result": "passed", "model_name": "std", "repository": "altair", "full_method_name": "sanitize_pandas_dataframe", "method_path": "../srcdata/Visualization/altair/altair/utils/core.py", "method_code_mask": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\n\n\ndef numpy_is_subtype(dtype: Any, subtype: Any) ->bool:\n    import numpy as np\n    try:\n        return np.issubdtype(dtype, subtype)\n    except (NotImplementedError, TypeError):\n        return False\n\n\ndef sanitize_pandas_dataframe(df: pd.DataFrame) ->pd.DataFrame: [MASK]\n", "response": "from __future__ import annotations\nfrom collections.abc import Mapping\nfrom collections.abc import MutableMapping\nfrom copy import deepcopy\nimport json\nimport itertools\nimport re\nimport sys\nimport traceback\nimport warnings\nfrom typing import Callable\nfrom typing import TypeVar\nfrom typing import Any\nfrom typing import Iterator\nfrom typing import cast\nfrom typing import Literal\nfrom typing import TYPE_CHECKING\nfrom itertools import groupby\nfrom operator import itemgetter\nimport jsonschema\nfrom typing import runtime_checkable\nfrom typing import Protocol\nfrom typing_extensions import runtime_checkable\nfrom typing_extensions import Protocol\nfrom typing_extensions import ParamSpec\nfrom types import ModuleType\nimport typing as t\nimport pandas as pd\nfrom pandas.api.types import infer_dtype\nimport numpy as np\nfrom IPython.core.getipython import get_ipython\ndef numpy_is_subtype(dtype: Any, subtype: Any) ->bool:\n    import numpy as np\n    try:\n        return np.issubdtype(dtype, subtype)\n    except (NotImplementedError, TypeError):\n        return False\ndef sanitize_pandas_dataframe(df: pd.DataFrame) ->pd.DataFrame:\n    \"\"\"Sanitize a DataFrame to prepare it for serialization.\n    * Make a copy\n    * Convert RangeIndex columns to strings\n    * Raise ValueError if column names are not strings\n    * Raise ValueError if it has a hierarchical index.\n    * Convert categoricals to strings.\n    * Convert np.bool_ dtypes to Python bool objects\n    * Convert np.int dtypes to Python int objects\n    * Convert floats to objects and replace NaNs/infs with None.\n    * Convert DateTime dtypes into appropriate string representations\n    * Convert Nullable integers to objects and replace NaN with None\n    * Convert Nullable boolean to objects and replace NaN with None\n    * convert dedicated string column to objects and replace NaN with None\n    * Raise a ValueError for TimeDelta dtypes\n    \"\"\"\n    import pandas as pd\n    import numpy as np\n    df = df.copy()\n    if isinstance(df.columns, pd.RangeIndex):\n        df.columns = df.columns.astype(str)\n    for col_name in df.columns:\n        if not isinstance(col_name, str):\n            msg = (\n                f'Dataframe contains invalid column name: {col_name!r}. Column names must be strings'\n                )\n            raise ValueError(msg)\n    if isinstance(df.index, pd.MultiIndex):\n        msg = 'Hierarchical indices not supported'\n        raise ValueError(msg)\n    if isinstance(df.columns, pd.MultiIndex):\n        msg = 'Hierarchical indices not supported'\n        raise ValueError(msg)\n    def to_list_if_array(val):\n        if isinstance(val, np.ndarray):\n            return val.tolist()\n        else:\n            return val\n    for dtype_item in df.dtypes.items():\n        col_name = cast(str, dtype_item[0])\n        dtype = dtype_item[1]\n        dtype_name = str(dtype)\n        if dtype_name == 'category':\n            col = df[col_name].astype(object)\n            df[col_name] = col.where(col.notnull(), None)\n        elif dtype_name == 'string':\n            col = df[col_name].astype(object)\n            df[col_name] = col.where(col.notnull(), None)\n        elif dtype_name == 'bool':\n            df[col_name] = df[col_name].astype(object)\n        elif dtype_name == 'boolean':\n            col = df[col_name].astype(object)\n            df[col_name] = col.where(col.notnull(), None)\n        elif dtype_name.startswith(('datetime', 'timestamp')):\n            df[col_name] = df[col_name].apply(lambda x: x.isoformat()).replace(\n                'NaT', '')\n        elif dtype_name.startswith('timedelta'):\n            msg = (\n                f'Field \"{col_name}\" has type \"{dtype}\" which is not supported by Altair. Please convert to either a timestamp or a numerical value.'\n                )\n            raise ValueError(msg)\n        elif dtype_name.startswith('geometry'):\n            continue\n        elif dtype_name in {'Int8', 'Int16', 'Int32', 'Int64', 'UInt8',\n            'UInt16', 'UInt32', 'UInt64', 'Float32', 'Float64'}:\n            col = df[col_name].astype(object)\n            df[col_name] = col.where(col.notnull(), None)\n        elif numpy_is_subtype(dtype, np.integer):\n            df[col_name] = df[col_name].astype(object)\n        elif numpy_is_subtype(dtype, np.floating):\n            col = df[col_name]\n            bad_values = col.isnull() | np.isinf(col)\n            df[col_name] = col.astype(object).where(~bad_values, None)\n        elif dtype == object:\n            col = df[col_name].astype(object).apply(to_list_if_array)\n            df[col_name] = col.where(col.notnull(), None)\n    return df"}
