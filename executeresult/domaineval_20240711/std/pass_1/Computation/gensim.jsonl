{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "strip_short", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef strip_short(s, minsize=3): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef strip_short(s, minsize=3):\n    \"\"\"Remove words with length lesser than `minsize` from `s`.\n\n    Parameters\n    ----------\n    s : str\n    minsize : int, optional\n\n    Returns\n    -------\n    str\n        Unicode string without short words.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import strip_short\n        >>> strip_short(\"salut les amis du 59\")\n        u'salut les amis'\n        >>>\n        >>> strip_short(\"one two three four five six seven eight nine ten\", minsize=5)\n        u'three seven eight'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return ' '.join(remove_short_tokens(s.split(), minsize))"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "strip_multiple_whitespaces", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef strip_multiple_whitespaces(s): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef strip_multiple_whitespaces(s):\n    \"\"\"Remove repeating whitespace characters (spaces, tabs, line breaks) from `s`\n    and turns tabs & line breaks into spaces using :const:`~gensim.parsing.preprocessing.RE_WHITESPACE`.\n\n    Parameters\n    ----------\n    s : str\n\n    Returns\n    -------\n    str\n        Unicode string without repeating in a row whitespace characters.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import strip_multiple_whitespaces\n        >>> strip_multiple_whitespaces(\"salut\" + '\\\\r' + \" les\" + '\\\\n' + \"         loulous!\")\n        u'salut les loulous!'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return RE_WHITESPACE.sub(' ', s)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "remove_stopword_tokens", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef remove_stopword_tokens(tokens, stopwords=None): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef remove_stopword_tokens(tokens, stopwords=None):\n    \"\"\"Remove stopword tokens using list `stopwords`.\n\n    Parameters\n    ----------\n    tokens : iterable of str\n        Sequence of tokens.\n    stopwords : iterable of str, optional\n        Sequence of stopwords\n        If None - using :const:`~gensim.parsing.preprocessing.STOPWORDS`\n\n    Returns\n    -------\n    list of str\n        List of tokens without `stopwords`.\n\n    \"\"\"\n    if stopwords is None:\n        stopwords = STOPWORDS\n    return [token for token in tokens if token not in stopwords]"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "split_alphanum", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef split_alphanum(s): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef split_alphanum(s):\n    \"\"\"Add spaces between digits & letters in `s` using :const:`~gensim.parsing.preprocessing.RE_AL_NUM`.\n\n    Parameters\n    ----------\n    s : str\n\n    Returns\n    -------\n    str\n        Unicode string with spaces between digits & letters.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import split_alphanum\n        >>> split_alphanum(\"24.0hours7 days365 a1b2c3\")\n        u'24.0 hours 7 days 365 a 1 b 2 c 3'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    s = RE_AL_NUM.sub('\\\\1 \\\\2', s)\n    return RE_NUM_AL.sub('\\\\1 \\\\2', s)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "remove_stopwords", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef remove_stopwords(s, stopwords=None): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef remove_stopwords(s, stopwords=None):\n    \"\"\"Remove :const:`~gensim.parsing.preprocessing.STOPWORDS` from `s`.\n\n    Parameters\n    ----------\n    s : str\n    stopwords : iterable of str, optional\n        Sequence of stopwords\n        If None - using :const:`~gensim.parsing.preprocessing.STOPWORDS`\n\n    Returns\n    -------\n    str\n        Unicode string without `stopwords`.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import remove_stopwords\n        >>> remove_stopwords(\"Better late than never, but better never late.\")\n        u'Better late never, better late.'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return ' '.join(remove_stopword_tokens(s.split(), stopwords))"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "any2utf8", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef any2utf8(text, errors='strict', encoding='utf8'): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef any2utf8(text, errors='strict', encoding='utf8'):\n    \"\"\"Convert a unicode or bytes string in the given encoding into a utf8 bytestring.\n\n    Parameters\n    ----------\n    text : str\n        Input text.\n    errors : str, optional\n        Error handling behaviour if `text` is a bytestring.\n    encoding : str, optional\n        Encoding of `text` if it is a bytestring.\n\n    Returns\n    -------\n    str\n        Bytestring in utf8.\n\n    \"\"\"\n    if isinstance(text, str):\n        return text.encode('utf8')\n    return str(text, encoding, errors=errors).encode('utf8')"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "strip_tags", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef strip_tags(s): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef strip_tags(s):\n    \"\"\"Remove tags from `s` using :const:`~gensim.parsing.preprocessing.RE_TAGS`.\n\n    Parameters\n    ----------\n    s : str\n\n    Returns\n    -------\n    str\n        Unicode string without tags.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import strip_tags\n        >>> strip_tags(\"<i>Hello</i> <b>World</b>!\")\n        u'Hello World!'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return RE_TAGS.sub('', s)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "strip_non_alphanum", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef strip_non_alphanum(s): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef strip_non_alphanum(s):\n    \"\"\"Remove non-alphabetic characters from `s` using :const:`~gensim.parsing.preprocessing.RE_NONALPHA`.\n\n    Parameters\n    ----------\n    s : str\n\n    Returns\n    -------\n    str\n        Unicode string with alphabetic characters only.\n\n    Notes\n    -----\n    Word characters - alphanumeric & underscore.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import strip_non_alphanum\n        >>> strip_non_alphanum(\"if-you#can%read$this&then@this#method^works\")\n        u'if you can read this then this method works'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return RE_NONALPHA.sub(' ', s)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "strip_numeric", "method_path": "../srcdata/Computation/gensim/gensim/parsing/preprocessing.py", "method_code_mask": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\n\n\ndef strip_numeric(s): [MASK]\n", "response": "import re\nimport string\nimport glob\nfrom gensim import utils\nfrom gensim.parsing.porter import PorterStemmer\ndef strip_numeric(s):\n    \"\"\"Remove digits from `s` using :const:`~gensim.parsing.preprocessing.RE_NUMERIC`.\n\n    Parameters\n    ----------\n    s : str\n\n    Returns\n    -------\n    str\n        Unicode  string without digits.\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.parsing.preprocessing import strip_numeric\n        >>> strip_numeric(\"0text24gensim365test\")\n        u'textgensimtest'\n\n    \"\"\"\n    s = utils.to_unicode(s)\n    return RE_NUMERIC.sub('', s)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "merge_counts", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef merge_counts(dict1, dict2): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef merge_counts(dict1, dict2):\n    \"\"\"Merge `dict1` of (word, freq1) and `dict2` of (word, freq2) into `dict1` of (word, freq1+freq2).\n    Parameters\n    ----------\n    dict1 : dict of (str, int)\n        First dictionary.\n    dict2 : dict of (str, int)\n        Second dictionary.\n    Returns\n    -------\n    result : dict\n        Merged dictionary with sum of frequencies as values.\n    \"\"\"\n    for word, freq in dict2.items():\n        if word in dict1:\n            dict1[word] += freq\n        else:\n            dict1[word] = freq\n    return dict1"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "sample_dict", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef sample_dict(d, n=10, use_random=True): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef sample_dict(d, n=10, use_random=True):\n    \"\"\"Selected `n` (possibly random) items from the dictionary `d`.\n\n    Parameters\n    ----------\n    d : dict\n        Input dictionary.\n    n : int, optional\n        Number of items to select.\n    use_random : bool, optional\n        Select items randomly (without replacement), instead of by the natural dict iteration order?\n\n    Returns\n    -------\n    list of (object, object)\n        Selected items from dictionary, as a list.\n\n    \"\"\"\n    selected_keys = random.sample(list(d), min(len(d), n)\n        ) if use_random else itertools.islice(d.keys(), n)\n    return [(key, d[key]) for key in selected_keys]"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "open_file", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\n@contextmanager\ndef open_file(input): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n@contextmanager\ndef open_file(input):\n    \"\"\"Provide \"with-like\" behaviour without closing the file object.\n\n    Parameters\n    ----------\n    input : str or file-like\n        Filename or file-like object.\n\n    Yields\n    -------\n    file\n        File-like object based on input (or input if this already file-like).\n\n    \"\"\"\n    mgr = file_or_filename(input)\n    exc = False\n    try:\n        yield mgr\n    except Exception:\n        exc = True\n        if not isinstance(input, str) or not mgr.__exit__(*sys.exc_info()):\n            raise\n    finally:\n        if not exc and isinstance(input, str):\n            mgr.__exit__(None, None, None)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "_nlargest", "method_path": "../srcdata/Computation/gensim/gensim/similarities/docsim.py", "method_code_mask": "import logging\nimport itertools\nimport os\nimport heapq\nimport warnings\nimport numpy\nimport scipy.sparse\nfrom gensim import interfaces\nfrom gensim import utils\nfrom gensim import matutils\nimport multiprocessing\nimport glob\n\n\ndef _nlargest(n, iterable): [MASK]\n", "response": "import logging\nimport itertools\nimport os\nimport heapq\nimport warnings\nimport numpy\nimport scipy.sparse\nfrom gensim import interfaces\nfrom gensim import utils\nfrom gensim import matutils\nimport multiprocessing\nimport glob\ndef _nlargest(n, iterable):\n    \"\"\"Helper for extracting n documents with maximum similarity.\n\n    Parameters\n    ----------\n    n : int\n        Number of elements to be extracted\n    iterable : iterable of list of (int, float)\n        Iterable containing documents with computed similarities\n\n    Returns\n    -------\n    :class:`list`\n        List with the n largest elements from the dataset defined by iterable.\n\n    Notes\n    -----\n    Elements are compared by the absolute value of similarity, because negative value of similarity\n    does not mean some form of dissimilarity.\n\n    \"\"\"\n    return heapq.nlargest(n, itertools.chain(*iterable), key=lambda item:\n        abs(item[1]))"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "sparse2full", "method_path": "../srcdata/Computation/gensim/gensim/matutils.py", "method_code_mask": "from __future__ import with_statement\nimport logging\nimport math\nfrom gensim import utils\nimport numpy as np\nimport scipy.sparse\nfrom scipy.stats import entropy\nfrom scipy.linalg import get_blas_funcs\nfrom scipy.linalg.lapack import get_lapack_funcs\nfrom scipy.special import psi\nfrom numpy import triu\nfrom scipy.linalg import triu\nfrom gensim._matutils import logsumexp\nfrom gensim._matutils import mean_absolute_difference\nfrom gensim._matutils import dirichlet_expectation\nfrom gensim.corpora._mmreader import MmReader\n\n\ndef sparse2full(doc, length): [MASK]\n", "response": "from __future__ import with_statement\nimport logging\nimport math\nfrom gensim import utils\nimport numpy as np\nimport scipy.sparse\nfrom scipy.stats import entropy\nfrom scipy.linalg import get_blas_funcs\nfrom scipy.linalg.lapack import get_lapack_funcs\nfrom scipy.special import psi\nfrom numpy import triu\nfrom scipy.linalg import triu\nfrom gensim._matutils import logsumexp\nfrom gensim._matutils import mean_absolute_difference\nfrom gensim._matutils import dirichlet_expectation\nfrom gensim.corpora._mmreader import MmReader\ndef sparse2full(doc, length):\n    \"\"\"Convert a document in Gensim bag-of-words format into a dense numpy array.\n\n    Parameters\n    ----------\n    doc : list of (int, number)\n        Document in BoW format.\n    length : int\n        Vector dimensionality. This cannot be inferred from the BoW, and you must supply it explicitly.\n        This is typically the vocabulary size or number of topics, depending on how you created `doc`.\n\n    Returns\n    -------\n    numpy.ndarray\n        Dense numpy vector for `doc`.\n\n    See Also\n    --------\n    :func:`~gensim.matutils.full2sparse`\n        Convert dense array to gensim bag-of-words format.\n\n    \"\"\"\n    result = np.zeros(length, dtype=np.float32)\n    doc = ((int(id_), float(val_)) for id_, val_ in doc)\n    doc = dict(doc)\n    result[list(doc)] = list(doc.values())\n    return result"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "get_random_state", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef get_random_state(seed): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef get_random_state(seed):\n    \"\"\"Generate :class:`numpy.random.RandomState` based on input seed.\n\n    Parameters\n    ----------\n    seed : {None, int, array_like}\n        Seed for random state.\n\n    Returns\n    -------\n    :class:`numpy.random.RandomState`\n        Random state.\n\n    Raises\n    ------\n    AttributeError\n        If seed is not {None, int, array_like}.\n\n    Notes\n    -----\n    Method originally from `maciejkula/glove-python <https://github.com/maciejkula/glove-python>`_\n    and written by `@joshloyal <https://github.com/joshloyal>`_.\n\n    \"\"\"\n    if seed is None or seed is np.random:\n        return np.random.mtrand._rand\n    if isinstance(seed, (numbers.Integral, np.integer)):\n        return np.random.RandomState(seed)\n    if isinstance(seed, np.random.RandomState):\n        return seed\n    raise ValueError(\n        '%r cannot be used to seed a np.random.RandomState instance' % seed)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "isbow", "method_path": "../srcdata/Computation/gensim/gensim/matutils.py", "method_code_mask": "from __future__ import with_statement\nimport logging\nimport math\nfrom gensim import utils\nimport numpy as np\nimport scipy.sparse\nfrom scipy.stats import entropy\nfrom scipy.linalg import get_blas_funcs\nfrom scipy.linalg.lapack import get_lapack_funcs\nfrom scipy.special import psi\nfrom numpy import triu\nfrom scipy.linalg import triu\nfrom gensim._matutils import logsumexp\nfrom gensim._matutils import mean_absolute_difference\nfrom gensim._matutils import dirichlet_expectation\nfrom gensim.corpora._mmreader import MmReader\n\n\ndef isbow(vec): [MASK]\n", "response": "from __future__ import with_statement\nimport logging\nimport math\nfrom gensim import utils\nimport numpy as np\nimport scipy.sparse\nfrom scipy.stats import entropy\nfrom scipy.linalg import get_blas_funcs\nfrom scipy.linalg.lapack import get_lapack_funcs\nfrom scipy.special import psi\nfrom numpy import triu\nfrom scipy.linalg import triu\nfrom gensim._matutils import logsumexp\nfrom gensim._matutils import mean_absolute_difference\nfrom gensim._matutils import dirichlet_expectation\nfrom gensim.corpora._mmreader import MmReader\ndef isbow(vec):\n    \"\"\"Checks if a vector is in the sparse Gensim bag-of-words format.\n\n    Parameters\n    ----------\n    vec : object\n        Object to check.\n\n    Returns\n    -------\n    bool\n        Is `vec` in BoW format.\n\n    \"\"\"\n    if scipy.sparse.issparse(vec):\n        vec = vec.todense().tolist()\n    try:\n        id_, val_ = vec[0]\n        int(id_), float(val_)\n    except IndexError:\n        return True\n    except (ValueError, TypeError):\n        return False\n    return True"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "load_native", "method_path": "../srcdata/Computation/gensim/gensim/test/test_fasttext.py", "method_code_mask": "from __future__ import division\nimport gzip\nimport io\nimport logging\nimport unittest\nimport os\nimport shutil\nimport subprocess\nimport struct\nimport sys\nimport numpy as np\nimport pytest\nfrom gensim import utils\nfrom gensim.models.word2vec import LineSentence\nfrom gensim.models.fasttext import FastText as FT_gensim\nfrom gensim.models.fasttext import FastTextKeyedVectors\nfrom gensim.models.fasttext import _unpack\nfrom gensim.models.keyedvectors import KeyedVectors\nfrom gensim.test.utils import datapath\nfrom gensim.test.utils import get_tmpfile\nfrom gensim.test.utils import temporary_file\nfrom gensim.test.utils import common_texts as sentences\nfrom gensim.test.utils import lee_corpus_list as list_corpus\nimport gensim.models._fasttext_bin\nfrom gensim.models.fasttext_inner import compute_ngrams\nfrom gensim.models.fasttext_inner import compute_ngrams_bytes\nfrom gensim.models.fasttext_inner import ft_hash_bytes\nimport gensim.models.fasttext\n\n\ndef load_native(): [MASK]\n", "response": "from __future__ import division\nimport gzip\nimport io\nimport logging\nimport unittest\nimport os\nimport shutil\nimport subprocess\nimport struct\nimport sys\nimport numpy as np\nimport pytest\nfrom gensim import utils\nfrom gensim.models.word2vec import LineSentence\nfrom gensim.models.fasttext import FastText as FT_gensim\nfrom gensim.models.fasttext import FastTextKeyedVectors\nfrom gensim.models.fasttext import _unpack\nfrom gensim.models.keyedvectors import KeyedVectors\nfrom gensim.test.utils import datapath\nfrom gensim.test.utils import get_tmpfile\nfrom gensim.test.utils import temporary_file\nfrom gensim.test.utils import common_texts as sentences\nfrom gensim.test.utils import lee_corpus_list as list_corpus\nimport gensim.models._fasttext_bin\nfrom gensim.models.fasttext_inner import compute_ngrams\nfrom gensim.models.fasttext_inner import compute_ngrams_bytes\nfrom gensim.models.fasttext_inner import ft_hash_bytes\nimport gensim.models.fasttext\ndef load_native():\n    path = datapath('toy-model.bin')\n    model = gensim.models.fasttext.load_facebook_model(path)\n    return model"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "pseudorandom_weak_vector", "method_path": "../srcdata/Computation/gensim/gensim/models/keyedvectors.py", "method_code_mask": "import logging\nimport sys\nimport itertools\nimport warnings\nfrom numbers import Integral\nfrom typing import Iterable\nfrom numpy import dot\nfrom numpy import float32 as REAL\nfrom numpy import double\nfrom numpy import zeros\nfrom numpy import vstack\nfrom numpy import ndarray\nfrom numpy import sum as np_sum\nfrom numpy import prod\nfrom numpy import argmax\nfrom numpy import dtype\nfrom numpy import ascontiguousarray\nfrom numpy import frombuffer\nimport numpy as np\nfrom scipy import stats\nfrom scipy.spatial.distance import cdist\nfrom gensim import utils\nfrom gensim import matutils\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.utils import deprecated\n\n\ndef pseudorandom_weak_vector(size, seed_string=None, hashfxn=hash): [MASK]\n", "response": "import logging\nimport sys\nimport itertools\nimport warnings\nfrom numbers import Integral\nfrom typing import Iterable\nfrom numpy import dot\nfrom numpy import float32 as REAL\nfrom numpy import double\nfrom numpy import zeros\nfrom numpy import vstack\nfrom numpy import ndarray\nfrom numpy import sum as np_sum\nfrom numpy import prod\nfrom numpy import argmax\nfrom numpy import dtype\nfrom numpy import ascontiguousarray\nfrom numpy import frombuffer\nimport numpy as np\nfrom scipy import stats\nfrom scipy.spatial.distance import cdist\nfrom gensim import utils\nfrom gensim import matutils\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.utils import deprecated\ndef pseudorandom_weak_vector(size, seed_string=None, hashfxn=hash):\n    \"\"\"Get a random vector, derived deterministically from `seed_string` if supplied.\n\n    Useful for initializing KeyedVectors that will be the starting projection/input layers of _2Vec models.\n\n    \"\"\"\n    if seed_string:\n        once = np.random.Generator(np.random.SFC64(hashfxn(seed_string) & \n            4294967295))\n    else:\n        once = utils.default_prng\n    return (once.random(size).astype(REAL) - 0.5) / size"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "is_corpus", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef is_corpus(obj): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef is_corpus(obj):\n    \"\"\"Check whether `obj` is a corpus, by peeking at its first element. Works even on streamed generators.\n    The peeked element is put back into a object returned by this function, so always use\n    that returned object instead of the original `obj`.\n\n    Parameters\n    ----------\n    obj : object\n        An `iterable of iterable` that contains (int, numeric).\n\n    Returns\n    -------\n    (bool, object)\n        Pair of (is `obj` a corpus, `obj` with peeked element restored)\n\n    Examples\n    --------\n    .. sourcecode:: pycon\n\n        >>> from gensim.utils import is_corpus\n        >>> corpus = [[(1, 1.0)], [(2, -0.3), (3, 0.12)]]\n        >>> corpus_or_not, corpus = is_corpus(corpus)\n\n    Warnings\n    --------\n    An \"empty\" corpus (empty input sequence) is ambiguous, so in this case\n    the result is forcefully defined as (False, `obj`).\n\n    \"\"\"\n    try:\n        if 'Corpus' in obj.__class__.__name__:\n            return True, obj\n    except Exception:\n        pass\n    try:\n        if hasattr(obj, 'next') or hasattr(obj, '__next__'):\n            doc1 = next(obj)\n            obj = itertools.chain([doc1], obj)\n        else:\n            doc1 = next(iter(obj))\n        if len(doc1) == 0:\n            return True, obj\n        id1, val1 = next(iter(doc1))\n        id1, val1 = int(id1), float(val1)\n    except Exception:\n        return False, obj\n    return True, obj"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "any2unicode", "method_path": "../srcdata/Computation/gensim/gensim/utils.py", "method_code_mask": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\n\n\ndef any2unicode(text, encoding='utf8', errors='strict'): [MASK]\n", "response": "from contextlib import contextmanager\nimport collections.abc\nimport logging\nimport warnings\nimport numbers\nfrom html.entities import name2codepoint as n2cp\nimport pickle as _pickle\nimport re\nimport unicodedata\nimport os\nimport random\nimport itertools\nimport tempfile\nfrom functools import wraps\nimport multiprocessing\nimport shutil\nimport sys\nimport subprocess\nimport inspect\nimport heapq\nfrom copy import deepcopy\nfrom datetime import datetime\nimport platform\nimport types\nimport numpy as np\nimport scipy.sparse\nfrom smart_open import open\nfrom gensim import __version__ as gensim_version\nimport socket\ndef any2unicode(text, encoding='utf8', errors='strict'):\n    \"\"\"Convert `text` (bytestring in given encoding or unicode) to unicode.\n\n    Parameters\n    ----------\n    text : str\n        Input text.\n    errors : str, optional\n        Error handling behaviour if `text` is a bytestring.\n    encoding : str, optional\n        Encoding of `text` if it is a bytestring.\n\n    Returns\n    -------\n    str\n        Unicode version of `text`.\n\n    \"\"\"\n    if isinstance(text, str):\n        return text\n    return str(text, encoding, errors=errors)"}
{"result": "passed", "model_name": "std", "repository": "gensim", "full_method_name": "manual_unitvec", "method_path": "../srcdata/Computation/gensim/gensim/test/test_matutils.py", "method_code_mask": "import logging\nimport unittest\nimport numpy as np\nfrom numpy.testing import assert_array_equal\nfrom scipy import sparse\nfrom scipy.sparse import csc_matrix\nfrom scipy.special import psi\nimport gensim.matutils as matutils\n\n\ndef manual_unitvec(vec): [MASK]\n", "response": "import logging\nimport unittest\nimport numpy as np\nfrom numpy.testing import assert_array_equal\nfrom scipy import sparse\nfrom scipy.sparse import csc_matrix\nfrom scipy.special import psi\nimport gensim.matutils as matutils\ndef manual_unitvec(vec):\n    vec = vec.astype(float)\n    if sparse.issparse(vec):\n        vec_sum_of_squares = vec.multiply(vec)\n        unit = 1.0 / np.sqrt(vec_sum_of_squares.sum())\n        return vec.multiply(unit)\n    elif not sparse.issparse(vec):\n        sum_vec_squared = np.sum(vec ** 2)\n        vec /= np.sqrt(sum_vec_squared)\n        return vec"}
