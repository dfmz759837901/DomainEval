{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "slice_along_axes", "method_path": "../srcdata/Computation/scikit-image/skimage/util/_slice_along_axes.py", "method_code_mask": "def slice_along_axes(image, slices, axes=None, copy=False): [MASK]\n", "response": "\ndef slice_along_axes(image, slices, axes=None, copy=False):\n    \"\"\"Slice an image along given axes.\n\n    Parameters\n    ----------\n    image : ndarray\n        Input image.\n    slices : list of 2-tuple (a, b) where a < b.\n        For each axis in `axes`, a corresponding 2-tuple\n        ``(min_val, max_val)`` to slice with (as with Python slices,\n        ``max_val`` is non-inclusive).\n    axes : int or tuple, optional\n        Axes corresponding to the limits given in `slices`. If None,\n        axes are in ascending order, up to the length of `slices`.\n    copy : bool, optional\n        If True, ensure that the output is not a view of `image`.\n\n    Returns\n    -------\n    out : ndarray\n        The region of `image` corresponding to the given slices and axes.\n\n    Examples\n    --------\n    >>> from skimage import data\n    >>> img = data.camera()\n    >>> img.shape\n    (512, 512)\n    >>> cropped_img = slice_along_axes(img, [(0, 100)])\n    >>> cropped_img.shape\n    (100, 512)\n    >>> cropped_img = slice_along_axes(img, [(0, 100), (0, 100)])\n    >>> cropped_img.shape\n    (100, 100)\n    >>> cropped_img = slice_along_axes(img, [(0, 100), (0, 75)], axes=[1, 0])\n    >>> cropped_img.shape\n    (75, 100)\n    \"\"\"\n    if not slices:\n        return image\n    if axes is None:\n        axes = list(range(image.ndim))\n        if len(axes) < len(slices):\n            raise ValueError('More `slices` than available axes')\n    elif len(axes) != len(slices):\n        raise ValueError('`axes` and `slices` must have equal length')\n    if len(axes) != len(set(axes)):\n        raise ValueError('`axes` must be unique')\n    if not all(a >= 0 and a < image.ndim for a in axes):\n        raise ValueError(\n            f'axes {axes} out of range; image has only {image.ndim} dimensions'\n            )\n    _slices = [slice(None)] * image.ndim\n    for (a, b), ax in zip(slices, axes):\n        if a < 0:\n            a %= image.shape[ax]\n        if b < 0:\n            b %= image.shape[ax]\n        if a > b:\n            raise ValueError(\n                f'Invalid slice ({a}, {b}): must be ordered `(min_val, max_val)`'\n                )\n        if a < 0 or b > image.shape[ax]:\n            raise ValueError(\n                f'Invalid slice ({a}, {b}) for image with dimensions {image.shape}'\n                )\n        _slices[ax] = slice(a, b)\n    image_slice = image[tuple(_slices)]\n    if copy and image_slice.base is not None:\n        image_slice = image_slice.copy()\n    return image_slice"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "deltaE_cmc", "method_path": "../srcdata/Computation/scikit-image/skimage/color/delta_e.py", "method_code_mask": "import numpy as np\n\n\ndef deltaE_cmc(lab1, lab2, kL=1, kC=1, *, channel_axis=-1): [MASK]\n", "response": "import numpy as np\ndef deltaE_cmc(lab1, lab2, kL=1, kC=1, *, channel_axis=-1):\n    \"\"\"Color difference from the  CMC l:c standard.\n\n    This color difference was developed by the Colour Measurement Committee\n    (CMC) of the Society of Dyers and Colourists (United Kingdom). It is\n    intended for use in the textile industry.\n\n    The scale factors `kL`, `kC` set the weight given to differences in\n    lightness and chroma relative to differences in hue.  The usual values are\n    ``kL=2``, ``kC=1`` for \"acceptability\" and ``kL=1``, ``kC=1`` for\n    \"imperceptibility\".  Colors with ``dE > 1`` are \"different\" for the given\n    scale factors.\n\n    Parameters\n    ----------\n    lab1 : array_like\n        reference color (Lab colorspace)\n    lab2 : array_like\n        comparison color (Lab colorspace)\n    channel_axis : int, optional\n        This parameter indicates which axis of the arrays corresponds to\n        channels.\n\n        .. versionadded:: 0.19\n           ``channel_axis`` was added in 0.19.\n\n    Returns\n    -------\n    dE : array_like\n        distance between colors `lab1` and `lab2`\n\n    Notes\n    -----\n    deltaE_cmc the defines the scales for the lightness, hue, and chroma\n    in terms of the first color.  Consequently\n    ``deltaE_cmc(lab1, lab2) != deltaE_cmc(lab2, lab1)``\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Color_difference\n    .. [2] http://www.brucelindbloom.com/index.html?Eqn_DeltaE_CIE94.html\n    .. [3] F. J. J. Clarke, R. McDonald, and B. Rigg, \"Modification to the\n           JPC79 colour-difference formula,\" J. Soc. Dyers Colour. 100, 128-132\n           (1984).\n    \"\"\"\n    lab1, lab2 = _float_inputs(lab1, lab2, allow_float32=True)\n    lab1 = np.moveaxis(lab1, source=channel_axis, destination=0)\n    lab2 = np.moveaxis(lab2, source=channel_axis, destination=0)\n    L1, C1, h1 = lab2lch(lab1, channel_axis=0)[:3]\n    L2, C2, h2 = lab2lch(lab2, channel_axis=0)[:3]\n    dC = C1 - C2\n    dL = L1 - L2\n    dH2 = get_dH2(lab1, lab2, channel_axis=0)\n    T = np.where(np.logical_and(np.rad2deg(h1) >= 164, np.rad2deg(h1) <= \n        345), 0.56 + 0.2 * np.abs(np.cos(h1 + np.deg2rad(168))), 0.36 + 0.4 *\n        np.abs(np.cos(h1 + np.deg2rad(35))))\n    c1_4 = C1 ** 4\n    F = np.sqrt(c1_4 / (c1_4 + 1900))\n    SL = np.where(L1 < 16, 0.511, 0.040975 * L1 / (1.0 + 0.01765 * L1))\n    SC = 0.638 + 0.0638 * C1 / (1.0 + 0.0131 * C1)\n    SH = SC * (F * T + 1 - F)\n    dE2 = (dL / (kL * SL)) ** 2\n    dE2 += (dC / (kC * SC)) ** 2\n    dE2 += dH2 / SH ** 2\n    return np.sqrt(np.maximum(dE2, 0))"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "h_minima", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/extrema.py", "method_code_mask": "import numpy as np\n\n\ndef h_minima(image, h, footprint=None): [MASK]\n", "response": "import numpy as np\ndef h_minima(image, h, footprint=None):\n    \"\"\"Determine all minima of the image with depth >= h.\n\n    The local minima are defined as connected sets of pixels with equal\n    gray level strictly smaller than the gray levels of all pixels in direct\n    neighborhood of the set.\n\n    A local minimum M of depth h is a local minimum for which\n    there is at least one path joining M with an equal or lower local minimum\n    on which the maximal value is f(M) + h (i.e. the values along the path\n    are not increasing by more than h with respect to the minimum's value)\n    and no path to an equal or lower local minimum for which the maximal\n    value is smaller.\n\n    The global minima of the image are also found by this function.\n\n    Parameters\n    ----------\n    image : ndarray\n        The input image for which the minima are to be calculated.\n    h : unsigned integer\n        The minimal depth of all extracted minima.\n    footprint : ndarray, optional\n        The neighborhood expressed as an n-D array of 1's and 0's.\n        Default is the ball of radius 1 according to the maximum norm\n        (i.e. a 3x3 square for 2D images, a 3x3x3 cube for 3D images, etc.)\n\n    Returns\n    -------\n    h_min : ndarray\n        The local minima of depth >= h and the global minima.\n        The resulting image is a binary image, where pixels belonging to\n        the determined minima take value 1, the others take value 0.\n\n    See Also\n    --------\n    skimage.morphology.h_maxima\n    skimage.morphology.local_maxima\n    skimage.morphology.local_minima\n\n    References\n    ----------\n    .. [1] Soille, P., \"Morphological Image Analysis: Principles and\n           Applications\" (Chapter 6), 2nd edition (2003), ISBN 3540429883.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.morphology import extrema\n\n    We create an image (quadratic function with a minimum in the center and\n    4 additional constant maxima.\n    The depth of the minima are: 1, 21, 41, 61, 81\n\n    >>> w = 10\n    >>> x, y = np.mgrid[0:w,0:w]\n    >>> f = 180 + 0.2*((x - w/2)**2 + (y-w/2)**2)\n    >>> f[2:4,2:4] = 160; f[2:4,7:9] = 140; f[7:9,2:4] = 120; f[7:9,7:9] = 100\n    >>> f = f.astype(int)\n\n    We can calculate all minima with a depth of at least 40:\n\n    >>> minima = extrema.h_minima(f, 40)\n\n    The resulting image will contain 3 local minima.\n    \"\"\"\n    if h > np.ptp(image):\n        return np.zeros(image.shape, dtype=np.uint8)\n    if np.issubdtype(type(h), np.floating) and np.issubdtype(image.dtype,\n        np.integer):\n        if h % 1 != 0:\n            warn(\n                'possible precision loss converting image to floating point. To silence this warning, ensure image and h have same data type.'\n                , stacklevel=2)\n            image = image.astype(float)\n        else:\n            h = image.dtype.type(h)\n    if h == 0:\n        raise ValueError('h = 0 is ambiguous, use local_minima() instead?')\n    if np.issubdtype(image.dtype, np.floating):\n        resolution = 2 * np.finfo(image.dtype).resolution * np.abs(image)\n        shifted_img = image + h + resolution\n    else:\n        shifted_img = _add_constant_clip(image, h)\n    rec_img = grayreconstruct.reconstruction(shifted_img, image, method=\n        'erosion', footprint=footprint)\n    residue_img = rec_img - image\n    return (residue_img >= h).astype(np.uint8)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "h_maxima", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/extrema.py", "method_code_mask": "import numpy as np\n\n\ndef h_maxima(image, h, footprint=None): [MASK]\n", "response": "import numpy as np\ndef h_maxima(image, h, footprint=None):\n    \"\"\"Determine all maxima of the image with height >= h.\n\n    The local maxima are defined as connected sets of pixels with equal\n    gray level strictly greater than the gray level of all pixels in direct\n    neighborhood of the set.\n\n    A local maximum M of height h is a local maximum for which\n    there is at least one path joining M with an equal or higher local maximum\n    on which the minimal value is f(M) - h (i.e. the values along the path\n    are not decreasing by more than h with respect to the maximum's value)\n    and no path to an equal or higher local maximum for which the minimal\n    value is greater.\n\n    The global maxima of the image are also found by this function.\n\n    Parameters\n    ----------\n    image : ndarray\n        The input image for which the maxima are to be calculated.\n    h : unsigned integer\n        The minimal height of all extracted maxima.\n    footprint : ndarray, optional\n        The neighborhood expressed as an n-D array of 1's and 0's.\n        Default is the ball of radius 1 according to the maximum norm\n        (i.e. a 3x3 square for 2D images, a 3x3x3 cube for 3D images, etc.)\n\n    Returns\n    -------\n    h_max : ndarray\n        The local maxima of height >= h and the global maxima.\n        The resulting image is a binary image, where pixels belonging to\n        the determined maxima take value 1, the others take value 0.\n\n    See Also\n    --------\n    skimage.morphology.h_minima\n    skimage.morphology.local_maxima\n    skimage.morphology.local_minima\n\n    References\n    ----------\n    .. [1] Soille, P., \"Morphological Image Analysis: Principles and\n           Applications\" (Chapter 6), 2nd edition (2003), ISBN 3540429883.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.morphology import extrema\n\n    We create an image (quadratic function with a maximum in the center and\n    4 additional constant maxima.\n    The heights of the maxima are: 1, 21, 41, 61, 81\n\n    >>> w = 10\n    >>> x, y = np.mgrid[0:w,0:w]\n    >>> f = 20 - 0.2*((x - w/2)**2 + (y-w/2)**2)\n    >>> f[2:4,2:4] = 40; f[2:4,7:9] = 60; f[7:9,2:4] = 80; f[7:9,7:9] = 100\n    >>> f = f.astype(int)\n\n    We can calculate all maxima with a height of at least 40:\n\n    >>> maxima = extrema.h_maxima(f, 40)\n\n    The resulting image will contain 3 local maxima.\n    \"\"\"\n    if h > np.ptp(image):\n        return np.zeros(image.shape, dtype=np.uint8)\n    if np.issubdtype(type(h), np.floating) and np.issubdtype(image.dtype,\n        np.integer):\n        if h % 1 != 0:\n            warn(\n                'possible precision loss converting image to floating point. To silence this warning, ensure image and h have same data type.'\n                , stacklevel=2)\n            image = image.astype(float)\n        else:\n            h = image.dtype.type(h)\n    if h == 0:\n        raise ValueError('h = 0 is ambiguous, use local_maxima() instead?')\n    if np.issubdtype(image.dtype, np.floating):\n        resolution = 2 * np.finfo(image.dtype).resolution * np.abs(image)\n        shifted_img = image - h - resolution\n    else:\n        shifted_img = _subtract_constant_clip(image, h)\n    rec_img = grayreconstruct.reconstruction(shifted_img, image, method=\n        'dilation', footprint=footprint)\n    residue_img = image - rec_img\n    return (residue_img >= h).astype(np.uint8)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "local_maxima", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/extrema.py", "method_code_mask": "import numpy as np\n\n\ndef local_maxima(image, footprint=None, connectivity=None, indices=False,\n    allow_borders=True): [MASK]\n", "response": "import numpy as np\ndef local_maxima(image, footprint=None, connectivity=None, indices=False,\n    allow_borders=True):\n    \"\"\"Find local maxima of n-dimensional array.\n\n    The local maxima are defined as connected sets of pixels with equal gray\n    level (plateaus) strictly greater than the gray levels of all pixels in the\n    neighborhood.\n\n    Parameters\n    ----------\n    image : ndarray\n        An n-dimensional array.\n    footprint : ndarray, optional\n        The footprint (structuring element) used to determine the neighborhood\n        of each evaluated pixel (``True`` denotes a connected pixel). It must\n        be a boolean array and have the same number of dimensions as `image`.\n        If neither `footprint` nor `connectivity` are given, all adjacent\n        pixels are considered as part of the neighborhood.\n    connectivity : int, optional\n        A number used to determine the neighborhood of each evaluated pixel.\n        Adjacent pixels whose squared distance from the center is less than or\n        equal to `connectivity` are considered neighbors. Ignored if\n        `footprint` is not None.\n    indices : bool, optional\n        If True, the output will be a tuple of one-dimensional arrays\n        representing the indices of local maxima in each dimension. If False,\n        the output will be a boolean array with the same shape as `image`.\n    allow_borders : bool, optional\n        If true, plateaus that touch the image border are valid maxima.\n\n    Returns\n    -------\n    maxima : ndarray or tuple[ndarray]\n        If `indices` is false, a boolean array with the same shape as `image`\n        is returned with ``True`` indicating the position of local maxima\n        (``False`` otherwise). If `indices` is true, a tuple of one-dimensional\n        arrays containing the coordinates (indices) of all found maxima.\n\n    Warns\n    -----\n    UserWarning\n        If `allow_borders` is false and any dimension of the given `image` is\n        shorter than 3 samples, maxima can't exist and a warning is shown.\n\n    See Also\n    --------\n    skimage.morphology.local_minima\n    skimage.morphology.h_maxima\n    skimage.morphology.h_minima\n\n    Notes\n    -----\n    This function operates on the following ideas:\n\n    1. Make a first pass over the image's last dimension and flag candidates\n       for local maxima by comparing pixels in only one direction.\n       If the pixels aren't connected in the last dimension all pixels are\n       flagged as candidates instead.\n\n    For each candidate:\n\n    2. Perform a flood-fill to find all connected pixels that have the same\n       gray value and are part of the plateau.\n    3. Consider the connected neighborhood of a plateau: if no bordering sample\n       has a higher gray level, mark the plateau as a definite local maximum.\n\n    Examples\n    --------\n    >>> from skimage.morphology import local_maxima\n    >>> image = np.zeros((4, 7), dtype=int)\n    >>> image[1:3, 1:3] = 1\n    >>> image[3, 0] = 1\n    >>> image[1:3, 4:6] = 2\n    >>> image[3, 6] = 3\n    >>> image\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [1, 0, 0, 0, 0, 0, 3]])\n\n    Find local maxima by comparing to all neighboring pixels (maximal\n    connectivity):\n\n    >>> local_maxima(image)\n    array([[False, False, False, False, False, False, False],\n           [False,  True,  True, False, False, False, False],\n           [False,  True,  True, False, False, False, False],\n           [ True, False, False, False, False, False,  True]])\n    >>> local_maxima(image, indices=True)\n    (array([1, 1, 2, 2, 3, 3]), array([1, 2, 1, 2, 0, 6]))\n\n    Find local maxima without comparing to diagonal pixels (connectivity 1):\n\n    >>> local_maxima(image, connectivity=1)\n    array([[False, False, False, False, False, False, False],\n           [False,  True,  True, False,  True,  True, False],\n           [False,  True,  True, False,  True,  True, False],\n           [ True, False, False, False, False, False,  True]])\n\n    and exclude maxima that border the image edge:\n\n    >>> local_maxima(image, connectivity=1, allow_borders=False)\n    array([[False, False, False, False, False, False, False],\n           [False,  True,  True, False,  True,  True, False],\n           [False,  True,  True, False,  True,  True, False],\n           [False, False, False, False, False, False, False]])\n    \"\"\"\n    image = np.asarray(image, order='C')\n    if image.size == 0:\n        if indices:\n            return np.nonzero(image)\n        else:\n            return np.zeros(image.shape, dtype=bool)\n    if allow_borders:\n        image = np.pad(image, 1, mode='constant', constant_values=image.min())\n    flags = np.zeros(image.shape, dtype=np.uint8)\n    _util._set_border_values(flags, value=3)\n    if any(s < 3 for s in image.shape):\n        warn(\n            \"maxima can't exist for an image with any dimension smaller 3 if borders aren't allowed\"\n            , stacklevel=3)\n    else:\n        footprint = _util._resolve_neighborhood(footprint, connectivity,\n            image.ndim)\n        neighbor_offsets = _util._offsets_to_raveled_neighbors(image.shape,\n            footprint, center=(1,) * image.ndim)\n        try:\n            _local_maxima(image.ravel(), flags.ravel(), neighbor_offsets)\n        except TypeError:\n            if image.dtype == np.float16:\n                raise TypeError(\n                    'dtype of `image` is float16 which is not supported, try upcasting to float32'\n                    )\n            else:\n                raise\n    if allow_borders:\n        flags = crop(flags, 1)\n    else:\n        _util._set_border_values(flags, value=0)\n    if indices:\n        return np.nonzero(flags)\n    else:\n        return flags.view(bool)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "label_points", "method_path": "../srcdata/Computation/scikit-image/skimage/util/_label.py", "method_code_mask": "import numpy as np\n\n\ndef label_points(coords, output_shape): [MASK]\n", "response": "import numpy as np\ndef label_points(coords, output_shape):\n    \"\"\"Assign unique integer labels to coordinates on an image mask\n\n    Parameters\n    ----------\n    coords: ndarray\n        An array of N coordinates with dimension D\n    output_shape: tuple\n        The shape of the mask on which `coords` are labelled\n\n    Returns\n    -------\n    labels: ndarray\n        A mask of zeroes containing unique integer labels at the `coords`\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.util._label import label_points\n    >>> coords = np.array([[0, 1], [2, 2]])\n    >>> output_shape = (5, 5)\n    >>> mask = label_points(coords, output_shape)\n    >>> mask\n    array([[0, 1, 0, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 2, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0]], dtype=uint64)\n\n    Notes\n    -----\n    - The labels are assigned to coordinates that are converted to\n      integer and considered to start from 0.\n    - Coordinates that are out of range of the mask raise an IndexError.\n    - Negative coordinates raise a ValueError\n    \"\"\"\n    if coords.shape[1] != len(output_shape):\n        raise ValueError(\n            'Dimensionality of points should match the output shape')\n    if np.any(coords < 0):\n        raise ValueError('Coordinates should be positive and start from 0')\n    np_indices = tuple(np.transpose(np.round(coords).astype(int, copy=False)))\n    labels = np.zeros(output_shape, dtype=np.uint64)\n    labels[np_indices] = np.arange(1, coords.shape[0] + 1)\n    return labels"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "convex_hull_object", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/convex_hull.py", "method_code_mask": "from itertools import product\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\n\ndef convex_hull_object(image, *, connectivity=2): [MASK]\n", "response": "from itertools import product\nimport numpy as np\nfrom scipy.spatial import ConvexHull\ndef convex_hull_object(image, *, connectivity=2):\n    \"\"\"Compute the convex hull image of individual objects in a binary image.\n\n    The convex hull is the set of pixels included in the smallest convex\n    polygon that surround all white pixels in the input image.\n\n    Parameters\n    ----------\n    image : (M, N) ndarray\n        Binary input image.\n    connectivity : {1, 2}, int, optional\n        Determines the neighbors of each pixel. Adjacent elements\n        within a squared distance of ``connectivity`` from pixel center\n        are considered neighbors.::\n\n            1-connectivity      2-connectivity\n                  [ ]           [ ]  [ ]  [ ]\n                   |               \\\\  |  /\n             [ ]--[x]--[ ]      [ ]--[x]--[ ]\n                   |               /  |  \\\\\n                  [ ]           [ ]  [ ]  [ ]\n\n    Returns\n    -------\n    hull : ndarray of bool\n        Binary image with pixels inside convex hull set to ``True``.\n\n    Notes\n    -----\n    This function uses ``skimage.morphology.label`` to define unique objects,\n    finds the convex hull of each using ``convex_hull_image``, and combines\n    these regions with logical OR. Be aware the convex hulls of unconnected\n    objects may overlap in the result. If this is suspected, consider using\n    convex_hull_image separately on each object or adjust ``connectivity``.\n    \"\"\"\n    if image.ndim > 2:\n        raise ValueError('Input must be a 2D image')\n    if connectivity not in (1, 2):\n        raise ValueError('`connectivity` must be either 1 or 2.')\n    labeled_im = label(image, connectivity=connectivity, background=0)\n    convex_obj = np.zeros(image.shape, dtype=bool)\n    convex_img = np.zeros(image.shape, dtype=bool)\n    for i in range(1, labeled_im.max() + 1):\n        convex_obj = convex_hull_image(labeled_im == i)\n        convex_img = np.logical_or(convex_img, convex_obj)\n    return convex_img"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "unique_rows", "method_path": "../srcdata/Computation/scikit-image/skimage/util/unique.py", "method_code_mask": "import numpy as np\n\n\ndef unique_rows(ar): [MASK]\n", "response": "import numpy as np\ndef unique_rows(ar):\n    \"\"\"Remove repeated rows from a 2D array.\n\n    In particular, if given an array of coordinates of shape\n    (Npoints, Ndim), it will remove repeated points.\n\n    Parameters\n    ----------\n    ar : ndarray, shape (M, N)\n        The input array.\n\n    Returns\n    -------\n    ar_out : ndarray, shape (P, N)\n        A copy of the input array with repeated rows removed.\n\n    Raises\n    ------\n    ValueError : if `ar` is not two-dimensional.\n\n    Notes\n    -----\n    The function will generate a copy of `ar` if it is not\n    C-contiguous, which will negatively affect performance for large\n    input arrays.\n\n    Examples\n    --------\n    >>> ar = np.array([[1, 0, 1],\n    ...                [0, 1, 0],\n    ...                [1, 0, 1]], np.uint8)\n    >>> unique_rows(ar)\n    array([[0, 1, 0],\n           [1, 0, 1]], dtype=uint8)\n    \"\"\"\n    if ar.ndim != 2:\n        raise ValueError(\n            f'unique_rows() only makes sense for 2D arrays, got {ar.ndim}')\n    ar = np.ascontiguousarray(ar)\n    ar_row_view = ar.view(f'|S{ar.itemsize * ar.shape[1]}')\n    _, unique_row_indices = np.unique(ar_row_view, return_index=True)\n    ar_out = ar[unique_row_indices]\n    return ar_out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "rectangle", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/footprints.py", "method_code_mask": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\n\n\ndef rectangle(nrows, ncols, dtype=np.uint8, *, decomposition=None): [MASK]\n", "response": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\ndef rectangle(nrows, ncols, dtype=np.uint8, *, decomposition=None):\n    \"\"\"Generates a flat, rectangular-shaped footprint.\n\n    Every pixel in the rectangle generated for a given width and given height\n    belongs to the neighborhood.\n\n    Parameters\n    ----------\n    nrows : int\n        The number of rows of the rectangle.\n    ncols : int\n        The number of columns of the rectangle.\n\n    Other Parameters\n    ----------------\n    dtype : data-type, optional\n        The data type of the footprint.\n    decomposition : {None, 'separable', 'sequence'}, optional\n        If None, a single array is returned. For 'sequence', a tuple of smaller\n        footprints is returned. Applying this series of smaller footprints will\n        given an identical result to a single, larger footprint, but often with\n        better computational performance. See Notes for more details.\n        With 'separable', this function uses separable 1D footprints for each\n        axis. Whether 'sequence' or 'separable' is computationally faster may\n        be architecture-dependent.\n\n    Returns\n    -------\n    footprint : ndarray or tuple\n        A footprint consisting only of ones, i.e. every pixel belongs to the\n        neighborhood. When `decomposition` is None, this is just a\n        numpy.ndarray. Otherwise, this will be a tuple whose length is equal to\n        the number of unique structuring elements to apply (see Notes for more\n        detail)\n\n    Notes\n    -----\n    When `decomposition` is not None, each element of the `footprint`\n    tuple is a 2-tuple of the form ``(ndarray, num_iter)`` that specifies a\n    footprint array and the number of iterations it is to be applied.\n\n    For binary morphology, using ``decomposition='sequence'``\n    was observed to give better performance, with the magnitude of the\n    performance increase rapidly increasing with footprint size. For grayscale\n    morphology with rectangular footprints, it is recommended to use\n    ``decomposition=None`` since the internal SciPy functions that are called\n    already have a fast implementation based on separable 1D sliding windows.\n\n    The `sequence` decomposition mode only supports odd valued `nrows` and\n    `ncols`. If either `nrows` or `ncols` is even, the sequence used will be\n    identical to ``decomposition='separable'``.\n\n    - The use of ``width`` and ``height`` has been deprecated in\n      version 0.18.0. Use ``nrows`` and ``ncols`` instead.\n    \"\"\"\n    if decomposition is None:\n        return np.ones((nrows, ncols), dtype=dtype)\n    even_rows = nrows % 2 == 0\n    even_cols = ncols % 2 == 0\n    if decomposition == 'separable' or even_rows or even_cols:\n        sequence = [(np.ones((nrows, 1), dtype=dtype), 1), (np.ones((1,\n            ncols), dtype=dtype), 1)]\n    elif decomposition == 'sequence':\n        sq_size = 3\n        sq_reps = _decompose_size(min(nrows, ncols), sq_size)\n        sequence = [(np.ones((3, 3), dtype=dtype), sq_reps)]\n        if nrows > ncols:\n            nextra = nrows - ncols\n            sequence.append((np.ones((nextra + 1, 1), dtype=dtype), 1))\n        elif ncols > nrows:\n            nextra = ncols - nrows\n            sequence.append((np.ones((1, nextra + 1), dtype=dtype), 1))\n    else:\n        raise ValueError(f'Unrecognized decomposition: {decomposition}')\n    return tuple(sequence)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "regular_grid", "method_path": "../srcdata/Computation/scikit-image/skimage/util/_regular_grid.py", "method_code_mask": "import numpy as np\n\n\ndef regular_grid(ar_shape, n_points): [MASK]\n", "response": "import numpy as np\ndef regular_grid(ar_shape, n_points):\n    \"\"\"Find `n_points` regularly spaced along `ar_shape`.\n\n    The returned points (as slices) should be as close to cubically-spaced as\n    possible. Essentially, the points are spaced by the Nth root of the input\n    array size, where N is the number of dimensions. However, if an array\n    dimension cannot fit a full step size, it is \"discarded\", and the\n    computation is done for only the remaining dimensions.\n\n    Parameters\n    ----------\n    ar_shape : array-like of ints\n        The shape of the space embedding the grid. ``len(ar_shape)`` is the\n        number of dimensions.\n    n_points : int\n        The (approximate) number of points to embed in the space.\n\n    Returns\n    -------\n    slices : tuple of slice objects\n        A slice along each dimension of `ar_shape`, such that the intersection\n        of all the slices give the coordinates of regularly spaced points.\n\n        .. versionchanged:: 0.14.1\n            In scikit-image 0.14.1 and 0.15, the return type was changed from a\n            list to a tuple to ensure `compatibility with Numpy 1.15`_ and\n            higher. If your code requires the returned result to be a list, you\n            may convert the output of this function to a list with:\n\n            >>> result = list(regular_grid(ar_shape=(3, 20, 40), n_points=8))\n\n            .. _compatibility with NumPy 1.15: https://github.com/numpy/numpy/blob/master/doc/release/1.15.0-notes.rst#deprecations\n\n    Examples\n    --------\n    >>> ar = np.zeros((20, 40))\n    >>> g = regular_grid(ar.shape, 8)\n    >>> g\n    (slice(5, None, 10), slice(5, None, 10))\n    >>> ar[g] = 1\n    >>> ar.sum()\n    8.0\n    >>> ar = np.zeros((20, 40))\n    >>> g = regular_grid(ar.shape, 32)\n    >>> g\n    (slice(2, None, 5), slice(2, None, 5))\n    >>> ar[g] = 1\n    >>> ar.sum()\n    32.0\n    >>> ar = np.zeros((3, 20, 40))\n    >>> g = regular_grid(ar.shape, 8)\n    >>> g\n    (slice(1, None, 3), slice(5, None, 10), slice(5, None, 10))\n    >>> ar[g] = 1\n    >>> ar.sum()\n    8.0\n    \"\"\"\n    ar_shape = np.asanyarray(ar_shape)\n    ndim = len(ar_shape)\n    unsort_dim_idxs = np.argsort(np.argsort(ar_shape))\n    sorted_dims = np.sort(ar_shape)\n    space_size = float(np.prod(ar_shape))\n    if space_size <= n_points:\n        return (slice(None),) * ndim\n    stepsizes = np.full(ndim, (space_size / n_points) ** (1.0 / ndim),\n        dtype='float64')\n    if (sorted_dims < stepsizes).any():\n        for dim in range(ndim):\n            stepsizes[dim] = sorted_dims[dim]\n            space_size = float(np.prod(sorted_dims[dim + 1:]))\n            stepsizes[dim + 1:] = (space_size / n_points) ** (1.0 / (ndim -\n                dim - 1))\n            if (sorted_dims >= stepsizes).all():\n                break\n    starts = (stepsizes // 2).astype(int)\n    stepsizes = np.round(stepsizes).astype(int)\n    slices = [slice(start, None, step) for start, step in zip(starts,\n        stepsizes)]\n    slices = tuple(slices[i] for i in unsort_dim_idxs)\n    return slices"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "view_as_blocks", "method_path": "../srcdata/Computation/scikit-image/skimage/util/shape.py", "method_code_mask": "import numbers\nimport numpy as np\nfrom numpy.lib.stride_tricks import as_strided\n\n\ndef view_as_blocks(arr_in, block_shape): [MASK]\n", "response": "import numbers\nimport numpy as np\nfrom numpy.lib.stride_tricks import as_strided\ndef view_as_blocks(arr_in, block_shape):\n    \"\"\"Block view of the input n-dimensional array (using re-striding).\n\n    Blocks are non-overlapping views of the input array.\n\n    Parameters\n    ----------\n    arr_in : ndarray, shape (M[, ...])\n        Input array.\n    block_shape : tuple\n        The shape of the block. Each dimension must divide evenly into the\n        corresponding dimensions of `arr_in`.\n\n    Returns\n    -------\n    arr_out : ndarray\n        Block view of the input array.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.util.shape import view_as_blocks\n    >>> A = np.arange(4*4).reshape(4,4)\n    >>> A\n    array([[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11],\n           [12, 13, 14, 15]])\n    >>> B = view_as_blocks(A, block_shape=(2, 2))\n    >>> B[0, 0]\n    array([[0, 1],\n           [4, 5]])\n    >>> B[0, 1]\n    array([[2, 3],\n           [6, 7]])\n    >>> B[1, 0, 1, 1]\n    13\n\n    >>> A = np.arange(4*4*6).reshape(4,4,6)\n    >>> A  # doctest: +NORMALIZE_WHITESPACE\n    array([[[ 0,  1,  2,  3,  4,  5],\n            [ 6,  7,  8,  9, 10, 11],\n            [12, 13, 14, 15, 16, 17],\n            [18, 19, 20, 21, 22, 23]],\n           [[24, 25, 26, 27, 28, 29],\n            [30, 31, 32, 33, 34, 35],\n            [36, 37, 38, 39, 40, 41],\n            [42, 43, 44, 45, 46, 47]],\n           [[48, 49, 50, 51, 52, 53],\n            [54, 55, 56, 57, 58, 59],\n            [60, 61, 62, 63, 64, 65],\n            [66, 67, 68, 69, 70, 71]],\n           [[72, 73, 74, 75, 76, 77],\n            [78, 79, 80, 81, 82, 83],\n            [84, 85, 86, 87, 88, 89],\n            [90, 91, 92, 93, 94, 95]]])\n    >>> B = view_as_blocks(A, block_shape=(1, 2, 2))\n    >>> B.shape\n    (4, 2, 3, 1, 2, 2)\n    >>> B[2:, 0, 2]  # doctest: +NORMALIZE_WHITESPACE\n    array([[[[52, 53],\n             [58, 59]]],\n           [[[76, 77],\n             [82, 83]]]])\n    \"\"\"\n    if not isinstance(block_shape, tuple):\n        raise TypeError('block needs to be a tuple')\n    block_shape = np.array(block_shape)\n    if (block_shape <= 0).any():\n        raise ValueError(\"'block_shape' elements must be strictly positive\")\n    if block_shape.size != arr_in.ndim:\n        raise ValueError(\n            \"'block_shape' must have the same length as 'arr_in.shape'\")\n    arr_shape = np.array(arr_in.shape)\n    if (arr_shape % block_shape).sum() != 0:\n        raise ValueError(\"'block_shape' is not compatible with 'arr_in'\")\n    new_shape = tuple(arr_shape // block_shape) + tuple(block_shape)\n    new_strides = tuple(arr_in.strides * block_shape) + arr_in.strides\n    arr_out = as_strided(arr_in, shape=new_shape, strides=new_strides)\n    return arr_out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "cube", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/footprints.py", "method_code_mask": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\n\n\ndef cube(width, dtype=np.uint8, *, decomposition=None): [MASK]\n", "response": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\ndef cube(width, dtype=np.uint8, *, decomposition=None):\n    \"\"\"Generates a cube-shaped footprint.\n\n    This is the 3D equivalent of a square.\n    Every pixel along the perimeter has a chessboard distance\n    no greater than radius (radius=floor(width/2)) pixels.\n\n    Parameters\n    ----------\n    width : int\n        The width, height and depth of the cube.\n\n    Other Parameters\n    ----------------\n    dtype : data-type, optional\n        The data type of the footprint.\n    decomposition : {None, 'separable', 'sequence'}, optional\n        If None, a single array is returned. For 'sequence', a tuple of smaller\n        footprints is returned. Applying this series of smaller footprints will\n        given an identical result to a single, larger footprint, but often with\n        better computational performance. See Notes for more details.\n\n    Returns\n    -------\n    footprint : ndarray or tuple\n        The footprint where elements of the neighborhood are 1 and 0 otherwise.\n        When `decomposition` is None, this is just a numpy.ndarray. Otherwise,\n        this will be a tuple whose length is equal to the number of unique\n        structuring elements to apply (see Notes for more detail)\n\n    Notes\n    -----\n    When `decomposition` is not None, each element of the `footprint`\n    tuple is a 2-tuple of the form ``(ndarray, num_iter)`` that specifies a\n    footprint array and the number of iterations it is to be applied.\n\n    For binary morphology, using ``decomposition='sequence'``\n    was observed to give better performance, with the magnitude of the\n    performance increase rapidly increasing with footprint size. For grayscale\n    morphology with square footprints, it is recommended to use\n    ``decomposition=None`` since the internal SciPy functions that are called\n    already have a fast implementation based on separable 1D sliding windows.\n\n    The 'sequence' decomposition mode only supports odd valued `width`. If\n    `width` is even, the sequence used will be identical to the 'separable'\n    mode.\n    \"\"\"\n    if decomposition is None:\n        return np.ones((width, width, width), dtype=dtype)\n    if decomposition == 'separable' or width % 2 == 0:\n        sequence = [(np.ones((width, 1, 1), dtype=dtype), 1), (np.ones((1,\n            width, 1), dtype=dtype), 1), (np.ones((1, 1, width), dtype=\n            dtype), 1)]\n    elif decomposition == 'sequence':\n        sequence = [(np.ones((3, 3, 3), dtype=dtype), _decompose_size(width,\n            3))]\n    else:\n        raise ValueError(f'Unrecognized decomposition: {decomposition}')\n    return tuple(sequence)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "diamond", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/footprints.py", "method_code_mask": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\n\n\ndef diamond(radius, dtype=np.uint8, *, decomposition=None): [MASK]\n", "response": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\ndef diamond(radius, dtype=np.uint8, *, decomposition=None):\n    \"\"\"Generates a flat, diamond-shaped footprint.\n\n    A pixel is part of the neighborhood (i.e. labeled 1) if\n    the city block/Manhattan distance between it and the center of\n    the neighborhood is no greater than radius.\n\n    Parameters\n    ----------\n    radius : int\n        The radius of the diamond-shaped footprint.\n\n    Other Parameters\n    ----------------\n    dtype : data-type, optional\n        The data type of the footprint.\n    decomposition : {None, 'sequence'}, optional\n        If None, a single array is returned. For 'sequence', a tuple of smaller\n        footprints is returned. Applying this series of smaller footprints will\n        given an identical result to a single, larger footprint, but with\n        better computational performance. See Notes for more details.\n\n    Returns\n    -------\n    footprint : ndarray or tuple\n        The footprint where elements of the neighborhood are 1 and 0 otherwise.\n        When `decomposition` is None, this is just a numpy.ndarray. Otherwise,\n        this will be a tuple whose length is equal to the number of unique\n        structuring elements to apply (see Notes for more detail)\n\n    Notes\n    -----\n    When `decomposition` is not None, each element of the `footprint`\n    tuple is a 2-tuple of the form ``(ndarray, num_iter)`` that specifies a\n    footprint array and the number of iterations it is to be applied.\n\n    For either binary or grayscale morphology, using\n    ``decomposition='sequence'`` was observed to have a performance benefit,\n    with the magnitude of the benefit increasing with increasing footprint\n    size.\n\n    \"\"\"\n    if decomposition is None:\n        L = np.arange(0, radius * 2 + 1)\n        I, J = np.meshgrid(L, L)\n        footprint = np.array(np.abs(I - radius) + np.abs(J - radius) <=\n            radius, dtype=dtype)\n    elif decomposition == 'sequence':\n        fp = diamond(1, dtype=dtype, decomposition=None)\n        nreps = _decompose_size(2 * radius + 1, fp.shape[0])\n        footprint = (fp, nreps),\n    else:\n        raise ValueError(f'Unrecognized decomposition: {decomposition}')\n    return footprint"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "dtype_limits", "method_path": "../srcdata/Computation/scikit-image/skimage/util/dtype.py", "method_code_mask": "import warnings\nfrom warnings import warn\nimport numpy as np\n\n\ndef dtype_limits(image, clip_negative=False): [MASK]\n", "response": "import warnings\nfrom warnings import warn\nimport numpy as np\ndef dtype_limits(image, clip_negative=False):\n    \"\"\"Return intensity limits, i.e. (min, max) tuple, of the image's dtype.\n\n    Parameters\n    ----------\n    image : ndarray\n        Input image.\n    clip_negative : bool, optional\n        If True, clip the negative range (i.e. return 0 for min intensity)\n        even if the image dtype allows negative values.\n\n    Returns\n    -------\n    imin, imax : tuple\n        Lower and upper intensity limits.\n    \"\"\"\n    imin, imax = dtype_range[image.dtype.type]\n    if clip_negative:\n        imin = 0\n    return imin, imax"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "view_as_windows", "method_path": "../srcdata/Computation/scikit-image/skimage/util/shape.py", "method_code_mask": "import numbers\nimport numpy as np\nfrom numpy.lib.stride_tricks import as_strided\n\n\ndef view_as_windows(arr_in, window_shape, step=1): [MASK]\n", "response": "import numbers\nimport numpy as np\nfrom numpy.lib.stride_tricks import as_strided\ndef view_as_windows(arr_in, window_shape, step=1):\n    \"\"\"Rolling window view of the input n-dimensional array.\n\n    Windows are overlapping views of the input array, with adjacent windows\n    shifted by a single row or column (or an index of a higher dimension).\n\n    Parameters\n    ----------\n    arr_in : ndarray, shape (M[, ...])\n        Input array.\n    window_shape : integer or tuple of length arr_in.ndim\n        Defines the shape of the elementary n-dimensional orthotope\n        (better know as hyperrectangle [1]_) of the rolling window view.\n        If an integer is given, the shape will be a hypercube of\n        sidelength given by its value.\n    step : integer or tuple of length arr_in.ndim\n        Indicates step size at which extraction shall be performed.\n        If integer is given, then the step is uniform in all dimensions.\n\n    Returns\n    -------\n    arr_out : ndarray\n        (rolling) window view of the input array.\n\n    Notes\n    -----\n    One should be very careful with rolling views when it comes to\n    memory usage.  Indeed, although a 'view' has the same memory\n    footprint as its base array, the actual array that emerges when this\n    'view' is used in a computation is generally a (much) larger array\n    than the original, especially for 2-dimensional arrays and above.\n\n    For example, let us consider a 3 dimensional array of size (100,\n    100, 100) of ``float64``. This array takes about 8*100**3 Bytes for\n    storage which is just 8 MB. If one decides to build a rolling view\n    on this array with a window of (3, 3, 3) the hypothetical size of\n    the rolling view (if one was to reshape the view for example) would\n    be 8*(100-3+1)**3*3**3 which is about 203 MB! The scaling becomes\n    even worse as the dimension of the input array becomes larger.\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Hyperrectangle\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.util.shape import view_as_windows\n    >>> A = np.arange(4*4).reshape(4,4)\n    >>> A\n    array([[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11],\n           [12, 13, 14, 15]])\n    >>> window_shape = (2, 2)\n    >>> B = view_as_windows(A, window_shape)\n    >>> B[0, 0]\n    array([[0, 1],\n           [4, 5]])\n    >>> B[0, 1]\n    array([[1, 2],\n           [5, 6]])\n\n    >>> A = np.arange(10)\n    >>> A\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> window_shape = (3,)\n    >>> B = view_as_windows(A, window_shape)\n    >>> B.shape\n    (8, 3)\n    >>> B\n    array([[0, 1, 2],\n           [1, 2, 3],\n           [2, 3, 4],\n           [3, 4, 5],\n           [4, 5, 6],\n           [5, 6, 7],\n           [6, 7, 8],\n           [7, 8, 9]])\n\n    >>> A = np.arange(5*4).reshape(5, 4)\n    >>> A\n    array([[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11],\n           [12, 13, 14, 15],\n           [16, 17, 18, 19]])\n    >>> window_shape = (4, 3)\n    >>> B = view_as_windows(A, window_shape)\n    >>> B.shape\n    (2, 2, 4, 3)\n    >>> B  # doctest: +NORMALIZE_WHITESPACE\n    array([[[[ 0,  1,  2],\n             [ 4,  5,  6],\n             [ 8,  9, 10],\n             [12, 13, 14]],\n            [[ 1,  2,  3],\n             [ 5,  6,  7],\n             [ 9, 10, 11],\n             [13, 14, 15]]],\n           [[[ 4,  5,  6],\n             [ 8,  9, 10],\n             [12, 13, 14],\n             [16, 17, 18]],\n            [[ 5,  6,  7],\n             [ 9, 10, 11],\n             [13, 14, 15],\n             [17, 18, 19]]]])\n    \"\"\"\n    if not isinstance(arr_in, np.ndarray):\n        raise TypeError('`arr_in` must be a numpy ndarray')\n    ndim = arr_in.ndim\n    if isinstance(window_shape, numbers.Number):\n        window_shape = (window_shape,) * ndim\n    if not len(window_shape) == ndim:\n        raise ValueError('`window_shape` is incompatible with `arr_in.shape`')\n    if isinstance(step, numbers.Number):\n        if step < 1:\n            raise ValueError('`step` must be >= 1')\n        step = (step,) * ndim\n    if len(step) != ndim:\n        raise ValueError('`step` is incompatible with `arr_in.shape`')\n    arr_shape = np.array(arr_in.shape)\n    window_shape = np.array(window_shape, dtype=arr_shape.dtype)\n    if (arr_shape - window_shape < 0).any():\n        raise ValueError('`window_shape` is too large')\n    if (window_shape - 1 < 0).any():\n        raise ValueError('`window_shape` is too small')\n    slices = tuple(slice(None, None, st) for st in step)\n    window_strides = np.array(arr_in.strides)\n    indexing_strides = arr_in[slices].strides\n    win_indices_shape = (np.array(arr_in.shape) - np.array(window_shape)\n        ) // np.array(step) + 1\n    new_shape = tuple(list(win_indices_shape) + list(window_shape))\n    strides = tuple(list(indexing_strides) + list(window_strides))\n    arr_out = as_strided(arr_in, shape=new_shape, strides=strides)\n    return arr_out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "isotropic_erosion", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/isotropic.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef isotropic_erosion(image, radius, out=None, spacing=None): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef isotropic_erosion(image, radius, out=None, spacing=None):\n    \"\"\"Return binary morphological erosion of an image.\n\n    This function returns the same result as :func:`skimage.morphology.binary_erosion`\n    but performs faster for large circular structuring elements.\n    This works by applying a threshold to the exact Euclidean distance map\n    of the image [1]_, [2]_.\n    The implementation is based on: func:`scipy.ndimage.distance_transform_edt`.\n\n    Parameters\n    ----------\n    image : ndarray\n        Binary input image.\n    radius : float\n        The radius by which regions should be eroded.\n    out : ndarray of bool, optional\n        The array to store the result of the morphology. If None,\n        a new array will be allocated.\n    spacing : float, or sequence of float, optional\n        Spacing of elements along each dimension.\n        If a sequence, must be of length equal to the input's dimension (number of axes).\n        If a single number, this value is used for all axes.\n        If not specified, a grid spacing of unity is implied.\n\n    Returns\n    -------\n    eroded : ndarray of bool\n        The result of the morphological erosion taking values in\n        ``[False, True]``.\n\n    References\n    ----------\n    .. [1] Cuisenaire, O. and Macq, B., \"Fast Euclidean morphological operators\n        using local distance transformation by propagation, and applications,\"\n        Image Processing And Its Applications, 1999. Seventh International\n        Conference on (Conf. Publ. No. 465), 1999, pp. 856-860 vol.2.\n        :DOI:`10.1049/cp:19990446`\n\n    .. [2] Ingemar Ragnemalm, Fast erosion and dilation by contour processing\n        and thresholding of distance maps, Pattern Recognition Letters,\n        Volume 13, Issue 3, 1992, Pages 161-166.\n        :DOI:`10.1016/0167-8655(92)90055-5`\n    \"\"\"\n    dist = ndi.distance_transform_edt(image, sampling=spacing)\n    return np.greater(dist, radius, out=out)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "remove_small_objects", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/misc.py", "method_code_mask": "import numpy as np\nimport functools\nfrom scipy import ndimage as ndi\nfrom scipy.spatial import cKDTree\n\n\ndef remove_small_objects(ar, min_size=64, connectivity=1, *, out=None): [MASK]\n", "response": "import numpy as np\nimport functools\nfrom scipy import ndimage as ndi\nfrom scipy.spatial import cKDTree\ndef remove_small_objects(ar, min_size=64, connectivity=1, *, out=None):\n    \"\"\"Remove objects smaller than the specified size.\n\n    Expects ar to be an array with labeled objects, and removes objects\n    smaller than min_size. If `ar` is bool, the image is first labeled.\n    This leads to potentially different behavior for bool and 0-and-1\n    arrays.\n\n    Parameters\n    ----------\n    ar : ndarray (arbitrary shape, int or bool type)\n        The array containing the objects of interest. If the array type is\n        int, the ints must be non-negative.\n    min_size : int, optional (default: 64)\n        The smallest allowable object size.\n    connectivity : int, {1, 2, ..., ar.ndim}, optional (default: 1)\n        The connectivity defining the neighborhood of a pixel. Used during\n        labelling if `ar` is bool.\n    out : ndarray\n        Array of the same shape as `ar`, into which the output is\n        placed. By default, a new array is created.\n\n    Raises\n    ------\n    TypeError\n        If the input array is of an invalid type, such as float or string.\n    ValueError\n        If the input array contains negative values.\n\n    Returns\n    -------\n    out : ndarray, same shape and type as input `ar`\n        The input array with small connected components removed.\n\n    See Also\n    --------\n    skimage.morphology.remove_objects_by_distance\n\n    Examples\n    --------\n    >>> from skimage import morphology\n    >>> a = np.array([[0, 0, 0, 1, 0],\n    ...               [1, 1, 1, 0, 0],\n    ...               [1, 1, 1, 0, 1]], bool)\n    >>> b = morphology.remove_small_objects(a, 6)\n    >>> b\n    array([[False, False, False, False, False],\n           [ True,  True,  True, False, False],\n           [ True,  True,  True, False, False]])\n    >>> c = morphology.remove_small_objects(a, 7, connectivity=2)\n    >>> c\n    array([[False, False, False,  True, False],\n           [ True,  True,  True, False, False],\n           [ True,  True,  True, False, False]])\n    >>> d = morphology.remove_small_objects(a, 6, out=a)\n    >>> d is a\n    True\n\n    \"\"\"\n    _check_dtype_supported(ar)\n    if out is None:\n        out = ar.copy()\n    else:\n        out[:] = ar\n    if min_size == 0:\n        return out\n    if out.dtype == bool:\n        footprint = ndi.generate_binary_structure(ar.ndim, connectivity)\n        ccs = np.zeros_like(ar, dtype=np.int32)\n        ndi.label(ar, footprint, output=ccs)\n    else:\n        ccs = out\n    try:\n        component_sizes = np.bincount(ccs.ravel())\n    except ValueError:\n        raise ValueError(\n            'Negative value labels are not supported. Try relabeling the input with `scipy.ndimage.label` or `skimage.morphology.label`.'\n            )\n    if len(component_sizes) == 2 and out.dtype != bool:\n        warn(\n            'Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?'\n            )\n    too_small = component_sizes < min_size\n    too_small_mask = too_small[ccs]\n    out[too_small_mask] = 0\n    return out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "thin", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_skeletonize.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef thin(image, max_num_iter=None): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef thin(image, max_num_iter=None):\n    \"\"\"\n    Perform morphological thinning of a binary image.\n\n    Parameters\n    ----------\n    image : binary (M, N) ndarray\n        The image to thin. If this input isn't already a binary image,\n        it gets converted into one: In this case, zero values are considered\n        background (False), nonzero values are considered foreground (True).\n    max_num_iter : int, number of iterations, optional\n        Regardless of the value of this parameter, the thinned image\n        is returned immediately if an iteration produces no change.\n        If this parameter is specified it thus sets an upper bound on\n        the number of iterations performed.\n\n    Returns\n    -------\n    out : ndarray of bool\n        Thinned image.\n\n    See Also\n    --------\n    skeletonize, medial_axis\n\n    Notes\n    -----\n    This algorithm [1]_ works by making multiple passes over the image,\n    removing pixels matching a set of criteria designed to thin\n    connected regions while preserving eight-connected components and\n    2 x 2 squares [2]_. In each of the two sub-iterations the algorithm\n    correlates the intermediate skeleton image with a neighborhood mask,\n    then looks up each neighborhood in a lookup table indicating whether\n    the central pixel should be deleted in that sub-iteration.\n\n    References\n    ----------\n    .. [1] Z. Guo and R. W. Hall, \"Parallel thinning with\n           two-subiteration algorithms,\" Comm. ACM, vol. 32, no. 3,\n           pp. 359-373, 1989. :DOI:`10.1145/62065.62074`\n    .. [2] Lam, L., Seong-Whan Lee, and Ching Y. Suen, \"Thinning\n           Methodologies-A Comprehensive Survey,\" IEEE Transactions on\n           Pattern Analysis and Machine Intelligence, Vol 14, No. 9,\n           p. 879, 1992. :DOI:`10.1109/34.161346`\n\n    Examples\n    --------\n    >>> square = np.zeros((7, 7), dtype=bool)\n    >>> square[1:-1, 2:-2] = 1\n    >>> square[0, 1] =  1\n    >>> square.view(np.uint8)\n    array([[0, 1, 0, 0, 0, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    >>> skel = thin(square)\n    >>> skel.view(np.uint8)\n    array([[0, 1, 0, 0, 0, 0, 0],\n           [0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    \"\"\"\n    check_nD(image, 2)\n    skel = np.asanyarray(image, dtype=bool).view(np.uint8)\n    mask = np.array([[8, 4, 2], [16, 0, 1], [32, 64, 128]], dtype=np.uint8)\n    max_num_iter = max_num_iter or np.inf\n    num_iter = 0\n    n_pts_old, n_pts_new = np.inf, np.sum(skel)\n    while n_pts_old != n_pts_new and num_iter < max_num_iter:\n        n_pts_old = n_pts_new\n        for lut in [G123_LUT, G123P_LUT]:\n            N = ndi.correlate(skel, mask, mode='constant')\n            D = np.take(lut, N)\n            skel[D] = 0\n        n_pts_new = np.sum(skel)\n        num_iter += 1\n    return skel.astype(bool)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_generate_thin_luts", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_skeletonize.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef _generate_thin_luts(): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef _generate_thin_luts():\n    \"\"\"generate LUTs for thinning algorithm (for reference)\"\"\"\n\n    def nabe(n):\n        return np.array([(n >> i & 1) for i in range(0, 9)]).astype(bool)\n\n    def G1(n):\n        s = 0\n        bits = nabe(n)\n        for i in (0, 2, 4, 6):\n            if not bits[i] and (bits[i + 1] or bits[(i + 2) % 8]):\n                s += 1\n        return s == 1\n    g1_lut = np.array([G1(n) for n in range(256)])\n\n    def G2(n):\n        n1, n2 = 0, 0\n        bits = nabe(n)\n        for k in (1, 3, 5, 7):\n            if bits[k] or bits[k - 1]:\n                n1 += 1\n            if bits[k] or bits[(k + 1) % 8]:\n                n2 += 1\n        return min(n1, n2) in [2, 3]\n    g2_lut = np.array([G2(n) for n in range(256)])\n    g12_lut = g1_lut & g2_lut\n\n    def G3(n):\n        bits = nabe(n)\n        return not ((bits[1] or bits[2] or not bits[7]) and bits[0])\n\n    def G3p(n):\n        bits = nabe(n)\n        return not ((bits[5] or bits[6] or not bits[3]) and bits[4])\n    g3_lut = np.array([G3(n) for n in range(256)])\n    g3p_lut = np.array([G3p(n) for n in range(256)])\n    g123_lut = g12_lut & g3_lut\n    g123p_lut = g12_lut & g3p_lut\n    return g123_lut, g123p_lut"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "remove_small_holes", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/misc.py", "method_code_mask": "import numpy as np\nimport functools\nfrom scipy import ndimage as ndi\nfrom scipy.spatial import cKDTree\n\n\ndef remove_small_holes(ar, area_threshold=64, connectivity=1, *, out=None): [M\n    ASK]\n", "response": "import numpy as np\nimport functools\nfrom scipy import ndimage as ndi\nfrom scipy.spatial import cKDTree\ndef remove_small_holes(ar, area_threshold=64, connectivity=1, *, out=None):\n    \"\"\"Remove contiguous holes smaller than the specified size.\n\n    Parameters\n    ----------\n    ar : ndarray (arbitrary shape, int or bool type)\n        The array containing the connected components of interest.\n    area_threshold : int, optional (default: 64)\n        The maximum area, in pixels, of a contiguous hole that will be filled.\n        Replaces `min_size`.\n    connectivity : int, {1, 2, ..., ar.ndim}, optional (default: 1)\n        The connectivity defining the neighborhood of a pixel.\n    out : ndarray\n        Array of the same shape as `ar` and bool dtype, into which the\n        output is placed. By default, a new array is created.\n\n    Raises\n    ------\n    TypeError\n        If the input array is of an invalid type, such as float or string.\n    ValueError\n        If the input array contains negative values.\n\n    Returns\n    -------\n    out : ndarray, same shape and type as input `ar`\n        The input array with small holes within connected components removed.\n\n    Examples\n    --------\n    >>> from skimage import morphology\n    >>> a = np.array([[1, 1, 1, 1, 1, 0],\n    ...               [1, 1, 1, 0, 1, 0],\n    ...               [1, 0, 0, 1, 1, 0],\n    ...               [1, 1, 1, 1, 1, 0]], bool)\n    >>> b = morphology.remove_small_holes(a, 2)\n    >>> b\n    array([[ True,  True,  True,  True,  True, False],\n           [ True,  True,  True,  True,  True, False],\n           [ True, False, False,  True,  True, False],\n           [ True,  True,  True,  True,  True, False]])\n    >>> c = morphology.remove_small_holes(a, 2, connectivity=2)\n    >>> c\n    array([[ True,  True,  True,  True,  True, False],\n           [ True,  True,  True, False,  True, False],\n           [ True, False, False,  True,  True, False],\n           [ True,  True,  True,  True,  True, False]])\n    >>> d = morphology.remove_small_holes(a, 2, out=a)\n    >>> d is a\n    True\n\n    Notes\n    -----\n    If the array type is int, it is assumed that it contains already-labeled\n    objects. The labels are not kept in the output image (this function always\n    outputs a bool image). It is suggested that labeling is completed after\n    using this function.\n\n    \"\"\"\n    _check_dtype_supported(ar)\n    if ar.dtype != bool:\n        warn(\n            'Any labeled images will be returned as a boolean array. Did you mean to use a boolean array?'\n            , UserWarning)\n    if out is not None:\n        if out.dtype != bool:\n            raise TypeError('out dtype must be bool')\n    else:\n        out = ar.astype(bool, copy=True)\n    np.logical_not(ar, out=out)\n    out = remove_small_objects(out, area_threshold, connectivity, out=out)\n    np.logical_not(out, out=out)\n    return out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "flood", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_flood_fill.py", "method_code_mask": "import numpy as np\n\n\ndef flood(image, seed_point, *, footprint=None, connectivity=None,\n    tolerance=None): [MASK]\n", "response": "import numpy as np\ndef flood(image, seed_point, *, footprint=None, connectivity=None,\n    tolerance=None):\n    \"\"\"Mask corresponding to a flood fill.\n\n    Starting at a specific `seed_point`, connected points equal or within\n    `tolerance` of the seed value are found.\n\n    Parameters\n    ----------\n    image : ndarray\n        An n-dimensional array.\n    seed_point : tuple or int\n        The point in `image` used as the starting point for the flood fill.  If\n        the image is 1D, this point may be given as an integer.\n    footprint : ndarray, optional\n        The footprint (structuring element) used to determine the neighborhood\n        of each evaluated pixel. It must contain only 1's and 0's, have the\n        same number of dimensions as `image`. If not given, all adjacent pixels\n        are considered as part of the neighborhood (fully connected).\n    connectivity : int, optional\n        A number used to determine the neighborhood of each evaluated pixel.\n        Adjacent pixels whose squared distance from the center is less than or\n        equal to `connectivity` are considered neighbors. Ignored if\n        `footprint` is not None.\n    tolerance : float or int, optional\n        If None (default), adjacent values must be strictly equal to the\n        initial value of `image` at `seed_point`.  This is fastest.  If a value\n        is given, a comparison will be done at every point and if within\n        tolerance of the initial value will also be filled (inclusive).\n\n    Returns\n    -------\n    mask : ndarray\n        A Boolean array with the same shape as `image` is returned, with True\n        values for areas connected to and equal (or within tolerance of) the\n        seed point.  All other values are False.\n\n    Notes\n    -----\n    The conceptual analogy of this operation is the 'paint bucket' tool in many\n    raster graphics programs.  This function returns just the mask\n    representing the fill.\n\n    If indices are desired rather than masks for memory reasons, the user can\n    simply run `numpy.nonzero` on the result, save the indices, and discard\n    this mask.\n\n    Examples\n    --------\n    >>> from skimage.morphology import flood\n    >>> image = np.zeros((4, 7), dtype=int)\n    >>> image[1:3, 1:3] = 1\n    >>> image[3, 0] = 1\n    >>> image[1:3, 4:6] = 2\n    >>> image[3, 6] = 3\n    >>> image\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [1, 0, 0, 0, 0, 0, 3]])\n\n    Fill connected ones with 5, with full connectivity (diagonals included):\n\n    >>> mask = flood(image, (1, 1))\n    >>> image_flooded = image.copy()\n    >>> image_flooded[mask] = 5\n    >>> image_flooded\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [5, 0, 0, 0, 0, 0, 3]])\n\n    Fill connected ones with 5, excluding diagonal points (connectivity 1):\n\n    >>> mask = flood(image, (1, 1), connectivity=1)\n    >>> image_flooded = image.copy()\n    >>> image_flooded[mask] = 5\n    >>> image_flooded\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [1, 0, 0, 0, 0, 0, 3]])\n\n    Fill with a tolerance:\n\n    >>> mask = flood(image, (0, 0), tolerance=1)\n    >>> image_flooded = image.copy()\n    >>> image_flooded[mask] = 5\n    >>> image_flooded\n    array([[5, 5, 5, 5, 5, 5, 5],\n           [5, 5, 5, 5, 2, 2, 5],\n           [5, 5, 5, 5, 2, 2, 5],\n           [5, 5, 5, 5, 5, 5, 3]])\n    \"\"\"\n    image = np.asarray(image)\n    if image.flags.f_contiguous is True:\n        order = 'F'\n    elif image.flags.c_contiguous is True:\n        order = 'C'\n    else:\n        image = np.ascontiguousarray(image)\n        order = 'C'\n    if 0 in image.shape:\n        return np.zeros(image.shape, dtype=bool)\n    try:\n        iter(seed_point)\n    except TypeError:\n        seed_point = seed_point,\n    seed_value = image[seed_point]\n    seed_point = tuple(np.asarray(seed_point) % image.shape)\n    footprint = _resolve_neighborhood(footprint, connectivity, image.ndim,\n        enforce_adjacency=False)\n    center = tuple(s // 2 for s in footprint.shape)\n    pad_width = [((np.max(np.abs(idx - c)),) * 2) for idx, c in zip(np.\n        nonzero(footprint), center)]\n    working_image = np.pad(image, pad_width, mode='constant',\n        constant_values=image.min())\n    ravelled_seed_idx = np.ravel_multi_index([(i + pad_start) for i, (\n        pad_start, pad_end) in zip(seed_point, pad_width)], working_image.\n        shape, order=order)\n    neighbor_offsets = _offsets_to_raveled_neighbors(working_image.shape,\n        footprint, center=center, order=order)\n    flags = np.zeros(working_image.shape, dtype=np.uint8, order=order)\n    _set_border_values(flags, value=2, border_width=pad_width)\n    try:\n        if tolerance is not None:\n            tolerance = abs(tolerance)\n            min_value, max_value = numeric_dtype_min_max(seed_value.dtype)\n            low_tol = max(min_value.item(), seed_value.item() - tolerance)\n            high_tol = min(max_value.item(), seed_value.item() + tolerance)\n            _flood_fill_tolerance(working_image.ravel(order), flags.ravel(\n                order), neighbor_offsets, ravelled_seed_idx, seed_value,\n                low_tol, high_tol)\n        else:\n            _flood_fill_equal(working_image.ravel(order), flags.ravel(order\n                ), neighbor_offsets, ravelled_seed_idx, seed_value)\n    except TypeError:\n        if working_image.dtype == np.float16:\n            raise TypeError(\n                'dtype of `image` is float16 which is not supported, try upcasting to float32'\n                )\n        else:\n            raise\n    return crop(flags, pad_width, copy=False).view(bool)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "learn_gmm", "method_path": "../srcdata/Computation/scikit-image/skimage/feature/_fisher_vector.py", "method_code_mask": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\n\n\ndef learn_gmm(descriptors, *, n_modes=32, gm_args=None): [MASK]\n", "response": "import numpy as np\nfrom sklearn.mixture import GaussianMixture\ndef learn_gmm(descriptors, *, n_modes=32, gm_args=None):\n    \"\"\"Estimate a Gaussian mixture model (GMM) given a set of descriptors and\n    number of modes (i.e. Gaussians). This function is essentially a wrapper\n    around the scikit-learn implementation of GMM, namely the\n    :class:`sklearn.mixture.GaussianMixture` class.\n\n    Due to the nature of the Fisher vector, the only enforced parameter of the\n    underlying scikit-learn class is the covariance_type, which must be 'diag'.\n\n    There is no simple way to know what value to use for `n_modes` a-priori.\n    Typically, the value is usually one of ``{16, 32, 64, 128}``. One may train\n    a few GMMs and choose the one that maximises the log probability of the\n    GMM, or choose `n_modes` such that the downstream classifier trained on\n    the resultant Fisher vectors has maximal performance.\n\n    Parameters\n    ----------\n    descriptors : np.ndarray (N, M) or list [(N1, M), (N2, M), ...]\n        List of NumPy arrays, or a single NumPy array, of the descriptors\n        used to estimate the GMM. The reason a list of NumPy arrays is\n        permissible is because often when using a Fisher vector encoding,\n        descriptors/vectors are computed separately for each sample/image in\n        the dataset, such as SIFT vectors for each image. If a list if passed\n        in, then each element must be a NumPy array in which the number of\n        rows may differ (e.g. different number of SIFT vector for each image),\n        but the number of columns for each must be the same (i.e. the\n        dimensionality must be the same).\n    n_modes : int\n        The number of modes/Gaussians to estimate during the GMM estimate.\n    gm_args : dict\n        Keyword arguments that can be passed into the underlying scikit-learn\n        :class:`sklearn.mixture.GaussianMixture` class.\n\n    Returns\n    -------\n    gmm : :class:`sklearn.mixture.GaussianMixture`\n        The estimated GMM object, which contains the necessary parameters\n        needed to compute the Fisher vector.\n\n    References\n    ----------\n    .. [1] https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n\n    Examples\n    --------\n    .. testsetup::\n        >>> import pytest; _ = pytest.importorskip('sklearn')\n\n    >>> from skimage.feature import fisher_vector\n    >>> rng = np.random.Generator(np.random.PCG64())\n    >>> sift_for_images = [rng.standard_normal((10, 128)) for _ in range(10)]\n    >>> num_modes = 16\n    >>> # Estimate 16-mode GMM with these synthetic SIFT vectors\n    >>> gmm = learn_gmm(sift_for_images, n_modes=num_modes)\n    \"\"\"\n    try:\n        from sklearn.mixture import GaussianMixture\n    except ImportError:\n        raise ImportError(\n            'scikit-learn is not installed. Please ensure it is installed in order to use the Fisher vector functionality.'\n            )\n    if not isinstance(descriptors, (list, np.ndarray)):\n        raise DescriptorException(\n            'Please ensure descriptors are either a NumPy array, or a list of NumPy arrays.'\n            )\n    d_mat_1 = descriptors[0]\n    if isinstance(descriptors, list) and not isinstance(d_mat_1, np.ndarray):\n        raise DescriptorException(\n            'Please ensure descriptors are a list of NumPy arrays.')\n    if isinstance(descriptors, list):\n        expected_shape = descriptors[0].shape\n        ranks = [(len(e.shape) == len(expected_shape)) for e in descriptors]\n        if not all(ranks):\n            raise DescriptorException(\n                'Please ensure all elements of your descriptor list are of rank 2.'\n                )\n        dims = [(e.shape[1] == descriptors[0].shape[1]) for e in descriptors]\n        if not all(dims):\n            raise DescriptorException(\n                'Please ensure all descriptors are of the same dimensionality.'\n                )\n    if not isinstance(n_modes, int) or n_modes <= 0:\n        raise FisherVectorException(\n            'Please ensure n_modes is a positive integer.')\n    if gm_args:\n        has_cov_type = 'covariance_type' in gm_args\n        cov_type_not_diag = gm_args['covariance_type'] != 'diag'\n        if has_cov_type and cov_type_not_diag:\n            raise FisherVectorException('Covariance type must be \"diag\".')\n    if isinstance(descriptors, list):\n        descriptors = np.vstack(descriptors)\n    if gm_args:\n        has_cov_type = 'covariance_type' in gm_args\n        if has_cov_type:\n            gmm = GaussianMixture(n_components=n_modes, **gm_args)\n        else:\n            gmm = GaussianMixture(n_components=n_modes, covariance_type=\n                'diag', **gm_args)\n    else:\n        gmm = GaussianMixture(n_components=n_modes, covariance_type='diag')\n    gmm.fit(descriptors)\n    return gmm"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "max_tree_local_maxima", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/max_tree.py", "method_code_mask": "import numpy as np\n\n\ndef max_tree_local_maxima(image, connectivity=1, parent=None,\n    tree_traverser=None): [MASK]\n", "response": "import numpy as np\ndef max_tree_local_maxima(image, connectivity=1, parent=None,\n    tree_traverser=None):\n    \"\"\"Determine all local maxima of the image.\n\n    The local maxima are defined as connected sets of pixels with equal\n    gray level strictly greater than the gray levels of all pixels in direct\n    neighborhood of the set. The function labels the local maxima.\n\n    Technically, the implementation is based on the max-tree representation\n    of an image. The function is very efficient if the max-tree representation\n    has already been computed. Otherwise, it is preferable to use\n    the function local_maxima.\n\n    Parameters\n    ----------\n    image : ndarray\n        The input image for which the maxima are to be calculated.\n    connectivity : unsigned int, optional\n        The neighborhood connectivity. The integer represents the maximum\n        number of orthogonal steps to reach a neighbor. In 2D, it is 1 for\n        a 4-neighborhood and 2 for a 8-neighborhood. Default value is 1.\n    parent : ndarray, int64, optional\n        The value of each pixel is the index of its parent in the ravelled\n        array.\n    tree_traverser : 1D array, int64, optional\n        The ordered pixel indices (referring to the ravelled array). The pixels\n        are ordered such that every pixel is preceded by its parent (except for\n        the root which has no parent).\n\n    Returns\n    -------\n    local_max : ndarray, uint64\n        Labeled local maxima of the image.\n\n    See Also\n    --------\n    skimage.morphology.local_maxima\n    skimage.morphology.max_tree\n\n    References\n    ----------\n    .. [1] Vincent L., Proc. \"Grayscale area openings and closings,\n           their efficient implementation and applications\",\n           EURASIP Workshop on Mathematical Morphology and its\n           Applications to Signal Processing, Barcelona, Spain, pp.22-27,\n           May 1993.\n    .. [2] Soille, P., \"Morphological Image Analysis: Principles and\n           Applications\" (Chapter 6), 2nd edition (2003), ISBN 3540429883.\n           :DOI:`10.1007/978-3-662-05088-0`\n    .. [3] Salembier, P., Oliveras, A., & Garrido, L. (1998). Antiextensive\n           Connected Operators for Image and Sequence Processing.\n           IEEE Transactions on Image Processing, 7(4), 555-570.\n           :DOI:`10.1109/83.663500`\n    .. [4] Najman, L., & Couprie, M. (2006). Building the component tree in\n           quasi-linear time. IEEE Transactions on Image Processing, 15(11),\n           3531-3539.\n           :DOI:`10.1109/TIP.2006.877518`\n    .. [5] Carlinet, E., & Geraud, T. (2014). A Comparative Review of\n           Component Tree Computation Algorithms. IEEE Transactions on Image\n           Processing, 23(9), 3885-3895.\n           :DOI:`10.1109/TIP.2014.2336551`\n\n    Examples\n    --------\n    We create an image (quadratic function with a maximum in the center and\n    4 additional constant maxima.\n\n    >>> w = 10\n    >>> x, y = np.mgrid[0:w,0:w]\n    >>> f = 20 - 0.2*((x - w/2)**2 + (y-w/2)**2)\n    >>> f[2:4,2:4] = 40; f[2:4,7:9] = 60; f[7:9,2:4] = 80; f[7:9,7:9] = 100\n    >>> f = f.astype(int)\n\n    We can calculate all local maxima:\n\n    >>> maxima = max_tree_local_maxima(f)\n\n    The resulting image contains the labeled local maxima.\n    \"\"\"\n    output = np.ones(image.shape, dtype=np.uint64)\n    if parent is None or tree_traverser is None:\n        parent, tree_traverser = max_tree(image, connectivity)\n    _max_tree._max_tree_local_maxima(image.ravel(), output.ravel(), parent.\n        ravel(), tree_traverser)\n    return output"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_mask_border_keypoints", "method_path": "../srcdata/Computation/scikit-image/skimage/feature/util.py", "method_code_mask": "import numpy as np\n\n\ndef _mask_border_keypoints(image_shape, keypoints, distance): [MASK]\n", "response": "import numpy as np\ndef _mask_border_keypoints(image_shape, keypoints, distance):\n    \"\"\"Mask coordinates that are within certain distance from the image border.\n\n    Parameters\n    ----------\n    image_shape : (2,) array_like\n        Shape of the image as ``(rows, cols)``.\n    keypoints : (N, 2) array\n        Keypoint coordinates as ``(rows, cols)``.\n    distance : int\n        Image border distance.\n\n    Returns\n    -------\n    mask : (N,) bool array\n        Mask indicating if pixels are within the image (``True``) or in the\n        border region of the image (``False``).\n\n    \"\"\"\n    rows = image_shape[0]\n    cols = image_shape[1]\n    mask = (distance - 1 < keypoints[:, 0]) & (keypoints[:, 0] < rows -\n        distance + 1) & (distance - 1 < keypoints[:, 1]) & (keypoints[:, 1] <\n        cols - distance + 1)\n    return mask"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_blob_overlap", "method_path": "../srcdata/Computation/scikit-image/skimage/feature/blob.py", "method_code_mask": "import math\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom scipy import spatial\n\n\ndef _blob_overlap(blob1, blob2, *, sigma_dim=1): [MASK]\n", "response": "import math\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom scipy import spatial\ndef _blob_overlap(blob1, blob2, *, sigma_dim=1):\n    \"\"\"Finds the overlapping area fraction between two blobs.\n\n    Returns a float representing fraction of overlapped area. Note that 0.0\n    is *always* returned for dimension greater than 3.\n\n    Parameters\n    ----------\n    blob1 : sequence of arrays\n        A sequence of ``(row, col, sigma)`` or ``(pln, row, col, sigma)``,\n        where ``row, col`` (or ``(pln, row, col)``) are coordinates\n        of blob and ``sigma`` is the standard deviation of the Gaussian kernel\n        which detected the blob.\n    blob2 : sequence of arrays\n        A sequence of ``(row, col, sigma)`` or ``(pln, row, col, sigma)``,\n        where ``row, col`` (or ``(pln, row, col)``) are coordinates\n        of blob and ``sigma`` is the standard deviation of the Gaussian kernel\n        which detected the blob.\n    sigma_dim : int, optional\n        The dimensionality of the sigma value. Can be 1 or the same as the\n        dimensionality of the blob space (2 or 3).\n\n    Returns\n    -------\n    f : float\n        Fraction of overlapped area (or volume in 3D).\n    \"\"\"\n    ndim = len(blob1) - sigma_dim\n    if ndim > 3:\n        return 0.0\n    root_ndim = math.sqrt(ndim)\n    if blob1[-1] == blob2[-1] == 0:\n        return 0.0\n    elif blob1[-1] > blob2[-1]:\n        max_sigma = blob1[-sigma_dim:]\n        r1 = 1\n        r2 = blob2[-1] / blob1[-1]\n    else:\n        max_sigma = blob2[-sigma_dim:]\n        r2 = 1\n        r1 = blob1[-1] / blob2[-1]\n    pos1 = blob1[:ndim] / (max_sigma * root_ndim)\n    pos2 = blob2[:ndim] / (max_sigma * root_ndim)\n    d = np.sqrt(np.sum((pos2 - pos1) ** 2))\n    if d > r1 + r2:\n        return 0.0\n    if d <= abs(r1 - r2):\n        return 1.0\n    if ndim == 2:\n        return _compute_disk_overlap(d, r1, r2)\n    else:\n        return _compute_sphere_overlap(d, r1, r2)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "apply_parallel", "method_path": "../srcdata/Computation/scikit-image/skimage/util/apply_parallel.py", "method_code_mask": "import numpy\nfrom math import ceil\nimport dask.array as da\nfrom multiprocessing import cpu_count\n\n\ndef apply_parallel(function, array, chunks=None, depth=0, mode=None,\n    extra_arguments=(), extra_keywords=None, *, dtype=None, compute=None,\n    channel_axis=None): [MASK]\n", "response": "import numpy\nfrom math import ceil\nimport dask.array as da\nfrom multiprocessing import cpu_count\ndef apply_parallel(function, array, chunks=None, depth=0, mode=None,\n    extra_arguments=(), extra_keywords=None, *, dtype=None, compute=None,\n    channel_axis=None):\n    \"\"\"Map a function in parallel across an array.\n\n    Split an array into possibly overlapping chunks of a given depth and\n    boundary type, call the given function in parallel on the chunks, combine\n    the chunks and return the resulting array.\n\n    Parameters\n    ----------\n    function : function\n        Function to be mapped which takes an array as an argument.\n    array : numpy array or dask array\n        Array which the function will be applied to.\n    chunks : int, tuple, or tuple of tuples, optional\n        A single integer is interpreted as the length of one side of a square\n        chunk that should be tiled across the array.  One tuple of length\n        ``array.ndim`` represents the shape of a chunk, and it is tiled across\n        the array.  A list of tuples of length ``ndim``, where each sub-tuple\n        is a sequence of chunk sizes along the corresponding dimension. If\n        None, the array is broken up into chunks based on the number of\n        available cpus. More information about chunks is in the documentation\n        `here <https://dask.pydata.org/en/latest/array-design.html>`_. When\n        `channel_axis` is not None, the tuples can be length ``ndim - 1`` and\n        a single chunk will be used along the channel axis.\n    depth : int or sequence of int, optional\n        The depth of the added boundary cells. A tuple can be used to specify a\n        different depth per array axis. Defaults to zero. When `channel_axis`\n        is not None, and a tuple of length ``ndim - 1`` is provided, a depth of\n        0 will be used along the channel axis.\n    mode : {'reflect', 'symmetric', 'periodic', 'wrap', 'nearest', 'edge'}, optional\n        Type of external boundary padding.\n    extra_arguments : tuple, optional\n        Tuple of arguments to be passed to the function.\n    extra_keywords : dictionary, optional\n        Dictionary of keyword arguments to be passed to the function.\n    dtype : data-type or None, optional\n        The data-type of the `function` output. If None, Dask will attempt to\n        infer this by calling the function on data of shape ``(1,) * ndim``.\n        For functions expecting RGB or multichannel data this may be\n        problematic. In such cases, the user should manually specify this dtype\n        argument instead.\n\n        .. versionadded:: 0.18\n           ``dtype`` was added in 0.18.\n    compute : bool, optional\n        If ``True``, compute eagerly returning a NumPy Array.\n        If ``False``, compute lazily returning a Dask Array.\n        If ``None`` (default), compute based on array type provided\n        (eagerly for NumPy Arrays and lazily for Dask Arrays).\n    channel_axis : int or None, optional\n        If None, the image is assumed to be a grayscale (single channel) image.\n        Otherwise, this parameter indicates which axis of the array corresponds\n        to channels.\n\n    Returns\n    -------\n    out : ndarray or dask Array\n        Returns the result of the applying the operation.\n        Type is dependent on the ``compute`` argument.\n\n    Notes\n    -----\n    Numpy edge modes 'symmetric', 'wrap', and 'edge' are converted to the\n    equivalent ``dask`` boundary modes 'reflect', 'periodic' and 'nearest',\n    respectively.\n    Setting ``compute=False`` can be useful for chaining later operations.\n    For example region selection to preview a result or storing large data\n    to disk instead of loading in memory.\n\n    \"\"\"\n    try:\n        import dask.array as da\n    except ImportError:\n        raise RuntimeError(\n            \"Could not import 'dask'.  Please install using 'pip install dask'\"\n            )\n    if extra_keywords is None:\n        extra_keywords = {}\n    if compute is None:\n        compute = not isinstance(array, da.Array)\n    if channel_axis is not None:\n        channel_axis = channel_axis % array.ndim\n    if chunks is None:\n        shape = array.shape\n        try:\n            from multiprocessing import cpu_count\n            ncpu = cpu_count()\n        except NotImplementedError:\n            ncpu = 4\n        if channel_axis is not None:\n            spatial_shape = shape[:channel_axis] + shape[channel_axis + 1:]\n            chunks = list(_get_chunks(spatial_shape, ncpu))\n            chunks.insert(channel_axis, shape[channel_axis])\n            chunks = tuple(chunks)\n        else:\n            chunks = _get_chunks(shape, ncpu)\n    elif channel_axis is not None and len(chunks) == array.ndim - 1:\n        chunks = list(chunks)\n        chunks.insert(channel_axis, array.shape[channel_axis])\n        chunks = tuple(chunks)\n    if mode == 'wrap':\n        mode = 'periodic'\n    elif mode == 'symmetric':\n        mode = 'reflect'\n    elif mode == 'edge':\n        mode = 'nearest'\n    elif mode is None:\n        mode = 'reflect'\n    if channel_axis is not None:\n        if numpy.isscalar(depth):\n            depth = [depth] * (array.ndim - 1)\n        depth = list(depth)\n        if len(depth) == array.ndim - 1:\n            depth.insert(channel_axis, 0)\n        depth = tuple(depth)\n\n    def wrapped_func(arr):\n        return function(arr, *extra_arguments, **extra_keywords)\n    darr = _ensure_dask_array(array, chunks=chunks)\n    res = darr.map_overlap(wrapped_func, depth, boundary=mode, dtype=dtype)\n    if compute:\n        res = res.compute()\n    return res"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "convex_hull_image", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/convex_hull.py", "method_code_mask": "from itertools import product\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\n\ndef convex_hull_image(image, offset_coordinates=True, tolerance=1e-10,\n    include_borders=True): [MASK]\n", "response": "from itertools import product\nimport numpy as np\nfrom scipy.spatial import ConvexHull\ndef convex_hull_image(image, offset_coordinates=True, tolerance=1e-10,\n    include_borders=True):\n    \"\"\"Compute the convex hull image of a binary image.\n\n    The convex hull is the set of pixels included in the smallest convex\n    polygon that surround all white pixels in the input image.\n\n    Parameters\n    ----------\n    image : array\n        Binary input image. This array is cast to bool before processing.\n    offset_coordinates : bool, optional\n        If ``True``, a pixel at coordinate, e.g., (4, 7) will be represented\n        by coordinates (3.5, 7), (4.5, 7), (4, 6.5), and (4, 7.5). This adds\n        some \"extent\" to a pixel when computing the hull.\n    tolerance : float, optional\n        Tolerance when determining whether a point is inside the hull. Due\n        to numerical floating point errors, a tolerance of 0 can result in\n        some points erroneously being classified as being outside the hull.\n    include_borders: bool, optional\n        If ``False``, vertices/edges are excluded from the final hull mask.\n\n    Returns\n    -------\n    hull : (M, N) array of bool\n        Binary image with pixels in convex hull set to True.\n\n    References\n    ----------\n    .. [1] https://blogs.mathworks.com/steve/2011/10/04/binary-image-convex-hull-algorithm-notes/\n\n    \"\"\"\n    ndim = image.ndim\n    if np.count_nonzero(image) == 0:\n        warn(\n            'Input image is entirely zero, no valid convex hull. Returning empty image'\n            , UserWarning)\n        return np.zeros(image.shape, dtype=bool)\n    if ndim == 2:\n        coords = possible_hull(np.ascontiguousarray(image, dtype=np.uint8))\n    else:\n        coords = np.transpose(np.nonzero(image))\n        if offset_coordinates:\n            try:\n                hull0 = ConvexHull(coords)\n            except QhullError as err:\n                warn(\n                    f\"\"\"Failed to get convex hull image. Returning empty image, see error message below:\n{err}\"\"\"\n                    )\n                return np.zeros(image.shape, dtype=bool)\n            coords = hull0.points[hull0.vertices]\n    if offset_coordinates:\n        offsets = _offsets_diamond(image.ndim)\n        coords = (coords[:, np.newaxis, :] + offsets).reshape(-1, ndim)\n    coords = unique_rows(coords)\n    try:\n        hull = ConvexHull(coords)\n    except QhullError as err:\n        warn(\n            f\"\"\"Failed to get convex hull image. Returning empty image, see error message below:\n{err}\"\"\"\n            )\n        return np.zeros(image.shape, dtype=bool)\n    vertices = hull.points[hull.vertices]\n    if ndim == 2:\n        labels = grid_points_in_poly(image.shape, vertices, binarize=False)\n        mask = labels >= 1 if include_borders else labels == 1\n    else:\n        gridcoords = np.reshape(np.mgrid[tuple(map(slice, image.shape))], (\n            ndim, -1))\n        coords_in_hull = _check_coords_in_hull(gridcoords, hull.equations,\n            tolerance)\n        mask = np.reshape(coords_in_hull, image.shape)\n    return mask"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_stackcopy", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/_warps.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef _stackcopy(a, b): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef _stackcopy(a, b):\n    \"\"\"Copy b into each color layer of a, such that::\n\n      a[:,:,0] = a[:,:,1] = ... = b\n\n    Parameters\n    ----------\n    a : (M, N) or (M, N, P) ndarray\n        Target array.\n    b : (M, N)\n        Source array.\n\n    Notes\n    -----\n    Color images are stored as an ``(M, N, 3)`` or ``(M, N, 4)`` arrays.\n\n    \"\"\"\n    if a.ndim == 3:\n        a[:] = b[:, :, np.newaxis]\n    else:\n        a[:] = b"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "disk", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/footprints.py", "method_code_mask": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\n\n\ndef disk(radius, dtype=np.uint8, *, strict_radius=True, decomposition=None): [M\n    ASK]\n", "response": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\ndef disk(radius, dtype=np.uint8, *, strict_radius=True, decomposition=None):\n    \"\"\"Generates a flat, disk-shaped footprint.\n\n    A pixel is within the neighborhood if the Euclidean distance between\n    it and the origin is no greater than radius (This is only approximately\n    True, when `decomposition == 'sequence'`).\n\n    Parameters\n    ----------\n    radius : int\n        The radius of the disk-shaped footprint.\n\n    Other Parameters\n    ----------------\n    dtype : data-type, optional\n        The data type of the footprint.\n    strict_radius : bool, optional\n        If False, extend the radius by 0.5. This allows the circle to expand\n        further within a cube that remains of size ``2 * radius + 1`` along\n        each axis. This parameter is ignored if decomposition is not None.\n    decomposition : {None, 'sequence', 'crosses'}, optional\n        If None, a single array is returned. For 'sequence', a tuple of smaller\n        footprints is returned. Applying this series of smaller footprints will\n        given a result equivalent to a single, larger footprint, but with\n        better computational performance. For disk footprints, the 'sequence'\n        or 'crosses' decompositions are not always exactly equivalent to\n        ``decomposition=None``. See Notes for more details.\n\n    Returns\n    -------\n    footprint : ndarray\n        The footprint where elements of the neighborhood are 1 and 0 otherwise.\n\n    Notes\n    -----\n    When `decomposition` is not None, each element of the `footprint`\n    tuple is a 2-tuple of the form ``(ndarray, num_iter)`` that specifies a\n    footprint array and the number of iterations it is to be applied.\n\n    The disk produced by the ``decomposition='sequence'`` mode may not be\n    identical to that with ``decomposition=None``. A disk footprint can be\n    approximated by applying a series of smaller footprints of extent 3 along\n    each axis. Specific solutions for this are given in [1]_ for the case of\n    2D disks with radius 2 through 10. Here, we numerically computed the number\n    of repetitions of each element that gives the closest match to the disk\n    computed with kwargs ``strict_radius=False, decomposition=None``.\n\n    Empirically, the series decomposition at large radius approaches a\n    hexadecagon (a 16-sided polygon [2]_). In [3]_, the authors demonstrate\n    that a hexadecagon is the closest approximation to a disk that can be\n    achieved for decomposition with footprints of shape (3, 3).\n\n    The disk produced by the ``decomposition='crosses'`` is often but not\n    always  identical to that with ``decomposition=None``. It tends to give a\n    closer approximation than ``decomposition='sequence'``, at a performance\n    that is fairly comparable. The individual cross-shaped elements are not\n    limited to extent (3, 3) in size. Unlike the 'seqeuence' decomposition, the\n    'crosses' decomposition can also accurately approximate the shape of disks\n    with ``strict_radius=True``. The method is based on an adaption of\n    algorithm 1 given in [4]_.\n\n    References\n    ----------\n    .. [1] Park, H and Chin R.T. Decomposition of structuring elements for\n           optimal implementation of morphological operations. In Proceedings:\n           1997 IEEE Workshop on Nonlinear Signal and Image Processing, London,\n           UK.\n           https://www.iwaenc.org/proceedings/1997/nsip97/pdf/scan/ns970226.pdf\n    .. [2] https://en.wikipedia.org/wiki/Hexadecagon\n    .. [3] Vanrell, M and Vitri\u00e0, J. Optimal 3 \u00d7 3 decomposable disks for\n           morphological transformations. Image and Vision Computing, Vol. 15,\n           Issue 11, 1997.\n           :DOI:`10.1016/S0262-8856(97)00026-7`\n    .. [4] Li, D. and Ritter, G.X. Decomposition of Separable and Symmetric\n           Convex Templates. Proc. SPIE 1350, Image Algebra and Morphological\n           Image Processing, (1 November 1990).\n           :DOI:`10.1117/12.23608`\n    \"\"\"\n    if decomposition is None:\n        L = np.arange(-radius, radius + 1)\n        X, Y = np.meshgrid(L, L)\n        if not strict_radius:\n            radius += 0.5\n        return np.array(X ** 2 + Y ** 2 <= radius ** 2, dtype=dtype)\n    elif decomposition == 'sequence':\n        sequence = _nsphere_series_decomposition(radius, ndim=2, dtype=dtype)\n    elif decomposition == 'crosses':\n        fp = disk(radius, dtype, strict_radius=strict_radius, decomposition\n            =None)\n        sequence = _cross_decomposition(fp)\n    return sequence"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "warp_coords", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/_warps.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef warp_coords(coord_map, shape, dtype=np.float64): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef warp_coords(coord_map, shape, dtype=np.float64):\n    \"\"\"Build the source coordinates for the output of a 2-D image warp.\n\n    Parameters\n    ----------\n    coord_map : callable like GeometricTransform.inverse\n        Return input coordinates for given output coordinates.\n        Coordinates are in the shape (P, 2), where P is the number\n        of coordinates and each element is a ``(row, col)`` pair.\n    shape : tuple\n        Shape of output image ``(rows, cols[, bands])``.\n    dtype : np.dtype or string\n        dtype for return value (sane choices: float32 or float64).\n\n    Returns\n    -------\n    coords : (ndim, rows, cols[, bands]) array of dtype `dtype`\n            Coordinates for `scipy.ndimage.map_coordinates`, that will yield\n            an image of shape (orows, ocols, bands) by drawing from source\n            points according to the `coord_transform_fn`.\n\n    Notes\n    -----\n\n    This is a lower-level routine that produces the source coordinates for 2-D\n    images used by `warp()`.\n\n    It is provided separately from `warp` to give additional flexibility to\n    users who would like, for example, to re-use a particular coordinate\n    mapping, to use specific dtypes at various points along the the\n    image-warping process, or to implement different post-processing logic\n    than `warp` performs after the call to `ndi.map_coordinates`.\n\n\n    Examples\n    --------\n    Produce a coordinate map that shifts an image up and to the right:\n\n    >>> from skimage import data\n    >>> from scipy.ndimage import map_coordinates\n    >>>\n    >>> def shift_up10_left20(xy):\n    ...     return xy - np.array([-20, 10])[None, :]\n    >>>\n    >>> image = data.astronaut().astype(np.float32)\n    >>> coords = warp_coords(shift_up10_left20, image.shape)\n    >>> warped_image = map_coordinates(image, coords)\n\n    \"\"\"\n    shape = safe_as_int(shape)\n    rows, cols = shape[0], shape[1]\n    coords_shape = [len(shape), rows, cols]\n    if len(shape) == 3:\n        coords_shape.append(shape[2])\n    coords = np.empty(coords_shape, dtype=dtype)\n    tf_coords = np.indices((cols, rows), dtype=dtype).reshape(2, -1).T\n    tf_coords = coord_map(tf_coords)\n    tf_coords = tf_coords.T.reshape((-1, cols, rows)).swapaxes(1, 2)\n    _stackcopy(coords[1, ...], tf_coords[0, ...])\n    _stackcopy(coords[0, ...], tf_coords[1, ...])\n    if len(shape) == 3:\n        coords[2, ...] = range(shape[2])\n    return coords"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_log_polar_mapping", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/_warps.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef _log_polar_mapping(output_coords, k_angle, k_radius, center): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef _log_polar_mapping(output_coords, k_angle, k_radius, center):\n    \"\"\"Inverse mapping function to convert from cartesian to polar coordinates\n\n    Parameters\n    ----------\n    output_coords : (M, 2) ndarray\n        Array of `(col, row)` coordinates in the output image.\n    k_angle : float\n        Scaling factor that relates the intended number of rows in the output\n        image to angle: ``k_angle = nrows / (2 * np.pi)``.\n    k_radius : float\n        Scaling factor that relates the radius of the circle bounding the\n        area to be transformed to the intended number of columns in the output\n        image: ``k_radius = width / np.log(radius)``.\n    center : 2-tuple\n        `(row, col)` coordinates that represent the center of the circle that bounds the\n        area to be transformed in an input image.\n\n    Returns\n    -------\n    coords : ndarray, shape (M, 2)\n        Array of `(col, row)` coordinates in the input image that\n        correspond to the `output_coords` given as input.\n    \"\"\"\n    angle = output_coords[:, 1] / k_angle\n    rr = np.exp(output_coords[:, 0] / k_radius) * np.sin(angle) + center[0]\n    cc = np.exp(output_coords[:, 0] / k_radius) * np.cos(angle) + center[1]\n    coords = np.column_stack((cc, rr))\n    return coords"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_linear_polar_mapping", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/_warps.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef _linear_polar_mapping(output_coords, k_angle, k_radius, center): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef _linear_polar_mapping(output_coords, k_angle, k_radius, center):\n    \"\"\"Inverse mapping function to convert from cartesian to polar coordinates\n\n    Parameters\n    ----------\n    output_coords : (M, 2) ndarray\n        Array of `(col, row)` coordinates in the output image.\n    k_angle : float\n        Scaling factor that relates the intended number of rows in the output\n        image to angle: ``k_angle = nrows / (2 * np.pi)``.\n    k_radius : float\n        Scaling factor that relates the radius of the circle bounding the\n        area to be transformed to the intended number of columns in the output\n        image: ``k_radius = ncols / radius``.\n    center : tuple (row, col)\n        Coordinates that represent the center of the circle that bounds the\n        area to be transformed in an input image.\n\n    Returns\n    -------\n    coords : (M, 2) ndarray\n        Array of `(col, row)` coordinates in the input image that\n        correspond to the `output_coords` given as input.\n    \"\"\"\n    angle = output_coords[:, 1] / k_angle\n    rr = output_coords[:, 0] / k_radius * np.sin(angle) + center[0]\n    cc = output_coords[:, 0] / k_radius * np.cos(angle) + center[1]\n    coords = np.column_stack((cc, rr))\n    return coords"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "order_angles_golden_ratio", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/radon_transform.py", "method_code_mask": "import numpy as np\nfrom scipy.interpolate import interp1d\nfrom scipy.constants import golden_ratio\nfrom scipy.fft import fft\nfrom scipy.fft import ifft\nfrom scipy.fft import fftfreq\nfrom scipy.fft import fftshift\nfrom warnings import warn\nfrom functools import partial\n\n\ndef order_angles_golden_ratio(theta): [MASK]\n", "response": "import numpy as np\nfrom scipy.interpolate import interp1d\nfrom scipy.constants import golden_ratio\nfrom scipy.fft import fft\nfrom scipy.fft import ifft\nfrom scipy.fft import fftfreq\nfrom scipy.fft import fftshift\nfrom warnings import warn\nfrom functools import partial\ndef order_angles_golden_ratio(theta):\n    \"\"\"Order angles to reduce the amount of correlated information in\n    subsequent projections.\n\n    Parameters\n    ----------\n    theta : array of floats, shape (M,)\n        Projection angles in degrees. Duplicate angles are not allowed.\n\n    Returns\n    -------\n    indices_generator : generator yielding unsigned integers\n        The returned generator yields indices into ``theta`` such that\n        ``theta[indices]`` gives the approximate golden ratio ordering\n        of the projections. In total, ``len(theta)`` indices are yielded.\n        All non-negative integers < ``len(theta)`` are yielded exactly once.\n\n    Notes\n    -----\n    The method used here is that of the golden ratio introduced\n    by T. Kohler.\n\n    References\n    ----------\n    .. [1] Kohler, T. \"A projection access scheme for iterative\n           reconstruction based on the golden section.\" Nuclear Science\n           Symposium Conference Record, 2004 IEEE. Vol. 6. IEEE, 2004.\n    .. [2] Winkelmann, Stefanie, et al. \"An optimal radial profile order\n           based on the Golden Ratio for time-resolved MRI.\"\n           Medical Imaging, IEEE Transactions on 26.1 (2007): 68-76.\n\n    \"\"\"\n    interval = 180\n    remaining_indices = list(np.argsort(theta))\n    angle = theta[remaining_indices[0]]\n    yield remaining_indices.pop(0)\n    angle_increment = interval / golden_ratio ** 2\n    while remaining_indices:\n        remaining_angles = theta[remaining_indices]\n        angle = (angle + angle_increment) % interval\n        index_above = np.searchsorted(remaining_angles, angle)\n        index_below = index_above - 1\n        index_above %= len(remaining_indices)\n        diff_below = abs(angle - remaining_angles[index_below])\n        distance_below = min(diff_below % interval, diff_below % -interval)\n        diff_above = abs(angle - remaining_angles[index_above])\n        distance_above = min(diff_above % interval, diff_above % -interval)\n        if distance_below < distance_above:\n            yield remaining_indices.pop(index_below)\n        else:\n            yield remaining_indices.pop(index_above)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "polygon_area", "method_path": "../srcdata/Computation/scikit-image/skimage/_shared/_geometry.py", "method_code_mask": "import numpy as np\nfrom matplotlib import path\nfrom matplotlib import transforms\n\n\ndef polygon_area(pr, pc): [MASK]\n", "response": "import numpy as np\nfrom matplotlib import path\nfrom matplotlib import transforms\ndef polygon_area(pr, pc):\n    \"\"\"Compute the area of a polygon.\n\n    Parameters\n    ----------\n    pr, pc : (K,) array of float\n        Polygon row and column coordinates.\n\n    Returns\n    -------\n    a : float\n        Area of the polygon.\n    \"\"\"\n    pr = np.asarray(pr)\n    pc = np.asarray(pc)\n    return 0.5 * np.abs(np.sum(pc[:-1] * pr[1:] - pc[1:] * pr[:-1]))"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_rescale_intensity", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/tests/test_radon_transform.py", "method_code_mask": "import itertools\nimport numpy as np\nimport pytest\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.utils import convert_to_float\nfrom skimage.data import shepp_logan_phantom\nfrom skimage.transform import radon\nfrom skimage.transform import iradon\nfrom skimage.transform import iradon_sart\nfrom skimage.transform import rescale\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nfrom skimage.transform.radon_transform import _sinogram_circle_to_square\nfrom skimage.transform.radon_transform import order_angles_golden_ratio\n\n\ndef _rescale_intensity(x): [MASK]\n", "response": "import itertools\nimport numpy as np\nimport pytest\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.utils import convert_to_float\nfrom skimage.data import shepp_logan_phantom\nfrom skimage.transform import radon\nfrom skimage.transform import iradon\nfrom skimage.transform import iradon_sart\nfrom skimage.transform import rescale\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nfrom skimage.transform.radon_transform import _sinogram_circle_to_square\nfrom skimage.transform.radon_transform import order_angles_golden_ratio\ndef _rescale_intensity(x):\n    x = x.astype(float)\n    x -= x.min()\n    x /= x.max()\n    return x"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "get_module_version", "method_path": "../srcdata/Computation/scikit-image/skimage/_shared/version_requirements.py", "method_code_mask": "import sys\nfrom packaging import version as _version\nimport re\nimport functools\n\n\ndef get_module_version(module_name): [MASK]\n", "response": "import sys\nfrom packaging import version as _version\nimport re\nimport functools\ndef get_module_version(module_name):\n    \"\"\"Return module version or None if version can't be retrieved.\"\"\"\n    mod = __import__(module_name, fromlist=[module_name.rpartition('.')[-1]])\n    return getattr(mod, '__version__', getattr(mod, 'VERSION', None))"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "ellipsoid", "method_path": "../srcdata/Computation/scikit-image/skimage/draw/draw3d.py", "method_code_mask": "import numpy as np\nfrom scipy.special import ellipkinc as ellip_F\nfrom scipy.special import ellipeinc as ellip_E\n\n\ndef ellipsoid(a, b, c, spacing=(1.0, 1.0, 1.0), levelset=False): [MASK]\n", "response": "import numpy as np\nfrom scipy.special import ellipkinc as ellip_F\nfrom scipy.special import ellipeinc as ellip_E\ndef ellipsoid(a, b, c, spacing=(1.0, 1.0, 1.0), levelset=False):\n    \"\"\"\n    Generates ellipsoid with semimajor axes aligned with grid dimensions\n    on grid with specified `spacing`.\n\n    Parameters\n    ----------\n    a : float\n        Length of semimajor axis aligned with x-axis.\n    b : float\n        Length of semimajor axis aligned with y-axis.\n    c : float\n        Length of semimajor axis aligned with z-axis.\n    spacing : 3-tuple of floats\n        Spacing in three spatial dimensions.\n    levelset : bool\n        If True, returns the level set for this ellipsoid (signed level\n        set about zero, with positive denoting interior) as np.float64.\n        False returns a binarized version of said level set.\n\n    Returns\n    -------\n    ellipsoid : (M, N, P) array\n        Ellipsoid centered in a correctly sized array for given `spacing`.\n        Boolean dtype unless `levelset=True`, in which case a float array is\n        returned with the level set above 0.0 representing the ellipsoid.\n\n    \"\"\"\n    if a <= 0 or b <= 0 or c <= 0:\n        raise ValueError('Parameters a, b, and c must all be > 0')\n    offset = np.r_[1, 1, 1] * np.r_[spacing]\n    low = np.ceil(-np.r_[a, b, c] - offset)\n    high = np.floor(np.r_[a, b, c] + offset + 1)\n    for dim in range(3):\n        if (high[dim] - low[dim]) % 2 == 0:\n            low[dim] -= 1\n        num = np.arange(low[dim], high[dim], spacing[dim])\n        if 0 not in num:\n            low[dim] -= np.max(num[num < 0])\n    x, y, z = np.mgrid[low[0]:high[0]:spacing[0], low[1]:high[1]:spacing[1],\n        low[2]:high[2]:spacing[2]]\n    if not levelset:\n        arr = (x / float(a)) ** 2 + (y / float(b)) ** 2 + (z / float(c)\n            ) ** 2 <= 1\n    else:\n        arr = (x / float(a)) ** 2 + (y / float(b)) ** 2 + (z / float(c)\n            ) ** 2 - 1\n    return arr"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "label2rgb", "method_path": "../srcdata/Computation/scikit-image/skimage/color/colorlabel.py", "method_code_mask": "import itertools\nimport numpy as np\n\n\ndef label2rgb(label, image=None, colors=None, alpha=0.3, bg_label=0,\n    bg_color=(0, 0, 0), image_alpha=1, kind='overlay', *, saturation=0,\n    channel_axis=-1): [MASK]\n", "response": "import itertools\nimport numpy as np\ndef label2rgb(label, image=None, colors=None, alpha=0.3, bg_label=0,\n    bg_color=(0, 0, 0), image_alpha=1, kind='overlay', *, saturation=0,\n    channel_axis=-1):\n    \"\"\"Return an RGB image where color-coded labels are painted over the image.\n\n    Parameters\n    ----------\n    label : ndarray\n        Integer array of labels with the same shape as `image`.\n    image : ndarray, optional\n        Image used as underlay for labels. It should have the same shape as\n        `labels`, optionally with an additional RGB (channels) axis. If `image`\n        is an RGB image, it is converted to grayscale before coloring.\n    colors : list, optional\n        List of colors. If the number of labels exceeds the number of colors,\n        then the colors are cycled.\n    alpha : float [0, 1], optional\n        Opacity of colorized labels. Ignored if image is `None`.\n    bg_label : int, optional\n        Label that's treated as the background. If `bg_label` is specified,\n        `bg_color` is `None`, and `kind` is `overlay`,\n        background is not painted by any colors.\n    bg_color : str or array, optional\n        Background color. Must be a name in ``skimage.color.color_dict`` or RGB float\n        values between [0, 1].\n    image_alpha : float [0, 1], optional\n        Opacity of the image.\n    kind : string, one of {'overlay', 'avg'}\n        The kind of color image desired. 'overlay' cycles over defined colors\n        and overlays the colored labels over the original image. 'avg' replaces\n        each labeled segment with its average color, for a stained-class or\n        pastel painting appearance.\n    saturation : float [0, 1], optional\n        Parameter to control the saturation applied to the original image\n        between fully saturated (original RGB, `saturation=1`) and fully\n        unsaturated (grayscale, `saturation=0`). Only applies when\n        `kind='overlay'`.\n    channel_axis : int, optional\n        This parameter indicates which axis of the output array will correspond\n        to channels. If `image` is provided, this must also match the axis of\n        `image` that corresponds to channels.\n\n        .. versionadded:: 0.19\n            ``channel_axis`` was added in 0.19.\n\n    Returns\n    -------\n    result : ndarray of float, same shape as `image`\n        The result of blending a cycling colormap (`colors`) for each distinct\n        value in `label` with the image, at a certain alpha value.\n    \"\"\"\n    if image is not None:\n        image = np.moveaxis(image, source=channel_axis, destination=-1)\n    if kind == 'overlay':\n        rgb = _label2rgb_overlay(label, image, colors, alpha, bg_label,\n            bg_color, image_alpha, saturation)\n    elif kind == 'avg':\n        rgb = _label2rgb_avg(label, image, bg_label, bg_color)\n    else:\n        raise ValueError(\"`kind` must be either 'overlay' or 'avg'.\")\n    return np.moveaxis(rgb, source=-1, destination=channel_axis)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_sigma_prefactor", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/_gabor.py", "method_code_mask": "import math\nimport numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef _sigma_prefactor(bandwidth): [MASK]\n", "response": "import math\nimport numpy as np\nfrom scipy import ndimage as ndi\ndef _sigma_prefactor(bandwidth):\n    b = bandwidth\n    return 1.0 / np.pi * math.sqrt(math.log(2) / 2.0) * (2.0 ** b + 1) / (\n        2.0 ** b - 1)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "gabor", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/_gabor.py", "method_code_mask": "import math\nimport numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef gabor(image, frequency, theta=0, bandwidth=1, sigma_x=None, sigma_y=\n    None, n_stds=3, offset=0, mode='reflect', cval=0): [MASK]\n", "response": "import math\nimport numpy as np\nfrom scipy import ndimage as ndi\ndef gabor(image, frequency, theta=0, bandwidth=1, sigma_x=None, sigma_y=\n    None, n_stds=3, offset=0, mode='reflect', cval=0):\n    \"\"\"Return real and imaginary responses to Gabor filter.\n\n    The real and imaginary parts of the Gabor filter kernel are applied to the\n    image and the response is returned as a pair of arrays.\n\n    Gabor filter is a linear filter with a Gaussian kernel which is modulated\n    by a sinusoidal plane wave. Frequency and orientation representations of\n    the Gabor filter are similar to those of the human visual system.\n    Gabor filter banks are commonly used in computer vision and image\n    processing. They are especially suitable for edge detection and texture\n    classification.\n\n    Parameters\n    ----------\n    image : 2-D array\n        Input image.\n    frequency : float\n        Spatial frequency of the harmonic function. Specified in pixels.\n    theta : float, optional\n        Orientation in radians. If 0, the harmonic is in the x-direction.\n    bandwidth : float, optional\n        The bandwidth captured by the filter. For fixed bandwidth, ``sigma_x``\n        and ``sigma_y`` will decrease with increasing frequency. This value is\n        ignored if ``sigma_x`` and ``sigma_y`` are set by the user.\n    sigma_x, sigma_y : float, optional\n        Standard deviation in x- and y-directions. These directions apply to\n        the kernel *before* rotation. If `theta = pi/2`, then the kernel is\n        rotated 90 degrees so that ``sigma_x`` controls the *vertical*\n        direction.\n    n_stds : scalar, optional\n        The linear size of the kernel is n_stds (3 by default) standard\n        deviations.\n    offset : float, optional\n        Phase offset of harmonic function in radians.\n    mode : {'constant', 'nearest', 'reflect', 'mirror', 'wrap'}, optional\n        Mode used to convolve image with a kernel, passed to `ndi.convolve`\n    cval : scalar, optional\n        Value to fill past edges of input if ``mode`` of convolution is\n        'constant'. The parameter is passed to `ndi.convolve`.\n\n    Returns\n    -------\n    real, imag : arrays\n        Filtered images using the real and imaginary parts of the Gabor filter\n        kernel. Images are of the same dimensions as the input one.\n\n    References\n    ----------\n    .. [1] https://en.wikipedia.org/wiki/Gabor_filter\n    .. [2] https://web.archive.org/web/20180127125930/http://mplab.ucsd.edu/tutorials/gabor.pdf\n\n    Examples\n    --------\n    >>> from skimage.filters import gabor\n    >>> from skimage import data, io\n    >>> from matplotlib import pyplot as plt  # doctest: +SKIP\n\n    >>> image = data.coins()\n    >>> # detecting edges in a coin image\n    >>> filt_real, filt_imag = gabor(image, frequency=0.6)\n    >>> plt.figure()            # doctest: +SKIP\n    >>> io.imshow(filt_real)    # doctest: +SKIP\n    >>> io.show()               # doctest: +SKIP\n\n    >>> # less sensitivity to finer details with the lower frequency kernel\n    >>> filt_real, filt_imag = gabor(image, frequency=0.1)\n    >>> plt.figure()            # doctest: +SKIP\n    >>> io.imshow(filt_real)    # doctest: +SKIP\n    >>> io.show()               # doctest: +SKIP\n    \"\"\"\n    check_nD(image, 2)\n    if image.dtype.kind == 'f':\n        float_dtype = _supported_float_type(image.dtype)\n        image = image.astype(float_dtype, copy=False)\n        kernel_dtype = np.promote_types(image.dtype, np.complex64)\n    else:\n        kernel_dtype = np.complex128\n    g = gabor_kernel(frequency, theta, bandwidth, sigma_x, sigma_y, n_stds,\n        offset, dtype=kernel_dtype)\n    filtered_real = ndi.convolve(image, np.real(g), mode=mode, cval=cval)\n    filtered_imag = ndi.convolve(image, np.imag(g), mode=mode, cval=cval)\n    return filtered_real, filtered_imag"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_mask_filter_result", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/edges.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\nfrom scipy.ndimage import binary_erosion\nfrom scipy.ndimage import convolve\n\n\ndef _mask_filter_result(result, mask): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\nfrom scipy.ndimage import binary_erosion\nfrom scipy.ndimage import convolve\ndef _mask_filter_result(result, mask):\n    \"\"\"Return result after masking.\n\n    Input masks are eroded so that mask areas in the original image don't\n    affect values in the result.\n    \"\"\"\n    if mask is not None:\n        erosion_footprint = ndi.generate_binary_structure(mask.ndim, mask.ndim)\n        mask = binary_erosion(mask, erosion_footprint, border_value=0)\n        result *= mask\n    return result"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "crop", "method_path": "../srcdata/Computation/scikit-image/skimage/util/arraycrop.py", "method_code_mask": "import numpy as np\nfrom numbers import Integral\n\n\ndef crop(ar, crop_width, copy=False, order='K'): [MASK]\n", "response": "import numpy as np\nfrom numbers import Integral\ndef crop(ar, crop_width, copy=False, order='K'):\n    \"\"\"Crop array `ar` by `crop_width` along each dimension.\n\n    Parameters\n    ----------\n    ar : array-like of rank N\n        Input array.\n    crop_width : {sequence, int}\n        Number of values to remove from the edges of each axis.\n        ``((before_1, after_1),`` ... ``(before_N, after_N))`` specifies\n        unique crop widths at the start and end of each axis.\n        ``((before, after),) or (before, after)`` specifies\n        a fixed start and end crop for every axis.\n        ``(n,)`` or ``n`` for integer ``n`` is a shortcut for\n        before = after = ``n`` for all axes.\n    copy : bool, optional\n        If `True`, ensure the returned array is a contiguous copy. Normally,\n        a crop operation will return a discontiguous view of the underlying\n        input array.\n    order : {'C', 'F', 'A', 'K'}, optional\n        If ``copy==True``, control the memory layout of the copy. See\n        ``np.copy``.\n\n    Returns\n    -------\n    cropped : array\n        The cropped array. If ``copy=False`` (default), this is a sliced\n        view of the input array.\n    \"\"\"\n    ar = np.array(ar, copy=False)\n    if isinstance(crop_width, Integral):\n        crops = [[crop_width, crop_width]] * ar.ndim\n    elif isinstance(crop_width[0], Integral):\n        if len(crop_width) == 1:\n            crops = [[crop_width[0], crop_width[0]]] * ar.ndim\n        elif len(crop_width) == 2:\n            crops = [crop_width] * ar.ndim\n        else:\n            raise ValueError(\n                f\"\"\"crop_width has an invalid length: {len(crop_width)}\ncrop_width should be a sequence of N pairs, a single pair, or a single integer\"\"\"\n                )\n    elif len(crop_width) == 1:\n        crops = [crop_width[0]] * ar.ndim\n    elif len(crop_width) == ar.ndim:\n        crops = crop_width\n    else:\n        raise ValueError(\n            f\"\"\"crop_width has an invalid length: {len(crop_width)}\ncrop_width should be a sequence of N pairs, a single pair, or a single integer\"\"\"\n            )\n    slices = tuple(slice(a, ar.shape[i] - b) for i, (a, b) in enumerate(crops))\n    if copy:\n        cropped = np.array(ar[slices], order=order, copy=True)\n    else:\n        cropped = ar[slices]\n    return cropped"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "medial_axis", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_skeletonize.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef medial_axis(image, mask=None, return_distance=False, *, rng=None): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef medial_axis(image, mask=None, return_distance=False, *, rng=None):\n    \"\"\"Compute the medial axis transform of a binary image.\n\n    Parameters\n    ----------\n    image : binary ndarray, shape (M, N)\n        The image of the shape to skeletonize. If this input isn't already a\n        binary image, it gets converted into one: In this case, zero values are\n        considered background (False), nonzero values are considered\n        foreground (True).\n    mask : binary ndarray, shape (M, N), optional\n        If a mask is given, only those elements in `image` with a true\n        value in `mask` are used for computing the medial axis.\n    return_distance : bool, optional\n        If true, the distance transform is returned as well as the skeleton.\n    rng : {`numpy.random.Generator`, int}, optional\n        Pseudo-random number generator.\n        By default, a PCG64 generator is used (see :func:`numpy.random.default_rng`).\n        If `rng` is an int, it is used to seed the generator.\n\n        The PRNG determines the order in which pixels are processed for\n        tiebreaking.\n\n        .. versionadded:: 0.19\n\n    Returns\n    -------\n    out : ndarray of bools\n        Medial axis transform of the image\n    dist : ndarray of ints, optional\n        Distance transform of the image (only returned if `return_distance`\n        is True)\n\n    See Also\n    --------\n    skeletonize, thin\n\n    Notes\n    -----\n    This algorithm computes the medial axis transform of an image\n    as the ridges of its distance transform.\n\n    The different steps of the algorithm are as follows\n     * A lookup table is used, that assigns 0 or 1 to each configuration of\n       the 3x3 binary square, whether the central pixel should be removed\n       or kept. We want a point to be removed if it has more than one neighbor\n       and if removing it does not change the number of connected components.\n\n     * The distance transform to the background is computed, as well as\n       the cornerness of the pixel.\n\n     * The foreground (value of 1) points are ordered by\n       the distance transform, then the cornerness.\n\n     * A cython function is called to reduce the image to its skeleton. It\n       processes pixels in the order determined at the previous step, and\n       removes or maintains a pixel according to the lookup table. Because\n       of the ordering, it is possible to process all pixels in only one\n       pass.\n\n    Examples\n    --------\n    >>> square = np.zeros((7, 7), dtype=bool)\n    >>> square[1:-1, 2:-2] = 1\n    >>> square.view(np.uint8)\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    >>> medial_axis(square).view(np.uint8)\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 0, 1, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 0, 0, 0],\n           [0, 0, 1, 0, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n\n    \"\"\"\n    global _eight_connect\n    if mask is None:\n        masked_image = image.astype(bool)\n    else:\n        masked_image = image.astype(bool).copy()\n        masked_image[~mask] = False\n    center_is_foreground = (np.arange(512) & 2 ** 4).astype(bool)\n    table = center_is_foreground & (np.array([(ndi.label(_pattern_of(index),\n        _eight_connect)[1] != ndi.label(_pattern_of(index & ~2 ** 4),\n        _eight_connect)[1]) for index in range(512)]) | np.array([(np.sum(\n        _pattern_of(index)) < 3) for index in range(512)]))\n    distance = ndi.distance_transform_edt(masked_image)\n    if return_distance:\n        store_distance = distance.copy()\n    cornerness_table = np.array([(9 - np.sum(_pattern_of(index))) for index in\n        range(512)])\n    corner_score = _table_lookup(masked_image, cornerness_table)\n    i, j = np.mgrid[0:image.shape[0], 0:image.shape[1]]\n    result = masked_image.copy()\n    distance = distance[result]\n    i = np.ascontiguousarray(i[result], dtype=np.intp)\n    j = np.ascontiguousarray(j[result], dtype=np.intp)\n    result = np.ascontiguousarray(result, np.uint8)\n    generator = np.random.default_rng(rng)\n    tiebreaker = generator.permutation(np.arange(masked_image.sum()))\n    order = np.lexsort((tiebreaker, corner_score[masked_image], distance))\n    order = np.ascontiguousarray(order, dtype=np.int32)\n    table = np.ascontiguousarray(table, dtype=np.uint8)\n    _skeletonize_loop(result, i, j, order, table)\n    result = result.astype(bool)\n    if mask is not None:\n        result[~mask] = image[~mask]\n    if return_distance:\n        return result, store_distance\n    else:\n        return result"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "fetch", "method_path": "../srcdata/Computation/scikit-image/skimage/_shared/testing.py", "method_code_mask": "import os\nimport platform\nimport re\nimport struct\nimport sys\nimport functools\nimport inspect\nfrom tempfile import NamedTemporaryFile\nimport numpy as np\nfrom numpy import testing\nfrom numpy.testing import TestCase\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_no_warnings\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_almost_equal_nulp\nfrom numpy.testing import assert_array_less\nimport pytest\nimport threading\n\n\ndef fetch(data_filename): [MASK]\n", "response": "import os\nimport platform\nimport re\nimport struct\nimport sys\nimport functools\nimport inspect\nfrom tempfile import NamedTemporaryFile\nimport numpy as np\nfrom numpy import testing\nfrom numpy.testing import TestCase\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_no_warnings\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_almost_equal_nulp\nfrom numpy.testing import assert_array_less\nimport pytest\nimport threading\ndef fetch(data_filename):\n    \"\"\"Attempt to fetch data, but if unavailable, skip the tests.\"\"\"\n    try:\n        return _fetch(data_filename)\n    except (ConnectionError, ModuleNotFoundError):\n        pytest.skip(f'Unable to download {data_filename}',\n            allow_module_level=True)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "skeletonize", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_skeletonize.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef skeletonize(image, *, method=None): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef skeletonize(image, *, method=None):\n    \"\"\"Compute the skeleton of a binary image.\n\n    Thinning is used to reduce each connected component in a binary image\n    to a single-pixel wide skeleton.\n\n    Parameters\n    ----------\n    image : ndarray, 2D or 3D\n        An image containing the objects to be skeletonized. Zeros or ``False``\n        represent background, nonzero values or ``True`` are foreground.\n    method : {'zhang', 'lee'}, optional\n        Which algorithm to use. Zhang's algorithm [Zha84]_ only works for\n        2D images, and is the default for 2D. Lee's algorithm [Lee94]_\n        works for 2D or 3D images and is the default for 3D.\n\n    Returns\n    -------\n    skeleton : ndarray of bool\n        The thinned image.\n\n    See Also\n    --------\n    medial_axis\n\n    References\n    ----------\n    .. [Lee94] T.-C. Lee, R.L. Kashyap and C.-N. Chu, Building skeleton models\n           via 3-D medial surface/axis thinning algorithms.\n           Computer Vision, Graphics, and Image Processing, 56(6):462-478, 1994.\n\n    .. [Zha84] A fast parallel algorithm for thinning digital patterns,\n           T. Y. Zhang and C. Y. Suen, Communications of the ACM,\n           March 1984, Volume 27, Number 3.\n\n    Examples\n    --------\n    >>> X, Y = np.ogrid[0:9, 0:9]\n    >>> ellipse = (1./3 * (X - 4)**2 + (Y - 4)**2 < 3**2).astype(bool)\n    >>> ellipse.view(np.uint8)\n    array([[0, 0, 0, 1, 1, 1, 0, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 1, 1, 1, 1, 1, 0, 0],\n           [0, 0, 0, 1, 1, 1, 0, 0, 0]], dtype=uint8)\n    >>> skel = skeletonize(ellipse)\n    >>> skel.view(np.uint8)\n    array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n\n    \"\"\"\n    image = image.astype(bool, order='C', copy=False)\n    if method not in {'zhang', 'lee', None}:\n        raise ValueError(\n            f'skeletonize method should be either \"lee\" or \"zhang\", got {method}.'\n            )\n    if image.ndim == 2 and (method is None or method == 'zhang'):\n        skeleton = _skeletonize_2d(image)\n    elif image.ndim == 3 and method == 'zhang':\n        raise ValueError('skeletonize method \"zhang\" only works for 2D images.'\n            )\n    elif image.ndim == 3 or image.ndim == 2 and method == 'lee':\n        skeleton = _skeletonize_3d(image)\n    else:\n        raise ValueError(\n            f'skeletonize requires a 2D or 3D image as input, got {image.ndim}D.'\n            )\n    return skeleton"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_niblack", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_niblack(image, window_size=15, k=0.2): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_niblack(image, window_size=15, k=0.2):\n    \"\"\"Applies Niblack local threshold to an array.\n\n    A threshold T is calculated for every pixel in the image using the\n    following formula::\n\n        T = m(x,y) - k * s(x,y)\n\n    where m(x,y) and s(x,y) are the mean and standard deviation of\n    pixel (x,y) neighborhood defined by a rectangular window with size w\n    times w centered around the pixel. k is a configurable parameter\n    that weights the effect of standard deviation.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray\n        Grayscale input image.\n    window_size : int, or iterable of int, optional\n        Window size specified as a single odd integer (3, 5, 7, \u2026),\n        or an iterable of length ``image.ndim`` containing only odd\n        integers (e.g. ``(1, 5, 5)``).\n    k : float, optional\n        Value of parameter k in threshold formula.\n\n    Returns\n    -------\n    threshold : (M, N[, ...]) ndarray\n        Threshold mask. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    Notes\n    -----\n    This algorithm is originally designed for text recognition.\n\n    The Bradley threshold is a particular case of the Niblack\n    one, being equivalent to\n\n    >>> from skimage import data\n    >>> image = data.page()\n    >>> q = 1\n    >>> threshold_image = threshold_niblack(image, k=0) * q\n\n    for some value ``q``. By default, Bradley and Roth use ``q=1``.\n\n\n    References\n    ----------\n    .. [1] W. Niblack, An introduction to Digital Image Processing,\n           Prentice-Hall, 1986.\n    .. [2] D. Bradley and G. Roth, \"Adaptive thresholding using Integral\n           Image\", Journal of Graphics Tools 12(2), pp. 13-21, 2007.\n           :DOI:`10.1080/2151237X.2007.10129236`\n\n    Examples\n    --------\n    >>> from skimage import data\n    >>> image = data.page()\n    >>> threshold_image = threshold_niblack(image, window_size=7, k=0.1)\n    \"\"\"\n    m, s = _mean_std(image, window_size)\n    return m - k * s"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "morphological_geodesic_active_contour", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/morphsnakes.py", "method_code_mask": "from itertools import cycle\nimport numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef morphological_geodesic_active_contour(gimage, num_iter, init_level_set=\n    'disk', smoothing=1, threshold='auto', balloon=0, iter_callback=lambda\n    x: None): [MASK]\n", "response": "from itertools import cycle\nimport numpy as np\nfrom scipy import ndimage as ndi\ndef morphological_geodesic_active_contour(gimage, num_iter, init_level_set=\n    'disk', smoothing=1, threshold='auto', balloon=0, iter_callback=lambda\n    x: None):\n    \"\"\"Morphological Geodesic Active Contours (MorphGAC).\n\n    Geodesic active contours implemented with morphological operators. It can\n    be used to segment objects with visible but noisy, cluttered, broken\n    borders.\n\n    Parameters\n    ----------\n    gimage : (M, N) or (L, M, N) array\n        Preprocessed image or volume to be segmented. This is very rarely the\n        original image. Instead, this is usually a preprocessed version of the\n        original image that enhances and highlights the borders (or other\n        structures) of the object to segment.\n        :func:`morphological_geodesic_active_contour` will try to stop the contour\n        evolution in areas where `gimage` is small. See\n        :func:`inverse_gaussian_gradient` as an example function to\n        perform this preprocessing. Note that the quality of\n        :func:`morphological_geodesic_active_contour` might greatly depend on this\n        preprocessing.\n    num_iter : uint\n        Number of num_iter to run.\n    init_level_set : str, (M, N) array, or (L, M, N) array\n        Initial level set. If an array is given, it will be binarized and used\n        as the initial level set. If a string is given, it defines the method\n        to generate a reasonable initial level set with the shape of the\n        `image`. Accepted values are 'checkerboard' and 'disk'. See the\n        documentation of `checkerboard_level_set` and `disk_level_set`\n        respectively for details about how these level sets are created.\n    smoothing : uint, optional\n        Number of times the smoothing operator is applied per iteration.\n        Reasonable values are around 1-4. Larger values lead to smoother\n        segmentations.\n    threshold : float, optional\n        Areas of the image with a value smaller than this threshold will be\n        considered borders. The evolution of the contour will stop in these\n        areas.\n    balloon : float, optional\n        Balloon force to guide the contour in non-informative areas of the\n        image, i.e., areas where the gradient of the image is too small to push\n        the contour towards a border. A negative value will shrink the contour,\n        while a positive value will expand the contour in these areas. Setting\n        this to zero will disable the balloon force.\n    iter_callback : function, optional\n        If given, this function is called once per iteration with the current\n        level set as the only argument. This is useful for debugging or for\n        plotting intermediate results during the evolution.\n\n    Returns\n    -------\n    out : (M, N) or (L, M, N) array\n        Final segmentation (i.e., the final level set)\n\n    See Also\n    --------\n    inverse_gaussian_gradient, disk_level_set, checkerboard_level_set\n\n    Notes\n    -----\n    This is a version of the Geodesic Active Contours (GAC) algorithm that uses\n    morphological operators instead of solving partial differential equations\n    (PDEs) for the evolution of the contour. The set of morphological operators\n    used in this algorithm are proved to be infinitesimally equivalent to the\n    GAC PDEs (see [1]_). However, morphological operators are do not suffer\n    from the numerical stability issues typically found in PDEs (e.g., it is\n    not necessary to find the right time step for the evolution), and are\n    computationally faster.\n\n    The algorithm and its theoretical derivation are described in [1]_.\n\n    References\n    ----------\n    .. [1] A Morphological Approach to Curvature-based Evolution of Curves and\n           Surfaces, Pablo M\u00e1rquez-Neila, Luis Baumela, Luis \u00c1lvarez. In IEEE\n           Transactions on Pattern Analysis and Machine Intelligence (PAMI),\n           2014, :DOI:`10.1109/TPAMI.2013.106`\n    \"\"\"\n    image = gimage\n    init_level_set = _init_level_set(init_level_set, image.shape)\n    _check_input(image, init_level_set)\n    if threshold == 'auto':\n        threshold = np.percentile(image, 40)\n    structure = np.ones((3,) * len(image.shape), dtype=np.int8)\n    dimage = np.gradient(image)\n    if balloon != 0:\n        threshold_mask_balloon = image > threshold / np.abs(balloon)\n    u = np.int8(init_level_set > 0)\n    iter_callback(u)\n    for _ in range(num_iter):\n        if balloon > 0:\n            aux = ndi.binary_dilation(u, structure)\n        elif balloon < 0:\n            aux = ndi.binary_erosion(u, structure)\n        if balloon != 0:\n            u[threshold_mask_balloon] = aux[threshold_mask_balloon]\n        aux = np.zeros_like(image)\n        du = np.gradient(u)\n        for el1, el2 in zip(dimage, du):\n            aux += el1 * el2\n        u[aux > 0] = 1\n        u[aux < 0] = 0\n        for _ in range(smoothing):\n            u = _curvop(u)\n        iter_callback(u)\n    return u"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "flood_fill", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/_flood_fill.py", "method_code_mask": "import numpy as np\n\n\ndef flood_fill(image, seed_point, new_value, *, footprint=None,\n    connectivity=None, tolerance=None, in_place=False): [MASK]\n", "response": "import numpy as np\ndef flood_fill(image, seed_point, new_value, *, footprint=None,\n    connectivity=None, tolerance=None, in_place=False):\n    \"\"\"Perform flood filling on an image.\n\n    Starting at a specific `seed_point`, connected points equal or within\n    `tolerance` of the seed value are found, then set to `new_value`.\n\n    Parameters\n    ----------\n    image : ndarray\n        An n-dimensional array.\n    seed_point : tuple or int\n        The point in `image` used as the starting point for the flood fill.  If\n        the image is 1D, this point may be given as an integer.\n    new_value : `image` type\n        New value to set the entire fill.  This must be chosen in agreement\n        with the dtype of `image`.\n    footprint : ndarray, optional\n        The footprint (structuring element) used to determine the neighborhood\n        of each evaluated pixel. It must contain only 1's and 0's, have the\n        same number of dimensions as `image`. If not given, all adjacent pixels\n        are considered as part of the neighborhood (fully connected).\n    connectivity : int, optional\n        A number used to determine the neighborhood of each evaluated pixel.\n        Adjacent pixels whose squared distance from the center is less than or\n        equal to `connectivity` are considered neighbors. Ignored if\n        `footprint` is not None.\n    tolerance : float or int, optional\n        If None (default), adjacent values must be strictly equal to the\n        value of `image` at `seed_point` to be filled.  This is fastest.\n        If a tolerance is provided, adjacent points with values within plus or\n        minus tolerance from the seed point are filled (inclusive).\n    in_place : bool, optional\n        If True, flood filling is applied to `image` in place.  If False, the\n        flood filled result is returned without modifying the input `image`\n        (default).\n\n    Returns\n    -------\n    filled : ndarray\n        An array with the same shape as `image` is returned, with values in\n        areas connected to and equal (or within tolerance of) the seed point\n        replaced with `new_value`.\n\n    Notes\n    -----\n    The conceptual analogy of this operation is the 'paint bucket' tool in many\n    raster graphics programs.\n\n    Examples\n    --------\n    >>> from skimage.morphology import flood_fill\n    >>> image = np.zeros((4, 7), dtype=int)\n    >>> image[1:3, 1:3] = 1\n    >>> image[3, 0] = 1\n    >>> image[1:3, 4:6] = 2\n    >>> image[3, 6] = 3\n    >>> image\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [0, 1, 1, 0, 2, 2, 0],\n           [1, 0, 0, 0, 0, 0, 3]])\n\n    Fill connected ones with 5, with full connectivity (diagonals included):\n\n    >>> flood_fill(image, (1, 1), 5)\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [5, 0, 0, 0, 0, 0, 3]])\n\n    Fill connected ones with 5, excluding diagonal points (connectivity 1):\n\n    >>> flood_fill(image, (1, 1), 5, connectivity=1)\n    array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [0, 5, 5, 0, 2, 2, 0],\n           [1, 0, 0, 0, 0, 0, 3]])\n\n    Fill with a tolerance:\n\n    >>> flood_fill(image, (0, 0), 5, tolerance=1)\n    array([[5, 5, 5, 5, 5, 5, 5],\n           [5, 5, 5, 5, 2, 2, 5],\n           [5, 5, 5, 5, 2, 2, 5],\n           [5, 5, 5, 5, 5, 5, 3]])\n    \"\"\"\n    mask = flood(image, seed_point, footprint=footprint, connectivity=\n        connectivity, tolerance=tolerance)\n    if not in_place:\n        image = image.copy()\n    image[mask] = new_value\n    return image"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "morphological_chan_vese", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/morphsnakes.py", "method_code_mask": "from itertools import cycle\nimport numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef morphological_chan_vese(image, num_iter, init_level_set='checkerboard',\n    smoothing=1, lambda1=1, lambda2=1, iter_callback=lambda x: None): [MASK]\n", "response": "from itertools import cycle\nimport numpy as np\nfrom scipy import ndimage as ndi\ndef morphological_chan_vese(image, num_iter, init_level_set='checkerboard',\n    smoothing=1, lambda1=1, lambda2=1, iter_callback=lambda x: None):\n    \"\"\"Morphological Active Contours without Edges (MorphACWE)\n\n    Active contours without edges implemented with morphological operators. It\n    can be used to segment objects in images and volumes without well defined\n    borders. It is required that the inside of the object looks different on\n    average than the outside (i.e., the inner area of the object should be\n    darker or lighter than the outer area on average).\n\n    Parameters\n    ----------\n    image : (M, N) or (L, M, N) array\n        Grayscale image or volume to be segmented.\n    num_iter : uint\n        Number of num_iter to run\n    init_level_set : str, (M, N) array, or (L, M, N) array\n        Initial level set. If an array is given, it will be binarized and used\n        as the initial level set. If a string is given, it defines the method\n        to generate a reasonable initial level set with the shape of the\n        `image`. Accepted values are 'checkerboard' and 'disk'. See the\n        documentation of `checkerboard_level_set` and `disk_level_set`\n        respectively for details about how these level sets are created.\n    smoothing : uint, optional\n        Number of times the smoothing operator is applied per iteration.\n        Reasonable values are around 1-4. Larger values lead to smoother\n        segmentations.\n    lambda1 : float, optional\n        Weight parameter for the outer region. If `lambda1` is larger than\n        `lambda2`, the outer region will contain a larger range of values than\n        the inner region.\n    lambda2 : float, optional\n        Weight parameter for the inner region. If `lambda2` is larger than\n        `lambda1`, the inner region will contain a larger range of values than\n        the outer region.\n    iter_callback : function, optional\n        If given, this function is called once per iteration with the current\n        level set as the only argument. This is useful for debugging or for\n        plotting intermediate results during the evolution.\n\n    Returns\n    -------\n    out : (M, N) or (L, M, N) array\n        Final segmentation (i.e., the final level set)\n\n    See Also\n    --------\n    disk_level_set, checkerboard_level_set\n\n    Notes\n    -----\n    This is a version of the Chan-Vese algorithm that uses morphological\n    operators instead of solving a partial differential equation (PDE) for the\n    evolution of the contour. The set of morphological operators used in this\n    algorithm are proved to be infinitesimally equivalent to the Chan-Vese PDE\n    (see [1]_). However, morphological operators are do not suffer from the\n    numerical stability issues typically found in PDEs (it is not necessary to\n    find the right time step for the evolution), and are computationally\n    faster.\n\n    The algorithm and its theoretical derivation are described in [1]_.\n\n    References\n    ----------\n    .. [1] A Morphological Approach to Curvature-based Evolution of Curves and\n           Surfaces, Pablo M\u00e1rquez-Neila, Luis Baumela, Luis \u00c1lvarez. In IEEE\n           Transactions on Pattern Analysis and Machine Intelligence (PAMI),\n           2014, :DOI:`10.1109/TPAMI.2013.106`\n    \"\"\"\n    init_level_set = _init_level_set(init_level_set, image.shape)\n    _check_input(image, init_level_set)\n    u = np.int8(init_level_set > 0)\n    iter_callback(u)\n    for _ in range(num_iter):\n        c0 = (image * (1 - u)).sum() / float((1 - u).sum() + 1e-08)\n        c1 = (image * u).sum() / float(u.sum() + 1e-08)\n        du = np.gradient(u)\n        abs_du = np.abs(du).sum(0)\n        aux = abs_du * (lambda1 * (image - c1) ** 2 - lambda2 * (image - c0\n            ) ** 2)\n        u[aux < 0] = 1\n        u[aux > 0] = 0\n        for _ in range(smoothing):\n            u = _curvop(u)\n        iter_callback(u)\n    return u"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "invert", "method_path": "../srcdata/Computation/scikit-image/skimage/util/_invert.py", "method_code_mask": "import numpy as np\n\n\ndef invert(image, signed_float=False): [MASK]\n", "response": "import numpy as np\ndef invert(image, signed_float=False):\n    \"\"\"Invert an image.\n\n    Invert the intensity range of the input image, so that the dtype maximum\n    is now the dtype minimum, and vice-versa. This operation is\n    slightly different depending on the input dtype:\n\n    - unsigned integers: subtract the image from the dtype maximum\n    - signed integers: subtract the image from -1 (see Notes)\n    - floats: subtract the image from 1 (if signed_float is False, so we\n      assume the image is unsigned), or from 0 (if signed_float is True).\n\n    See the examples for clarification.\n\n    Parameters\n    ----------\n    image : ndarray\n        Input image.\n    signed_float : bool, optional\n        If True and the image is of type float, the range is assumed to\n        be [-1, 1]. If False and the image is of type float, the range is\n        assumed to be [0, 1].\n\n    Returns\n    -------\n    inverted : ndarray\n        Inverted image.\n\n    Notes\n    -----\n    Ideally, for signed integers we would simply multiply by -1. However,\n    signed integer ranges are asymmetric. For example, for np.int8, the range\n    of possible values is [-128, 127], so that -128 * -1 equals -128! By\n    subtracting from -1, we correctly map the maximum dtype value to the\n    minimum.\n\n    Examples\n    --------\n    >>> img = np.array([[100,  0, 200],\n    ...                 [  0, 50,   0],\n    ...                 [ 30,  0, 255]], np.uint8)\n    >>> invert(img)\n    array([[155, 255,  55],\n           [255, 205, 255],\n           [225, 255,   0]], dtype=uint8)\n    >>> img2 = np.array([[ -2, 0, -128],\n    ...                  [127, 0,    5]], np.int8)\n    >>> invert(img2)\n    array([[   1,   -1,  127],\n           [-128,   -1,   -6]], dtype=int8)\n    >>> img3 = np.array([[ 0., 1., 0.5, 0.75]])\n    >>> invert(img3)\n    array([[1.  , 0.  , 0.5 , 0.25]])\n    >>> img4 = np.array([[ 0., 1., -1., -0.25]])\n    >>> invert(img4, signed_float=True)\n    array([[-0.  , -1.  ,  1.  ,  0.25]])\n    \"\"\"\n    if image.dtype == 'bool':\n        inverted = ~image\n    elif np.issubdtype(image.dtype, np.unsignedinteger):\n        max_val = dtype_limits(image, clip_negative=False)[1]\n        inverted = np.subtract(max_val, image, dtype=image.dtype)\n    elif np.issubdtype(image.dtype, np.signedinteger):\n        inverted = np.subtract(-1, image, dtype=image.dtype)\n    elif signed_float:\n        inverted = -image\n    else:\n        inverted = np.subtract(1, image, dtype=image.dtype)\n    return inverted"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_sin_flow_gen", "method_path": "../srcdata/Computation/scikit-image/skimage/registration/tests/test_tvl1.py", "method_code_mask": "import numpy as np\nimport pytest\nfrom skimage.registration import optical_flow_tvl1\nfrom skimage.transform import warp\n\n\ndef _sin_flow_gen(image0, max_motion=4.5, npics=5): [MASK]\n", "response": "import numpy as np\nimport pytest\nfrom skimage.registration import optical_flow_tvl1\nfrom skimage.transform import warp\ndef _sin_flow_gen(image0, max_motion=4.5, npics=5):\n    \"\"\"Generate a synthetic ground truth optical flow with a sinusoid as\n      first component.\n\n    Parameters\n    ----------\n    image0: ndarray\n        The base image to be warped.\n    max_motion: float\n        Maximum flow magnitude.\n    npics: int\n        Number of sinusoid pics.\n\n    Returns\n    -------\n    flow, image1 : ndarray\n        The synthetic ground truth optical flow with a sinusoid as\n        first component and the corresponding warped image.\n\n    \"\"\"\n    grid = np.meshgrid(*[np.arange(n) for n in image0.shape], indexing='ij')\n    grid = np.stack(grid)\n    gt_flow = np.zeros_like(grid, dtype=float)\n    gt_flow[0, ...] = max_motion * np.sin(grid[0] / grid[0].max() * npics *\n        np.pi)\n    image1 = warp(image0, grid - gt_flow, mode='edge')\n    return gt_flow, image1"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_triangle", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_triangle(image, nbins=256): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_triangle(image, nbins=256):\n    \"\"\"Return threshold value based on the triangle algorithm.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray\n        Grayscale input image.\n    nbins : int, optional\n        Number of bins used to calculate histogram. This value is ignored for\n        integer arrays.\n\n    Returns\n    -------\n    threshold : float\n        Upper threshold value. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    References\n    ----------\n    .. [1] Zack, G. W., Rogers, W. E. and Latt, S. A., 1977,\n       Automatic Measurement of Sister Chromatid Exchange Frequency,\n       Journal of Histochemistry and Cytochemistry 25 (7), pp. 741-753\n       :DOI:`10.1177/25.7.70454`\n    .. [2] ImageJ AutoThresholder code,\n       http://fiji.sc/wiki/index.php/Auto_Threshold\n\n    Examples\n    --------\n    >>> from skimage.data import camera\n    >>> image = camera()\n    >>> thresh = threshold_triangle(image)\n    >>> binary = image > thresh\n    \"\"\"\n    hist, bin_centers = histogram(image.reshape(-1), nbins, source_range=\n        'image')\n    nbins = len(hist)\n    arg_peak_height = np.argmax(hist)\n    peak_height = hist[arg_peak_height]\n    arg_low_level, arg_high_level = np.flatnonzero(hist)[[0, -1]]\n    if arg_low_level == arg_high_level:\n        return image.ravel()[0]\n    flip = arg_peak_height - arg_low_level < arg_high_level - arg_peak_height\n    if flip:\n        hist = hist[::-1]\n        arg_low_level = nbins - arg_high_level - 1\n        arg_peak_height = nbins - arg_peak_height - 1\n    del arg_high_level\n    width = arg_peak_height - arg_low_level\n    x1 = np.arange(width)\n    y1 = hist[x1 + arg_low_level]\n    norm = np.sqrt(peak_height ** 2 + width ** 2)\n    peak_height /= norm\n    width /= norm\n    length = peak_height * x1 - width * y1\n    arg_level = np.argmax(length) + arg_low_level\n    if flip:\n        arg_level = nbins - arg_level - 1\n    return bin_centers[arg_level]"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_minimum", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_minimum(image=None, nbins=256, max_num_iter=10000, *, hist=None\n    ): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_minimum(image=None, nbins=256, max_num_iter=10000, *, hist=None):\n    \"\"\"Return threshold value based on minimum method.\n\n    The histogram of the input ``image`` is computed if not provided and\n    smoothed until there are only two maxima. Then the minimum in between is\n    the threshold value.\n\n    Either image or hist must be provided. In case hist is given, the actual\n    histogram of the image is ignored.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray, optional\n        Grayscale input image.\n    nbins : int, optional\n        Number of bins used to calculate histogram. This value is ignored for\n        integer arrays.\n    max_num_iter : int, optional\n        Maximum number of iterations to smooth the histogram.\n    hist : array, or 2-tuple of arrays, optional\n        Histogram to determine the threshold from and a corresponding array\n        of bin center intensities. Alternatively, only the histogram can be\n        passed.\n\n    Returns\n    -------\n    threshold : float\n        Upper threshold value. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    Raises\n    ------\n    RuntimeError\n        If unable to find two local maxima in the histogram or if the\n        smoothing takes more than 1e4 iterations.\n\n    References\n    ----------\n    .. [1] C. A. Glasbey, \"An analysis of histogram-based thresholding\n           algorithms,\" CVGIP: Graphical Models and Image Processing,\n           vol. 55, pp. 532-537, 1993.\n    .. [2] Prewitt, JMS & Mendelsohn, ML (1966), \"The analysis of cell\n           images\", Annals of the New York Academy of Sciences 128: 1035-1053\n           :DOI:`10.1111/j.1749-6632.1965.tb11715.x`\n\n    Examples\n    --------\n    >>> from skimage.data import camera\n    >>> image = camera()\n    >>> thresh = threshold_minimum(image)\n    >>> binary = image > thresh\n    \"\"\"\n\n    def find_local_maxima_idx(hist):\n        maximum_idxs = list()\n        direction = 1\n        for i in range(hist.shape[0] - 1):\n            if direction > 0:\n                if hist[i + 1] < hist[i]:\n                    direction = -1\n                    maximum_idxs.append(i)\n            elif hist[i + 1] > hist[i]:\n                direction = 1\n        return maximum_idxs\n    counts, bin_centers = _validate_image_histogram(image, hist, nbins)\n    smooth_hist = counts.astype('float32', copy=False)\n    for counter in range(max_num_iter):\n        smooth_hist = ndi.uniform_filter1d(smooth_hist, 3)\n        maximum_idxs = find_local_maxima_idx(smooth_hist)\n        if len(maximum_idxs) < 3:\n            break\n    if len(maximum_idxs) != 2:\n        raise RuntimeError('Unable to find two maxima in histogram')\n    elif counter == max_num_iter - 1:\n        raise RuntimeError('Maximum iteration reached for histogramsmoothing')\n    threshold_idx = np.argmin(smooth_hist[maximum_idxs[0]:maximum_idxs[1] + 1])\n    return bin_centers[maximum_idxs[0] + threshold_idx]"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "make_2d_syntheticdata", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/tests/test_random_walker.py", "method_code_mask": "import numpy as np\nfrom skimage._shared import testing\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.testing import xfail\nfrom skimage._shared.testing import arch32\nfrom skimage.segmentation import random_walker\nfrom skimage.transform import resize\nfrom skimage.segmentation import random_walker_segmentation\n\n\ndef make_2d_syntheticdata(lx, ly=None): [MASK]\n", "response": "import numpy as np\nfrom skimage._shared import testing\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.testing import xfail\nfrom skimage._shared.testing import arch32\nfrom skimage.segmentation import random_walker\nfrom skimage.transform import resize\nfrom skimage.segmentation import random_walker_segmentation\ndef make_2d_syntheticdata(lx, ly=None):\n    if ly is None:\n        ly = lx\n    np.random.seed(1234)\n    data = np.zeros((lx, ly)) + 0.1 * np.random.randn(lx, ly)\n    small_l = int(lx // 5)\n    data[lx // 2 - small_l:lx // 2 + small_l, ly // 2 - small_l:ly // 2 +\n        small_l] = 1\n    data[lx // 2 - small_l + 1:lx // 2 + small_l - 1, ly // 2 - small_l + 1\n        :ly // 2 + small_l - 1] = 0.1 * np.random.randn(2 * small_l - 2, 2 *\n        small_l - 2)\n    data[lx // 2 - small_l, ly // 2 - small_l // 8:ly // 2 + small_l // 8] = 0\n    seeds = np.zeros_like(data)\n    seeds[lx // 5, ly // 5] = 1\n    seeds[lx // 2 + small_l // 4, ly // 2 - small_l // 4] = 2\n    return data, seeds"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_masked_phase_cross_correlation", "method_path": "../srcdata/Computation/scikit-image/skimage/registration/_masked_phase_cross_correlation.py", "method_code_mask": "from functools import partial\nimport numpy as np\nimport scipy.fft as fftmodule\nfrom scipy.fft import next_fast_len\n\n\ndef _masked_phase_cross_correlation(reference_image, moving_image,\n    reference_mask, moving_mask=None, overlap_ratio=0.3): [MASK]\n", "response": "from functools import partial\nimport numpy as np\nimport scipy.fft as fftmodule\nfrom scipy.fft import next_fast_len\ndef _masked_phase_cross_correlation(reference_image, moving_image,\n    reference_mask, moving_mask=None, overlap_ratio=0.3):\n    \"\"\"Masked image translation registration by masked normalized\n    cross-correlation.\n\n    Parameters\n    ----------\n    reference_image : ndarray\n        Reference image.\n    moving_image : ndarray\n        Image to register. Must be same dimensionality as ``reference_image``,\n        but not necessarily the same size.\n    reference_mask : ndarray\n        Boolean mask for ``reference_image``. The mask should evaluate\n        to ``True`` (or 1) on valid pixels. ``reference_mask`` should\n        have the same shape as ``reference_image``.\n    moving_mask : ndarray or None, optional\n        Boolean mask for ``moving_image``. The mask should evaluate to ``True``\n        (or 1) on valid pixels. ``moving_mask`` should have the same shape\n        as ``moving_image``. If ``None``, ``reference_mask`` will be used.\n    overlap_ratio : float, optional\n        Minimum allowed overlap ratio between images. The correlation for\n        translations corresponding with an overlap ratio lower than this\n        threshold will be ignored. A lower `overlap_ratio` leads to smaller\n        maximum translation, while a higher `overlap_ratio` leads to greater\n        robustness against spurious matches due to small overlap between\n        masked images.\n\n    Returns\n    -------\n    shifts : ndarray\n        Shift vector (in pixels) required to register ``moving_image``\n        with ``reference_image``. Axis ordering is consistent with numpy.\n\n    References\n    ----------\n    .. [1] Dirk Padfield. Masked Object Registration in the Fourier Domain.\n           IEEE Transactions on Image Processing, vol. 21(5),\n           pp. 2706-2718 (2012). :DOI:`10.1109/TIP.2011.2181402`\n    .. [2] D. Padfield. \"Masked FFT registration\". In Proc. Computer Vision and\n           Pattern Recognition, pp. 2918-2925 (2010).\n           :DOI:`10.1109/CVPR.2010.5540032`\n\n    \"\"\"\n    if moving_mask is None:\n        if reference_image.shape != moving_image.shape:\n            raise ValueError(\n                'Input images have different shapes, moving_mask must be explicitly set.'\n                )\n        moving_mask = reference_mask.astype(bool)\n    for im, mask in [(reference_image, reference_mask), (moving_image,\n        moving_mask)]:\n        if im.shape != mask.shape:\n            raise ValueError(\n                'Image sizes must match their respective mask sizes.')\n    xcorr = cross_correlate_masked(moving_image, reference_image,\n        moving_mask, reference_mask, axes=tuple(range(moving_image.ndim)),\n        mode='full', overlap_ratio=overlap_ratio)\n    maxima = np.stack(np.nonzero(xcorr == xcorr.max()), axis=1)\n    center = np.mean(maxima, axis=0)\n    shifts = center - np.array(reference_image.shape) + 1\n    size_mismatch = np.array(moving_image.shape) - np.array(reference_image\n        .shape)\n    return -shifts + size_mismatch / 2"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "ball", "method_path": "../srcdata/Computation/scikit-image/skimage/morphology/footprints.py", "method_code_mask": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\n\n\ndef ball(radius, dtype=np.uint8, *, strict_radius=True, decomposition=None): [M\n    ASK]\n", "response": "import os\nfrom collections.abc import Sequence\nfrom numbers import Integral\nimport numpy as np\nfrom skimage import morphology\ndef ball(radius, dtype=np.uint8, *, strict_radius=True, decomposition=None):\n    \"\"\"Generates a ball-shaped footprint.\n\n    This is the 3D equivalent of a disk.\n    A pixel is within the neighborhood if the Euclidean distance between\n    it and the origin is no greater than radius.\n\n    Parameters\n    ----------\n    radius : int\n        The radius of the ball-shaped footprint.\n\n    Other Parameters\n    ----------------\n    dtype : data-type, optional\n        The data type of the footprint.\n    strict_radius : bool, optional\n        If False, extend the radius by 0.5. This allows the circle to expand\n        further within a cube that remains of size ``2 * radius + 1`` along\n        each axis. This parameter is ignored if decomposition is not None.\n    decomposition : {None, 'sequence'}, optional\n        If None, a single array is returned. For 'sequence', a tuple of smaller\n        footprints is returned. Applying this series of smaller footprints will\n        given a result equivalent to a single, larger footprint, but with\n        better computational performance. For ball footprints, the sequence\n        decomposition is not exactly equivalent to decomposition=None.\n        See Notes for more details.\n\n    Returns\n    -------\n    footprint : ndarray or tuple\n        The footprint where elements of the neighborhood are 1 and 0 otherwise.\n\n    Notes\n    -----\n    The disk produced by the decomposition='sequence' mode is not identical\n    to that with decomposition=None. Here we extend the approach taken in [1]_\n    for disks to the 3D case, using 3-dimensional extensions of the \"square\",\n    \"diamond\" and \"t-shaped\" elements from that publication. All of these\n    elementary elements have size ``(3,) * ndim``. We numerically computed the\n    number of repetitions of each element that gives the closest match to the\n    ball computed with kwargs ``strict_radius=False, decomposition=None``.\n\n    Empirically, the equivalent composite footprint to the sequence\n    decomposition approaches a rhombicuboctahedron (26-faces [2]_).\n\n    References\n    ----------\n    .. [1] Park, H and Chin R.T. Decomposition of structuring elements for\n           optimal implementation of morphological operations. In Proceedings:\n           1997 IEEE Workshop on Nonlinear Signal and Image Processing, London,\n           UK.\n           https://www.iwaenc.org/proceedings/1997/nsip97/pdf/scan/ns970226.pdf\n    .. [2] https://en.wikipedia.org/wiki/Rhombicuboctahedron\n    \"\"\"\n    if decomposition is None:\n        n = 2 * radius + 1\n        Z, Y, X = np.mgrid[-radius:radius:n * 1.0j, -radius:radius:n * 1.0j,\n            -radius:radius:n * 1.0j]\n        s = X ** 2 + Y ** 2 + Z ** 2\n        if not strict_radius:\n            radius += 0.5\n        return np.array(s <= radius * radius, dtype=dtype)\n    elif decomposition == 'sequence':\n        sequence = _nsphere_series_decomposition(radius, ndim=3, dtype=dtype)\n    else:\n        raise ValueError(f'Unrecognized decomposition: {decomposition}')\n    return sequence"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "alphanumeric_key", "method_path": "../srcdata/Computation/scikit-image/skimage/io/collection.py", "method_code_mask": "import os\nfrom glob import glob\nimport re\nfrom collections.abc import Sequence\nfrom copy import copy\nimport numpy as np\nfrom PIL import Image\nfrom tifffile import TiffFile\n\n\ndef alphanumeric_key(s): [MASK]\n", "response": "import os\nfrom glob import glob\nimport re\nfrom collections.abc import Sequence\nfrom copy import copy\nimport numpy as np\nfrom PIL import Image\nfrom tifffile import TiffFile\ndef alphanumeric_key(s):\n    \"\"\"Convert string to list of strings and ints that gives intuitive sorting.\n\n    Parameters\n    ----------\n    s : string\n\n    Returns\n    -------\n    k : a list of strings and ints\n\n    Examples\n    --------\n    >>> alphanumeric_key('z23a')\n    ['z', 23, 'a']\n    >>> filenames = ['f9.10.png', 'e10.png', 'f9.9.png', 'f10.10.png',\n    ...              'f10.9.png']\n    >>> sorted(filenames)\n    ['e10.png', 'f10.10.png', 'f10.9.png', 'f9.10.png', 'f9.9.png']\n    >>> sorted(filenames, key=alphanumeric_key)\n    ['e10.png', 'f9.9.png', 'f9.10.png', 'f10.9.png', 'f10.10.png']\n    \"\"\"\n    k = [(int(c) if c.isdigit() else c) for c in re.split('([0-9]+)', s)]\n    return k"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_same_mesh", "method_path": "../srcdata/Computation/scikit-image/skimage/measure/tests/test_marching_cubes.py", "method_code_mask": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom skimage.draw import ellipsoid\nfrom skimage.draw import ellipsoid_stats\nfrom skimage.measure import marching_cubes\nfrom skimage.measure import mesh_surface_area\n\n\ndef _same_mesh(vertices1, faces1, vertices2, faces2, tol=1e-10): [MASK]\n", "response": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom skimage.draw import ellipsoid\nfrom skimage.draw import ellipsoid_stats\nfrom skimage.measure import marching_cubes\nfrom skimage.measure import mesh_surface_area\ndef _same_mesh(vertices1, faces1, vertices2, faces2, tol=1e-10):\n    \"\"\"Compare two meshes, using a certain tolerance and invariant to\n    the order of the faces.\n    \"\"\"\n    triangles1 = vertices1[np.array(faces1)]\n    triangles2 = vertices2[np.array(faces2)]\n    triang1 = [np.concatenate(sorted(t, key=lambda x: tuple(x))) for t in\n        triangles1]\n    triang2 = [np.concatenate(sorted(t, key=lambda x: tuple(x))) for t in\n        triangles2]\n    triang1 = np.array(sorted([tuple(x) for x in triang1]))\n    triang2 = np.array(sorted([tuple(x) for x in triang2]))\n    return triang1.shape == triang2.shape and np.allclose(triang1, triang2,\n        0, tol)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_palette_is_grayscale", "method_path": "../srcdata/Computation/scikit-image/skimage/io/_plugins/pil_plugin.py", "method_code_mask": "import numpy as np\nfrom PIL import Image\n\n\ndef _palette_is_grayscale(pil_image): [MASK]\n", "response": "import numpy as np\nfrom PIL import Image\ndef _palette_is_grayscale(pil_image):\n    \"\"\"Return True if PIL image in palette mode is grayscale.\n\n    Parameters\n    ----------\n    pil_image : PIL image\n        PIL Image that is in Palette mode.\n\n    Returns\n    -------\n    is_grayscale : bool\n        True if all colors in image palette are gray.\n    \"\"\"\n    if pil_image.mode != 'P':\n        raise ValueError('pil_image.mode must be equal to \"P\".')\n    palette = np.asarray(pil_image.getpalette()).reshape((-1, 3))\n    start, stop = pil_image.getextrema()\n    valid_palette = palette[start:stop + 1]\n    return np.allclose(np.diff(valid_palette), 0)"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "intensity_range", "method_path": "../srcdata/Computation/scikit-image/skimage/exposure/exposure.py", "method_code_mask": "import numpy as np\n\n\ndef intensity_range(image, range_values='image', clip_negative=False): [MASK]\n", "response": "import numpy as np\ndef intensity_range(image, range_values='image', clip_negative=False):\n    \"\"\"Return image intensity range (min, max) based on desired value type.\n\n    Parameters\n    ----------\n    image : array\n        Input image.\n    range_values : str or 2-tuple, optional\n        The image intensity range is configured by this parameter.\n        The possible values for this parameter are enumerated below.\n\n        'image'\n            Return image min/max as the range.\n        'dtype'\n            Return min/max of the image's dtype as the range.\n        dtype-name\n            Return intensity range based on desired `dtype`. Must be valid key\n            in `DTYPE_RANGE`. Note: `image` is ignored for this range type.\n        2-tuple\n            Return `range_values` as min/max intensities. Note that there's no\n            reason to use this function if you just want to specify the\n            intensity range explicitly. This option is included for functions\n            that use `intensity_range` to support all desired range types.\n\n    clip_negative : bool, optional\n        If True, clip the negative range (i.e. return 0 for min intensity)\n        even if the image dtype allows negative values.\n    \"\"\"\n    if range_values == 'dtype':\n        range_values = image.dtype.type\n    if range_values == 'image':\n        i_min = np.min(image)\n        i_max = np.max(image)\n    elif range_values in DTYPE_RANGE:\n        i_min, i_max = DTYPE_RANGE[range_values]\n        if clip_negative:\n            i_min = 0\n    else:\n        i_min, i_max = range_values\n    return i_min, i_max"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "clear_border", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/_clear_border.py", "method_code_mask": "import numpy as np\n\n\ndef clear_border(labels, buffer_size=0, bgval=0, mask=None, *, out=None): [MASK\n    ]\n", "response": "import numpy as np\ndef clear_border(labels, buffer_size=0, bgval=0, mask=None, *, out=None):\n    \"\"\"Clear objects connected to the label image border.\n\n    Parameters\n    ----------\n    labels : (M[, N[, ..., P]]) array of int or bool\n        Imaging data labels.\n    buffer_size : int, optional\n        The width of the border examined.  By default, only objects\n        that touch the outside of the image are removed.\n    bgval : float or int, optional\n        Cleared objects are set to this value.\n    mask : ndarray of bool, same shape as `image`, optional.\n        Image data mask. Objects in labels image overlapping with\n        False pixels of mask will be removed. If defined, the\n        argument buffer_size will be ignored.\n    out : ndarray\n        Array of the same shape as `labels`, into which the\n        output is placed. By default, a new array is created.\n\n    Returns\n    -------\n    out : (M[, N[, ..., P]]) array\n        Imaging data labels with cleared borders\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from skimage.segmentation import clear_border\n    >>> labels = np.array([[0, 0, 0, 0, 0, 0, 0, 1, 0],\n    ...                    [1, 1, 0, 0, 1, 0, 0, 1, 0],\n    ...                    [1, 1, 0, 1, 0, 1, 0, 0, 0],\n    ...                    [0, 0, 0, 1, 1, 1, 1, 0, 0],\n    ...                    [0, 1, 1, 1, 1, 1, 1, 1, 0],\n    ...                    [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n    >>> clear_border(labels)\n    array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 0, 1, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 1, 1, 1, 1, 1, 1, 1, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n    >>> mask = np.array([[0, 0, 1, 1, 1, 1, 1, 1, 1],\n    ...                  [0, 0, 1, 1, 1, 1, 1, 1, 1],\n    ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1],\n    ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1],\n    ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1],\n    ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1]]).astype(bool)\n    >>> clear_border(labels, mask=mask)\n    array([[0, 0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 1, 0, 0, 1, 0],\n           [0, 0, 0, 1, 0, 1, 0, 0, 0],\n           [0, 0, 0, 1, 1, 1, 1, 0, 0],\n           [0, 1, 1, 1, 1, 1, 1, 1, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n\n    \"\"\"\n    if any(buffer_size >= s for s in labels.shape) and mask is None:\n        raise ValueError('buffer size may not be greater than labels size')\n    if out is None:\n        out = labels.copy()\n    if mask is not None:\n        err_msg = (\n            f'labels and mask should have the same shape but are {out.shape} and {mask.shape}'\n            )\n        if out.shape != mask.shape:\n            raise (ValueError, err_msg)\n        if mask.dtype != bool:\n            raise TypeError('mask should be of type bool.')\n        borders = ~mask\n    else:\n        borders = np.zeros_like(out, dtype=bool)\n        ext = buffer_size + 1\n        slstart = slice(ext)\n        slend = slice(-ext, None)\n        slices = [slice(None) for _ in out.shape]\n        for d in range(out.ndim):\n            slices[d] = slstart\n            borders[tuple(slices)] = True\n            slices[d] = slend\n            borders[tuple(slices)] = True\n            slices[d] = slice(None)\n    labels, number = label(out, background=0, return_num=True)\n    borders_indices = np.unique(labels[borders])\n    indices = np.arange(number + 1)\n    label_mask = np.isin(indices, borders_indices)\n    mask = label_mask[labels.reshape(-1)].reshape(labels.shape)\n    out[mask] = bgval\n    return out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_multiotsu", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_multiotsu(image=None, classes=3, nbins=256, *, hist=None): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_multiotsu(image=None, classes=3, nbins=256, *, hist=None):\n    \"\"\"Generate `classes`-1 threshold values to divide gray levels in `image`,\n    following Otsu's method for multiple classes.\n\n    The threshold values are chosen to maximize the total sum of pairwise\n    variances between the thresholded graylevel classes. See Notes and [1]_\n    for more details.\n\n    Either image or hist must be provided. If hist is provided, the actual\n    histogram of the image is ignored.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray, optional\n        Grayscale input image.\n    classes : int, optional\n        Number of classes to be thresholded, i.e. the number of resulting\n        regions.\n    nbins : int, optional\n        Number of bins used to calculate the histogram. This value is ignored\n        for integer arrays.\n    hist : array, or 2-tuple of arrays, optional\n        Histogram from which to determine the threshold, and optionally a\n        corresponding array of bin center intensities. If no hist provided,\n        this function will compute it from the image (see notes).\n\n    Returns\n    -------\n    thresh : array\n        Array containing the threshold values for the desired classes.\n\n    Raises\n    ------\n    ValueError\n         If ``image`` contains less grayscale value then the desired\n         number of classes.\n\n    Notes\n    -----\n    This implementation relies on a Cython function whose complexity\n    is :math:`O\\\\left(\\\\frac{Ch^{C-1}}{(C-1)!}\\\\right)`, where :math:`h`\n    is the number of histogram bins and :math:`C` is the number of\n    classes desired.\n\n    If no hist is given, this function will make use of\n    `skimage.exposure.histogram`, which behaves differently than\n    `np.histogram`. While both allowed, use the former for consistent\n    behaviour.\n\n    The input image must be grayscale.\n\n    References\n    ----------\n    .. [1] Liao, P-S., Chen, T-S. and Chung, P-C., \"A fast algorithm for\n           multilevel thresholding\", Journal of Information Science and\n           Engineering 17 (5): 713-727, 2001. Available at:\n           <https://ftp.iis.sinica.edu.tw/JISE/2001/200109_01.pdf>\n           :DOI:`10.6688/JISE.2001.17.5.1`\n    .. [2] Tosa, Y., \"Multi-Otsu Threshold\", a java plugin for ImageJ.\n           Available at:\n           <http://imagej.net/plugins/download/Multi_OtsuThreshold.java>\n\n    Examples\n    --------\n    >>> from skimage.color import label2rgb\n    >>> from skimage import data\n    >>> image = data.camera()\n    >>> thresholds = threshold_multiotsu(image)\n    >>> regions = np.digitize(image, bins=thresholds)\n    >>> regions_colorized = label2rgb(regions)\n    \"\"\"\n    if image is not None and image.ndim > 2 and image.shape[-1] in (3, 4):\n        warn(\n            f'threshold_multiotsu is expected to work correctly only for grayscale images; image shape {image.shape} looks like that of an RGB image.'\n            )\n    prob, bin_centers = _validate_image_histogram(image, hist, nbins,\n        normalize=True)\n    prob = prob.astype('float32', copy=False)\n    nvalues = np.count_nonzero(prob)\n    if nvalues < classes:\n        msg = (\n            f'After discretization into bins, the input image has only {nvalues} different values. It cannot be thresholded in {classes} classes. If there are more unique values before discretization, try increasing the number of bins (`nbins`).'\n            )\n        raise ValueError(msg)\n    elif nvalues == classes:\n        thresh_idx = np.flatnonzero(prob)[:-1]\n    else:\n        try:\n            thresh_idx = _get_multiotsu_thresh_indices_lut(prob, classes - 1)\n        except MemoryError:\n            thresh_idx = _get_multiotsu_thresh_indices(prob, classes - 1)\n    thresh = bin_centers[thresh_idx]\n    return thresh"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "norm_brightness_err", "method_path": "../srcdata/Computation/scikit-image/skimage/exposure/tests/test_exposure.py", "method_code_mask": "import warnings\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom packaging.version import Version\nfrom skimage import data\nfrom skimage import exposure\nfrom skimage import util\nfrom skimage.color import rgb2gray\nfrom skimage.exposure.exposure import intensity_range\nfrom skimage.util.dtype import dtype_range\nfrom skimage._shared._warnings import expected_warnings\nimport dask.array as da\n\n\ndef norm_brightness_err(img1, img2): [MASK]\n", "response": "import warnings\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom packaging.version import Version\nfrom skimage import data\nfrom skimage import exposure\nfrom skimage import util\nfrom skimage.color import rgb2gray\nfrom skimage.exposure.exposure import intensity_range\nfrom skimage.util.dtype import dtype_range\nfrom skimage._shared._warnings import expected_warnings\nimport dask.array as da\ndef norm_brightness_err(img1, img2):\n    \"\"\"Normalized Absolute Mean Brightness Error between two images\n\n    Parameters\n    ----------\n    img1 : array-like\n    img2 : array-like\n\n    Returns\n    -------\n    norm_brightness_error : float\n        Normalized absolute mean brightness error\n    \"\"\"\n    if img1.ndim == 3:\n        img1, img2 = rgb2gray(img1), rgb2gray(img2)\n    ambe = np.abs(img1.mean() - img2.mean())\n    nbe = ambe / dtype_range[img1.dtype.type][1]\n    return nbe"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "resize", "method_path": "../srcdata/Computation/scikit-image/skimage/transform/_warps.py", "method_code_mask": "import numpy as np\nfrom scipy import ndimage as ndi\n\n\ndef resize(image, output_shape, order=None, mode='reflect', cval=0, clip=\n    True, preserve_range=False, anti_aliasing=None, anti_aliasing_sigma=None\n    ): [MASK]\n", "response": "import numpy as np\nfrom scipy import ndimage as ndi\ndef resize(image, output_shape, order=None, mode='reflect', cval=0, clip=\n    True, preserve_range=False, anti_aliasing=None, anti_aliasing_sigma=None):\n    \"\"\"Resize image to match a certain size.\n\n    Performs interpolation to up-size or down-size N-dimensional images. Note\n    that anti-aliasing should be enabled when down-sizing images to avoid\n    aliasing artifacts. For downsampling with an integer factor also see\n    `skimage.transform.downscale_local_mean`.\n\n    Parameters\n    ----------\n    image : ndarray\n        Input image.\n    output_shape : iterable\n        Size of the generated output image `(rows, cols[, ...][, dim])`. If\n        `dim` is not provided, the number of channels is preserved. In case the\n        number of input channels does not equal the number of output channels a\n        n-dimensional interpolation is applied.\n\n    Returns\n    -------\n    resized : ndarray\n        Resized version of the input.\n\n    Other parameters\n    ----------------\n    order : int, optional\n        The order of the spline interpolation, default is 0 if\n        image.dtype is bool and 1 otherwise. The order has to be in\n        the range 0-5. See `skimage.transform.warp` for detail.\n    mode : {'constant', 'edge', 'symmetric', 'reflect', 'wrap'}, optional\n        Points outside the boundaries of the input are filled according\n        to the given mode.  Modes match the behaviour of `numpy.pad`.\n    cval : float, optional\n        Used in conjunction with mode 'constant', the value outside\n        the image boundaries.\n    clip : bool, optional\n        Whether to clip the output to the range of values of the input image.\n        This is enabled by default, since higher order interpolation may\n        produce values outside the given input range.\n    preserve_range : bool, optional\n        Whether to keep the original range of values. Otherwise, the input\n        image is converted according to the conventions of `img_as_float`.\n        Also see https://scikit-image.org/docs/dev/user_guide/data_types.html\n    anti_aliasing : bool, optional\n        Whether to apply a Gaussian filter to smooth the image prior\n        to downsampling. It is crucial to filter when downsampling\n        the image to avoid aliasing artifacts. If not specified, it is set to\n        True when downsampling an image whose data type is not bool.\n        It is also set to False when using nearest neighbor interpolation\n        (``order`` == 0) with integer input data type.\n    anti_aliasing_sigma : {float, tuple of floats}, optional\n        Standard deviation for Gaussian filtering used when anti-aliasing.\n        By default, this value is chosen as (s - 1) / 2 where s is the\n        downsampling factor, where s > 1. For the up-size case, s < 1, no\n        anti-aliasing is performed prior to rescaling.\n\n    Notes\n    -----\n    Modes 'reflect' and 'symmetric' are similar, but differ in whether the edge\n    pixels are duplicated during the reflection.  As an example, if an array\n    has values [0, 1, 2] and was padded to the right by four values using\n    symmetric, the result would be [0, 1, 2, 2, 1, 0, 0], while for reflect it\n    would be [0, 1, 2, 1, 0, 1, 2].\n\n    Examples\n    --------\n    >>> from skimage import data\n    >>> from skimage.transform import resize\n    >>> image = data.camera()\n    >>> resize(image, (100, 100)).shape\n    (100, 100)\n\n    \"\"\"\n    image, output_shape = _preprocess_resize_output_shape(image, output_shape)\n    input_shape = image.shape\n    input_type = image.dtype\n    if input_type == np.float16:\n        image = image.astype(np.float32)\n    if anti_aliasing is None:\n        anti_aliasing = not input_type == bool and not (np.issubdtype(\n            input_type, np.integer) and order == 0) and any(x < y for x, y in\n            zip(output_shape, input_shape))\n    if input_type == bool and anti_aliasing:\n        raise ValueError('anti_aliasing must be False for boolean images')\n    factors = np.divide(input_shape, output_shape)\n    order = _validate_interpolation_order(input_type, order)\n    if order > 0:\n        image = convert_to_float(image, preserve_range)\n    ndi_mode = _to_ndimage_mode(mode)\n    if anti_aliasing:\n        if anti_aliasing_sigma is None:\n            anti_aliasing_sigma = np.maximum(0, (factors - 1) / 2)\n        else:\n            anti_aliasing_sigma = np.atleast_1d(anti_aliasing_sigma\n                ) * np.ones_like(factors)\n            if np.any(anti_aliasing_sigma < 0):\n                raise ValueError(\n                    'Anti-aliasing standard deviation must be greater than or equal to zero'\n                    )\n            elif np.any((anti_aliasing_sigma > 0) & (factors <= 1)):\n                warn(\n                    'Anti-aliasing standard deviation greater than zero but not down-sampling along all axes'\n                    )\n        filtered = ndi.gaussian_filter(image, anti_aliasing_sigma, cval=\n            cval, mode=ndi_mode)\n    else:\n        filtered = image\n    zoom_factors = [(1 / f) for f in factors]\n    out = ndi.zoom(filtered, zoom_factors, order=order, mode=ndi_mode, cval\n        =cval, grid_mode=True)\n    _clip_warp_output(image, out, mode, cval, clip)\n    return out"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "relabel_sequential", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/_join.py", "method_code_mask": "import numpy as np\n\n\ndef relabel_sequential(label_field, offset=1): [MASK]\n", "response": "import numpy as np\ndef relabel_sequential(label_field, offset=1):\n    \"\"\"Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}.\n\n    This function also returns the forward map (mapping the original labels to\n    the reduced labels) and the inverse map (mapping the reduced labels back\n    to the original ones).\n\n    Parameters\n    ----------\n    label_field : numpy array of int, arbitrary shape\n        An array of labels, which must be non-negative integers.\n    offset : int, optional\n        The return labels will start at `offset`, which should be\n        strictly positive.\n\n    Returns\n    -------\n    relabeled : numpy array of int, same shape as `label_field`\n        The input label field with labels mapped to\n        {offset, ..., number_of_labels + offset - 1}.\n        The data type will be the same as `label_field`, except when\n        offset + number_of_labels causes overflow of the current data type.\n    forward_map : ArrayMap\n        The map from the original label space to the returned label\n        space. Can be used to re-apply the same mapping. See examples\n        for usage. The output data type will be the same as `relabeled`.\n    inverse_map : ArrayMap\n        The map from the new label space to the original space. This\n        can be used to reconstruct the original label field from the\n        relabeled one. The output data type will be the same as `label_field`.\n\n    Notes\n    -----\n    The label 0 is assumed to denote the background and is never remapped.\n\n    The forward map can be extremely big for some inputs, since its\n    length is given by the maximum of the label field. However, in most\n    situations, ``label_field.max()`` is much smaller than\n    ``label_field.size``, and in these cases the forward map is\n    guaranteed to be smaller than either the input or output images.\n\n    Examples\n    --------\n    >>> from skimage.segmentation import relabel_sequential\n    >>> label_field = np.array([1, 1, 5, 5, 8, 99, 42])\n    >>> relab, fw, inv = relabel_sequential(label_field)\n    >>> relab\n    array([1, 1, 2, 2, 3, 5, 4])\n    >>> print(fw)\n    ArrayMap:\n      1 \u2192 1\n      5 \u2192 2\n      8 \u2192 3\n      42 \u2192 4\n      99 \u2192 5\n    >>> np.array(fw)\n    array([0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5])\n    >>> np.array(inv)\n    array([ 0,  1,  5,  8, 42, 99])\n    >>> (fw[label_field] == relab).all()\n    True\n    >>> (inv[relab] == label_field).all()\n    True\n    >>> relab, fw, inv = relabel_sequential(label_field, offset=5)\n    >>> relab\n    array([5, 5, 6, 6, 7, 9, 8])\n    \"\"\"\n    if offset <= 0:\n        raise ValueError('Offset must be strictly positive.')\n    if np.min(label_field) < 0:\n        raise ValueError('Cannot relabel array that contains negative values.')\n    offset = int(offset)\n    in_vals = np.unique(label_field)\n    if in_vals[0] == 0:\n        out_vals = np.concatenate([[0], np.arange(offset, offset + len(\n            in_vals) - 1)])\n    else:\n        out_vals = np.arange(offset, offset + len(in_vals))\n    input_type = label_field.dtype\n    if input_type.kind not in 'iu':\n        raise TypeError('label_field must have an integer dtype')\n    required_type = np.min_scalar_type(out_vals[-1])\n    if input_type.itemsize < required_type.itemsize:\n        output_type = required_type\n    elif out_vals[-1] < np.iinfo(input_type).max:\n        output_type = input_type\n    else:\n        output_type = required_type\n    out_array = np.empty(label_field.shape, dtype=output_type)\n    out_vals = out_vals.astype(output_type)\n    map_array(label_field, in_vals, out_vals, out=out_array)\n    fw_map = ArrayMap(in_vals, out_vals)\n    inv_map = ArrayMap(out_vals, in_vals)\n    return out_array, fw_map, inv_map"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "_label_bool", "method_path": "../srcdata/Computation/scikit-image/skimage/measure/_label.py", "method_code_mask": "from scipy import ndimage\n\n\ndef _label_bool(image, background=None, return_num=False, connectivity=None): [\n    MASK]\n", "response": "from scipy import ndimage\ndef _label_bool(image, background=None, return_num=False, connectivity=None):\n    \"\"\"Faster implementation of clabel for boolean input.\n\n    See context: https://github.com/scikit-image/scikit-image/issues/4833\n    \"\"\"\n    from ..morphology._util import _resolve_neighborhood\n    if background == 1:\n        image = ~image\n    if connectivity is None:\n        connectivity = image.ndim\n    if not 1 <= connectivity <= image.ndim:\n        raise ValueError(\n            f'Connectivity for {image.ndim}D image should be in [1, ..., {image.ndim}]. Got {connectivity}.'\n            )\n    footprint = _resolve_neighborhood(None, connectivity, image.ndim)\n    result = ndimage.label(image, structure=footprint)\n    if return_num:\n        return result\n    else:\n        return result[0]"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_yen", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_yen(image=None, nbins=256, *, hist=None): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_yen(image=None, nbins=256, *, hist=None):\n    \"\"\"Return threshold value based on Yen's method.\n    Either image or hist must be provided. In case hist is given, the actual\n    histogram of the image is ignored.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray\n        Grayscale input image.\n    nbins : int, optional\n        Number of bins used to calculate histogram. This value is ignored for\n        integer arrays.\n    hist : array, or 2-tuple of arrays, optional\n        Histogram from which to determine the threshold, and optionally a\n        corresponding array of bin center intensities.\n        An alternative use of this function is to pass it only hist.\n\n    Returns\n    -------\n    threshold : float\n        Upper threshold value. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    References\n    ----------\n    .. [1] Yen J.C., Chang F.J., and Chang S. (1995) \"A New Criterion\n           for Automatic Multilevel Thresholding\" IEEE Trans. on Image\n           Processing, 4(3): 370-378. :DOI:`10.1109/83.366472`\n    .. [2] Sezgin M. and Sankur B. (2004) \"Survey over Image Thresholding\n           Techniques and Quantitative Performance Evaluation\" Journal of\n           Electronic Imaging, 13(1): 146-165, :DOI:`10.1117/1.1631315`\n           http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf\n    .. [3] ImageJ AutoThresholder code, http://fiji.sc/wiki/index.php/Auto_Threshold\n\n    Examples\n    --------\n    >>> from skimage.data import camera\n    >>> image = camera()\n    >>> thresh = threshold_yen(image)\n    >>> binary = image <= thresh\n    \"\"\"\n    counts, bin_centers = _validate_image_histogram(image, hist, nbins)\n    if bin_centers.size == 1:\n        return bin_centers[0]\n    pmf = counts.astype('float32', copy=False) / counts.sum()\n    P1 = np.cumsum(pmf)\n    P1_sq = np.cumsum(pmf ** 2)\n    P2_sq = np.cumsum(pmf[::-1] ** 2)[::-1]\n    crit = np.log((P1_sq[:-1] * P2_sq[1:]) ** -1 * (P1[:-1] * (1.0 - P1[:-1\n        ])) ** 2)\n    return bin_centers[crit.argmax()]"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "make_3d_syntheticdata", "method_path": "../srcdata/Computation/scikit-image/skimage/segmentation/tests/test_random_walker.py", "method_code_mask": "import numpy as np\nfrom skimage._shared import testing\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.testing import xfail\nfrom skimage._shared.testing import arch32\nfrom skimage.segmentation import random_walker\nfrom skimage.transform import resize\nfrom skimage.segmentation import random_walker_segmentation\n\n\ndef make_3d_syntheticdata(lx, ly=None, lz=None): [MASK]\n", "response": "import numpy as np\nfrom skimage._shared import testing\nfrom skimage._shared._warnings import expected_warnings\nfrom skimage._shared.testing import xfail\nfrom skimage._shared.testing import arch32\nfrom skimage.segmentation import random_walker\nfrom skimage.transform import resize\nfrom skimage.segmentation import random_walker_segmentation\ndef make_3d_syntheticdata(lx, ly=None, lz=None):\n    if ly is None:\n        ly = lx\n    if lz is None:\n        lz = lx\n    np.random.seed(1234)\n    data = np.zeros((lx, ly, lz)) + 0.1 * np.random.randn(lx, ly, lz)\n    small_l = int(lx // 5)\n    data[lx // 2 - small_l:lx // 2 + small_l, ly // 2 - small_l:ly // 2 +\n        small_l, lz // 2 - small_l:lz // 2 + small_l] = 1\n    data[lx // 2 - small_l + 1:lx // 2 + small_l - 1, ly // 2 - small_l + 1\n        :ly // 2 + small_l - 1, lz // 2 - small_l + 1:lz // 2 + small_l - 1\n        ] = 0\n    hole_size = np.max([1, small_l // 8])\n    data[lx // 2 - small_l, ly // 2 - hole_size:ly // 2 + hole_size, lz // \n        2 - hole_size:lz // 2 + hole_size] = 0\n    seeds = np.zeros_like(data)\n    seeds[lx // 5, ly // 5, lz // 5] = 1\n    seeds[lx // 2 + small_l // 4, ly // 2 - small_l // 4, lz // 2 - small_l //\n        4] = 2\n    return data, seeds"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_li", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_li(image, *, tolerance=None, initial_guess=None,\n    iter_callback=None): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_li(image, *, tolerance=None, initial_guess=None,\n    iter_callback=None):\n    \"\"\"Compute threshold value by Li's iterative Minimum Cross Entropy method.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray\n        Grayscale input image.\n    tolerance : float, optional\n        Finish the computation when the change in the threshold in an iteration\n        is less than this value. By default, this is half the smallest\n        difference between intensity values in ``image``.\n    initial_guess : float or Callable[[array[float]], float], optional\n        Li's iterative method uses gradient descent to find the optimal\n        threshold. If the image intensity histogram contains more than two\n        modes (peaks), the gradient descent could get stuck in a local optimum.\n        An initial guess for the iteration can help the algorithm find the\n        globally-optimal threshold. A float value defines a specific start\n        point, while a callable should take in an array of image intensities\n        and return a float value. Example valid callables include\n        ``numpy.mean`` (default), ``lambda arr: numpy.quantile(arr, 0.95)``,\n        or even :func:`skimage.filters.threshold_otsu`.\n    iter_callback : Callable[[float], Any], optional\n        A function that will be called on the threshold at every iteration of\n        the algorithm.\n\n    Returns\n    -------\n    threshold : float\n        Upper threshold value. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    References\n    ----------\n    .. [1] Li C.H. and Lee C.K. (1993) \"Minimum Cross Entropy Thresholding\"\n           Pattern Recognition, 26(4): 617-625\n           :DOI:`10.1016/0031-3203(93)90115-D`\n    .. [2] Li C.H. and Tam P.K.S. (1998) \"An Iterative Algorithm for Minimum\n           Cross Entropy Thresholding\" Pattern Recognition Letters, 18(8): 771-776\n           :DOI:`10.1016/S0167-8655(98)00057-9`\n    .. [3] Sezgin M. and Sankur B. (2004) \"Survey over Image Thresholding\n           Techniques and Quantitative Performance Evaluation\" Journal of\n           Electronic Imaging, 13(1): 146-165\n           :DOI:`10.1117/1.1631315`\n    .. [4] ImageJ AutoThresholder code, http://fiji.sc/wiki/index.php/Auto_Threshold\n\n    Examples\n    --------\n    >>> from skimage.data import camera\n    >>> image = camera()\n    >>> thresh = threshold_li(image)\n    >>> binary = image > thresh\n    \"\"\"\n    image = image[~np.isnan(image)]\n    if image.size == 0:\n        return np.nan\n    if np.all(image == image.flat[0]):\n        return image.flat[0]\n    image = image[np.isfinite(image)]\n    if image.size == 0:\n        return 0.0\n    image_min = np.min(image)\n    image -= image_min\n    if image.dtype.kind in 'iu':\n        tolerance = tolerance or 0.5\n    else:\n        tolerance = tolerance or np.min(np.diff(np.unique(image))) / 2\n    if initial_guess is None:\n        t_next = np.mean(image)\n    elif callable(initial_guess):\n        t_next = initial_guess(image)\n    elif np.isscalar(initial_guess):\n        t_next = initial_guess - float(image_min)\n        image_max = np.max(image) + image_min\n        if not 0 < t_next < np.max(image):\n            msg = (\n                f'The initial guess for threshold_li must be within the range of the image. Got {initial_guess} for image min {image_min} and max {image_max}.'\n                )\n            raise ValueError(msg)\n        t_next = image.dtype.type(t_next)\n    else:\n        raise TypeError(\n            'Incorrect type for `initial_guess`; should be a floating point value, or a function mapping an array to a floating point value.'\n            )\n    t_curr = -2 * tolerance\n    if iter_callback is not None:\n        iter_callback(t_next + image_min)\n    if image.dtype.kind in 'iu':\n        hist, bin_centers = histogram(image.reshape(-1), source_range='image')\n        hist = hist.astype('float32', copy=False)\n        while abs(t_next - t_curr) > tolerance:\n            t_curr = t_next\n            foreground = bin_centers > t_curr\n            background = ~foreground\n            mean_fore = np.average(bin_centers[foreground], weights=hist[\n                foreground])\n            mean_back = np.average(bin_centers[background], weights=hist[\n                background])\n            if mean_back == 0:\n                break\n            t_next = (mean_back - mean_fore) / (np.log(mean_back) - np.log(\n                mean_fore))\n            if iter_callback is not None:\n                iter_callback(t_next + image_min)\n    else:\n        while abs(t_next - t_curr) > tolerance:\n            t_curr = t_next\n            foreground = image > t_curr\n            mean_fore = np.mean(image[foreground])\n            mean_back = np.mean(image[~foreground])\n            if mean_back == 0.0:\n                break\n            t_next = (mean_back - mean_fore) / (np.log(mean_back) - np.log(\n                mean_fore))\n            if iter_callback is not None:\n                iter_callback(t_next + image_min)\n    threshold = t_next + image_min\n    return threshold"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_otsu", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_otsu(image=None, nbins=256, *, hist=None): [MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_otsu(image=None, nbins=256, *, hist=None):\n    \"\"\"Return threshold value based on Otsu's method.\n\n    Either image or hist must be provided. If hist is provided, the actual\n    histogram of the image is ignored.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray, optional\n        Grayscale input image.\n    nbins : int, optional\n        Number of bins used to calculate histogram. This value is ignored for\n        integer arrays.\n    hist : array, or 2-tuple of arrays, optional\n        Histogram from which to determine the threshold, and optionally a\n        corresponding array of bin center intensities. If no hist provided,\n        this function will compute it from the image.\n\n\n    Returns\n    -------\n    threshold : float\n        Upper threshold value. All pixels with an intensity higher than\n        this value are assumed to be foreground.\n\n    References\n    ----------\n    .. [1] Wikipedia, https://en.wikipedia.org/wiki/Otsu's_Method\n\n    Examples\n    --------\n    >>> from skimage.data import camera\n    >>> image = camera()\n    >>> thresh = threshold_otsu(image)\n    >>> binary = image <= thresh\n\n    Notes\n    -----\n    The input image must be grayscale.\n    \"\"\"\n    if image is not None and image.ndim > 2 and image.shape[-1] in (3, 4):\n        warn(\n            f'threshold_otsu is expected to work correctly only for grayscale images; image shape {image.shape} looks like that of an RGB image.'\n            )\n    if image is not None:\n        first_pixel = image.reshape(-1)[0]\n        if np.all(image == first_pixel):\n            return first_pixel\n    counts, bin_centers = _validate_image_histogram(image, hist, nbins)\n    weight1 = np.cumsum(counts)\n    weight2 = np.cumsum(counts[::-1])[::-1]\n    mean1 = np.cumsum(counts * bin_centers) / weight1\n    mean2 = (np.cumsum((counts * bin_centers)[::-1]) / weight2[::-1])[::-1]\n    variance12 = weight1[:-1] * weight2[1:] * (mean1[:-1] - mean2[1:]) ** 2\n    idx = np.argmax(variance12)\n    threshold = bin_centers[idx]\n    return threshold"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "threshold_isodata", "method_path": "../srcdata/Computation/scikit-image/skimage/filters/thresholding.py", "method_code_mask": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\n\n\ndef threshold_isodata(image=None, nbins=256, return_all=False, *, hist=None): [\n    MASK]\n", "response": "import inspect\nimport itertools\nimport math\nfrom collections import OrderedDict\nfrom collections.abc import Iterable\nimport numpy as np\nfrom scipy import ndimage as ndi\nfrom matplotlib import pyplot as plt\ndef threshold_isodata(image=None, nbins=256, return_all=False, *, hist=None):\n    \"\"\"Return threshold value(s) based on ISODATA method.\n\n    Histogram-based threshold, known as Ridler-Calvard method or inter-means.\n    Threshold values returned satisfy the following equality::\n\n        threshold = (image[image <= threshold].mean() +\n                     image[image > threshold].mean()) / 2.0\n\n    That is, returned thresholds are intensities that separate the image into\n    two groups of pixels, where the threshold intensity is midway between the\n    mean intensities of these groups.\n\n    For integer images, the above equality holds to within one; for floating-\n    point images, the equality holds to within the histogram bin-width.\n\n    Either image or hist must be provided. In case hist is given, the actual\n    histogram of the image is ignored.\n\n    Parameters\n    ----------\n    image : (M, N[, ...]) ndarray\n        Grayscale input image.\n    nbins : int, optional\n        Number of bins used to calculate histogram. This value is ignored for\n        integer arrays.\n    return_all : bool, optional\n        If False (default), return only the lowest threshold that satisfies\n        the above equality. If True, return all valid thresholds.\n    hist : array, or 2-tuple of arrays, optional\n        Histogram to determine the threshold from and a corresponding array\n        of bin center intensities. Alternatively, only the histogram can be\n        passed.\n\n    Returns\n    -------\n    threshold : float or int or array\n        Threshold value(s).\n\n    References\n    ----------\n    .. [1] Ridler, TW & Calvard, S (1978), \"Picture thresholding using an\n           iterative selection method\"\n           IEEE Transactions on Systems, Man and Cybernetics 8: 630-632,\n           :DOI:`10.1109/TSMC.1978.4310039`\n    .. [2] Sezgin M. and Sankur B. (2004) \"Survey over Image Thresholding\n           Techniques and Quantitative Performance Evaluation\" Journal of\n           Electronic Imaging, 13(1): 146-165,\n           http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf\n           :DOI:`10.1117/1.1631315`\n    .. [3] ImageJ AutoThresholder code,\n           http://fiji.sc/wiki/index.php/Auto_Threshold\n\n    Examples\n    --------\n    >>> from skimage.data import coins\n    >>> image = coins()\n    >>> thresh = threshold_isodata(image)\n    >>> binary = image > thresh\n    \"\"\"\n    counts, bin_centers = _validate_image_histogram(image, hist, nbins)\n    if len(bin_centers) == 1:\n        if return_all:\n            return bin_centers\n        else:\n            return bin_centers[0]\n    counts = counts.astype('float32', copy=False)\n    csuml = np.cumsum(counts)\n    csumh = csuml[-1] - csuml\n    intensity_sum = counts * bin_centers\n    csum_intensity = np.cumsum(intensity_sum)\n    lower = csum_intensity[:-1] / csuml[:-1]\n    higher = (csum_intensity[-1] - csum_intensity[:-1]) / csumh[:-1]\n    all_mean = (lower + higher) / 2.0\n    bin_width = bin_centers[1] - bin_centers[0]\n    distances = all_mean - bin_centers[:-1]\n    thresholds = bin_centers[:-1][(distances >= 0) & (distances < bin_width)]\n    if return_all:\n        return thresholds\n    else:\n        return thresholds[0]"}
{"result": "passed", "model_name": "std", "repository": "scikit-image", "full_method_name": "expected_warnings", "method_path": "../srcdata/Computation/scikit-image/skimage/_shared/_warnings.py", "method_code_mask": "from contextlib import contextmanager\nimport sys\nimport warnings\nimport re\nimport functools\nimport os\nimport inspect\n\n\n@contextmanager\ndef expected_warnings(matching): [MASK]\n", "response": "from contextlib import contextmanager\nimport sys\nimport warnings\nimport re\nimport functools\nimport os\nimport inspect\n@contextmanager\ndef expected_warnings(matching):\n    \"\"\"Context for use in testing to catch known warnings matching regexes\n\n    Parameters\n    ----------\n    matching : None or a list of strings or compiled regexes\n        Regexes for the desired warning to catch\n        If matching is None, this behaves as a no-op.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> rng = np.random.default_rng()\n    >>> image = rng.integers(0, 2**16, size=(100, 100), dtype=np.uint16)\n    >>> # rank filters are slow when bit-depth exceeds 10 bits\n    >>> from skimage import filters\n    >>> with expected_warnings(['Bad rank filter performance']):\n    ...     median_filtered = filters.rank.median(image)\n\n    Notes\n    -----\n    Uses `all_warnings` to ensure all warnings are raised.\n    Upon exiting, it checks the recorded warnings for the desired matching\n    pattern(s).\n    Raises a ValueError if any match was not found or an unexpected\n    warning was raised.\n    Allows for three types of behaviors: `and`, `or`, and `optional` matches.\n    This is done to accommodate different build environments or loop conditions\n    that may produce different warnings.  The behaviors can be combined.\n    If you pass multiple patterns, you get an orderless `and`, where all of the\n    warnings must be raised.\n    If you use the `|` operator in a pattern, you can catch one of several\n    warnings.\n    Finally, you can use `|\\\\A\\\\Z` in a pattern to signify it as optional.\n\n    \"\"\"\n    if isinstance(matching, str):\n        raise ValueError(\n            '``matching`` should be a list of strings and not a string itself.'\n            )\n    if matching is None:\n        yield None\n        return\n    strict_warnings = os.environ.get('SKIMAGE_TEST_STRICT_WARNINGS', '1')\n    if strict_warnings.lower() == 'true':\n        strict_warnings = True\n    elif strict_warnings.lower() == 'false':\n        strict_warnings = False\n    else:\n        strict_warnings = bool(int(strict_warnings))\n    with all_warnings() as w:\n        yield w\n        while None in matching:\n            matching.remove(None)\n        remaining = [m for m in matching if '\\\\A\\\\Z' not in m.split('|')]\n        for warn in w:\n            found = False\n            for match in matching:\n                if re.search(match, str(warn.message)) is not None:\n                    found = True\n                    if match in remaining:\n                        remaining.remove(match)\n            if strict_warnings and not found:\n                raise ValueError(f'Unexpected warning: {str(warn.message)}')\n        if strict_warnings and len(remaining) > 0:\n            newline = '\\n'\n            msg = (\n                f'No warning raised matching:{newline}{newline.join(remaining)}'\n                )\n            raise ValueError(msg)"}
