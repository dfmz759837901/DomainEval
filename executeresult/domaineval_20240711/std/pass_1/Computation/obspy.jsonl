{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "get_dependency_version", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef get_dependency_version(package_name, raw_string=False): [MASK]\n", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef get_dependency_version(package_name, raw_string=False):\n    \"\"\"\n    Get version information of a dependency package.\n\n    :type package_name: str\n    :param package_name: Name of package to return version info for\n    :returns: Package version as a list of three integers or ``None`` if\n        import fails. With option ``raw_string=True`` returns raw version\n        string instead (or ``None`` if import fails).\n        The last version number can indicate different things like it being a\n        version from the old svn trunk, the latest git repo, some release\n        candidate version, ...\n        If the last number cannot be converted to an integer it will be set to\n        0.\n    \"\"\"\n    try:\n        version_string = pkg_resources.get_distribution(package_name).version\n    except pkg_resources.DistributionNotFound:\n        return []\n    if raw_string:\n        return version_string\n    version_list = version_string.split('rc')[0].strip('~')\n    version_list = list(map(to_int_or_zero, version_list.split('.')))\n    return version_list"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "resample_preview", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef resample_preview(trace, samples, method='accurate'): [MASK]\n", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef resample_preview(trace, samples, method='accurate'):\n    \"\"\"\n    Resamples a preview Trace to the chosen number of samples.\n\n    :type trace: :class:`~obspy.core.trace.Trace`\n    :param trace: Trace object to be resampled.\n    :type samples: int\n    :param samples: Desired number of samples.\n    :type method: str, optional\n    :param method: Resample method. Available are ``'fast'`` and\n        ``'accurate'``. Defaults to ``'accurate'``.\n\n    .. rubric:: Notes\n\n    This method will destroy the data in the original Trace object.\n    Deepcopy the Trace if you want to continue using the original data.\n\n    The fast method works by reshaping the data array to a\n    sample x int(npts/samples) matrix (npts are the number of samples in\n    the original trace) and taking the maximum of each row. Therefore\n    the last npts - int(npts/samples)*samples will be omitted. The worst\n    case scenario is resampling a 1999 samples array to 1000 samples. 999\n    samples, almost half the data will be omitted.\n\n    The accurate method has no such problems because it will move a window\n    over the whole array and take the maximum for each window. It loops\n    over each window and is up to 10 times slower than the fast method.\n    This of course is highly depended on the number of wished samples and\n    the original trace and usually the accurate method is still fast\n    enough.\n    \"\"\"\n    if not hasattr(trace.stats, 'preview') or not trace.stats.preview:\n        msg = 'Trace\\n%s\\n is no preview file.' % str(trace)\n        raise Exception(msg)\n    endtime = trace.stats.endtime\n    dtype = trace.data.dtype\n    npts = trace.stats.npts\n    if trace.stats.npts < samples:\n        msg = 'Can only downsample so far. Interpolation not yet implemented.'\n        raise NotImplementedError(msg)\n    elif trace.stats.npts == samples:\n        return 0\n    if method == 'fast':\n        data = trace.data[:int(npts / samples) * samples]\n        data = data.reshape(samples, len(data) // samples)\n        trace.data = data.max(axis=1)\n        trace.stats.delta = (endtime - trace.stats.starttime) / float(\n            samples - 1)\n        return npts - int(npts / samples) * samples\n    elif method == 'accurate':\n        new_data = np.empty(samples, dtype=dtype)\n        step = trace.stats.npts / float(samples)\n        for _i in range(samples):\n            new_data[_i] = trace.data[int(_i * step):int((_i + 1) * step)].max(\n                )\n        trace.data = new_data\n        trace.stats.delta = (endtime - trace.stats.starttime) / float(\n            samples - 1)\n        return npts - int(samples * step)\n    else:\n        raise NotImplementedError('Unknown method')"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "map_example_filename", "method_path": "../srcdata/Computation/obspy/obspy/core/util/decorator.py", "method_code_mask": "import functools\nimport inspect\nfrom pathlib import Path\nimport re\nimport socket\nimport tarfile\nimport warnings\nimport zipfile\nimport numpy as np\nfrom decorator import decorator\nfrom obspy.core.util import get_example_file\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nimport pytest\nimport bz2\nimport gzip\nimport doctest\n\n\ndef map_example_filename(arg_kwarg_name): [MASK]\n", "response": "import functools\nimport inspect\nfrom pathlib import Path\nimport re\nimport socket\nimport tarfile\nimport warnings\nimport zipfile\nimport numpy as np\nfrom decorator import decorator\nfrom obspy.core.util import get_example_file\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nimport pytest\nimport bz2\nimport gzip\nimport doctest\ndef map_example_filename(arg_kwarg_name):\n    \"\"\"\n    Decorator that replaces \"/path/to/filename\" patterns in the arg or kwarg\n    of the specified name with the correct file path. If the pattern is not\n    encountered nothing is done.\n\n    .. note::\n        Actually, this is not a decorator itself but a decorator factory,\n        returning the correct decorator for the specified options. It can be\n        used just like a decorator.\n\n    :type arg_kwarg_name: str\n    :param arg_kwarg_name: name of the arg/kwarg that should be (tried) to map\n    \"\"\"\n\n    @decorator\n    def _map_example_filename(func, *args, **kwargs):\n        prefix = '/path/to/'\n        if arg_kwarg_name in kwargs:\n            if isinstance(kwargs[arg_kwarg_name], str):\n                if re.match(prefix, kwargs[arg_kwarg_name]):\n                    try:\n                        kwargs[arg_kwarg_name] = get_example_file(kwargs[\n                            arg_kwarg_name][9:])\n                    except IOError:\n                        pass\n        else:\n            try:\n                inspected_args = [p.name for p in inspect.signature(func).\n                    parameters.values()]\n            except AttributeError:\n                inspected_args = inspect.getargspec(func).args\n            try:\n                ind = inspected_args.index(arg_kwarg_name)\n            except ValueError:\n                pass\n            else:\n                if ind < len(args) and isinstance(args[ind], str):\n                    if re.match(prefix, args[ind]):\n                        try:\n                            args = list(args)\n                            args[ind] = get_example_file(args[ind][9:])\n                            args = tuple(args)\n                        except IOError:\n                            pass\n        return func(*args, **kwargs)\n    return _map_example_filename"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "leg_puller", "method_path": "../srcdata/Computation/obspy/obspy/taup/seismic_phase.py", "method_code_mask": "from itertools import count\nimport math\nimport re\nimport numpy as np\nfrom scipy.optimize import brentq\nfrom obspy.core.util.obspy_types import Enum\n\n\ndef leg_puller(name): [MASK]\n", "response": "from itertools import count\nimport math\nimport re\nimport numpy as np\nfrom scipy.optimize import brentq\nfrom obspy.core.util.obspy_types import Enum\ndef leg_puller(name):\n    \"\"\"\n    Tokenize a phase name into legs.\n\n    For example, ``PcS`` becomes ``'P' + 'c' + 'S'`` while ``p^410P`` would\n    become ``'p' + '^410' + 'P'``. Once a phase name has been broken into\n    tokens, we can begin to construct the sequence of branches to which it\n    corresponds. Only minor error checking is done at this point, for instance\n    ``PIP`` generates an exception but ``^410`` doesn't. It also appends\n    ``\"END\"`` as the last leg.\n    \"\"\"\n    results, remainder = tokenizer.scan(name)\n    if remainder:\n        raise ValueError('Invalid phase name: %s could not be parsed in %s' %\n            (str(remainder), name))\n    return results + ['END']"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "bullen_depth_for", "method_path": "../srcdata/Computation/obspy/obspy/taup/slowness_layer.py", "method_code_mask": "import math\nimport numpy as np\n\n\ndef bullen_depth_for(layer, ray_param, radius_of_planet, check=True): [MASK]\n", "response": "import math\nimport numpy as np\ndef bullen_depth_for(layer, ray_param, radius_of_planet, check=True):\n    \"\"\"\n    Finds the depth for a ray parameter within this layer.\n\n    Uses a Bullen interpolant, Ar^B. Special case for ``bot_p == 0`` or\n    ``bot_depth == radius_of_planet`` as these cause division by 0; use linear\n    interpolation in this case.\n\n    The ``layer`` and ``ray_param`` parameters must be either 0-D, or both of\n    the same shape.\n\n    :param layer: The layer(s) to check.\n    :type layer: :class:`~numpy.ndarray` (shape = (1, ), dtype =\n        :class:`obspy.taup.helper_classes.SlownessLayer`)\n    :param ray_param: The ray parameter(s) to use for calculation, in s/km.\n    :type ray_param: float\n    :param radius_of_planet: The radius (in km) of the planet to use.\n    :type radius_of_planet: float\n\n    :returns: The depth (in km) for the specified ray parameter.\n    :rtype: float\n    \"\"\"\n    ldim = np.ndim(layer)\n    pdim = np.ndim(ray_param)\n    if ldim == 1 and pdim == 0:\n        ray_param = ray_param * np.ones(layer.shape, dtype=np.float64)\n        depth = np.zeros(shape=layer.shape, dtype=np.float64)\n    elif ldim == 0 and pdim == 1:\n        layer = layer * np.ones(ray_param.shape, dtype=SlownessLayer)\n        depth = np.zeros(shape=ray_param.shape, dtype=np.float64)\n    elif ldim == pdim and (ldim == 0 or layer.shape == ray_param.shape):\n        if ldim == 0:\n            layer = np.array([layer], dtype=SlownessLayer)\n            ray_param = np.array([ray_param])\n        depth = np.zeros(shape=layer.shape, dtype=np.float64)\n    else:\n        raise TypeError(\n            'Either layer or ray_param must be 0D, or they must have the same shape.'\n            )\n    valid = (layer['top_p'] - ray_param) * (ray_param - layer['bot_p']) >= 0\n    if not check or np.all(valid):\n        leftover = np.ones_like(depth, dtype=np.bool_)\n        mask = layer['top_depth'] == layer['bot_depth']\n        depth[mask] = layer['bot_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & (layer['top_p'] == ray_param)\n        depth[mask] = layer['top_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & (layer['bot_p'] == ray_param)\n        depth[mask] = layer['bot_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & ((layer['bot_p'] != 0) & (layer['bot_depth'] !=\n            radius_of_planet))\n        if np.any(mask):\n            top_p_mask = layer['top_p'][mask]\n            bot_p_mask = layer['bot_p'][mask]\n            top_depth_mask = layer['top_depth'][mask]\n            bot_depth_mask = layer['bot_depth'][mask]\n            ray_param_mask = ray_param[mask]\n            b = np.divide(np.log(top_p_mask / bot_p_mask), np.log((\n                radius_of_planet - top_depth_mask) / (radius_of_planet -\n                bot_depth_mask)))\n            with np.errstate(over='ignore'):\n                denom = np.power(radius_of_planet - top_depth_mask, b)\n            a = np.divide(top_p_mask, denom)\n            temp_depth = np.empty_like(a)\n            mask2 = (a != 0) & (b != 0)\n            temp_depth[mask2] = radius_of_planet - np.exp(1.0 / b[mask2] *\n                np.log(np.divide(ray_param_mask[mask2], a[mask2])))\n            temp_depth[~mask2] = (bot_depth_mask[~mask2] - top_depth_mask[~\n                mask2]) / (bot_p_mask[~mask2] - top_p_mask[~mask2]) * (\n                ray_param_mask[~mask2] - top_p_mask[~mask2]) + top_depth_mask[\n                ~mask2]\n            mask2 = (top_depth_mask > temp_depth) & (temp_depth > \n                top_depth_mask - 1e-06)\n            temp_depth[mask2] = top_depth_mask[mask2]\n            mask2 = (bot_depth_mask < temp_depth) & (temp_depth < \n                bot_depth_mask + 1e-06)\n            temp_depth[mask2] = bot_depth_mask[mask2]\n            mask2 = (temp_depth < 0) | np.isnan(temp_depth) | np.isinf(\n                temp_depth) | (temp_depth < top_depth_mask) | (temp_depth >\n                bot_depth_mask)\n            small_layer = bot_depth_mask[mask2] - top_depth_mask[mask2] > 5\n            if np.any(small_layer):\n                if check:\n                    raise SlownessModelError(\n                        'Calculated depth is outside layer, negative, or NaN.')\n                else:\n                    temp_depth[mask2][small_layer] = np.nan\n            linear = (bot_depth_mask[mask2] - top_depth_mask[mask2]) / (\n                bot_p_mask[mask2] - top_p_mask[mask2]) * (ray_param_mask[\n                mask2] - top_p_mask[mask2]) + top_depth_mask[mask2]\n            outside_layer = small_layer & (linear < 0 | np.isnan(linear) |\n                np.isinf(linear))\n            if np.any(outside_layer):\n                if check:\n                    raise SlownessModelError(\n                        'Calculated depth is outside layer, negative, or NaN.')\n                else:\n                    temp_depth[mask2][outside_layer] = np.nan\n            temp_depth[mask2] = linear\n            mask2 = (temp_depth < top_depth_mask) & (top_depth_mask -\n                temp_depth < 1e-10)\n            temp_depth[mask2] = top_depth_mask[mask2]\n            mask2 = (temp_depth > bot_depth_mask) & (temp_depth -\n                bot_depth_mask < 1e-10)\n            temp_depth[mask2] = bot_depth_mask[mask2]\n            depth[mask] = temp_depth\n            leftover &= ~mask\n        mask = leftover & (layer['top_p'] != layer['bot_p'])\n        depth[mask] = layer['bot_depth'][mask] + (ray_param[mask] - layer[\n            'bot_p'][mask]) * (layer['top_depth'][mask] - layer['bot_depth'\n            ][mask]) / (layer['top_p'][mask] - layer['bot_p'][mask])\n        leftover &= ~mask\n        depth[leftover] = layer['bot_depth'][leftover]\n        depth[~valid] = np.nan\n        if ldim == 0 and pdim == 0:\n            return depth[0]\n        else:\n            return depth\n    else:\n        raise SlownessModelError(\n            'Ray parameter is not contained within this slowness layer.')"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "sanitize_filename", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef sanitize_filename(filename): [MASK]\n", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef sanitize_filename(filename):\n    \"\"\"\n    Adapted from Django's slugify functions.\n\n    :param filename: The filename.\n    \"\"\"\n    try:\n        filename = filename.decode()\n    except AttributeError:\n        pass\n    value = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore'\n        ).decode('ascii')\n    value = re.sub('[^\\\\w\\\\.\\\\s-]', '', value).strip()\n    return re.sub('[-\\\\s]+', '-', value)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "merge_previews", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef merge_previews(stream): [MASK]\n", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef merge_previews(stream):\n    \"\"\"\n    Merges all preview traces in one Stream object. Does not change the\n    original stream because the data needs to be copied anyway.\n\n    :type stream: :class:`~obspy.core.stream.Stream`\n    :param stream: Stream object to be merged\n    :rtype: :class:`~obspy.core.stream.Stream`\n    :return: Merged Stream object.\n    \"\"\"\n    copied_traces = copy(stream.traces)\n    stream.sort()\n    traces = {}\n    dtypes = []\n    for trace in stream:\n        if trace.stats.npts == 0:\n            continue\n        if not hasattr(trace.stats, 'preview') or not trace.stats.preview:\n            msg = 'Trace\\n%s\\n is no preview file.' % str(trace)\n            raise Exception(msg)\n        traces.setdefault(trace.id, [])\n        traces[trace.id].append(trace)\n        dtypes.append(trace.data.dtype)\n    if len(traces) == 0:\n        return Stream()\n    new_stream = Stream()\n    for value in traces.values():\n        if len(value) == 1:\n            new_stream.append(value[0])\n            continue\n        sampling_rates = {tr.stats.sampling_rate for tr in value}\n        if len(sampling_rates) != 1:\n            msg = 'More than one sampling rate for traces with id %s.' % value[\n                0].id\n            raise Exception(msg)\n        delta = value[0].stats.delta\n        dtypes = {tr.data.dtype for tr in value}\n        if len(dtypes) > 1:\n            msg = 'Different dtypes for traces with id %s' % value[0].id\n            raise Exception(msg)\n        dtype = dtypes.pop()\n        min_starttime = min([tr.stats.starttime for tr in value])\n        max_endtime = max([tr.stats.endtime for tr in value])\n        samples = int(round((max_endtime - min_starttime) / delta)) + 1\n        data = np.empty(samples, dtype=dtype)\n        data[:] = -1\n        new_trace = Trace(data=data, header=value[0].stats)\n        for trace in value:\n            start_index = int((trace.stats.starttime - min_starttime) / delta)\n            end_index = start_index + len(trace.data)\n            data[start_index:end_index] = np.maximum(data[start_index:\n                end_index], trace.data)\n        new_trace.stats.npts = len(data)\n        new_stream.append(new_trace)\n    stream.traces = copied_traces\n    return new_stream"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "create_preview", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef create_preview(trace, delta=60): [MASK]\n", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef create_preview(trace, delta=60):\n    \"\"\"\n    Creates a preview trace.\n\n    A preview trace consists of maximum minus minimum of all samples within\n    ``delta`` seconds. The parameter ``delta`` must be a multiple of the\n    sampling rate of the ``trace`` object.\n\n    :type delta: int, optional\n    :param delta: Difference between two preview points. Defaults to ``60``.\n    :rtype: :class:`~obspy.core.trace.Trace`\n    :return: New Trace object.\n\n    This method will modify the original Trace object. Create a copy of the\n    Trace object if you want to continue using the original data.\n    \"\"\"\n    if not isinstance(delta, int) or delta < 1:\n        msg = 'The delta values need to be an Integer and at least 1.'\n        raise TypeError(msg)\n    data = trace.data\n    start_time = trace.stats.starttime.timestamp\n    samples_per_slice = delta * int(trace.stats.sampling_rate)\n    if samples_per_slice < 1:\n        raise ValueError('samples_per_slice is less than 0 - skipping')\n    start = int((delta - start_time % delta) * int(trace.stats.sampling_rate))\n    start_time = start_time - start_time % delta\n    if start > delta / 2 and data[0:start].size:\n        first_diff = [data[0:start].max() - data[0:start].min()]\n    else:\n        first_diff = []\n        start_time += delta\n    number_of_slices = int((len(data) - start) / samples_per_slice)\n    end = samples_per_slice * number_of_slices + start\n    if end > delta / 2 and data[end:].size:\n        last_diff = [data[end:].max() - data[end:].min()]\n    else:\n        last_diff = []\n    if len(last_diff) and np.isnan(last_diff)[0]:\n        last_diff = -1\n    data = trace.data[start:end].reshape([number_of_slices, samples_per_slice])\n    diff = ptp(data, axis=1)\n    if isinstance(diff, np.ma.masked_array):\n        diff = np.ma.filled(diff, -1)\n    data = np.concatenate([first_diff, diff, last_diff])\n    data = np.require(data, dtype=np.float32)\n    tr = Trace(data=data, header=trace.stats)\n    tr.stats.delta = delta\n    tr.stats.npts = len(data)\n    tr.stats.starttime = UTCDateTime(start_time)\n    tr.stats.preview = True\n    return tr"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "get_example_file", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef get_example_file(filename): [MASK]\n", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef get_example_file(filename):\n    \"\"\"\n    Function to find the absolute path of a data file\n\n    The ObsPy modules are installed to a custom installation directory.\n    That is the path cannot be predicted. This functions searches for all\n    installed ObsPy modules and checks whether the file is in any of\n    the \"tests/data/\" or \"data/\" subdirectories.\n\n    :param filename: A test file name to which the path should be returned.\n    :return: Full path to file.\n\n    .. rubric:: Example\n\n    >>> get_example_file('slist.ascii')  # doctest: +SKIP\n    /custom/path/to/obspy/io/ascii/tests/data/slist.ascii\n\n    >>> get_example_file('does.not.exists')  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n    ...\n    OSError: Could not find file does.not.exists ...\n    \"\"\"\n    for module in ALL_MODULES:\n        try:\n            mod = __import__('obspy.%s' % module, fromlist=['obspy'])\n        except ImportError:\n            continue\n        file_ = Path(mod.__path__[0]) / 'tests' / 'data' / filename\n        if file_.is_file():\n            return str(file_)\n        file_ = Path(mod.__path__[0]) / 'data' / filename\n        if file_.is_file():\n            return str(file_)\n    msg = (\n        'Could not find file %s in tests/data or data directory of ObsPy modules'\n         % filename)\n    raise OSError(msg)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "create_empty_data_chunk", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef create_empty_data_chunk(delta, dtype, fill_value=None): [MASK]\n", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef create_empty_data_chunk(delta, dtype, fill_value=None):\n    \"\"\"\n    Creates an NumPy array depending on the given data type and fill value.\n\n    If no ``fill_value`` is given a masked array will be returned.\n\n    :param delta: Number of samples for data chunk\n    :param dtype: NumPy dtype for returned data chunk\n    :param fill_value: If ``None``, masked array is returned, else the\n        array is filled with the corresponding value\n\n    .. rubric:: Example\n\n    >>> create_empty_data_chunk(3, 'int', 10)\n    array([10, 10, 10])\n\n    >>> create_empty_data_chunk(\n    ...     3, 'f')  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n    masked_array(data = [-- -- --],\n                 mask = ...,\n                 ...)\n    \"\"\"\n    if fill_value is None:\n        temp = np.ma.masked_all(delta, dtype=np.dtype(dtype))\n        if issubclass(temp.data.dtype.type, np.integer):\n            temp.data[:] = np.iinfo(temp.data.dtype).min\n        else:\n            temp.data[:] = np.nan\n    elif (isinstance(fill_value, list) or isinstance(fill_value, tuple)\n        ) and len(fill_value) == 2:\n        ls = fill_value[0]\n        rs = fill_value[1]\n        interpolation = np.linspace(ls, rs, delta + 2)\n        temp = np.require(interpolation[1:-1], dtype=np.dtype(dtype))\n    else:\n        temp = np.ones(delta, dtype=np.dtype(dtype))\n        temp *= fill_value\n    return temp"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "create_from_vlayer", "method_path": "../srcdata/Computation/obspy/obspy/taup/slowness_layer.py", "method_code_mask": "import math\nimport numpy as np\n\n\ndef create_from_vlayer(v_layer, is_p_wave, radius_of_planet, is_spherical=True\n    ): [MASK]\n", "response": "import math\nimport numpy as np\ndef create_from_vlayer(v_layer, is_p_wave, radius_of_planet, is_spherical=True\n    ):\n    \"\"\"\n    Compute the slowness layer from a velocity layer.\n\n    :param v_layer: The velocity layer to convert.\n    :type v_layer: :class:`numpy.ndarray`,\n        dtype = :class:`obspy.taup.velocity_layer.VelocityLayer`\n    :param is_p_wave: Whether this velocity layer is for compressional/P\n         (``True``) or shear/S (``False``) waves.\n    :type is_p_wave: bool\n    :param radius_of_planet: The radius of the planet to use, in km.\n    :type radius_of_planet: float\n    :param is_spherical: Whether the model is spherical. Non-spherical models\n        are not currently supported.\n    :type is_spherical: bool\n    \"\"\"\n    ret = np.empty(shape=v_layer.shape, dtype=SlownessLayer)\n    ret['top_depth'] = v_layer['top_depth']\n    ret['bot_depth'] = v_layer['bot_depth']\n    wave_type = 'p' if is_p_wave else 's'\n    if is_spherical:\n        ret['top_p'] = (radius_of_planet - ret['top_depth']\n            ) / evaluate_velocity_at_top(v_layer, wave_type)\n        bot_depth = ret['bot_depth']\n        bot_vel = evaluate_velocity_at_bottom(v_layer, wave_type)\n        if bot_depth.shape and bot_depth.size:\n            if bot_depth[-1] == radius_of_planet and bot_vel[-1] == 0.0:\n                bot_depth[-1] = 1.0\n        ret['bot_p'] = (radius_of_planet - bot_depth) / bot_vel\n    else:\n        raise NotImplementedError('no flat models yet')\n    return ret"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_pitick2latex", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/response.py", "method_code_mask": "import copy\nimport ctypes as C\nimport collections.abc\nfrom collections import defaultdict\nfrom copy import deepcopy\nimport itertools\nfrom math import pi\nimport warnings\nimport numpy as np\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nimport scipy.interpolate\nimport obspy.signal.evrespwrapper as ew\nfrom obspy.signal.headers import clibevresp\nimport matplotlib.pyplot as plt\nfrom matplotlib.transforms import blended_transform_factory\nimport doctest\n\n\ndef _pitick2latex(x): [MASK]\n", "response": "import copy\nimport ctypes as C\nimport collections.abc\nfrom collections import defaultdict\nfrom copy import deepcopy\nimport itertools\nfrom math import pi\nimport warnings\nimport numpy as np\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nimport scipy.interpolate\nimport obspy.signal.evrespwrapper as ew\nfrom obspy.signal.headers import clibevresp\nimport matplotlib.pyplot as plt\nfrom matplotlib.transforms import blended_transform_factory\nimport doctest\ndef _pitick2latex(x):\n    \"\"\"\n    Helper function to convert a float that is a multiple of pi/2\n    to a latex string.\n    \"\"\"\n    if x % (pi / 2) != 0:\n        return '%#.3g' % x\n    string = '$'\n    if x < 0:\n        string += '-'\n    if x / pi % 1 == 0:\n        x = abs(int(x / pi))\n        if x == 0:\n            return '$0$'\n        elif x == 1:\n            x = ''\n        string += '%s\\\\pi$' % x\n    else:\n        x = abs(int(2 * x / pi))\n        if x == 1:\n            x = ''\n        string += '\\\\frac{%s\\\\pi}{2}$' % x\n    return string"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_yield_obj_parent_attr", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef _yield_obj_parent_attr(obj, cls=None, is_attr=None, has_attr=None): [MASK]\n", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef _yield_obj_parent_attr(obj, cls=None, is_attr=None, has_attr=None):\n    \"\"\"\n    Recurse an object, yield a tuple of object, parent, attr.\n\n    Can be used, for example, to yield all ResourceIdentifier instances\n    contained in any obspy.core.event class instances and attached instances,\n    as well as the objects they are attached to (parents) and the attribute\n    name in which they are stored (attr).\n\n    :param obj:\n        The object to recurse through attributes of lists, tuples, and other\n        instances.\n    :param cls:\n        Only return instances of cls if not None, else return all instances.\n    :param is_attr:\n        Only return objects stored as attr_name, if None return all.\n    :param has_attr:\n        Only return objects that have attribute has_attr, if None return all.\n\n    .. rubric:: General Usage\n\n    Get a list of all resource_ids contained in an event, the objects they\n    are attached to, and the attribute name on the parent object.\n\n    >>> import obspy\n    >>> from obspy.core.event import ResourceIdentifier\n    >>> cat = obspy.read_events()\n    >>> resource_tuple = list(_yield_obj_parent_attr(cat, ResourceIdentifier))\n    \"\"\"\n    ids = set()\n\n    def func(obj, attr=None, parent=None):\n        id_tuple = id(obj), id(parent)\n        if id_tuple not in ids:\n            ids.add(id_tuple)\n            is_attribute = is_attr is None or attr == is_attr\n            has_attribute = has_attr is None or hasattr(obj, has_attr)\n            is_instance = cls is None or isinstance(obj, cls)\n            if is_attribute and has_attribute and is_instance:\n                yield obj, parent, attr\n            if isinstance(obj, (list, tuple)):\n                for val in obj:\n                    for out in func(val, attr=attr, parent=obj):\n                        yield out\n            elif isinstance(obj, dict):\n                for item, val in obj.items():\n                    for out in func(val, attr=item, parent=obj):\n                        yield out\n            elif hasattr(obj, '__slots__'):\n                for attr in obj.__slots__:\n                    val = getattr(obj, attr)\n                    for out in func(val, attr=attr, parent=obj):\n                        yield out\n            elif hasattr(obj, '__dict__'):\n                for item, val in obj.__dict__.items():\n                    for out in func(val, attr=item, parent=obj):\n                        yield out\n    return func(obj)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "farfield", "method_path": "../srcdata/Computation/obspy/obspy/core/event/source.py", "method_code_mask": "import numpy as np\nfrom obspy.core.event.base import _event_type_class_factory\nfrom obspy.core.event.base import CreationInfo\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event.header import EvaluationMode\nfrom obspy.core.event.header import EvaluationStatus\nfrom obspy.core.event.header import MomentTensorCategory\nfrom obspy.core.event.header import MTInversionType\nfrom obspy.core.event.header import SourceTimeFunctionType\nfrom obspy.core.event.header import ATTRIBUTE_HAS_ERRORS\nimport doctest\n\n\ndef farfield(mt, points, type): [MASK]\n", "response": "import numpy as np\nfrom obspy.core.event.base import _event_type_class_factory\nfrom obspy.core.event.base import CreationInfo\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event.header import EvaluationMode\nfrom obspy.core.event.header import EvaluationStatus\nfrom obspy.core.event.header import MomentTensorCategory\nfrom obspy.core.event.header import MTInversionType\nfrom obspy.core.event.header import SourceTimeFunctionType\nfrom obspy.core.event.header import ATTRIBUTE_HAS_ERRORS\nimport doctest\ndef farfield(mt, points, type):\n    \"\"\"\n    Returns the P/S farfield radiation pattern\n    based on [Aki1980]_ eq. 4.29.\n\n    :param mt: Focal mechanism NM x 6 (Mxx, Myy, Mzz, Mxy, Mxz, Myz - the\n               six independent components of the moment tensor)\n\n    :param points: 3D vector array with shape [3,npts] (x,y,z) or [2,npts]\n                   (theta,phi) The normalized displacement of the moment\n                   tensor source is computed at these points.\n    :type type: str\n    :param type: 'P' or 'S' (P or S wave).\n\n    :return: 3D vector array with shape [3,npts] that contains the\n             displacement vector for each grid point\n    \"\"\"\n    type = type.upper()\n    if type not in ('P', 'S'):\n        msg = \"type must be 'P' or 'S'\"\n        raise ValueError(msg)\n    is_p_wave = type == 'P'\n    ndim, npoints = points.shape\n    if ndim == 2:\n        _points = np.empty((3, npoints))\n        _points[0] = np.sin(points[0]) * np.cos(points[1])\n        _points[1] = np.sin(points[0]) * np.sin(points[1])\n        _points[2] = np.cos(points[0])\n        points = _points\n        ndim = 3\n    elif ndim == 3:\n        pass\n    else:\n        raise ValueError('points should have shape 2 x npoints or 3 x npoints')\n    m_pq = _fullmt(mt)\n    dists = np.sqrt(points[0] * points[0] + points[1] * points[1] + points[\n        2] * points[2])\n    gammas = points / dists\n    disp = np.empty((ndim, npoints))\n    if is_p_wave:\n        for ipoint in range(npoints):\n            gamma = gammas[:, ipoint]\n            gammapq = np.outer(gamma, gamma)\n            gammatimesmt = gammapq * m_pq\n            for n in range(ndim):\n                disp[n, ipoint] = gamma[n] * np.sum(gammatimesmt.flatten())\n    else:\n        for ipoint in range(npoints):\n            gamma = gammas[:, ipoint]\n            m_p = np.dot(m_pq, gamma)\n            for n in range(ndim):\n                psum = 0.0\n                for p in range(ndim):\n                    deltanp = int(n == p)\n                    psum += (gamma[n] * gamma[p] - deltanp) * m_p[p]\n                disp[n, ipoint] = psum\n    return disp"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "download_stationxml", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/mass_downloader/utils.py", "method_code_mask": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\n\n\ndef download_stationxml(client, client_name, bulk, filename, logger): [MASK]\n", "response": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\ndef download_stationxml(client, client_name, bulk, filename, logger):\n    \"\"\"\n    Download all channels for a station in the already prepared bulk list.\n\n    :param client: An active client instance.\n    :param client_name: The name of the client mainly used for logging\n        purposes.\n    :param bulk: An already prepared bulk download list for all channels and\n        time intervals for the given station. All items in there are assumed\n        to come from the same station.\n    :param filename: The filename to download to.\n    :param logger: The logger instance to use for logging.\n\n    :returns: A tuple with the network and station id and the filename upon\n        success\n    \"\"\"\n    network = bulk[0][0]\n    station = bulk[0][1]\n    try:\n        client.get_stations_bulk(bulk=bulk, level='response', filename=filename\n            )\n    except Exception:\n        logger.info(\n            \"Failed to download StationXML from '%s' for station '%s.%s'.\" %\n            (client_name, network, station))\n        return None\n    logger.info(\"Client '%s' - Successfully downloaded '%s'.\" % (\n        client_name, filename))\n    return (network, station), filename"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_unified_content_strings", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/util.py", "method_code_mask": "import copy\nimport re\nimport warnings\nfrom textwrap import TextWrapper\nfrom obspy import UTCDateTime\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.decorator import deprecated_keywords\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesFixedUnit\nimport doctest\n\n\ndef _unified_content_strings(contents): [MASK]\n", "response": "import copy\nimport re\nimport warnings\nfrom textwrap import TextWrapper\nfrom obspy import UTCDateTime\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.decorator import deprecated_keywords\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesFixedUnit\nimport doctest\ndef _unified_content_strings(contents):\n    contents_unique = sorted(set(contents), key=_seed_id_keyfunction)\n    contents_counts = [(item, contents.count(item)) for item in contents_unique\n        ]\n    items = [(item if count == 1 else '{} ({}x)'.format(item, count)) for \n        item, count in contents_counts]\n    return items"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "parse_simple_xml", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/client.py", "method_code_mask": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\n\n\ndef parse_simple_xml(xml_string): [MASK]\n", "response": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\ndef parse_simple_xml(xml_string):\n    \"\"\"\n    Simple helper function for parsing the Catalog and Contributor availability\n    files.\n\n    Parses XMLs of the form::\n\n        <Bs>\n            <total>4</total>\n            <B>1</B>\n            <B>2</B>\n            <B>3</B>\n            <B>4</B>\n        </Bs>\n\n    and return a dictionary with a single item::\n\n        {\"Bs\": set((\"1\", \"2\", \"3\", \"4\"))}\n    \"\"\"\n    root = etree.fromstring(xml_string.strip())\n    if not root.tag.endswith('s'):\n        msg = 'Could not parse the XML.'\n        raise ValueError(msg)\n    child_tag = root.tag[:-1]\n    children = [i.text for i in root if i.tag == child_tag]\n    return {root.tag.lower(): set(children)}"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "build_url", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/client.py", "method_code_mask": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\n\n\ndef build_url(base_url, service, major_version, resource_type, parameters=\n    None, service_mappings=None, subpath='fdsnws'): [MASK]\n", "response": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\ndef build_url(base_url, service, major_version, resource_type, parameters=\n    None, service_mappings=None, subpath='fdsnws'):\n    \"\"\"\n    URL builder for the FDSN webservices.\n\n    Built as a separate function to enhance testability.\n\n    >>> print(build_url(\"http://service.iris.edu\", \"dataselect\", 1,                         \"application.wadl\"))\n    http://service.iris.edu/fdsnws/dataselect/1/application.wadl\n\n    >>> print(build_url(\"http://service.iris.edu\", \"dataselect\", 1,                         \"query\", {\"cha\": \"EHE\"}))\n    http://service.iris.edu/fdsnws/dataselect/1/query?cha=EHE\n    \"\"\"\n    if parameters is None:\n        parameters = {}\n    if service_mappings is None:\n        service_mappings = {}\n    if service not in ['dataselect', 'event', 'station']:\n        msg = \"Resource type '%s' not allowed. Allowed types: \\n%s\" % (service,\n            ','.join(('dataselect', 'event', 'station')))\n        raise ValueError(msg)\n    if 'location' in parameters:\n        loc = parameters['location'].replace(' ', '')\n        if not loc:\n            loc = '--'\n        if loc.startswith(','):\n            loc = '--' + loc\n        if loc.endswith(','):\n            loc += '--'\n        loc = loc.replace(',,', ',--,')\n        parameters['location'] = loc\n    if service in service_mappings:\n        url = '/'.join((service_mappings[service], resource_type))\n    else:\n        if subpath is None:\n            parts = base_url, service, str(major_version), resource_type\n        else:\n            parts = base_url, subpath.lstrip('/'), service, str(major_version\n                ), resource_type\n        url = '/'.join(parts)\n    if parameters:\n        for key, value in parameters.items():\n            try:\n                parameters[key] = value.strip()\n            except Exception:\n                pass\n        url = '?'.join((url, urlencode(parameters)))\n    return url"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "locations2degrees", "method_path": "../srcdata/Computation/obspy/obspy/geodetics/base.py", "method_code_mask": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\n\n\ndef locations2degrees(lat1, long1, lat2, long2): [MASK]\n", "response": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\ndef locations2degrees(lat1, long1, lat2, long2):\n    \"\"\"\n    Convenience function to calculate the great circle distance between two\n    points on a spherical Earth.\n\n    This method uses the Vincenty formula in the special case of a spherical\n    Earth. For more accurate values use the geodesic distance calculations of\n    geopy (https://github.com/geopy/geopy).\n\n    :type lat1: float or :class:`numpy.ndarray`\n    :param lat1: Latitude(s) of point 1 in degrees\n    :type long1: float or :class:`numpy.ndarray`\n    :param long1: Longitude(s) of point 1 in degrees\n    :type lat2: float or :class:`numpy.ndarray`\n    :param lat2: Latitude(s) of point 2 in degrees\n    :type long2: float or :class:`numpy.ndarray`\n    :param long2: Longitude(s) of point 2 in degrees\n    :rtype: float or :class:`numpy.ndarray`\n    :return: Distance in degrees as a floating point number,\n        or numpy array of element-wise distances in degrees\n\n    .. rubric:: Example\n\n    >>> from obspy.geodetics import locations2degrees\n    >>> locations2degrees(5, 5, 10, 10) # doctest: +ELLIPSIS\n    7.03970141917538...\n    \"\"\"\n    lat1, lat2, long1, long2 = np.broadcast_arrays(lat1, lat2, long1, long2)\n    lat1 = np.radians(np.asarray(lat1))\n    lat2 = np.radians(np.asarray(lat2))\n    long1 = np.radians(np.asarray(long1))\n    long2 = np.radians(np.asarray(long2))\n    long_diff = long2 - long1\n    gd = np.degrees(np.arctan2(np.sqrt((np.cos(lat2) * np.sin(long_diff)) **\n        2 + (np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np\n        .cos(long_diff)) ** 2), np.sin(lat1) * np.sin(lat2) + np.cos(lat1) *\n        np.cos(lat2) * np.cos(long_diff)))\n    return gd"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "strike_dip", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef strike_dip(n, e, u): [MASK]\n", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef strike_dip(n, e, u):\n    \"\"\"\n    Finds strike and dip of plane given normal vector having components n, e,\n    and u.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    r2d = 180 / np.pi\n    if u < 0:\n        n = -n\n        e = -e\n        u = -u\n    strike = np.arctan2(e, n) * r2d\n    strike = strike - 90\n    while strike >= 360:\n        strike = strike - 360\n    while strike < 0:\n        strike = strike + 360\n    x = np.sqrt(np.power(n, 2) + np.power(e, 2))\n    dip = np.arctan2(x, u) * r2d\n    return strike, dip"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "filter_channel_priority", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/mass_downloader/utils.py", "method_code_mask": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\n\n\ndef filter_channel_priority(channels, key, priorities=None): [MASK]\n", "response": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\ndef filter_channel_priority(channels, key, priorities=None):\n    \"\"\"\n    This function takes a dictionary containing channels keys and returns a new\n    one filtered with the given priorities list.\n\n    All channels matching the first pattern in the list will be retrieved. If\n    one or more channels are found it stops. Otherwise it will attempt to\n    retrieve channels matching the next pattern. And so on.\n\n    :type channels: list\n    :param channels: A list containing channel names.\n    :type priorities: list of unicode or None\n    :param priorities: The desired channels with descending priority. Channels\n    will be matched by fnmatch.fnmatch() so wildcards and sequences are\n    supported. The advisable form to request the three standard components\n    of a channel is \"HH[ZNE]\" to avoid getting e.g. rotated components.\n    :returns: A new list containing only the filtered channels.\n    \"\"\"\n    if priorities is None:\n        return channels\n    filtered_channels = []\n    for pattern in priorities:\n        if filtered_channels:\n            break\n        for channel in channels:\n            if fnmatch.fnmatch(getattr(channel, key), pattern):\n                filtered_channels.append(channel)\n                continue\n    return filtered_channels"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "get_ray_paths", "method_path": "../srcdata/Computation/obspy/obspy/taup/ray_paths.py", "method_code_mask": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom obspy.taup import TauPyModel\n\n\ndef get_ray_paths(inventory, catalog, phase_list=['P'], coordinate_system=\n    'XYZ', taup_model='iasp91'): [MASK]\n", "response": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom obspy.taup import TauPyModel\ndef get_ray_paths(inventory, catalog, phase_list=['P'], coordinate_system=\n    'XYZ', taup_model='iasp91'):\n    \"\"\"\n    This function returns lat, lon, depth coordinates from an event\n    location to all stations in the inventory object\n\n    :param inventory: an obspy station inventory\n    :param catalog: an obspy event catalog\n    :param phase_list: a list of seismic phase names that is passed to taup\n    :param coordinate_system: can be either 'XYZ' or 'RTP'.\n    :param taup_model: the taup model for which the greatcircle paths are\n                  computed\n    :returns: a list of tuples\n        ``[(gcircle, phase_name, station_label, event_timestamp,\n        event_magnitude, event_id, origin_id), ...]``. ``gcircle`` is an array\n        of shape ``[3, npoints]`` with the path coordinates. ``phase_name`` is\n        the name of the seismic phase, ``station_label`` is the name of the\n        station and network that belongs to the path. ``event_timestamp``,\n        ``event_magnitude``, ``event_id`` and ``origin_id`` describe the event\n        that belongs to the path.\n    \"\"\"\n    if not geodetics.HAS_GEOGRAPHICLIB:\n        raise ImportError(\n            'Geographiclib not found but required by ray path routine')\n    stlats = []\n    stlons = []\n    stlabels = []\n    for network in inventory:\n        for station in network:\n            label_ = '.'.join((network.code, station.code))\n            if station.latitude is None or station.longitude is None:\n                msg = (\n                    \"Station '%s' does not have latitude/longitude information and will not be plotted.\"\n                     % label_)\n                warnings.warn(msg)\n                continue\n            stlats.append(station.latitude)\n            stlons.append(station.longitude)\n            stlabels.append(label_)\n    evlats = []\n    evlons = []\n    evdepths = []\n    event_ids = []\n    origin_ids = []\n    magnitudes = []\n    times = []\n    for event in catalog:\n        if not event.origins:\n            msg = (\n                \"Event '%s' does not have an origin and will not be plotted.\" %\n                str(event.resource_id))\n            warnings.warn(msg)\n            continue\n        if not event.magnitudes:\n            msg = (\n                \"Event '%s' does not have a magnitude and will not be plotted.\"\n                 % str(event.resource_id))\n            warnings.warn(msg)\n            continue\n        origin = event.preferred_origin() or event.origins[0]\n        evlats.append(origin.latitude)\n        evlons.append(origin.longitude)\n        if not origin.get('depth'):\n            origin.depth = 0.0\n        evdepths.append(origin.get('depth') * 0.001)\n        magnitude = event.preferred_magnitude() or event.magnitudes[0]\n        mag = magnitude.mag\n        event_ids.append(str(event.resource_id))\n        origin_ids.append(str(origin.resource_id))\n        magnitudes.append(mag)\n        times.append(origin.time.timestamp)\n    if isinstance(taup_model, str):\n        from obspy.taup import TauPyModel\n        model = TauPyModel(model=taup_model)\n    else:\n        model = taup_model\n    r_earth = model.model.radius_of_planet\n    greatcircles = []\n    for stlat, stlon, stlabel in zip(stlats, stlons, stlabels):\n        for evlat, evlon, evdepth_km, time, magnitude, event_id, origin_id in zip(\n            evlats, evlons, evdepths, times, magnitudes, event_ids, origin_ids\n            ):\n            arrivals = model.get_ray_paths_geo(evdepth_km, evlat, evlon,\n                stlat, stlon, phase_list=phase_list, resample=True)\n            if len(arrivals) == 0:\n                continue\n            for arr in arrivals:\n                radii = (r_earth - arr.path['depth']) / r_earth\n                thetas = np.radians(90.0 - arr.path['lat'])\n                phis = np.radians(arr.path['lon'])\n                if coordinate_system == 'RTP':\n                    gcircle = np.array([radii, thetas, phis])\n                if coordinate_system == 'XYZ':\n                    gcircle = np.array([radii * np.sin(thetas) * np.cos(\n                        phis), radii * np.sin(thetas) * np.sin(phis), radii *\n                        np.cos(thetas)])\n                greatcircles.append((gcircle, arr.name, stlabel, time,\n                    magnitude, event_id, origin_id))\n    return greatcircles"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "mt2axes", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef mt2axes(mt): [MASK]\n", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef mt2axes(mt):\n    \"\"\"\n    Calculates the principal axes of a given moment tensor.\n\n    :param mt: :class:`~MomentTensor`\n    :return: tuple of :class:`~PrincipalAxis` T, N and P\n\n    Adapted from ps_tensor / utilmeca.c /\n    `Generic Mapping Tools (GMT) <https://www.generic-mapping-tools.org>`_.\n    \"\"\"\n    d, v = np.linalg.eigh(mt.mt)\n    pl = np.arcsin(-v[0])\n    az = np.arctan2(v[2], -v[1])\n    for i in range(0, 3):\n        if pl[i] <= 0:\n            pl[i] = -pl[i]\n            az[i] += np.pi\n        if az[i] < 0:\n            az[i] += 2 * np.pi\n        if az[i] > 2 * np.pi:\n            az[i] -= 2 * np.pi\n    pl *= R2D\n    az *= R2D\n    t = PrincipalAxis(d[2], az[2], pl[2])\n    n = PrincipalAxis(d[1], az[1], pl[1])\n    p = PrincipalAxis(d[0], az[0], pl[0])\n    return t, n, p"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "tdl", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef tdl(an, bn): [MASK]\n", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef tdl(an, bn):\n    \"\"\"\n    Helper function for mt2plane.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    xn = an[0]\n    yn = an[1]\n    zn = an[2]\n    xe = bn[0]\n    ye = bn[1]\n    ze = bn[2]\n    aaa = 1.0 / 1000000\n    con = 57.2957795\n    if np.fabs(zn) < aaa:\n        fd = 90.0\n        axn = np.fabs(xn)\n        if axn > 1.0:\n            axn = 1.0\n        ft = np.arcsin(axn) * con\n        st = -xn\n        ct = yn\n        if st >= 0.0 and ct < 0:\n            ft = 180.0 - ft\n        if st < 0.0 and ct <= 0:\n            ft = 180.0 + ft\n        if st < 0.0 and ct > 0:\n            ft = 360.0 - ft\n        fl = np.arcsin(abs(ze)) * con\n        sl = -ze\n        if np.fabs(xn) < aaa:\n            cl = xe / yn\n        else:\n            cl = -ye / xn\n        if sl >= 0.0 and cl < 0:\n            fl = 180.0 - fl\n        if sl < 0.0 and cl <= 0:\n            fl = fl - 180.0\n        if sl < 0.0 and cl > 0:\n            fl = -fl\n    else:\n        if -zn > 1.0:\n            zn = -1.0\n        fdh = np.arccos(-zn)\n        fd = fdh * con\n        sd = np.sin(fdh)\n        if sd == 0:\n            return\n        st = -xn / sd\n        ct = yn / sd\n        sx = np.fabs(st)\n        if sx > 1.0:\n            sx = 1.0\n        ft = np.arcsin(sx) * con\n        if st >= 0.0 and ct < 0:\n            ft = 180.0 - ft\n        if st < 0.0 and ct <= 0:\n            ft = 180.0 + ft\n        if st < 0.0 and ct > 0:\n            ft = 360.0 - ft\n        sl = -ze / sd\n        sx = np.fabs(sl)\n        if sx > 1.0:\n            sx = 1.0\n        fl = np.arcsin(sx) * con\n        if st == 0:\n            cl = xe / ct\n        else:\n            xxx = yn * zn * ze / sd / sd + ye\n            cl = -sd * xxx / xn\n            if ct == 0:\n                cl = ye / st\n        if sl >= 0.0 and cl < 0:\n            fl = 180.0 - fl\n        if sl < 0.0 and cl <= 0:\n            fl = fl - 180.0\n        if sl < 0.0 and cl > 0:\n            fl = -fl\n    return ft, fd, fl"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "mt2plane", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef mt2plane(mt): [MASK]\n", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef mt2plane(mt):\n    \"\"\"\n    Calculates a nodal plane of a given moment tensor.\n\n    :param mt: :class:`~MomentTensor`\n    :return: :class:`~NodalPlane`\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    d, v = np.linalg.eig(mt.mt)\n    d = np.array([d[1], d[0], d[2]])\n    v = np.array([[v[1, 1], -v[1, 0], -v[1, 2]], [v[2, 1], -v[2, 0], -v[2, \n        2]], [-v[0, 1], v[0, 0], v[0, 2]]])\n    imax = d.argmax()\n    imin = d.argmin()\n    ae = (v[:, imax] + v[:, imin]) / np.sqrt(2.0)\n    an = (v[:, imax] - v[:, imin]) / np.sqrt(2.0)\n    aer = np.sqrt(np.power(ae[0], 2) + np.power(ae[1], 2) + np.power(ae[2], 2))\n    anr = np.sqrt(np.power(an[0], 2) + np.power(an[1], 2) + np.power(an[2], 2))\n    ae = ae / aer\n    if not anr:\n        an = np.array([np.nan, np.nan, np.nan])\n    else:\n        an = an / anr\n    if an[2] <= 0.0:\n        an1 = an\n        ae1 = ae\n    else:\n        an1 = -an\n        ae1 = -ae\n    ft, fd, fl = tdl(an1, ae1)\n    return NodalPlane(360 - ft, fd, 180 - fl)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "calculate_lanczos_kernel", "method_path": "../srcdata/Computation/obspy/obspy/signal/interpolation.py", "method_code_mask": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef calculate_lanczos_kernel(x, a, window): [MASK]\n", "response": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\ndef calculate_lanczos_kernel(x, a, window):\n    \"\"\"\n    Helper function to get the actually used kernel for a specific value of\n    a. Useful to analyse the behaviour of different tapers and different values\n    of a.\n\n    :type x: :class:`numpy.ndarray`\n    :param x: The x values at which to calculate the kernel.\n    :type a: int\n    :param a: The width of the window in samples on either side.\n    :type window: str\n    :param window: The window used to multiply the sinc function with. One\n        of ``\"lanczos\"``, ``\"hanning\"``, ``\"blackman\"``.\n\n    Returns a dictionary of arrays:\n\n    * ``\"full_kernel\"``: The tapered sinc function evaluated at samples ``x``.\n    * ``\"only_sinc\"``: The sinc function evaluated at samples ``x``.\n    * ``\"only_taper\"``: The taper function evaluated at samples ``x``.\n    \"\"\"\n    window = window.lower()\n    if window not in _LANCZOS_KERNEL_MAP:\n        msg = 'Invalid window. Valid windows: %s' % ', '.join(sorted(\n            _LANCZOS_KERNEL_MAP.keys()))\n        raise ValueError(msg)\n    x = np.require(x, dtype=np.float64)\n    y0 = np.zeros(x.shape, dtype=np.float64)\n    y1 = np.zeros(x.shape, dtype=np.float64)\n    y2 = np.zeros(x.shape, dtype=np.float64)\n    clibsignal.calculate_kernel(x, y0, len(x), a, 0, _LANCZOS_KERNEL_MAP[\n        window])\n    clibsignal.calculate_kernel(x, y1, len(x), a, 1, _LANCZOS_KERNEL_MAP[\n        window])\n    clibsignal.calculate_kernel(x, y2, len(x), a, 2, _LANCZOS_KERNEL_MAP[\n        window])\n    ret_val = {'full_kernel': y0, 'only_sinc': y1, 'only_taper': y2}\n    return ret_val"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "konno_ohmachi_smoothing_window", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef konno_ohmachi_smoothing_window(frequencies, center_frequency, bandwidth\n    =40.0, normalize=False): [MASK]\n", "response": "import warnings\nimport numpy as np\ndef konno_ohmachi_smoothing_window(frequencies, center_frequency, bandwidth\n    =40.0, normalize=False):\n    \"\"\"\n    Returns the Konno & Ohmachi Smoothing window for every frequency in\n    frequencies.\n\n    Returns the smoothing window around the center frequency with one value per\n    input frequency defined as follows (see [Konno1998]_)::\n\n        [sin(b * log_10(f/f_c)) / (b * log_10(f/f_c)]^4\n            b   = bandwidth\n            f   = frequency\n            f_c = center frequency\n\n    The bandwidth of the smoothing function is constant on a logarithmic scale.\n    A small value will lead to a strong smoothing, while a large value of will\n    lead to a low smoothing of the Fourier spectra.\n    The default (and generally used) value for the bandwidth is 40. (From the\n    `Geopsy documentation <http://www.geopsy.org>`_)\n\n    All parameters need to be positive. This is not checked due to performance\n    reasons and therefore any negative parameters might have unexpected\n    results.\n\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        All frequencies for which the smoothing window will be returned.\n    :type center_frequency: float\n    :param center_frequency:\n        The frequency around which the smoothing is performed. Must be greater\n        or equal to 0.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    if frequencies.dtype != np.float32 and frequencies.dtype != np.float64:\n        msg = 'frequencies needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if center_frequency == 0:\n        smoothing_window = np.zeros(len(frequencies), dtype=frequencies.dtype)\n        smoothing_window[frequencies == 0.0] = 1.0\n        return smoothing_window\n    with np.errstate(divide='ignore', invalid='ignore'):\n        smoothing_window = bandwidth * np.log10(frequencies / center_frequency)\n        smoothing_window[:] = (np.sin(smoothing_window) / smoothing_window\n            ) ** 4\n    smoothing_window[frequencies == center_frequency] = 1.0\n    smoothing_window[frequencies == 0.0] = 0.0\n    if normalize:\n        smoothing_window /= smoothing_window.sum()\n    return smoothing_window"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "aux_plane", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef aux_plane(s1, d1, r1): [MASK]\n", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef aux_plane(s1, d1, r1):\n    \"\"\"\n    Get Strike and dip of second plane.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    r2d = 180 / np.pi\n    z = (s1 + 90) / r2d\n    z2 = d1 / r2d\n    z3 = r1 / r2d\n    sl1 = -np.cos(z3) * np.cos(z) - np.sin(z3) * np.sin(z) * np.cos(z2)\n    sl2 = np.cos(z3) * np.sin(z) - np.sin(z3) * np.cos(z) * np.cos(z2)\n    sl3 = np.sin(z3) * np.sin(z2)\n    strike, dip = strike_dip(sl2, sl1, sl3)\n    n1 = np.sin(z) * np.sin(z2)\n    n2 = np.cos(z) * np.sin(z2)\n    h1 = -sl2\n    h2 = sl1\n    z = h1 * n1 + h2 * n2\n    z = z / np.sqrt(h1 * h1 + h2 * h2)\n    float64epsilon = 2.220446049250313e-16\n    if 1.0 < abs(z) < 1.0 + 100 * float64epsilon:\n        z = np.copysign(1.0, z)\n    z = np.arccos(z)\n    rake = 0\n    if sl3 > 0:\n        rake = z * r2d\n    if sl3 <= 0:\n        rake = -z * r2d\n    return strike, dip, rake"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "apply_smoothing_matrix", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef apply_smoothing_matrix(spectra, smoothing_matrix, count=1): [MASK]\n", "response": "import warnings\nimport numpy as np\ndef apply_smoothing_matrix(spectra, smoothing_matrix, count=1):\n    \"\"\"\n    Smooths a matrix containing one spectra per row with the Konno-Ohmachi\n    smoothing window, using a smoothing matrix pre-computed through the\n    :func:`~obspy.signal.konnoohmachismoothing.calculate_smoothing_matrix`\n    function.\n    This function is useful if one needs to smooth the same type of spectrum\n    (same shape) through different function calls.\n\n    All spectra need to have frequency bins corresponding to the same\n    frequencies.\n    \"\"\"\n    if spectra.dtype not in (np.float32, np.float64):\n        msg = '`spectra` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    new_spec = np.dot(spectra, smoothing_matrix)\n    for _i in range(count - 1):\n        new_spec = np.dot(new_spec, smoothing_matrix)\n    return new_spec"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "calc_dist", "method_path": "../srcdata/Computation/obspy/obspy/taup/taup_geo.py", "method_code_mask": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom geographiclib.geodesic import Geodesic\n\n\ndef calc_dist(source_latitude_in_deg, source_longitude_in_deg,\n    receiver_latitude_in_deg, receiver_longitude_in_deg,\n    radius_of_planet_in_km, flattening_of_planet): [MASK]\n", "response": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom geographiclib.geodesic import Geodesic\ndef calc_dist(source_latitude_in_deg, source_longitude_in_deg,\n    receiver_latitude_in_deg, receiver_longitude_in_deg,\n    radius_of_planet_in_km, flattening_of_planet):\n    \"\"\"\n    Given the source and receiver location, calculate distance.\n\n    :param source_latitude_in_deg: Source location latitude in degrees\n    :type source_latitude_in_deg: float\n    :param source_longitude_in_deg: Source location longitude in degrees\n    :type source_longitude_in_deg: float\n    :param receiver_latitude_in_deg: Receiver location latitude in degrees\n    :type receiver_latitude_in_deg: float\n    :param receiver_longitude_in_deg: Receiver location longitude in degrees\n    :type receiver_longitude_in_deg: float\n    :param radius_of_planet_in_km: Radius of the planet in km\n    :type radius_of_planet_in_km: float\n    :param flattening_of_planet: Flattening of planet (0 for a sphere)\n    :type receiver_longitude_in_deg: float\n\n    :return: distance_in_deg\n    :rtype: float\n    \"\"\"\n    return calc_dist_azi(source_latitude_in_deg, source_longitude_in_deg,\n        receiver_latitude_in_deg, receiver_longitude_in_deg,\n        radius_of_planet_in_km, flattening_of_planet)[0]"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_load_cdll", "method_path": "../srcdata/Computation/obspy/obspy/core/util/libnames.py", "method_code_mask": "import ctypes\nimport importlib.machinery\nfrom pathlib import Path\nimport re\nimport doctest\n\n\ndef _load_cdll(name): [MASK]\n", "response": "import ctypes\nimport importlib.machinery\nfrom pathlib import Path\nimport re\nimport doctest\ndef _load_cdll(name):\n    \"\"\"\n    Helper function to load a shared library built during ObsPy installation\n    with ctypes.\n\n    :type name: str\n    :param name: Name of the library to load (e.g. 'mseed').\n    :rtype: :class:`ctypes.CDLL`\n    \"\"\"\n    errors = []\n    libdir = Path(__file__).parent.parent.parent / 'lib'\n    for ext in importlib.machinery.EXTENSION_SUFFIXES:\n        libpath = (libdir / (name + ext)).resolve()\n        try:\n            cdll = ctypes.CDLL(str(libpath))\n        except Exception as e:\n            errors.append(f'    {str(e)}')\n        else:\n            return cdll\n    raise ImportError('\\n  '.join([\n        f'Could not load shared library \"{name}\"', *errors, \n        'Current directory: %s' % Path().resolve(),\n        'Directory listing of lib directory:', *(f'    {str(d)}' for d in\n        sorted(libpath.parent.iterdir()))]))"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "konno_ohmachi_smoothing", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef konno_ohmachi_smoothing(spectra, frequencies, bandwidth=40, count=1,\n    enforce_no_matrix=False, max_memory_usage=512, normalize=False): [MASK]\n", "response": "import warnings\nimport numpy as np\ndef konno_ohmachi_smoothing(spectra, frequencies, bandwidth=40, count=1,\n    enforce_no_matrix=False, max_memory_usage=512, normalize=False):\n    \"\"\"\n    Smooths a matrix containing one spectra per row with the Konno-Ohmachi\n    smoothing window.\n\n    All spectra need to have frequency bins corresponding to the same\n    frequencies.\n\n    This method first will estimate the memory usage and then either use a fast\n    and memory intensive method or a slow one with a better memory usage.\n\n    :type spectra: :class:`numpy.ndarray` (float32 or float64)\n    :param spectra:\n        One or more spectra per row. If more than one the first spectrum has to\n        be accessible via spectra[0], the next via spectra[1], ...\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        Contains the frequencies for the spectra.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type count: int, optional\n    :param count:\n        How often the apply the filter. For very noisy spectra it is useful to\n        apply is more than once. Defaults to 1.\n    :type enforce_no_matrix: bool, optional\n    :param enforce_no_matrix:\n        An efficient but memory intensive matrix-multiplication algorithm is\n        used in case more than one spectra is to be smoothed or one spectrum is\n        to be smoothed more than once if enough memory is available. This flag\n        disables the matrix algorithm altogether. Defaults to False\n    :type max_memory_usage: int, optional\n    :param max_memory_usage:\n        Set the maximum amount of extra memory in MB for this method. Decides\n        whether or not the matrix multiplication method is used. Defaults to\n        512 MB.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    if spectra.dtype not in (np.float32, np.float64):\n        msg = '`spectra` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if frequencies.dtype not in (np.float32, np.float64):\n        msg = '`frequencies` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if frequencies.dtype != spectra.dtype:\n        frequencies = np.require(frequencies, np.float64)\n        spectra = np.require(spectra, np.float64)\n        msg = (\n            '`frequencies` and `spectra` should have the same dtype. It ' +\n            'will be changed to np.float64 for both.')\n        warnings.warn(msg)\n    if frequencies.dtype == np.float32:\n        size = 4.0\n    elif frequencies.dtype == np.float64:\n        size = 8.0\n    length = len(frequencies)\n    approx_mem_usage = (length * length + 2 * len(spectra) + length\n        ) * size / 1048576.0\n    if enforce_no_matrix is False and (len(spectra.shape) > 1 or count > 1\n        ) and approx_mem_usage < max_memory_usage:\n        smoothing_matrix = calculate_smoothing_matrix(frequencies,\n            bandwidth, normalize=normalize)\n        return apply_smoothing_matrix(spectra, smoothing_matrix, count=count)\n    else:\n        new_spec = np.empty(spectra.shape, spectra.dtype)\n        if len(new_spec.shape) == 1:\n            for _i in range(len(frequencies)):\n                window = konno_ohmachi_smoothing_window(frequencies,\n                    frequencies[_i], bandwidth, normalize=normalize)\n                new_spec[_i] = (window * spectra).sum()\n        else:\n            for _i in range(len(frequencies)):\n                window = konno_ohmachi_smoothing_window(frequencies,\n                    frequencies[_i], bandwidth, normalize=normalize)\n                for _j, spec in enumerate(spectra):\n                    new_spec[_j, _i] = (window * spec).sum()\n        for _i in range(count - 1):\n            new_spec = konno_ohmachi_smoothing(new_spec, frequencies,\n                bandwidth, enforce_no_matrix=True, normalize=normalize)\n        return new_spec"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "lanczos_interpolation", "method_path": "../srcdata/Computation/obspy/obspy/signal/interpolation.py", "method_code_mask": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef lanczos_interpolation(data, old_start, old_dt, new_start, new_dt,\n    new_npts, a, window='lanczos', *args, **kwargs): [MASK]\n", "response": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\ndef lanczos_interpolation(data, old_start, old_dt, new_start, new_dt,\n    new_npts, a, window='lanczos', *args, **kwargs):\n    \"\"\"\n    Function performing Lanczos resampling, see\n    https://en.wikipedia.org/wiki/Lanczos_resampling for details. Essentially a\n    finite support version of sinc resampling (the ideal reconstruction\n    filter). For large values of ``a`` it converges towards sinc resampling. If\n    used for downsampling, make sure to apply an appropriate anti-aliasing\n    lowpass filter first.\n\n    .. note::\n\n        In most cases you do not want to call this method directly but invoke\n        it via either the :meth:`obspy.core.stream.Stream.interpolate` or\n        :meth:`obspy.core.trace.Trace.interpolate` method. These offer a nicer\n        API that naturally integrates with the rest of ObsPy. Use\n        ``method=\"lanczos\"`` to use this interpolation method. In that case the\n        only additional parameters of interest are ``a`` and ``window``.\n\n    :type data: array_like\n    :param data: Array to interpolate.\n    :type old_start: float\n    :param old_start: The start of the array as a number.\n    :type old_start: float\n    :param old_dt: The time delta of the current array.\n    :type new_start: float\n    :param new_start: The start of the interpolated array. Must be greater\n        or equal to the current start of the array.\n    :type new_dt: float\n    :param new_dt: The desired new time delta.\n    :type new_npts: int\n    :param new_npts: The new number of samples.\n    :type a: int\n    :param a: The width of the window in samples on either side. Runtime\n        scales linearly with the value of ``a`` but the interpolation also gets\n        better.\n    :type window: str\n    :param window: The window used to taper the sinc function. One of\n        ``\"lanczos\"``, ``\"hanning\"``, ``\"blackman\"``. The window determines\n        the trade-off between \"sharpness\" and the amplitude of the wiggles in\n        the pass and stop band. Please use the\n        :func:`~obspy.signal.interpolation.plot_lanczos_windows` function to\n        judge these for any given application.\n\n    Values of ``a`` >= 20 show good results even for data that has\n    energy close to the Nyquist frequency. If your data is extremely\n    oversampled you can get away with much smaller ``a``'s.\n\n    To get an idea of the response of the filter and the effect of the\n    different windows, please use the\n    :func:`~obspy.signal.interpolation.plot_lanczos_windows` function.\n\n    Also be aware of any boundary effects. All values outside the data\n    range are assumed to be zero which matters when calculating interpolated\n    values at the boundaries. At each side the area with potential boundary\n    effects is ``a`` * ``old_dt``. If you want to avoid any boundary effects\n    you will have to remove these values.\n\n    **Mathematical Details:**\n\n    The :math:`\\\\operatorname{sinc}` function is defined as\n\n    .. math::\n\n        \\\\operatorname{sinc}(t) = \\\\frac{\\\\sin(\\\\pi t)}{\\\\pi t}.\n\n    The Lanczos kernel is then given by a multiplication of the\n    :math:`\\\\operatorname{sinc}` function with an additional window function\n    resulting in a finite support kernel.\n\n    .. math::\n\n        \\\\begin{align}\n            L(t) =\n            \\\\begin{cases}\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\operatorname{sinc}(t/a)\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{lanczos}\\\\\\\\\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\frac{1}{2}\n                (1 + \\\\cos(\\\\pi\\\\, t/a))\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{hanning}\\\\\\\\\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\left( \\\\frac{21}{50} +\n                \\\\frac{1}{2}\n                \\\\cos(\\\\pi\\\\, t/a) + \\\\frac{2}{25} \\\\cos (2\\\\pi\\\\, t/a) \\\\right)\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{blackman}\\\\\\\\\n                0                     & \\\\text{else}\n            \\\\end{cases}\n        \\\\end{align}\n\n\n    Finally interpolation is performed by convolving the discrete signal\n    :math:`s_i` with that kernel and evaluating it at the new time samples\n    :math:`t_j`:\n\n    .. math::\n\n        \\\\begin{align}\n            S(t_j) =\n                \\\\sum_{i = \\\\left \\\\lfloor{t_j / \\\\Delta t}\\\\right \\\\rfloor -a + 1}\n                    ^{\\\\left \\\\lfloor{t_j / \\\\Delta t}\\\\right \\\\rfloor + a}\n            s_i L(t_j/\\\\Delta t - i),\n        \\\\end{align}\n\n    where :math:`\\\\lfloor \\\\cdot \\\\rfloor` denotes the floor function. For more\n    details and justification please see [Burger2009]_ and [vanDriel2015]_.\n    \"\"\"\n    _validate_parameters(data, old_start, old_dt, new_start, new_dt, new_npts)\n    dt_factor = float(new_dt) / old_dt\n    offset = (new_start - old_start) / float(old_dt)\n    if offset < 0:\n        raise ValueError(\n            'Cannot extrapolate. Make sure to only interpolate within the time range of the original signal.'\n            )\n    if a < 1:\n        raise ValueError('a must be at least 1.')\n    return_data = np.zeros(new_npts, dtype=np.float64)\n    clibsignal.lanczos_resample(np.require(data, dtype=np.float64),\n        return_data, dt_factor, offset, len(data), len(return_data), int(a), 0)\n    return return_data"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_create_stream", "method_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_waveform.py", "method_code_mask": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\n\n\ndef _create_stream(starttime, endtime, sampling_rate): [MASK]\n", "response": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\ndef _create_stream(starttime, endtime, sampling_rate):\n    \"\"\"\n    Helper method to create a Stream object that can be used for testing\n    waveform plotting.\n\n    Takes the time frame of the Stream to be created and a sampling rate.\n    Any other header information will have to be adjusted on a case by case\n    basis. Please remember to use the same sampling rate for one Trace as\n    merging and plotting will not work otherwise.\n\n    This method will create a single sine curve to a first approximation\n    with superimposed 10 smaller sine curves on it.\n\n    :return: Stream object\n    \"\"\"\n    time_delta = endtime - starttime\n    number_of_samples = int(time_delta * sampling_rate) + 1\n    curve = np.linspace(0, 2 * np.pi, number_of_samples // 2)\n    curve = np.sin(curve) + 0.2 * np.sin(10 * curve)\n    data = np.empty(number_of_samples)\n    if number_of_samples % 2 == 0:\n        data[0::2] = curve\n        data[1::2] = curve + 0.2\n    else:\n        data[-1] = 0.0\n        data[0:-1][0::2] = curve\n        data[0:-1][1::2] = curve + 0.2\n    tr = Trace()\n    tr.stats.starttime = starttime\n    tr.stats.sampling_rate = float(sampling_rate)\n    tr.stats.network = 'BW'\n    tr.stats.station = 'OBSPY'\n    tr.stats.channel = 'TEST'\n    tr.data = data\n    return Stream(traces=[tr])"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "xcorr_3c", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef xcorr_3c(st1, st2, shift_len, components=['Z', 'N', 'E'], full_xcorr=\n    False, abs_max=True): [MASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef xcorr_3c(st1, st2, shift_len, components=['Z', 'N', 'E'], full_xcorr=\n    False, abs_max=True):\n    \"\"\"\n    Calculates the cross correlation on each of the specified components\n    separately, stacks them together and estimates the maximum and shift of\n    maximum on the stack.\n\n    Basically the same as `~obspy.signal.cross_correlation.correlate` but\n    for (normally) three components, please also take a look at the\n    documentation of that function. Useful e.g. for estimation of waveform\n    similarity on a three component seismogram.\n\n    :type st1: :class:`~obspy.core.stream.Stream`\n    :param st1: Stream 1, containing one trace for Z, N, E component (other\n        component_id codes are ignored)\n    :type st2: :class:`~obspy.core.stream.Stream`\n    :param st2: Stream 2, containing one trace for Z, N, E component (other\n        component_id codes are ignored)\n    :type shift_len: int\n    :param shift_len: Total length of samples to shift for cross correlation.\n    :type components: list[str]\n    :param components: List of components to use in cross-correlation, defaults\n        to ``['Z', 'N', 'E']``.\n    :type full_xcorr: bool\n    :param full_xcorr: If ``True``, the complete xcorr function will be\n        returned as :class:`~numpy.ndarray`.\n    :param bool abs_max: *shift* will be calculated for maximum or\n        absolute maximum.\n    :return: **index, value[, fct]** - index of maximum xcorr value and the\n        value itself. The complete xcorr function is returned only if\n        ``full_xcorr=True``.\n    \"\"\"\n    streams = [st1, st2]\n    for st in streams:\n        if not isinstance(st, Stream):\n            raise TypeError('Expected Stream object but got %s.' % type(st))\n        for component in components:\n            if not len(st.select(component=component)) == 1:\n                msg = ('Expected exactly one %s trace in stream' %\n                    component + ' but got %s.' % len(st.select(component=\n                    component)))\n                raise ValueError(msg)\n    ndat = len(streams[0].select(component=components[0])[0])\n    if False in [(len(st.select(component=component)[0]) == ndat) for st in\n        streams for component in components]:\n        raise ValueError('All traces have to be the same length.')\n    corp = np.zeros(2 * shift_len + 1, dtype=np.float64, order='C')\n    for component in components:\n        xx = correlate(streams[0].select(component=component)[0], streams[1\n            ].select(component=component)[0], shift_len)\n        corp += xx\n    corp /= len(components)\n    shift, value = xcorr_max(corp, abs_max=abs_max)\n    if full_xcorr:\n        return shift, value, corp\n    else:\n        return shift, value"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "calculate_smoothing_matrix", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef calculate_smoothing_matrix(frequencies, bandwidth=40.0, normalize=False): [\n    MASK]\n", "response": "import warnings\nimport numpy as np\ndef calculate_smoothing_matrix(frequencies, bandwidth=40.0, normalize=False):\n    \"\"\"\n    Calculates a len(frequencies) x len(frequencies) matrix with the Konno &\n    Ohmachi window for each frequency as the center frequency.\n\n    Any spectrum with the same frequency bins as this matrix can later be\n    smoothed by using\n    :func:`~obspy.signal.konnoohmachismoothing.apply_smoothing_matrix`.\n\n    This also works for many spectra stored in one large matrix and is even\n    more efficient.\n\n    This makes it very efficient for smoothing the same spectra again and again\n    but it comes with a high memory consumption for larger frequency arrays!\n\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        The input frequencies.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    sm_matrix = np.empty((len(frequencies), len(frequencies)), frequencies.\n        dtype)\n    for _i, freq in enumerate(frequencies):\n        sm_matrix[_i, :] = konno_ohmachi_smoothing_window(frequencies, freq,\n            bandwidth, normalize=normalize)\n    return sm_matrix"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "traces_almost_equal", "method_path": "../srcdata/Computation/obspy/obspy/core/util/testing.py", "method_code_mask": "import difflib\nimport doctest\nimport inspect\nimport io\nimport os\nimport re\nimport numpy as np\nfrom lxml import etree\nimport obspy.core.event as ev\nfrom obspy import UTCDateTime\nfrom obspy import Catalog\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.trace import Stats\n\n\ndef traces_almost_equal(tr1, tr2, default_stats=True, rtol=1e-05, atol=\n    1e-08, equal_nan=True): [MASK]\n", "response": "import difflib\nimport doctest\nimport inspect\nimport io\nimport os\nimport re\nimport numpy as np\nfrom lxml import etree\nimport obspy.core.event as ev\nfrom obspy import UTCDateTime\nfrom obspy import Catalog\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.trace import Stats\ndef traces_almost_equal(tr1, tr2, default_stats=True, rtol=1e-05, atol=\n    1e-08, equal_nan=True):\n    \"\"\"\n    Return True if the two traces are almost equal.\n\n    :param tr1: The first :class:`~obspy.core.trace.Trace` object.\n    :param tr2: The second :class:`~obspy.core.trace.Trace` object.\n    :param default_stats:\n        If True only compare the default stats on the traces, such as seed\n        identification codes, start/end times, sampling_rates, etc. If\n        False also compare extra stats attributes such as processing and\n        format specific information.\n    :param rtol: The relative tolerance parameter passed to\n        :func:`~numpy.allclose` for comparing time series.\n    :param atol: The absolute tolerance parameter passed to\n        :func:`~numpy.allclose` for comparing time series.\n    :param equal_nan:\n        If ``True`` NaNs are evaluated equal when comparing the time\n        series.\n    :return: bool\n    \"\"\"\n    from obspy.core.trace import Trace\n    if not isinstance(tr2, Trace) or len(tr1.data) != len(tr2.data):\n        return False\n    try:\n        all_close = np.allclose(tr1.data, tr2.data, rtol=rtol, atol=atol,\n            equal_nan=equal_nan)\n    except TypeError:\n        is_close = np.isclose(tr1.data, tr2.data, rtol=rtol, atol=atol)\n        if equal_nan:\n            isnan = np.isnan(tr1.data) & np.isnan(tr2.data)\n        else:\n            isnan = np.zeros(tr1.data.shape).astype(bool)\n        all_close = np.all(isnan | is_close)\n    stats1 = _make_stats_dict(tr1, default_stats)\n    stats2 = _make_stats_dict(tr2, default_stats)\n    return all_close and stats1 == stats2"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "aic_simple_python", "method_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py", "method_code_mask": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef aic_simple_python(a): [MASK]\n", "response": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\ndef aic_simple_python(a):\n    if len(a) <= 2:\n        return np.zeros(len(a), dtype=np.float64)\n    a = np.asarray(a)\n    aic_cf = np.zeros(a.size - 1, dtype=np.float64)\n    with np.errstate(divide='ignore'):\n        aic_cf[0] = (a.size - 2) * np.log(np.var(a[1:]))\n        aic_cf[-1] = (a.size - 1) * np.log(np.var(a[:-1]))\n        for ii in range(2, a.size - 1):\n            var1 = np.log(np.var(a[:ii]))\n            var2 = np.log(np.var(a[ii:]))\n            val1 = ii * var1\n            val2 = (a.size - ii - 1) * var2\n            aic_cf[ii - 1] = val1 + val2\n    aic_cf = np.r_[aic_cf, aic_cf[-1]]\n    return aic_cf"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "trigger_onset", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef trigger_onset(charfct, thres1, thres2, max_len=9e+99, max_len_delete=False\n    ): [MASK]\n", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef trigger_onset(charfct, thres1, thres2, max_len=9e+99, max_len_delete=False\n    ):\n    \"\"\"\n    Calculate trigger on and off times.\n\n    Given thres1 and thres2 calculate trigger on and off times from\n    characteristic function.\n\n    This method is written in pure Python and gets slow as soon as there\n    are more then 1e6 triggerings (\"on\" AND \"off\") in charfct --- normally\n    this does not happen.\n\n    :type charfct: NumPy :class:`~numpy.ndarray`\n    :param charfct: Characteristic function of e.g. STA/LTA trigger\n    :type thres1: float\n    :param thres1: Value above which trigger (of characteristic function)\n                   is activated (higher threshold)\n    :type thres2: float\n    :param thres2: Value below which trigger (of characteristic function)\n        is deactivated (lower threshold)\n    :type max_len: int\n    :param max_len: Maximum length of triggered event in samples. A new\n                    event will be triggered as soon as the signal reaches\n                    again above thres1.\n    :type max_len_delete: bool\n    :param max_len_delete: Do not write events longer than max_len into\n                           report file.\n    :rtype: List\n    :return: Nested List of trigger on and of times in samples\n    \"\"\"\n    ind1 = np.where(charfct >= thres1)[0]\n    if len(ind1) == 0:\n        return []\n    ind2 = np.where(charfct >= thres2)[0]\n    on = deque([ind1[0]])\n    of = deque([-1])\n    ind2_ = np.empty_like(ind2, dtype=bool)\n    ind2_[:-1] = np.diff(ind2) > 1\n    ind2_[-1] = True\n    of.extend(ind2[ind2_].tolist())\n    on.extend(ind1[np.where(np.diff(ind1) > 1)[0] + 1].tolist())\n    if max_len_delete:\n        of.extend([1e+99])\n        on.extend([on[-1]])\n    else:\n        of.extend([ind2[-1]])\n    of.append(len(charfct))\n    pick = []\n    while on[-1] > of[0]:\n        while on[0] <= of[0]:\n            on.popleft()\n        while of[0] < on[0]:\n            of.popleft()\n        if of[0] - on[0] > max_len:\n            if max_len_delete:\n                on.popleft()\n                continue\n            of.appendleft(on[0] + max_len)\n        pick.append([on[0], of[0]])\n    return np.array(pick, dtype=np.int64)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "energy_ratio", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef energy_ratio(a, nsta): [MASK]\n", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef energy_ratio(a, nsta):\n    \"\"\"\n    Energy ratio detector.\n\n    Energy ratio defined as\n\n    .. math::\n        \\\\text{er}(i) = \\\\frac{\\\\sum_{j=i}^{i+L}{a_j^2}}{\\\\sum_{j=i-L}^{i}{a_j^2}}\n\n    where :math:`L` is ``nsta``.\n\n    :type a: NumPy :class:`~numpy.ndarray`\n    :param a: Seismic Trace\n    :type nsta: int\n    :param nsta: Length of the energy ratio window in samples. It's the same\n                 length as ``nsta`` in the classical STA/LTA methods.\n    :rtype: NumPy :class:`~numpy.ndarray`\n    :return: Energy Ratio\n\n    .. seealso:: [Han2009]_\n    \"\"\"\n    if nsta > len(a) // 2:\n        msg = (\n            f'nsta ({nsta}) must not be larger than half the length of the data ({len(a)} samples).'\n            )\n        raise ValueError(msg)\n    if nsta <= 0:\n        msg = f'nsta ({nsta}) must not be equal to or less than zero.'\n        raise ValueError(msg)\n    sig_power = np.r_[0, np.cumsum(a ** 2, dtype=np.float64)]\n    energy_diff = sig_power[nsta:] - sig_power[:len(sig_power) - nsta]\n    er = np.zeros(len(a), dtype=np.float64)\n    np.divide(energy_diff[nsta:], energy_diff[:len(energy_diff) - nsta],\n        where=energy_diff[:len(energy_diff) - nsta] != 0, out=er[nsta:len(\n        er) - nsta + 1])\n    return er"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "bandpass", "method_path": "../srcdata/Computation/obspy/obspy/signal/filter.py", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\n\n\ndef bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False, rp=\n    None, rs=None, ftype='butter', axis=-1): [MASK]\n", "response": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\ndef bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False, rp=\n    None, rs=None, ftype='butter', axis=-1):\n    \"\"\"\n    Bandpass Filter.\n\n    Filter data from ``freqmin`` to ``freqmax`` using ``corners``\n    corners.\n    The filter uses :func:`scipy.signal.iirfilter` (for design)\n    and :func:`scipy.signal.sosfilt` (for applying the filter).\n\n    :type data: numpy.ndarray\n    :param data: Data to filter.\n    :param freqmin: Pass band low corner frequency.\n    :param freqmax: Pass band high corner frequency.\n    :param df: Sampling rate in Hz.\n    :param corners: Filter corners / order.\n    :param zerophase: If True, apply filter once forwards and once backwards.\n        This results in twice the filter order but zero phase shift in\n        the resulting filtered trace.\n    :param rp:\n        For Chebyshev and elliptic filters, provides the maximum ripple\n        in the passband. (dB)\n    :param rs:\n        For Chebyshev and elliptic filters, provides the minimum attenuation\n        in the stop band. (dB)\n    :param ftype:\n        The type of filter\n            - Butterworth   : 'butter' (default)\n            - Chebyshev I   : 'cheby1'\n            - Chebyshev II  : 'cheby2'\n            - Cauer/elliptic: 'ellip'\n            - Bessel/Thomson: 'bessel'\n    :param axis: The axis of the input data array along which to apply the\n        linear filter. The filter is applied to each subarray along this axis.\n        Default is -1.\n    :return: Filtered data.\n    \"\"\"\n    fe = 0.5 * df\n    low = freqmin / fe\n    high = freqmax / fe\n    if high - 1.0 > -1e-06:\n        msg = (\n            'Selected high corner frequency ({}) of bandpass is at or above Nyquist ({}). Applying a high-pass instead.'\n            .format(freqmax, fe))\n        warnings.warn(msg)\n        return highpass(data, freq=freqmin, df=df, corners=corners, ftype=\n            ftype, zerophase=zerophase)\n    if low > 1:\n        msg = 'Selected low corner frequency is above Nyquist.'\n        raise ValueError(msg)\n    return _filter(data, (freqmin, freqmax), df, rp=rp, rs=rs, btype='band',\n        ftype=ftype, corners=corners, zerophase=zerophase, axis=axis)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "aic_simple", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef aic_simple(a): [MASK]\n", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef aic_simple(a):\n    \"\"\"\n    Simple Akaike Information Criterion [Maeda1985]_.\n\n    It's computed directly from input data :math:`a` and defined as\n\n    .. math::\n        \\\\text{AIC}(k) = k\\\\log(\\\\text{Var}(a_{1..k})) +\n                        (N-k-1)\\\\log(\\\\text{Var}(a_{k+1..N}))\n\n    which variance denoted as :math:`\\\\text{Var}`.\n\n    The true output is one data sample less. To make it convenient with other\n    metrics in this module, where the output length is preserved, the last\n    element is appended to the output: ``aic[-2] == aic[-1]``.\n\n    :type a: :class:`numpy.ndarray` or :class:`list`\n    :param a: Input time series\n    :rtype: :class:`numpy.ndarray`\n    :return: aic - Akaike Information Criterion array\n    \"\"\"\n    n = len(a)\n    if n <= 2:\n        return np.zeros(n, dtype=np.float64)\n    a = np.ascontiguousarray(a, np.float64)\n    aic_res = np.empty(n, dtype=np.float64)\n    clibsignal.aic_simple(aic_res, a, n)\n    return aic_res"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_get_default_eps", "method_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py", "method_code_mask": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\n\ndef _get_default_eps(group, subgroup=None): [MASK]\n", "response": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\ndef _get_default_eps(group, subgroup=None):\n    eps = _get_entry_points(group, subgroup=subgroup)\n    eps = {ep: f for ep, f in eps.items() if any(m in f.module_name for m in\n        DEFAULT_MODULES)}\n    return eps"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "peak_ground_motion", "method_path": "../srcdata/Computation/obspy/obspy/signal/freqattributes.py", "method_code_mask": "from operator import itemgetter\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom scipy import sparse\nfrom obspy.signal import util\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom obspy.signal.invsim import simulate_seismometer\n\n\ndef peak_ground_motion(data, delta, freq, damp=0.1): [MASK]\n", "response": "from operator import itemgetter\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom scipy import sparse\nfrom obspy.signal import util\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom obspy.signal.invsim import simulate_seismometer\ndef peak_ground_motion(data, delta, freq, damp=0.1):\n    \"\"\"\n    Peak ground motion parameters\n\n    Compute the maximal displacement, velocity, acceleration and the peak\n    ground acceleration at a certain frequency (standard periods for\n    ShakeMaps are 0.3/1.0/3.0 seconds. Note that the above input is expected as\n    frequency in Hertz.).\n\n    Data must be displacement\n\n    :type data: :class:`~numpy.ndarray`\n    :param data: Data in displacement to convolve with pendulum at freq.\n    :type delta: float\n    :param delta: Sampling interval\n    :type freq: float\n    :param freq: Frequency in Hz.\n    :type damp: float\n    :param damp: damping factor. Default is set to 0.1\n    :rtype: (float, float, float, float)\n    :return: Peak Ground Acceleration, maximal displacement, velocity,\n        acceleration\n    \"\"\"\n    data = data.copy()\n    if abs(max(data)) >= abs(min(data)):\n        m_dis = abs(max(data))\n    else:\n        m_dis = abs(min(data))\n    data = np.gradient(data, delta)\n    if abs(max(data)) >= abs(min(data)):\n        m_vel = abs(max(data))\n    else:\n        m_vel = abs(min(data))\n    data = np.gradient(data, delta)\n    if abs(max(data)) >= abs(min(data)):\n        m_acc = abs(max(data))\n    else:\n        m_acc = abs(min(data))\n    samp_rate = 1.0 / delta\n    t = freq * 1.0\n    d = damp\n    omega = (2 * 3.14159 * t) ** 2\n    paz_sa = corn_freq_2_paz(t, damp=d)\n    paz_sa['sensitivity'] = omega\n    paz_sa['zeros'] = []\n    data = simulate_seismometer(data, samp_rate, paz_remove=None,\n        paz_simulate=paz_sa, taper=True, simulate_sensitivity=True,\n        taper_fraction=0.05)\n    if abs(max(data)) >= abs(min(data)):\n        pga = abs(max(data))\n    else:\n        pga = abs(min(data))\n    return pga, m_dis, m_vel, m_acc"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "get_spoint", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef get_spoint(stream, stime, etime): [MASK]\n", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef get_spoint(stream, stime, etime):\n    \"\"\"\n    Calculates start and end offsets relative to stime and etime for each\n    trace in stream in samples.\n\n    :type stime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param stime: Start time\n    :type etime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param etime: End time\n    :returns: start and end sample offset arrays\n    \"\"\"\n    spoint = np.empty(len(stream), dtype=np.int32, order='C')\n    epoint = np.empty(len(stream), dtype=np.int32, order='C')\n    for i, tr in enumerate(stream):\n        if tr.stats.starttime > stime:\n            msg = 'Specified stime %s is smaller than starttime %s in stream'\n            raise ValueError(msg % (stime, tr.stats.starttime))\n        if tr.stats.endtime < etime:\n            msg = 'Specified etime %s is bigger than endtime %s in stream'\n            raise ValueError(msg % (etime, tr.stats.endtime))\n        spoint[i] = int((stime - tr.stats.starttime) * tr.stats.\n            sampling_rate + 0.5)\n        epoint[i] = int((tr.stats.endtime - etime) * tr.stats.sampling_rate +\n            0.5)\n    return spoint, epoint"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_parse_date_time", "method_path": "../srcdata/Computation/obspy/obspy/io/ndk/core.py", "method_code_mask": "import math\nimport re\nimport traceback\nimport uuid\nimport warnings\nfrom itertools import zip_longest\nfrom obspy import UTCDateTime\nfrom obspy.core.event import Axis\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import DataUsed\nfrom obspy.core.event import Event\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import Origin\nfrom obspy.core.event import PrincipalAxes\nfrom obspy.core.event import SourceTimeFunction\nfrom obspy.core.event import Tensor\nfrom obspy.geodetics import FlinnEngdahl\n\n\ndef _parse_date_time(date, time): [MASK]\n", "response": "import math\nimport re\nimport traceback\nimport uuid\nimport warnings\nfrom itertools import zip_longest\nfrom obspy import UTCDateTime\nfrom obspy.core.event import Axis\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import DataUsed\nfrom obspy.core.event import Event\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import Origin\nfrom obspy.core.event import PrincipalAxes\nfrom obspy.core.event import SourceTimeFunction\nfrom obspy.core.event import Tensor\nfrom obspy.geodetics import FlinnEngdahl\ndef _parse_date_time(date, time):\n    \"\"\"\n    Function taking a tuple of date and time string from an NDK file and\n    converting it to an UTCDateTime object.\n\n    In particular it is able to deal with a time string specifying 60\n    seconds which is not a valid ISO time string but occurs a lot in NDK\n    files.\n    \"\"\"\n    add_minute = False\n    if ':60.0' in time:\n        time = time.replace(':60.0', ':0.0')\n        add_minute = True\n    try:\n        dt = UTCDateTime(date.replace('/', '-') + 'T' + time)\n    except (TypeError, ValueError):\n        msg = (\n            \"Could not parse date/time string '%s' and '%s' to a valid time\" %\n            (date, time))\n        raise ObsPyNDKException(msg)\n    if add_minute:\n        dt += 60.0\n    return dt"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "lowpass_cheby_2", "method_path": "../srcdata/Computation/obspy/obspy/signal/filter.py", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\n\n\ndef lowpass_cheby_2(data, freq, df, maxorder=12, ba=False, freq_passband=False\n    ): [MASK]\n", "response": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\ndef lowpass_cheby_2(data, freq, df, maxorder=12, ba=False, freq_passband=False\n    ):\n    \"\"\"\n    Cheby2-Lowpass Filter\n\n    Filter data by passing data only below a certain frequency.\n    The main purpose of this cheby2 filter is downsampling.\n    #318 shows some plots of this filter design itself.\n\n    This method will iteratively design a filter, whose pass\n    band frequency is determined dynamically, such that the\n    values above the stop band frequency are lower than -96dB.\n\n    :type data: numpy.ndarray\n    :param data: Data to filter.\n    :param freq: The frequency above which signals are attenuated\n        with 95 dB\n    :param df: Sampling rate in Hz.\n    :param maxorder: Maximal order of the designed cheby2 filter\n    :param ba: If True return only the filter coefficients (b, a) instead\n        of filtering\n    :param freq_passband: If True return additionally to the filtered data,\n        the iteratively determined pass band frequency\n    :return: Filtered data.\n    \"\"\"\n    nyquist = df * 0.5\n    rp, rs, order = 1, 96, 1e+99\n    ws = freq / nyquist\n    wp = ws\n    if ws > 1:\n        ws = 1.0\n        msg = ('Selected corner frequency is above Nyquist. ' +\n            'Setting Nyquist as high corner.')\n        warnings.warn(msg)\n    while True:\n        if order <= maxorder:\n            break\n        wp = wp * 0.99\n        order, wn = cheb2ord(wp, ws, rp, rs, analog=0)\n    if ba:\n        return cheby2(order, rs, wn, btype='low', analog=0, output='ba')\n    sos = cheby2(order, rs, wn, btype='low', analog=0, output='sos')\n    if freq_passband:\n        return sosfilt(sos, data), wp * nyquist\n    return sosfilt(sos, data)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "array_transff_freqslowness", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef array_transff_freqslowness(coords, slim, sstep, fmin, fmax, fstep,\n    coordsys='lonlat'): [MASK]\n", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef array_transff_freqslowness(coords, slim, sstep, fmin, fmax, fstep,\n    coordsys='lonlat'):\n    \"\"\"\n    Returns array transfer function as a function of slowness difference and\n    frequency.\n\n    :type coords: numpy.ndarray\n    :param coords: coordinates of stations in longitude and latitude in degrees\n        elevation in km, or x, y, z in km\n    :type coordsys: str\n    :param coordsys: valid values: 'lonlat' and 'xy', choose which coordinates\n        to use\n    :param slim: either a float to use symmetric limits for slowness\n        differences or the tupel (sxmin, sxmax, symin, symax)\n    :type fmin: float\n    :param fmin: minimum frequency in signal\n    :type fmax: float\n    :param fmax: maximum frequency in signal\n    :type fstep: float\n    :param fstep: frequency sample distance\n    \"\"\"\n    coords = get_geometry(coords, coordsys)\n    if isinstance(slim, float):\n        sxmin = -slim\n        sxmax = slim\n        symin = -slim\n        symax = slim\n    elif isinstance(slim, tuple):\n        if len(slim) == 4:\n            sxmin = slim[0]\n            sxmax = slim[1]\n            symin = slim[2]\n            symax = slim[3]\n    else:\n        raise TypeError('slim must either be a float or a tuple of length 4')\n    nsx = int(np.ceil((sxmax + sstep / 10.0 - sxmin) / sstep))\n    nsy = int(np.ceil((symax + sstep / 10.0 - symin) / sstep))\n    nf = int(np.ceil((fmax + fstep / 10.0 - fmin) / fstep))\n    transff = np.empty((nsx, nsy))\n    buff = np.zeros(nf)\n    for i, sx in enumerate(np.arange(sxmin, sxmax + sstep / 10.0, sstep)):\n        for j, sy in enumerate(np.arange(symin, symax + sstep / 10.0, sstep)):\n            for k, f in enumerate(np.arange(fmin, fmax + fstep / 10.0, fstep)):\n                _sum = 0.0j\n                for l in np.arange(len(coords)):\n                    _sum += np.exp(complex(0.0, (coords[l, 0] * sx + coords\n                        [l, 1] * sy) * 2 * np.pi * f))\n                buff[k] = abs(_sum) ** 2\n            transff[i, j] = cumulative_trapezoid(buff, dx=fstep)[-1]\n    transff /= transff.max()\n    return transff"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_read_segy", "method_path": "../srcdata/Computation/obspy/obspy/io/segy/core.py", "method_code_mask": "import warnings\nfrom copy import deepcopy\nfrom struct import unpack\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import AttribDict\nimport doctest\n\n\ndef _read_segy(filename, headonly=False, byteorder=None,\n    textual_header_encoding=None, unpack_trace_headers=False, **kwargs): [MASK]\n", "response": "import warnings\nfrom copy import deepcopy\nfrom struct import unpack\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import AttribDict\nimport doctest\ndef _read_segy(filename, headonly=False, byteorder=None,\n    textual_header_encoding=None, unpack_trace_headers=False, **kwargs):\n    \"\"\"\n    Reads a SEG Y file and returns an ObsPy Stream object.\n\n    .. warning::\n        This function should NOT be called directly, it registers via the\n        ObsPy :func:`~obspy.core.stream.read` function, call this instead.\n\n    :type filename: str\n    :param filename: SEG Y rev1 file to be read.\n    :type headonly: bool, optional\n    :param headonly: If set to True, read only the header and omit the waveform\n        data.\n    :type byteorder: str or ``None``\n    :param byteorder: Determines the endianness of the file. Either ``'>'`` for\n        big endian or ``'<'`` for little endian. If it is ``None``, it will try\n        to autodetect the endianness. The endianness is always valid for the\n        whole file. Defaults to ``None``.\n    :type textual_header_encoding: str or ``None``\n    :param textual_header_encoding: The encoding of the textual header. Can be\n        ``'EBCDIC'``, ``'ASCII'`` or ``None``. If it is ``None``, autodetection\n        will be attempted. Defaults to ``None``.\n    :type unpack_trace_headers: bool, optional\n    :param unpack_trace_headers: Determines whether or not all trace header\n        values will be unpacked during reading. If ``False`` it will greatly\n        enhance performance and especially memory usage with large files. The\n        header values can still be accessed and will be calculated on the fly\n        but tab completion will no longer work. Look in the headers.py for a\n        list of all possible trace header values. Defaults to ``False``.\n    :returns: A ObsPy :class:`~obspy.core.stream.Stream` object.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> st = read(\"/path/to/00001034.sgy_first_trace\")\n    >>> st  # doctest: +ELLIPSIS\n    <obspy.core.stream.Stream object at 0x...>\n    >>> print(st)  # doctest: +ELLIPSIS\n    1 Trace(s) in Stream:\n    Seq. No. in line:    1 | 2009-06-22T14:47:37.000000Z - ... 2001 samples\n    \"\"\"\n    segy_object = _read_segyrev1(filename, endian=byteorder,\n        textual_header_encoding=textual_header_encoding, unpack_headers=\n        unpack_trace_headers)\n    stream = Stream()\n    stream.stats = AttribDict()\n    textual_file_header = segy_object.textual_file_header\n    binary_file_header = AttribDict()\n    for key, value in segy_object.binary_file_header.__dict__.items():\n        setattr(binary_file_header, key, value)\n    data_encoding = segy_object.traces[0].data_encoding\n    endian = segy_object.traces[0].endian\n    textual_file_header_encoding = segy_object.textual_header_encoding.upper()\n    stream.stats.textual_file_header = textual_file_header\n    stream.stats.binary_file_header = binary_file_header\n    stream.stats.data_encoding = data_encoding\n    stream.stats.endian = endian\n    stream.stats.textual_file_header_encoding = textual_file_header_encoding\n    for tr in segy_object.traces:\n        stream.append(tr.to_obspy_trace(headonly=headonly,\n            unpack_trace_headers=unpack_trace_headers))\n    return stream"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "correlate_stream_template", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate_stream_template(stream, template, template_time=None, **kwargs\n    ): [MASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate_stream_template(stream, template, template_time=None, **kwargs):\n    \"\"\"\n    Calculate cross-correlation of traces in stream with traces in template.\n\n    Only matching seed ids are correlated, other traces are silently discarded.\n    The template stream and data stream might have traces of different\n    length and different start times.\n    The data stream must not have gaps and will be sliced as necessary.\n\n    :param stream: Stream with data traces.\n    :param template: Stream with template traces (should be shorter than data).\n    :param template_time: UTCDateTime associated with template event\n        (e.g. origin time, default is the start time of the template stream).\n        The start times of the returned Stream will be shifted by the given\n        template time minus the template start time.\n    :param kwargs: kwargs are passed to\n        :func:`~obspy.signal.cross_correlation.correlate_template` function.\n\n    :return: Stream with cross-correlations.\n\n    .. note::\n\n        Use :func:`~obspy.signal.cross_correlation.correlation_detector`\n        for detecting events based on their similarity.\n        The returned stream of cross-correlations is suitable for\n        use with :func:`~obspy.signal.trigger.coincidence_trigger`, though.\n\n    .. rubric:: Example\n\n    >>> from obspy import read, UTCDateTime\n    >>> data = read().filter('highpass', freq=5)\n    >>> pick = UTCDateTime('2009-08-24T00:20:07.73')\n    >>> template = data.slice(pick, pick + 10)\n    >>> ccs = correlate_stream_template(data, template)\n    >>> print(ccs)  # doctest: +ELLIPSIS\n    3 Trace(s) in Stream:\n    BW.RJOB..EHE | 2009-08-24T00:20:03.000000Z - ... | 100.0 Hz, 2000 samples\n    BW.RJOB..EHN | 2009-08-24T00:20:03.000000Z - ... | 100.0 Hz, 2000 samples\n    BW.RJOB..EHZ | ... - 2009-08-24T00:20:22.990000Z | 100.0 Hz, 2000 samples\n    \"\"\"\n    stream, template = _prep_streams_correlate(stream, template,\n        template_time=template_time)\n    return _correlate_prepared_stream_template(stream, template, **kwargs)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "array_transff_wavenumber", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef array_transff_wavenumber(coords, klim, kstep, coordsys='lonlat'): [MASK]\n", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef array_transff_wavenumber(coords, klim, kstep, coordsys='lonlat'):\n    \"\"\"\n    Returns array transfer function as a function of wavenumber difference\n\n    :type coords: numpy.ndarray\n    :param coords: coordinates of stations in longitude and latitude in degrees\n        elevation in km, or x, y, z in km\n    :type coordsys: str\n    :param coordsys: valid values: 'lonlat' and 'xy', choose which coordinates\n        to use\n    :param klim: either a float to use symmetric limits for wavenumber\n        differences or the tuple (kxmin, kxmax, kymin, kymax)\n    \"\"\"\n    coords = get_geometry(coords, coordsys)\n    if isinstance(klim, float):\n        kxmin = -klim\n        kxmax = klim\n        kymin = -klim\n        kymax = klim\n    elif isinstance(klim, tuple):\n        if len(klim) == 4:\n            kxmin = klim[0]\n            kxmax = klim[1]\n            kymin = klim[2]\n            kymax = klim[3]\n    else:\n        raise TypeError('klim must either be a float or a tuple of length 4')\n    nkx = int(np.ceil((kxmax + kstep / 10.0 - kxmin) / kstep))\n    nky = int(np.ceil((kymax + kstep / 10.0 - kymin) / kstep))\n    kygrid, kxgrid = np.meshgrid(np.linspace(kymin, kymax, nky), np.\n        linspace(kxmin, kxmax, nkx))\n    ks = np.transpose(np.vstack((kxgrid.flatten(), kygrid.flatten())))\n    if np.__version__ == '1.14.0':\n        k_dot_r = np.einsum('ni,mi->nm', ks, coords[:, :2], optimize=False)\n    else:\n        k_dot_r = np.einsum('ni,mi->nm', ks, coords[:, :2])\n    transff = np.abs(np.sum(np.exp(1.0j * k_dot_r), axis=1)) ** 2 / len(coords\n        ) ** 2\n    return transff.reshape(nkx, nky)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "from_buffer", "method_path": "../srcdata/Computation/obspy/obspy/core/compatibility.py", "method_code_mask": "import numpy as np\n\n\ndef from_buffer(data, dtype): [MASK]\n", "response": "import numpy as np\ndef from_buffer(data, dtype):\n    try:\n        data = data.encode()\n    except Exception:\n        pass\n    return np.array(memoryview(data)).view(dtype).copy()"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_find_peaks", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef _find_peaks(data, height, holdon_samples, holdoff_samples): [MASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef _find_peaks(data, height, holdon_samples, holdoff_samples):\n    \"\"\"\n    Peak finding function used for Scipy versions smaller than 1.1.\n    \"\"\"\n    cond = data >= height\n    similarity_cond = data[cond]\n    cindices = np.nonzero(cond)[0]\n    detections_index = []\n    i = 0\n    while True:\n        try:\n            cindex = cindices[i]\n        except IndexError:\n            break\n        j = bisect_left(cindices, cindex + holdon_samples, lo=i)\n        k = i + np.argmax(similarity_cond[i:j])\n        cindex = cindices[k]\n        detections_index.append(cindex)\n        i = bisect_left(cindices, cindex + holdoff_samples, lo=j)\n    return detections_index"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "util_lon_lat", "method_path": "../srcdata/Computation/obspy/obspy/signal/util.py", "method_code_mask": "import ctypes as C\nimport math\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom obspy.core.util.misc import factorize_int\nfrom obspy.signal.headers import clibsignal\nfrom scipy.signal import hilbert\nfrom scipy.fftpack import next_fast_len\nimport doctest\n\n\ndef util_lon_lat(orig_lon, orig_lat, x, y): [MASK]\n", "response": "import ctypes as C\nimport math\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom obspy.core.util.misc import factorize_int\nfrom obspy.signal.headers import clibsignal\nfrom scipy.signal import hilbert\nfrom scipy.fftpack import next_fast_len\nimport doctest\ndef util_lon_lat(orig_lon, orig_lat, x, y):\n    \"\"\"\n    Transform x, y [km] to decimal degree in reference to orig_lon and orig_lat\n\n    >>> util_lon_lat(12.0, 48.0, 0.0, 0.0)\n    (12.0, 48.0)\n    >>> lon, lat = util_lon_lat(12.0, 48.0, 73.9041, 111.1908)\n    >>> print(\"%.4f, %.4f\" % (lon, lat))\n    13.0000, 49.0000\n\n    :param orig_lon: Longitude of reference origin\n    :param orig_lat: Latitude of reference origin\n    :param x: value [km] to calculate relative coordinate in degree\n    :param y: value [km] to calculate relative coordinate in degree\n    :return: lon, lat coordinate in degree (absolute)\n    \"\"\"\n    clibsignal.utl_lonlat.argtypes = [C.c_double, C.c_double, C.c_double, C\n        .c_double, C.POINTER(C.c_double), C.POINTER(C.c_double)]\n    clibsignal.utl_lonlat.restype = C.c_void_p\n    lon = C.c_double()\n    lat = C.c_double()\n    clibsignal.utl_lonlat(orig_lon, orig_lat, x, y, C.byref(lon), C.byref(lat))\n    return lon.value, lat.value"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_convert_flags_to_raw_byte", "method_path": "../srcdata/Computation/obspy/obspy/io/mseed/util.py", "method_code_mask": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\n\n\ndef _convert_flags_to_raw_byte(expected_flags, user_flags, recstart, recend): [\n    MASK]\n", "response": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\ndef _convert_flags_to_raw_byte(expected_flags, user_flags, recstart, recend):\n    \"\"\"\n    Converts a flag dictionary to a byte, ready to be encoded in a MiniSEED\n    header.\n\n    This is a utility function for set_flags_in_fixed_headers and is not\n    designed to be called by someone else.\n\n    expected_signals describes all the possible bit names for the user flags\n    and their place in the result byte. Expected: dict { exponent: bit_name }.\n    The fixed header flags are available in obspy.io.mseed.headers as\n    FIXED_HEADER_ACTIVITY_FLAGS, FIXED_HEADER_DATA_QUAL_FLAGS and\n    FIXED_HEADER_IO_CLOCK_FLAGS.\n\n    This expects a user_flags as a dictionary { bit_name : value }. bit_name is\n    compared to the expected_signals, and its value is converted to bool.\n    Missing values are considered false.\n\n    :type expected_flags: dict\n    :param expected_flags: every possible flag in this field, with its offset.\n        Structure: {int: str}.\n    :type user_flags: dict\n    :param user_flags: user defined flags and its value.\n        Structure: {str: bool}.\n    :type recstart: UTCDateTime\n    :param recstart: date of the first sample of the current record\n    :type recstart: UTCDateTime\n    :param recend: date of the last sample of the current record\n    :return: raw int value for the flag group\n    \"\"\"\n    flag_byte = 0\n    for bit, key in expected_flags.items():\n        use_in_this_record = False\n        if key in user_flags:\n            if isinstance(user_flags[key], bool) and user_flags[key]:\n                use_in_this_record = True\n            elif isinstance(user_flags[key], collections.abc.Sequence):\n                use_in_this_record = False\n                for tuple_value in user_flags[key]:\n                    event_start = tuple_value[0]\n                    event_end = tuple_value[1]\n                    if event_start < recend and recstart <= event_end:\n                        use_in_this_record = True\n                        break\n        if use_in_this_record:\n            flag_byte += 2 ** bit\n    return flag_byte"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_nortoevmag", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _nortoevmag(mag_type): [MASK]\n", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _nortoevmag(mag_type):\n    \"\"\"\n    Switch from nordic type magnitude notation to obspy event magnitudes.\n\n    >>> print(_nortoevmag('B'))  # doctest: +SKIP\n    mB\n    >>> print(_nortoevmag('bob'))  # doctest: +SKIP\n    <BLANKLINE>\n    \"\"\"\n    if mag_type.upper() == 'L':\n        return 'ML'\n    mag = INV_MAG_MAPPING.get(mag_type, '')\n    if mag == '':\n        warnings.warn(mag_type + ' is not convertible')\n    return mag"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_evmagtonor", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _evmagtonor(mag_type): [MASK]\n", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _evmagtonor(mag_type):\n    \"\"\"\n    Switch from obspy event magnitude types to seisan syntax.\n\n    >>> print(_evmagtonor('mB'))  # doctest: +SKIP\n    B\n    >>> print(_evmagtonor('M'))  # doctest: +SKIP\n    W\n    >>> print(_evmagtonor('bob'))  # doctest: +SKIP\n    <BLANKLINE>\n    \"\"\"\n    if mag_type == 'M' or mag_type is None:\n        warnings.warn('Converting generic magnitude to moment magnitude')\n        return 'W'\n    mag = MAG_MAPPING.get(mag_type, '')\n    if mag == '':\n        warnings.warn(mag_type + ' is not convertible')\n        return ' '\n    return mag"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_float_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _float_conv(string): [MASK]\n", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _float_conv(string):\n    \"\"\"\n    Convenience tool to convert from string to float.\n\n    If empty string return None rather than an error.\n\n    >>> _float_conv('12')\n    12.0\n    >>> _float_conv('')\n    >>> _float_conv('12.324')\n    12.324\n    \"\"\"\n    try:\n        floatstring = float(string)\n    except Exception:\n        floatstring = None\n    return floatstring"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "utcdatetime_to_sac_nztimes", "method_path": "../srcdata/Computation/obspy/obspy/io/sac/util.py", "method_code_mask": "import sys\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\n\n\ndef utcdatetime_to_sac_nztimes(utcdt): [MASK]\n", "response": "import sys\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\ndef utcdatetime_to_sac_nztimes(utcdt):\n    nztimes = {}\n    nztimes['nzyear'] = utcdt.year\n    nztimes['nzjday'] = utcdt.julday\n    nztimes['nzhour'] = utcdt.hour\n    nztimes['nzmin'] = utcdt.minute\n    nztimes['nzsec'] = utcdt.second\n    millisecond, microsecond = split_microseconds(utcdt.microsecond)\n    nztimes['nzmsec'] = millisecond\n    return nztimes, microsecond"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_int_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _int_conv(string): [MASK]\n", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _int_conv(string):\n    \"\"\"\n    Convenience tool to convert from string to integer.\n\n    If empty string return None rather than an error.\n\n    >>> _int_conv('12')\n    12\n    >>> _int_conv('')\n\n    \"\"\"\n    try:\n        intstring = int(string)\n    except Exception:\n        intstring = None\n    return intstring"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_determine_dtype", "method_path": "../srcdata/Computation/obspy/obspy/io/ascii/core.py", "method_code_mask": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\nfrom obspy.core.util import AttribDict\nimport doctest\n\n\ndef _determine_dtype(custom_fmt): [MASK]\n", "response": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\nfrom obspy.core.util import AttribDict\nimport doctest\ndef _determine_dtype(custom_fmt):\n    \"\"\"\n    :type custom_fmt: str\n    :param custom_fmt: Python string formatter.\n    :rtype: str\n    :return: Datatype string for writing in header. Currently supported\n        are 'INTEGER', 'FLOAT' and `CUSTOM`.\n    :raises ValueError: if provided string is empty.\n    \"\"\"\n    floats = 'e', 'f', 'g'\n    ints = 'd', 'i'\n    try:\n        if custom_fmt[-1].lower() in floats:\n            return 'FLOAT'\n        elif custom_fmt[-1].lower() in ints:\n            return 'INTEGER'\n        else:\n            return 'CUSTOM'\n    except IndexError:\n        raise ValueError('Provided string is not valid for determining ' +\n            'datatype. Provide a proper Python string formatter')"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "to_tag", "method_path": "../srcdata/Computation/obspy/obspy/io/xseed/utils.py", "method_code_mask": "import warnings\nfrom obspy import UTCDateTime\n\n\ndef to_tag(name): [MASK]\n", "response": "import warnings\nfrom obspy import UTCDateTime\ndef to_tag(name):\n    \"\"\"\n    Creates a XML tag from a given string.\n    \"\"\"\n    temp = name.lower().replace(' ', '_')\n    temp = temp.replace('fir_', 'FIR_')\n    temp = temp.replace('a0_', 'A0_')\n    return temp"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_str_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _str_conv(number, rounded=False): [MASK]\n", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _str_conv(number, rounded=False):\n    \"\"\"\n    Convenience tool to convert a number, either float or int into a string.\n\n    If the int or float is None, returns empty string.\n\n    >>> print(_str_conv(12.3))\n    12.3\n    >>> print(_str_conv(12.34546, rounded=1))\n    12.3\n    >>> print(_str_conv(None))\n    <BLANKLINE>\n    >>> print(_str_conv(1123040))\n    11.2e5\n    \"\"\"\n    if not number and number != 0:\n        return str(' ')\n    if not rounded and isinstance(number, (float, int)):\n        if number < 100000:\n            string = str(number)\n        else:\n            exponent = int('{0:.2E}'.format(number).split('E+')[-1]) - 1\n            divisor = 10 ** exponent\n            string = '{0:.1f}'.format(number / divisor) + 'e' + str(exponent)\n    elif rounded and isinstance(number, (float, int)):\n        if number < 100000:\n            string = '{:.{precision}f}'.format(number, precision=rounded)\n        else:\n            exponent = int('{0:.2E}'.format(number).split('E+')[-1]) - 1\n            divisor = 10 ** exponent\n            string = '{:.{precision}f}'.format(number / divisor, precision=\n                rounded) + 'e' + str(exponent)\n    else:\n        return str(number)\n    return string"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_convert_datetime_to_mstime", "method_path": "../srcdata/Computation/obspy/obspy/io/mseed/util.py", "method_code_mask": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\n\n\ndef _convert_datetime_to_mstime(dt): [MASK]\n", "response": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\ndef _convert_datetime_to_mstime(dt):\n    \"\"\"\n    Takes a obspy.util.UTCDateTime object and returns an epoch time in ms.\n\n    :param dt: obspy.util.UTCDateTime object.\n    \"\"\"\n    rest = dt._ns % 10 ** 3 >= 500 and 1 or 0\n    return dt._ns // 10 ** 3 + rest"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "datetime_2_string", "method_path": "../srcdata/Computation/obspy/obspy/io/xseed/utils.py", "method_code_mask": "import warnings\nfrom obspy import UTCDateTime\n\n\ndef datetime_2_string(dt, compact=False): [MASK]\n", "response": "import warnings\nfrom obspy import UTCDateTime\ndef datetime_2_string(dt, compact=False):\n    \"\"\"\n    Generates a valid SEED time string from a UTCDateTime object.\n    \"\"\"\n    if isinstance(dt, UTCDateTime):\n        return dt.format_seed(compact)\n    elif isinstance(dt, str):\n        dt = dt.strip()\n    if not dt:\n        return ''\n    try:\n        dt = UTCDateTime(dt)\n        return dt.format_seed(compact)\n    except Exception:\n        raise Exception('Invalid datetime %s: %s' % (type(dt), str(dt)))"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_is_rg16", "method_path": "../srcdata/Computation/obspy/obspy/io/rg16/core.py", "method_code_mask": "from collections import namedtuple\nimport numpy as np\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core import Stats\nfrom obspy.core import UTCDateTime\nfrom obspy.io.rg16.util import _read\nfrom obspy.io.rg16.util import _open_file\nfrom obspy.io.rg16.util import _quick_merge\nimport doctest\n\n\n@_open_file\ndef _is_rg16(filename, **kwargs): [MASK]\n", "response": "from collections import namedtuple\nimport numpy as np\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core import Stats\nfrom obspy.core import UTCDateTime\nfrom obspy.io.rg16.util import _read\nfrom obspy.io.rg16.util import _open_file\nfrom obspy.io.rg16.util import _quick_merge\nimport doctest\n@_open_file\ndef _is_rg16(filename, **kwargs):\n    \"\"\"\n    Determine if a file is a rg16 file.\n\n    :param filename: a path to a file or a file object\n    :type filename: str or file-like object\n    :rtype: bool\n    :return: True if the file object is a rg16 file.\n    \"\"\"\n    try:\n        sample_format = _read(filename, 2, 2, 'bcd')\n        sample_format = _read(filename, 2, 2, 'bcd')\n        manufacturer_code = _read(filename, 16, 1, 'bcd')\n        version = _read(filename, 42, 2, 'binary')\n    except ValueError:\n        return False\n    con1 = version == 262 and sample_format == 8058\n    return con1 and manufacturer_code == 20"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "ptp", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef ptp(a, *args, **kwargs): [MASK]\n", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef ptp(a, *args, **kwargs):\n    \"\"\"\n    Replacement for :meth:`numpy.ndarray.ptp()` and the corresponding method on\n    `MaskedArray` objects which are being removed in numpy 2.0\n    Basically just makes sure we call the correct replacement function numpy\n    put in place for regular and masked arrays.\n\n    :type a: :class:`numpy.ndarray` or :class:`numpy.ma.MaskedArray`\n    \"\"\"\n    if isinstance(a, np.ma.MaskedArray):\n        return np.ma.ptp(a, *args, **kwargs)\n    return np.ptp(a, *args, **kwargs)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "rotate_ne_rt", "method_path": "../srcdata/Computation/obspy/obspy/signal/rotate.py", "method_code_mask": "import warnings\nfrom math import cos\nfrom math import sin\nfrom math import radians\nimport numpy as np\nimport doctest\n\n\ndef rotate_ne_rt(n, e, ba): [MASK]\n", "response": "import warnings\nfrom math import cos\nfrom math import sin\nfrom math import radians\nimport numpy as np\nimport doctest\ndef rotate_ne_rt(n, e, ba):\n    \"\"\"\n    Rotates horizontal components of a seismogram.\n\n    The North- and East-Component of a seismogram will be rotated in Radial\n    and Transversal Component. The angle is given as the back-azimuth, that is\n    defined as the angle measured between the vector pointing from the station\n    to the source and the vector pointing from the station to the North.\n\n    :type n: :class:`~numpy.ndarray`\n    :param n: Data of the North component of the seismogram.\n    :type e: :class:`~numpy.ndarray`\n    :param e: Data of the East component of the seismogram.\n    :type ba: float\n    :param ba: The back azimuth from station to source in degrees.\n    :return: Radial and Transversal component of seismogram.\n    \"\"\"\n    if len(n) != len(e):\n        raise TypeError('North and East component have different length.')\n    if ba < 0 or ba > 360:\n        raise ValueError('Back Azimuth should be between 0 and 360 degrees.')\n    ba = radians(ba)\n    r = -e * sin(ba) - n * cos(ba)\n    t = -e * cos(ba) + n * sin(ba)\n    return r, t"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "correlate", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate(a, b, shift, demean=True, normalize='naive', method='auto'): [M\n    ASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate(a, b, shift, demean=True, normalize='naive', method='auto'):\n    \"\"\"\n    Cross-correlation of two signals up to a specified maximal shift.\n\n    This function only allows 'naive' normalization with the overall\n    standard deviations. This is a reasonable approximation for signals of\n    similar length and a relatively small shift parameter\n    (e.g. noise cross-correlation).\n    If you are interested in the full cross-correlation function better use\n    :func:`~obspy.signal.cross_correlation.correlate_template` which also\n    provides correct normalization.\n\n    :type a: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param a: first signal\n    :type b: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param b: second signal to correlate with first signal\n    :param int shift: Number of samples to shift for cross correlation.\n        The cross-correlation will consist of ``2*shift+1`` or\n        ``2*shift`` samples. The sample with zero shift will be in the middle.\n    :param bool demean: Demean data beforehand.\n    :param normalize: Method for normalization of cross-correlation.\n        One of ``'naive'`` or ``None``\n        (``True`` and ``False`` are supported for backwards compatibility).\n        ``'naive'`` normalizes by the overall standard deviation.\n        ``None`` does not normalize.\n    :param str method: Method to use to calculate the correlation.\n         ``'direct'``: The correlation is determined directly from sums,\n         the definition of correlation.\n         ``'fft'`` The Fast Fourier Transform is used to perform the\n         correlation more quickly.\n         ``'auto'`` Automatically chooses direct or Fourier method based on an\n         estimate of which is faster. (Only availlable for SciPy versions >=\n         0.19. For older Scipy version method defaults to ``'fft'``.)\n\n    :return: cross-correlation function.\n\n    To calculate shift and value of the maximum of the returned\n    cross-correlation function use\n    :func:`~obspy.signal.cross_correlation.xcorr_max`.\n\n    .. note::\n\n        For most input parameters cross-correlation using the FFT is much\n        faster.\n        Only for small values of ``shift`` (approximately less than 100)\n        direct time domain cross-correlation migth save some time.\n\n    .. note::\n\n        If the signals have different length, they will be aligned around\n        their middle. The sample with zero shift in the cross-correlation\n        function corresponds to this correlation:\n\n        ::\n\n            --aaaa--\n            bbbbbbbb\n\n        For odd ``len(a)-len(b)`` the cross-correlation function will\n        consist of only ``2*shift`` samples because a shift of 0\n        corresponds to the middle between two samples.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> a = read()[0][450:550]\n    >>> b = a[:-2]\n    >>> cc = correlate(a, b, 2)\n    >>> cc\n    array([ 0.62390515,  0.99630851,  0.62187106, -0.05864797, -0.41496995])\n    >>> shift, value = xcorr_max(cc)\n    >>> shift\n    -1\n    >>> round(value, 3)\n    0.996\n    \"\"\"\n    if normalize is False:\n        normalize = None\n    if normalize is True:\n        normalize = 'naive'\n    if isinstance(a, Trace):\n        a = a.data\n    if isinstance(b, Trace):\n        b = b.data\n    a = np.asarray(a)\n    b = np.asarray(b)\n    if demean:\n        a = a - np.mean(a)\n        b = b - np.mean(b)\n    _xcorr = _xcorr_padzeros if method == 'direct' else _xcorr_slice\n    cc = _xcorr(a, b, shift, method)\n    if normalize == 'naive':\n        norm = (np.sum(a ** 2) * np.sum(b ** 2)) ** 0.5\n        if norm <= np.finfo(float).eps:\n            cc[:] = 0\n        elif cc.dtype == float:\n            cc /= norm\n        else:\n            cc = cc / norm\n    elif normalize is not None:\n        raise ValueError(\"normalize has to be one of (None, 'naive'))\")\n    return cc"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_parse_list_of_complex_string", "method_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/inventory.py", "method_code_mask": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\n\n\ndef _parse_list_of_complex_string(complex_string): [MASK]\n", "response": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\ndef _parse_list_of_complex_string(complex_string):\n    \"\"\"\n    Returns a list of complex numbers, parsed from a string (formatted\n    according to SeisComp XML schema type \"ComplexArray\").\n    \"\"\"\n    count = _count_complex(complex_string)\n    numbers = re.findall('\\\\(\\\\s*([^,\\\\s]+)\\\\s*,\\\\s*([^)\\\\s]+)\\\\s*\\\\)',\n        complex_string)\n    if len(numbers) != count:\n        msg = (\n            \"\"\"Unexpected count of complex numbers parsed from string:\n  Raw string: '%s'\n  Expected count of complex numbers: %s\n  Parsed complex numbers: %s\"\"\"\n             % (complex_string, count, numbers))\n        raise ValueError(msg)\n    return numbers"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "get_window_times", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef get_window_times(starttime, endtime, window_length, step, offset,\n    include_partial_windows): [MASK]\n", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef get_window_times(starttime, endtime, window_length, step, offset,\n    include_partial_windows):\n    \"\"\"\n    Function calculating a list of times making up equal length windows from\n    within a given time interval.\n\n    :param starttime: The start time of the whole time interval.\n    :type starttime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param endtime: The end time of the whole time interval.\n    :type endtime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param window_length: The length of each window in seconds.\n    :type window_length: float\n    :param step: The step between the start times of two successive\n        windows in seconds. Can be negative if an offset is given.\n    :type step: float\n    :param offset: The offset of the first window in seconds relative to\n        the start time of the whole interval.\n    :type offset: float\n    :param include_partial_windows: Determines if windows that are\n        shorter then 99.9 % of the desired length are returned.\n    :type include_partial_windows: bool\n    \"\"\"\n    if step > 0:\n        end = endtime.timestamp - 0.001 * step\n    else:\n        end = starttime.timestamp - 0.001 * abs(step)\n    indices = np.arange(start=starttime.timestamp + offset, stop=end, step=\n        step, dtype=np.float64)\n    if step > 0:\n        windows = [(_i, min(_i + window_length, endtime.timestamp)) for _i in\n            indices]\n    else:\n        windows = [(max(_i - window_length, starttime.timestamp), _i) for\n            _i in indices]\n    if not include_partial_windows:\n        windows = [_i for _i in windows if abs(_i[1] - _i[0]) > 0.999 *\n            window_length]\n    t = type(starttime)\n    return [(t(_i[0]), t(_i[1])) for _i in windows]"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "_count_complex", "method_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/inventory.py", "method_code_mask": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\n\n\ndef _count_complex(complex_string): [MASK]\n", "response": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\ndef _count_complex(complex_string):\n    \"\"\"\n    Returns number of complex numbers in string (formatted according to\n    SeisComp XML schema type \"ComplexArray\"). Raises an Exception if string\n    seems invalid.\n    \"\"\"\n    counts = set()\n    for char in '(,)':\n        counts.add(complex_string.count(char))\n    if len(counts) != 1:\n        msg = (\"Invalid string for list of complex numbers:\\n'%s'\" %\n            complex_string)\n        raise ValueError(msg)\n    return counts.pop()"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "inside_geobounds", "method_path": "../srcdata/Computation/obspy/obspy/geodetics/base.py", "method_code_mask": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\n\n\ndef inside_geobounds(obj, minlatitude=None, maxlatitude=None, minlongitude=\n    None, maxlongitude=None, latitude=None, longitude=None, minradius=None,\n    maxradius=None): [MASK]\n", "response": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\ndef inside_geobounds(obj, minlatitude=None, maxlatitude=None, minlongitude=\n    None, maxlongitude=None, latitude=None, longitude=None, minradius=None,\n    maxradius=None):\n    \"\"\"\n    Check whether an object is within a given latitude and/or longitude range,\n    or within a given distance range from a reference geographic point.\n\n    The object must have ``latitude`` and ``longitude`` attributes, expressed\n    in degrees.\n\n    :type obj: object\n    :param obj: An object with `latitude` and `longitude` attributes.\n    :type minlatitude: float\n    :param minlatitude: Minimum latitude in degrees.\n    :type maxlatitude: float\n    :param maxlatitude: Maximum latitude in degrees. If this value is smaller\n        than ``minlatitude``, then 360 degrees are added to this value (i.e.,\n        wrapping around latitude of +/- 180 degrees)\n    :type minlongitude: float\n    :param minlongitude: Minimum longitude in degrees.\n    :type maxlongitude: float\n    :param maxlongitude: Minimum longitude in degrees.\n    :type latitude: float\n    :param latitude: Latitude of the reference point, in degrees, for distance\n        range selection.\n    :type longitude: float\n    :param longitude: Longitude of the reference point, in degrees, for\n        distance range selection.\n    :type minradius: float\n    :param minradius: Minimum distance, in degrees, from the reference\n        geographic point defined by the latitude and longitude parameters.\n    :type maxradius: float\n    :param maxradius: Maximum distance, in degrees, from the reference\n        geographic point defined by the latitude and longitude parameters.\n    :return: ``True`` if the object is within the given range, ``False``\n        otherwise.\n\n    .. rubric:: Example\n\n    >>> from obspy.geodetics import inside_geobounds\n    >>> from obspy import read_events\n    >>> ev = read_events()[0]\n    >>> orig = ev.origins[0]\n    >>> inside_geobounds(orig, minlatitude=40, maxlatitude=42)\n    True\n    >>> inside_geobounds(orig, minlatitude=40, maxlatitude=42,\n    ...                  minlongitude=78, maxlongitude=79)\n    False\n    >>> inside_geobounds(orig, latitude=40, longitude=80,\n    ...                  minradius=1, maxradius=10)\n    True\n    \"\"\"\n    if not hasattr(obj, 'latitude') or not hasattr(obj, 'longitude'):\n        raise AttributeError(\n            'Object must have \"latitude\" and \"longitude\" attributes.')\n    olatitude = obj.latitude\n    _check_latitude(olatitude, 'obj.latitude')\n    _check_latitude(minlatitude, 'minlatitude')\n    _check_latitude(maxlatitude, 'maxlatitude')\n    _check_latitude(latitude, 'latitude')\n    olongitude = _normalize_longitude(obj.longitude)\n    minlongitude = _normalize_longitude(minlongitude)\n    maxlongitude = _normalize_longitude(maxlongitude)\n    longitude = _normalize_longitude(longitude)\n    if minlatitude is not None:\n        if olatitude is None or olatitude < minlatitude:\n            return False\n    if maxlatitude is not None:\n        if olatitude is None or olatitude > maxlatitude:\n            return False\n    if None not in [minlongitude, maxlongitude\n        ] and maxlongitude < minlongitude:\n        maxlongitude += 360\n        if olongitude is not None and olongitude < minlongitude:\n            olongitude += 360\n    if minlongitude is not None:\n        if olongitude is None or olongitude < minlongitude:\n            return False\n    if maxlongitude is not None:\n        if olongitude is None or olongitude > maxlongitude:\n            return False\n    if all([(coord is not None) for coord in (latitude, longitude,\n        olatitude, olongitude)]):\n        distance = locations2degrees(latitude, longitude, olatitude, olongitude\n            )\n        if minradius is not None and distance < minradius:\n            return False\n        if maxradius is not None and distance > maxradius:\n            return False\n    return True"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "xcorr_max", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef xcorr_max(fct, abs_max=True): [MASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef xcorr_max(fct, abs_max=True):\n    \"\"\"\n    Return shift and value of the maximum of the cross-correlation function.\n\n    :type fct: :class:`~numpy.ndarray`\n    :param fct: Cross-correlation function e.g. returned by correlate.\n    :param bool abs_max: Determines if the largest value of the correlation\n        function is returned, independent of it being positive (correlation) or\n        negative (anti-correlation). Defaults to `True`. If `False` the maximum\n        returned is positive only.\n    :return: **shift, value** - Shift and value of maximum of\n        cross-correlation.\n\n    .. rubric:: Example\n\n    >>> fct = np.zeros(101)\n    >>> fct[50] = -1.0\n    >>> xcorr_max(fct)\n    (0, -1.0)\n    >>> fct[50], fct[60] = 0.0, 1.0\n    >>> xcorr_max(fct)\n    (10, 1.0)\n    >>> fct[60], fct[40] = 0.0, -1.0\n    >>> xcorr_max(fct)\n    (-10, -1.0)\n    >>> fct[60], fct[40] = 0.5, -1.0\n    >>> xcorr_max(fct, abs_max=True)\n    (-10, -1.0)\n    >>> xcorr_max(fct, abs_max=False)\n    (10, 0.5)\n    >>> xcorr_max(fct[:-1], abs_max=False)\n    (10.5, 0.5)\n    \"\"\"\n    mid = (len(fct) - 1) / 2\n    if len(fct) % 2 == 1:\n        mid = int(mid)\n    index = np.argmax(np.abs(fct) if abs_max else fct)\n    return index - mid, float(fct[index])"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "correlate_template", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate_template(data, template, mode='valid', normalize='full',\n    demean=True, method='auto'): [MASK]\n", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate_template(data, template, mode='valid', normalize='full',\n    demean=True, method='auto'):\n    \"\"\"\n    Normalized cross-correlation of two signals with specified mode.\n\n    If you are interested only in a part of the cross-correlation function\n    around zero shift consider using function\n    :func:`~obspy.signal.cross_correlation.correlate` which allows to\n    explicetly specify the maximum shift.\n\n    :type data: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param data: first signal\n    :type template: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param template: second signal to correlate with first signal.\n        Its length must be smaller or equal to the length of ``data``.\n    :param str mode: correlation mode to use.\n        It is passed to the used correlation function.\n        See :func:`scipy.signal.correlate` for possible options.\n        The parameter determines the length of the correlation function.\n    :param normalize:\n        One of ``'naive'``, ``'full'`` or ``None``.\n        ``'full'`` normalizes every correlation properly,\n        whereas ``'naive'`` normalizes by the overall standard deviations.\n        ``None`` does not normalize.\n    :param demean: Demean data beforehand. For ``normalize='full'`` data is\n        demeaned in different windows for each correlation value.\n    :param str method: Method to use to calculate the correlation.\n         ``'direct'``: The correlation is determined directly from sums,\n         the definition of correlation.\n         ``'fft'`` The Fast Fourier Transform is used to perform the\n         correlation more quickly.\n         ``'auto'`` Automatically chooses direct or Fourier method based on an\n         estimate of which is faster. (Only availlable for SciPy versions >=\n         0.19. For older Scipy version method defaults to ``'fft'``.)\n\n    :return: cross-correlation function.\n\n    .. note::\n        Calling the function with ``demean=True, normalize='full'`` (default)\n        returns the zero-normalized cross-correlation function.\n        Calling the function with ``demean=False, normalize='full'``\n        returns the normalized cross-correlation function.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> data = read()[0]\n    >>> template = data[450:550]\n    >>> cc = correlate_template(data, template)\n    >>> index = np.argmax(cc)\n    >>> index\n    450\n    >>> round(cc[index], 9)\n    1.0\n    \"\"\"\n    if isinstance(data, Trace):\n        data = data.data\n    if isinstance(template, Trace):\n        template = template.data\n    data = np.asarray(data)\n    template = np.asarray(template)\n    lent = len(template)\n    if len(data) < lent:\n        raise ValueError('Data must not be shorter than template.')\n    if demean:\n        template = template - np.mean(template)\n        if normalize != 'full':\n            data = data - np.mean(data)\n    cc = scipy.signal.correlate(data, template, mode=mode, method=method)\n    if normalize is not None:\n        tnorm = np.sum(template ** 2)\n        if normalize == 'naive':\n            norm = (tnorm * np.sum(data ** 2)) ** 0.5\n            if norm <= np.finfo(float).eps:\n                cc[:] = 0\n            elif cc.dtype == float:\n                cc /= norm\n            else:\n                cc = cc / norm\n        elif normalize == 'full':\n            pad = len(cc) - len(data) + lent\n            if mode == 'same':\n                pad1, pad2 = (pad + 2) // 2, (pad - 1) // 2\n            else:\n                pad1, pad2 = (pad + 1) // 2, pad // 2\n            data = _pad_zeros(data, pad1, pad2)\n            if demean:\n                norm = _window_sum(data, lent) ** 2\n                if norm.dtype == float:\n                    norm /= lent\n                else:\n                    norm = norm / lent\n                np.subtract(_window_sum(data ** 2, lent), norm, out=norm)\n            else:\n                norm = _window_sum(data ** 2, lent)\n            norm *= tnorm\n            if norm.dtype == float:\n                np.sqrt(norm, out=norm)\n            else:\n                norm = np.sqrt(norm)\n            mask = norm <= np.finfo(float).eps\n            if cc.dtype == float:\n                cc[~mask] /= norm[~mask]\n            else:\n                cc = cc / norm\n            cc[mask] = 0\n        else:\n            msg = \"normalize has to be one of (None, 'naive', 'full')\"\n            raise ValueError(msg)\n    return cc"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "read_events", "method_path": "../srcdata/Computation/obspy/obspy/core/event/catalog.py", "method_code_mask": "import copy\nimport warnings\nimport numpy as np\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import _read_from_plugin\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.imaging.maps import plot_map\nfrom obspy.imaging.maps import _plot_cartopy_into_axes\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.imaging.cm import obspy_sequential\nimport doctest\n\n\n@map_example_filename('pathname_or_url')\ndef read_events(pathname_or_url=None, format=None, **kwargs): [MASK]\n", "response": "import copy\nimport warnings\nimport numpy as np\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import _read_from_plugin\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.imaging.maps import plot_map\nfrom obspy.imaging.maps import _plot_cartopy_into_axes\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.imaging.cm import obspy_sequential\nimport doctest\n@map_example_filename('pathname_or_url')\ndef read_events(pathname_or_url=None, format=None, **kwargs):\n    \"\"\"\n    Read event files into an ObsPy\n    :class:`~obspy.core.event.catalog.Catalog` object.\n\n    The :func:`~obspy.core.event.read_events` function opens either one or\n    multiple event files given via file name or URL using the\n    ``pathname_or_url`` attribute.\n\n    :type pathname_or_url: str, pathlib.Path, or file-like object, optional\n    :param pathname_or_url: String containing a file name or a URL, Path\n        object, or an open file-like object. Wildcards are allowed for a file\n        name. If this attribute is omitted, an example\n        :class:`~obspy.core.event.Catalog` object will be returned.\n    :type format: str\n    :param format: Format of the file to read (e.g. ``\"QUAKEML\"``). See the\n        `Supported Formats`_ section below for a list of supported formats.\n    :rtype: :class:`~obspy.core.event.Catalog`\n    :return: An ObsPy :class:`~obspy.core.event.Catalog` object.\n\n    .. rubric:: _`Supported Formats`\n\n    Additional ObsPy modules extend the functionality of the\n    :func:`~obspy.core.event.read_events` function. The following table\n    summarizes all known file formats currently supported by ObsPy.\n\n    Please refer to the `Linked Function Call`_ of each module for any extra\n    options available at the import stage.\n\n    %s\n\n    Next to the :func:`~obspy.core.event.read_events` function the\n    :meth:`~obspy.core.event.catalog.Catalog.write` method of the returned\n    :class:`~obspy.core.event.catalog.Catalog` object can be used to export the\n    data to the file system.\n    \"\"\"\n    if pathname_or_url is None:\n        return _create_example_catalog()\n    else:\n        return _generic_reader(pathname_or_url, _read, format=format, **kwargs)"}
{"result": "passed", "model_name": "std", "repository": "obspy", "full_method_name": "read_inventory", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/inventory.py", "method_code_mask": "import copy\nimport fnmatch\nimport textwrap\nimport warnings\nimport obspy\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.base import _read_from_plugin\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nfrom obspy.imaging.maps import plot_map\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom obspy.core.inventory.response import _adjust_bode_plot_figure\nimport doctest\n\n\n@map_example_filename('path_or_file_object')\ndef read_inventory(path_or_file_object=None, format=None, level='response',\n    *args, **kwargs): [MASK]\n", "response": "import copy\nimport fnmatch\nimport textwrap\nimport warnings\nimport obspy\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.base import _read_from_plugin\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nfrom obspy.imaging.maps import plot_map\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom obspy.core.inventory.response import _adjust_bode_plot_figure\nimport doctest\n@map_example_filename('path_or_file_object')\ndef read_inventory(path_or_file_object=None, format=None, level='response',\n    *args, **kwargs):\n    \"\"\"\n    Function to read inventory files.\n\n    :type path_or_file_object: str, pathlib.Path, or file-like object, optional\n    :param path_or_file_object: String containing a file name or a URL, a Path\n        object, or a open file-like object. Wildcards are allowed for a file\n        name. If this attribute is omitted, an example\n        :class:`~obspy.core.inventory.inventory.Inventory` object will be\n        returned.\n    :type format: str\n    :param format: Format of the file to read (e.g. ``\"STATIONXML\"``). See the\n        `Supported Formats`_ section below for a list of supported formats.\n    :type level: str\n    :param level: Level of detail to read from file. One of ``'response'``,\n        ``'channel'``, ``'station'`` or ``'network'``. Lower level of detail\n        can result in much shorter reading times for some file formats.\n    :rtype: :class:`~obspy.core.inventory.inventory.Inventory`\n    :return: An ObsPy :class:`~obspy.core.inventory.inventory.Inventory`\n        object.\n\n    Additional args and kwargs are passed on to the underlying ``_read_X()``\n    methods of the inventory plugins.\n\n    .. rubric:: _`Supported Formats`\n\n    Additional ObsPy modules extend the functionality of the\n    :func:`~obspy.core.inventory.inventory.read_inventory` function. The\n    following table summarizes all known file formats currently supported by\n    ObsPy.\n\n    Please refer to the `Linked Function Call`_ of each module for any extra\n    options available at the import stage.\n\n    %s\n\n    .. note::\n\n        For handling additional information not covered by the\n        StationXML standard and how to output it to StationXML\n        see the :ref:`ObsPy Tutorial <stationxml-extra>`.\n    \"\"\"\n    kwargs['level'] = level\n    if path_or_file_object is None:\n        return _create_example_inventory()\n    else:\n        return _generic_reader(path_or_file_object, _read, format=format,\n            **kwargs)"}
