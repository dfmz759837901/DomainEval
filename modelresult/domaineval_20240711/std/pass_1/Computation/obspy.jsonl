{"model_name": "std", "repository": "obspy", "full_method_name": "calc_dist", "method_path": "../srcdata/Computation/obspy/obspy/taup/taup_geo.py", "response": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom geographiclib.geodesic import Geodesic\ndef calc_dist(source_latitude_in_deg, source_longitude_in_deg,\n    receiver_latitude_in_deg, receiver_longitude_in_deg,\n    radius_of_planet_in_km, flattening_of_planet):\n    \"\"\"\n    Given the source and receiver location, calculate distance.\n\n    :param source_latitude_in_deg: Source location latitude in degrees\n    :type source_latitude_in_deg: float\n    :param source_longitude_in_deg: Source location longitude in degrees\n    :type source_longitude_in_deg: float\n    :param receiver_latitude_in_deg: Receiver location latitude in degrees\n    :type receiver_latitude_in_deg: float\n    :param receiver_longitude_in_deg: Receiver location longitude in degrees\n    :type receiver_longitude_in_deg: float\n    :param radius_of_planet_in_km: Radius of the planet in km\n    :type radius_of_planet_in_km: float\n    :param flattening_of_planet: Flattening of planet (0 for a sphere)\n    :type receiver_longitude_in_deg: float\n\n    :return: distance_in_deg\n    :rtype: float\n    \"\"\"\n    return calc_dist_azi(source_latitude_in_deg, source_longitude_in_deg,\n        receiver_latitude_in_deg, receiver_longitude_in_deg,\n        radius_of_planet_in_km, flattening_of_planet)[0]", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup.tau import TauPyModel\nfrom obspy.taup.taup_geo import calc_dist\nfrom obspy.taup.taup_geo import calc_dist_azi\nimport obspy.geodetics.base as geodetics\n\nclass TestTaupGeoDist():\n\tdef test_taup_geo_calc_dist_1(self):\n\t    \"\"\"Test for calc_dist\"\"\"\n\t    dist = calc_dist(source_latitude_in_deg=20.0, source_longitude_in_deg=\n\t        33.0, receiver_latitude_in_deg=55.0, receiver_longitude_in_deg=33.0,\n\t        radius_of_planet_in_km=6371.0, flattening_of_planet=0.0)\n\t    assert round(abs(dist) - 35.0, 5) == 0.0\n\t\nTestTaupGeoDist().test_taup_geo_calc_dist_1()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_taup_geo.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup.tau import TauPyModel\nfrom obspy.taup.taup_geo import calc_dist\nfrom obspy.taup.taup_geo import calc_dist_azi\nimport obspy.geodetics.base as geodetics\n\nclass TestTaupGeoDist():\n\tdef test_taup_geo_calc_dist_2(self):\n\t    \"\"\"Test for calc_dist\"\"\"\n\t    dist = calc_dist(source_latitude_in_deg=55.0, source_longitude_in_deg=\n\t        33.0, receiver_latitude_in_deg=20.0, receiver_longitude_in_deg=33.0,\n\t        radius_of_planet_in_km=6371.0, flattening_of_planet=0.0)\n\t    assert round(abs(dist - 35.0), 5) == 0.0\n\t\nTestTaupGeoDist().test_taup_geo_calc_dist_2()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_taup_geo.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup.tau import TauPyModel\nfrom obspy.taup.taup_geo import calc_dist\nfrom obspy.taup.taup_geo import calc_dist_azi\nimport obspy.geodetics.base as geodetics\n\nclass TestTaupGeoDist():\n\tdef test_taup_geo_calc_dist_3(self):\n\t    \"\"\"Test for calc_dist\"\"\"\n\t    dist = calc_dist(source_latitude_in_deg=-20.0, source_longitude_in_deg=\n\t        33.0, receiver_latitude_in_deg=-55.0, receiver_longitude_in_deg=\n\t        33.0, radius_of_planet_in_km=6371.0, flattening_of_planet=0.0)\n\t    assert round(abs(dist - 35.0), 5) == 0\n\t\nTestTaupGeoDist().test_taup_geo_calc_dist_3()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_taup_geo.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup.tau import TauPyModel\nfrom obspy.taup.taup_geo import calc_dist\nfrom obspy.taup.taup_geo import calc_dist_azi\nimport obspy.geodetics.base as geodetics\n\nclass TestTaupGeoDist():\n\tdef test_taup_geo_calc_dist_4(self):\n\t    \"\"\"Test for calc_dist\"\"\"\n\t    dist = calc_dist(source_latitude_in_deg=-20.0, source_longitude_in_deg=\n\t        33.0, receiver_latitude_in_deg=-55.0, receiver_longitude_in_deg=\n\t        33.0, radius_of_planet_in_km=6.371, flattening_of_planet=0.0)\n\t    assert round(abs(dist - 35.0), 5) == 0\n\t\nTestTaupGeoDist().test_taup_geo_calc_dist_4()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_taup_geo.py"}], "method_code_mask": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom geographiclib.geodesic import Geodesic\n\n\ndef calc_dist(source_latitude_in_deg, source_longitude_in_deg,\n    receiver_latitude_in_deg, receiver_longitude_in_deg,\n    radius_of_planet_in_km, flattening_of_planet): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "leg_puller", "method_path": "../srcdata/Computation/obspy/obspy/taup/seismic_phase.py", "response": "from itertools import count\nimport math\nimport re\nimport numpy as np\nfrom scipy.optimize import brentq\nfrom obspy.core.util.obspy_types import Enum\ndef leg_puller(name):\n    \"\"\"\n    Tokenize a phase name into legs.\n\n    For example, ``PcS`` becomes ``'P' + 'c' + 'S'`` while ``p^410P`` would\n    become ``'p' + '^410' + 'P'``. Once a phase name has been broken into\n    tokens, we can begin to construct the sequence of branches to which it\n    corresponds. Only minor error checking is done at this point, for instance\n    ``PIP`` generates an exception but ``^410`` doesn't. It also appends\n    ``\"END\"`` as the last leg.\n    \"\"\"\n    results, remainder = tokenizer.scan(name)\n    if remainder:\n        raise ValueError('Invalid phase name: %s could not be parsed in %s' %\n            (str(remainder), name))\n    return results + ['END']", "test_code_list": [{"test_code": "from obspy.taup.seismic_phase import leg_puller\n\nclass TestTauPyMisc():\n\tdef test_leg_puller(self):\n\t    \"\"\"\n\t        Tests the leg puller.\n\t        \"\"\"\n\t    legs = [('P', ['P', 'END']), ('S', ['S', 'END']), ('PPP', ['P', 'P',\n\t        'P', 'END']), ('PPPP', ['P', 'P', 'P', 'P', 'END']), ('SSSS', ['S',\n\t        'S', 'S', 'S', 'END']), ('Sn', ['Sn', 'END']), ('Pn', ['Pn', 'END']\n\t        ), ('Pg', ['Pg', 'END']), ('Sg', ['Sg', 'END']), ('Sb', ['Sb',\n\t        'END']), ('Pb', ['Pb', 'END']), ('PmP', ['P', 'm', 'P', 'END']), (\n\t        'SmS', ['S', 'm', 'S', 'END']), ('PKP', ['P', 'K', 'P', 'END']), (\n\t        'PKIKP', ['P', 'K', 'I', 'K', 'P', 'END']), ('SKS', ['S', 'K', 'S',\n\t        'END']), ('SKP', ['S', 'K', 'P', 'END']), ('PKS', ['P', 'K', 'S',\n\t        'END']), ('SKKS', ['S', 'K', 'K', 'S', 'END']), ('PKKP', ['P', 'K',\n\t        'K', 'P', 'END']), ('PKiKP', ['P', 'K', 'i', 'K', 'P', 'END']), (\n\t        'PcP', ['P', 'c', 'P', 'END']), ('PmP', ['P', 'm', 'P', 'END']), (\n\t        'ScS', ['S', 'c', 'S', 'END']), ('SKSSKS', ['S', 'K', 'S', 'S', 'K',\n\t        'S', 'END']), ('Pdiff', ['Pdiff', 'END']), ('Sdiff', ['Sdiff',\n\t        'END']), ('PS', ['P', 'S', 'END']), ('SP', ['S', 'P', 'END']), (\n\t        'PmS', ['P', 'm', 'S', 'END']), ('SmP', ['S', 'm', 'P', 'END']), (\n\t        'PcS', ['P', 'c', 'S', 'END']), ('ScP', ['S', 'c', 'P', 'END']), (\n\t        'pP', ['p', 'P', 'END']), ('sS', ['s', 'S', 'END']), ('SSP', ['S',\n\t        'S', 'P', 'END']), ('PPS', ['P', 'P', 'S', 'END']), ('SKiKS', ['S',\n\t        'K', 'i', 'K', 'S', 'END']), ('SKJKP', ['S', 'K', 'J', 'K', 'P',\n\t        'END']), ('PKJKS', ['P', 'K', 'J', 'K', 'S', 'END']), ('PnPn', [\n\t        'Pn', 'Pn', 'END']), ('SnSn', ['Sn', 'Sn', 'END']), ('Pvmp', ['P',\n\t        'vm', 'p', 'END']), ('PvmP', ['P', 'vm', 'P', 'END']), ('P410P', [\n\t        'P', '410', 'P', 'END']), ('p^410P', ['p', '^410', 'P', 'END']), (\n\t        'pv410P', ['p', 'v410', 'P', 'END']), ('P^mP', ['P', '^m', 'P',\n\t        'END']), ('PvmP', ['P', 'vm', 'P', 'END']), ('2kmps', ['2kmps',\n\t        'END']), ('22kmps', ['22kmps', 'END']), ('.2kmps', ['.2kmps', 'END'\n\t        ]), ('23.kmps', ['23.kmps', 'END']), ('23.33kmps', ['23.33kmps',\n\t        'END'])]\n\t    for name, result in legs:\n\t        assert leg_puller(name) == result\n\t\nTestTauPyMisc().test_leg_puller()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_misc.py"}], "method_code_mask": "from itertools import count\nimport math\nimport re\nimport numpy as np\nfrom scipy.optimize import brentq\nfrom obspy.core.util.obspy_types import Enum\n\n\ndef leg_puller(name): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "create_from_vlayer", "method_path": "../srcdata/Computation/obspy/obspy/taup/slowness_layer.py", "response": "import math\nimport numpy as np\ndef create_from_vlayer(v_layer, is_p_wave, radius_of_planet, is_spherical=True\n    ):\n    \"\"\"\n    Compute the slowness layer from a velocity layer.\n\n    :param v_layer: The velocity layer to convert.\n    :type v_layer: :class:`numpy.ndarray`,\n        dtype = :class:`obspy.taup.velocity_layer.VelocityLayer`\n    :param is_p_wave: Whether this velocity layer is for compressional/P\n         (``True``) or shear/S (``False``) waves.\n    :type is_p_wave: bool\n    :param radius_of_planet: The radius of the planet to use, in km.\n    :type radius_of_planet: float\n    :param is_spherical: Whether the model is spherical. Non-spherical models\n        are not currently supported.\n    :type is_spherical: bool\n    \"\"\"\n    ret = np.empty(shape=v_layer.shape, dtype=SlownessLayer)\n    ret['top_depth'] = v_layer['top_depth']\n    ret['bot_depth'] = v_layer['bot_depth']\n    wave_type = 'p' if is_p_wave else 's'\n    if is_spherical:\n        ret['top_p'] = (radius_of_planet - ret['top_depth']\n            ) / evaluate_velocity_at_top(v_layer, wave_type)\n        bot_depth = ret['bot_depth']\n        bot_vel = evaluate_velocity_at_bottom(v_layer, wave_type)\n        if bot_depth.shape and bot_depth.size:\n            if bot_depth[-1] == radius_of_planet and bot_vel[-1] == 0.0:\n                bot_depth[-1] = 1.0\n        ret['bot_p'] = (radius_of_planet - bot_depth) / bot_vel\n    else:\n        raise NotImplementedError('no flat models yet')\n    return ret", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup import _DEFAULT_VALUES\nfrom obspy.taup.slowness_layer import SlownessLayer\nfrom obspy.taup.slowness_layer import SlownessModelError\nfrom obspy.taup.slowness_layer import bullen_depth_for\nfrom obspy.taup.slowness_layer import create_from_vlayer\nfrom obspy.taup.velocity_layer import VelocityLayer\n\nclass TestTauPySlownessModel():\n\tdef test_slowness_layer(self):\n\t    v_layer = np.array([(10, 31, 3, 5, 2, 4, _DEFAULT_VALUES['density'],\n\t        _DEFAULT_VALUES['density'], _DEFAULT_VALUES['qp'], _DEFAULT_VALUES[\n\t        'qp'], _DEFAULT_VALUES['qs'], _DEFAULT_VALUES['qs'])], dtype=\n\t        VelocityLayer)\n\t    a = create_from_vlayer(v_layer, True, radius_of_planet=6371.0)\n\t    assert a['bot_p'] == 1268.0\n\t    assert a['bot_depth'] == 31.0\n\t    b = create_from_vlayer(v_layer, False, radius_of_planet=6371.0)\n\t    assert b['top_p'] == 3180.5\n\t\nTestTauPySlownessModel().test_slowness_layer()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_slowness_model.py"}], "method_code_mask": "import math\nimport numpy as np\n\n\ndef create_from_vlayer(v_layer, is_p_wave, radius_of_planet, is_spherical=True\n    ): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "bullen_depth_for", "method_path": "../srcdata/Computation/obspy/obspy/taup/slowness_layer.py", "response": "import math\nimport numpy as np\ndef bullen_depth_for(layer, ray_param, radius_of_planet, check=True):\n    \"\"\"\n    Finds the depth for a ray parameter within this layer.\n\n    Uses a Bullen interpolant, Ar^B. Special case for ``bot_p == 0`` or\n    ``bot_depth == radius_of_planet`` as these cause division by 0; use linear\n    interpolation in this case.\n\n    The ``layer`` and ``ray_param`` parameters must be either 0-D, or both of\n    the same shape.\n\n    :param layer: The layer(s) to check.\n    :type layer: :class:`~numpy.ndarray` (shape = (1, ), dtype =\n        :class:`obspy.taup.helper_classes.SlownessLayer`)\n    :param ray_param: The ray parameter(s) to use for calculation, in s/km.\n    :type ray_param: float\n    :param radius_of_planet: The radius (in km) of the planet to use.\n    :type radius_of_planet: float\n\n    :returns: The depth (in km) for the specified ray parameter.\n    :rtype: float\n    \"\"\"\n    ldim = np.ndim(layer)\n    pdim = np.ndim(ray_param)\n    if ldim == 1 and pdim == 0:\n        ray_param = ray_param * np.ones(layer.shape, dtype=np.float64)\n        depth = np.zeros(shape=layer.shape, dtype=np.float64)\n    elif ldim == 0 and pdim == 1:\n        layer = layer * np.ones(ray_param.shape, dtype=SlownessLayer)\n        depth = np.zeros(shape=ray_param.shape, dtype=np.float64)\n    elif ldim == pdim and (ldim == 0 or layer.shape == ray_param.shape):\n        if ldim == 0:\n            layer = np.array([layer], dtype=SlownessLayer)\n            ray_param = np.array([ray_param])\n        depth = np.zeros(shape=layer.shape, dtype=np.float64)\n    else:\n        raise TypeError(\n            'Either layer or ray_param must be 0D, or they must have the same shape.'\n            )\n    valid = (layer['top_p'] - ray_param) * (ray_param - layer['bot_p']) >= 0\n    if not check or np.all(valid):\n        leftover = np.ones_like(depth, dtype=np.bool_)\n        mask = layer['top_depth'] == layer['bot_depth']\n        depth[mask] = layer['bot_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & (layer['top_p'] == ray_param)\n        depth[mask] = layer['top_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & (layer['bot_p'] == ray_param)\n        depth[mask] = layer['bot_depth'][mask]\n        leftover &= ~mask\n        mask = leftover & ((layer['bot_p'] != 0) & (layer['bot_depth'] !=\n            radius_of_planet))\n        if np.any(mask):\n            top_p_mask = layer['top_p'][mask]\n            bot_p_mask = layer['bot_p'][mask]\n            top_depth_mask = layer['top_depth'][mask]\n            bot_depth_mask = layer['bot_depth'][mask]\n            ray_param_mask = ray_param[mask]\n            b = np.divide(np.log(top_p_mask / bot_p_mask), np.log((\n                radius_of_planet - top_depth_mask) / (radius_of_planet -\n                bot_depth_mask)))\n            with np.errstate(over='ignore'):\n                denom = np.power(radius_of_planet - top_depth_mask, b)\n            a = np.divide(top_p_mask, denom)\n            temp_depth = np.empty_like(a)\n            mask2 = (a != 0) & (b != 0)\n            temp_depth[mask2] = radius_of_planet - np.exp(1.0 / b[mask2] *\n                np.log(np.divide(ray_param_mask[mask2], a[mask2])))\n            temp_depth[~mask2] = (bot_depth_mask[~mask2] - top_depth_mask[~\n                mask2]) / (bot_p_mask[~mask2] - top_p_mask[~mask2]) * (\n                ray_param_mask[~mask2] - top_p_mask[~mask2]) + top_depth_mask[\n                ~mask2]\n            mask2 = (top_depth_mask > temp_depth) & (temp_depth > \n                top_depth_mask - 1e-06)\n            temp_depth[mask2] = top_depth_mask[mask2]\n            mask2 = (bot_depth_mask < temp_depth) & (temp_depth < \n                bot_depth_mask + 1e-06)\n            temp_depth[mask2] = bot_depth_mask[mask2]\n            mask2 = (temp_depth < 0) | np.isnan(temp_depth) | np.isinf(\n                temp_depth) | (temp_depth < top_depth_mask) | (temp_depth >\n                bot_depth_mask)\n            small_layer = bot_depth_mask[mask2] - top_depth_mask[mask2] > 5\n            if np.any(small_layer):\n                if check:\n                    raise SlownessModelError(\n                        'Calculated depth is outside layer, negative, or NaN.')\n                else:\n                    temp_depth[mask2][small_layer] = np.nan\n            linear = (bot_depth_mask[mask2] - top_depth_mask[mask2]) / (\n                bot_p_mask[mask2] - top_p_mask[mask2]) * (ray_param_mask[\n                mask2] - top_p_mask[mask2]) + top_depth_mask[mask2]\n            outside_layer = small_layer & (linear < 0 | np.isnan(linear) |\n                np.isinf(linear))\n            if np.any(outside_layer):\n                if check:\n                    raise SlownessModelError(\n                        'Calculated depth is outside layer, negative, or NaN.')\n                else:\n                    temp_depth[mask2][outside_layer] = np.nan\n            temp_depth[mask2] = linear\n            mask2 = (temp_depth < top_depth_mask) & (top_depth_mask -\n                temp_depth < 1e-10)\n            temp_depth[mask2] = top_depth_mask[mask2]\n            mask2 = (temp_depth > bot_depth_mask) & (temp_depth -\n                bot_depth_mask < 1e-10)\n            temp_depth[mask2] = bot_depth_mask[mask2]\n            depth[mask] = temp_depth\n            leftover &= ~mask\n        mask = leftover & (layer['top_p'] != layer['bot_p'])\n        depth[mask] = layer['bot_depth'][mask] + (ray_param[mask] - layer[\n            'bot_p'][mask]) * (layer['top_depth'][mask] - layer['bot_depth'\n            ][mask]) / (layer['top_p'][mask] - layer['bot_p'][mask])\n        leftover &= ~mask\n        depth[leftover] = layer['bot_depth'][leftover]\n        depth[~valid] = np.nan\n        if ldim == 0 and pdim == 0:\n            return depth[0]\n        else:\n            return depth\n    else:\n        raise SlownessModelError(\n            'Ray parameter is not contained within this slowness layer.')", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom obspy.taup import _DEFAULT_VALUES\nfrom obspy.taup.slowness_layer import SlownessLayer\nfrom obspy.taup.slowness_layer import SlownessModelError\nfrom obspy.taup.slowness_layer import bullen_depth_for\nfrom obspy.taup.slowness_layer import create_from_vlayer\nfrom obspy.taup.velocity_layer import VelocityLayer\n\nclass TestBullenDepth():\n\tdef test_overflow(self):\n\t    sl = np.array([(2548.4, 6.546970605878823, 1846.2459389213773, \n\t        13.798727310994103)], dtype=SlownessLayer)\n\t    try:\n\t        depth = bullen_depth_for(sl, 2197.322969460689, 6371)\n\t    except SlownessModelError:\n\t        pytest.fail('SlownessModelError was incorrectly raised.')\n\t    assert not np.isnan(depth)\n\t\nTestBullenDepth().test_overflow()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_slowness_model.py"}], "method_code_mask": "import math\nimport numpy as np\n\n\ndef bullen_depth_for(layer, ray_param, radius_of_planet, check=True): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "get_ray_paths", "method_path": "../srcdata/Computation/obspy/obspy/taup/ray_paths.py", "response": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom obspy.taup import TauPyModel\ndef get_ray_paths(inventory, catalog, phase_list=['P'], coordinate_system=\n    'XYZ', taup_model='iasp91'):\n    \"\"\"\n    This function returns lat, lon, depth coordinates from an event\n    location to all stations in the inventory object\n\n    :param inventory: an obspy station inventory\n    :param catalog: an obspy event catalog\n    :param phase_list: a list of seismic phase names that is passed to taup\n    :param coordinate_system: can be either 'XYZ' or 'RTP'.\n    :param taup_model: the taup model for which the greatcircle paths are\n                  computed\n    :returns: a list of tuples\n        ``[(gcircle, phase_name, station_label, event_timestamp,\n        event_magnitude, event_id, origin_id), ...]``. ``gcircle`` is an array\n        of shape ``[3, npoints]`` with the path coordinates. ``phase_name`` is\n        the name of the seismic phase, ``station_label`` is the name of the\n        station and network that belongs to the path. ``event_timestamp``,\n        ``event_magnitude``, ``event_id`` and ``origin_id`` describe the event\n        that belongs to the path.\n    \"\"\"\n    if not geodetics.HAS_GEOGRAPHICLIB:\n        raise ImportError(\n            'Geographiclib not found but required by ray path routine')\n    stlats = []\n    stlons = []\n    stlabels = []\n    for network in inventory:\n        for station in network:\n            label_ = '.'.join((network.code, station.code))\n            if station.latitude is None or station.longitude is None:\n                msg = (\n                    \"Station '%s' does not have latitude/longitude information and will not be plotted.\"\n                     % label_)\n                warnings.warn(msg)\n                continue\n            stlats.append(station.latitude)\n            stlons.append(station.longitude)\n            stlabels.append(label_)\n    evlats = []\n    evlons = []\n    evdepths = []\n    event_ids = []\n    origin_ids = []\n    magnitudes = []\n    times = []\n    for event in catalog:\n        if not event.origins:\n            msg = (\n                \"Event '%s' does not have an origin and will not be plotted.\" %\n                str(event.resource_id))\n            warnings.warn(msg)\n            continue\n        if not event.magnitudes:\n            msg = (\n                \"Event '%s' does not have a magnitude and will not be plotted.\"\n                 % str(event.resource_id))\n            warnings.warn(msg)\n            continue\n        origin = event.preferred_origin() or event.origins[0]\n        evlats.append(origin.latitude)\n        evlons.append(origin.longitude)\n        if not origin.get('depth'):\n            origin.depth = 0.0\n        evdepths.append(origin.get('depth') * 0.001)\n        magnitude = event.preferred_magnitude() or event.magnitudes[0]\n        mag = magnitude.mag\n        event_ids.append(str(event.resource_id))\n        origin_ids.append(str(origin.resource_id))\n        magnitudes.append(mag)\n        times.append(origin.time.timestamp)\n    if isinstance(taup_model, str):\n        from obspy.taup import TauPyModel\n        model = TauPyModel(model=taup_model)\n    else:\n        model = taup_model\n    r_earth = model.model.radius_of_planet\n    greatcircles = []\n    for stlat, stlon, stlabel in zip(stlats, stlons, stlabels):\n        for evlat, evlon, evdepth_km, time, magnitude, event_id, origin_id in zip(\n            evlats, evlons, evdepths, times, magnitudes, event_ids, origin_ids\n            ):\n            arrivals = model.get_ray_paths_geo(evdepth_km, evlat, evlon,\n                stlat, stlon, phase_list=phase_list, resample=True)\n            if len(arrivals) == 0:\n                continue\n            for arr in arrivals:\n                radii = (r_earth - arr.path['depth']) / r_earth\n                thetas = np.radians(90.0 - arr.path['lat'])\n                phis = np.radians(arr.path['lon'])\n                if coordinate_system == 'RTP':\n                    gcircle = np.array([radii, thetas, phis])\n                if coordinate_system == 'XYZ':\n                    gcircle = np.array([radii * np.sin(thetas) * np.cos(\n                        phis), radii * np.sin(thetas) * np.sin(phis), radii *\n                        np.cos(thetas)])\n                greatcircles.append((gcircle, arr.name, stlabel, time,\n                    magnitude, event_id, origin_id))\n    return greatcircles", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport obspy\nimport obspy.geodetics.base as geodetics\nfrom obspy.taup.ray_paths import get_ray_paths\nfrom obspy.taup import TauPyModel\n\nclass TestRayPathCalculations():\n\t@pytest.mark.skipif(not geodetics.GEOGRAPHICLIB_VERSION_AT_LEAST_1_34,\n\t    reason='test needs geographiclib >= 1.34')\n\tdef test_compute_ray_paths(self):\n\t    station = obspy.core.inventory.Station(code='STA', latitude=0.0,\n\t        longitude=30.0, elevation=0.0)\n\t    network = obspy.core.inventory.Network(code='NET', stations=[station,\n\t        station])\n\t    inventory = obspy.core.inventory.Inventory(source='ME', networks=[network])\n\t    otime = obspy.UTCDateTime('2017-02-03T12:00:00.0Z')\n\t    origin = obspy.core.event.Origin(latitude=0.0, longitude=90.0, depth=\n\t        100000.0, time=otime)\n\t    origin.resource_id = 'smi:local/just-a-test2'\n\t    magnitude = obspy.core.event.Magnitude(mag=7.0)\n\t    event = obspy.core.event.Event(origins=[origin], magnitudes=[magnitude])\n\t    event.resource_id = 'smi:local/just-a-test'\n\t    catalog = obspy.core.event.Catalog(events=[event, event, event])\n\t    greatcircles = get_ray_paths(inventory, catalog, phase_list=['P', 'PP',\n\t        'S', 'SS'], coordinate_system='XYZ', taup_model='iasp91')\n\t    assert len(greatcircles) == 24\n\t    circ = greatcircles[0]\n\t    path = circ[0]\n\t    assert circ[1] == 'P'\n\t    assert circ[2] == 'NET.STA'\n\t    np.testing.assert_allclose(circ[3], otime.timestamp, atol=1e-05, rtol=0)\n\t    assert circ[4] == 7.0\n\t    assert circ[5] == 'smi:local/just-a-test'\n\t    assert circ[6] == 'smi:local/just-a-test2'\n\t    assert path.shape == (3, 274)\n\t    path_start_expected = [[6.02712296e-17, 4.63135005e-05, 0.00182928142, \n\t        0.00199453947, 0.00216015881], [0.984303877, 0.98422434, \n\t        0.981162947, 0.980879369, 0.980595408], [6.02712296e-17, \n\t        6.02663595e-17, 6.00790075e-17, 6.00616631e-17, 6.00442971e-17]]\n\t    np.testing.assert_allclose(path[:, :5], path_start_expected, rtol=1e-05)\n\t    path_end_expected = [[0.86519541, 0.865610142, 0.865817499, 0.86602485,\n\t        0.866025746], [0.499866617, 0.499932942, 0.499966104, 0.499999264, \n\t        0.499999407], [6.11842455e-17, 6.12082668e-17, 6.12202774e-17, \n\t        6.1232288e-17, 6.123234e-17]]\n\t    np.testing.assert_allclose(path[:, -5:], path_end_expected, rtol=1e-05)\n\t    path_steps_expected = [[6.02712296e-17, 0.00599694796, 0.0155844904, \n\t        0.0229391617, 0.0312959401, 0.0494819381, 0.0659026261, \n\t        0.0884601669, 0.115734196, 0.130670566, 0.183202229, 0.221387617, \n\t        0.300609265, 0.451339383, 0.539194024, 0.584050335, 0.648856399, \n\t        0.66801876, 0.7039626, 0.73480969, 0.7598879, 0.789619836, \n\t        0.804521516, 0.818115511, 0.836517555, 0.848367905, 0.859911335, \n\t        0.865610142], [0.984303877, 0.974082937, 0.958372986, 0.94692781, \n\t        0.934554991, 0.910758513, 0.891322841, 0.86880446, 0.843147543, \n\t        0.829702355, 0.785418525, 0.755840616, 0.700517755, 0.614315731, \n\t        0.574088249, 0.556174903, 0.533353699, 0.527297943, 0.516800783, \n\t        0.508777243, 0.504479841, 0.500872221, 0.499943609, 0.499408317, \n\t        0.499111122, 0.499125255, 0.499180374, 0.499932942], [\n\t        6.02712296e-17, 5.96465079e-17, 5.86911789e-17, 5.79996164e-17, \n\t        5.72570664e-17, 5.5850122e-17, 5.47267635e-17, 5.34739746e-17, \n\t        5.21120017e-17, 5.14308206e-17, 4.93839986e-17, 4.82263481e-17, \n\t        4.66770017e-17, 4.66770017e-17, 4.82263481e-17, 4.93839986e-17, \n\t        5.14308206e-17, 5.21120017e-17, 5.34739746e-17, 5.47267635e-17, \n\t        5.5850122e-17, 5.72570664e-17, 5.79996164e-17, 5.86911789e-17, \n\t        5.96465079e-17, 6.02712296e-17, 6.08831943e-17, 6.12082668e-17]]\n\t    np.testing.assert_allclose(path[:, ::10], path_steps_expected, rtol=1e-05)\n\t    greatcircles = get_ray_paths(inventory, catalog, phase_list=['P', 'PP',\n\t        'S', 'SS'], coordinate_system='RTP', taup_model='ak135')\n\t    assert len(greatcircles) == 24\n\t    circ = greatcircles[0]\n\t    path = circ[0]\n\t    assert circ[1] == 'P'\n\t    assert circ[2] == 'NET.STA'\n\t    np.testing.assert_allclose(circ[3], otime.timestamp, atol=1e-05, rtol=0)\n\t    assert circ[4] == 7.0\n\t    assert circ[5] == 'smi:local/just-a-test'\n\t    assert circ[6] == 'smi:local/just-a-test2'\n\t    assert path.shape == (3, 270)\n\t    path_start_expected = [[0.984304, 0.984217, 0.981165, 0.98088, 0.980595\n\t        ], [1.570796, 1.570796, 1.570796, 1.570796, 1.570796], [1.570796, \n\t        1.570745, 1.568935, 1.568765, 1.568595]]\n\t    np.testing.assert_allclose(path[:, :5], path_start_expected, rtol=1e-06)\n\t    path_end_expected = [[0.998124, 0.999062, 0.999531, 0.999765, 1.0], [\n\t        1.570796, 1.570796, 1.570796, 1.570796, 1.570796], [0.524316, \n\t        0.523957, 0.523778, 0.523688, 0.523599]]\n\t    np.testing.assert_allclose(path[:, -5:], path_end_expected, rtol=1e-06)\n\t    path_steps_expected = [[0.98430388, 0.9741014, 0.95847208, 0.94717382, \n\t        0.93508421, 0.91210171, 0.89145501, 0.86719412, 0.84963114, \n\t        0.83022016, 0.80548417, 0.78780343, 0.76158226, 0.76488692, \n\t        0.79524407, 0.80633663, 0.83604439, 0.85093573, 0.87434336, \n\t        0.89536778, 0.91994977, 0.93757572, 0.94908037, 0.95919008, \n\t        0.97447903, 0.98726847, 0.99568357], [1.57079633, 1.57079633, \n\t        1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633, \n\t        1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633, \n\t        1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633, \n\t        1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633, \n\t        1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633], [\n\t        1.57079633, 1.56464945, 1.55454336, 1.54659206, 1.53738096, \n\t        1.5166151, 1.49423077, 1.46055656, 1.4323689, 1.39637248, \n\t        1.33996718, 1.28795961, 1.16342477, 0.91617848, 0.7911088, \n\t        0.76040906, 0.69478715, 0.66799188, 0.63152179, 0.6034472, \n\t        0.57851384, 0.56322297, 0.55460834, 0.54755404, 0.53770068, \n\t        0.53004245, 0.52531799]]\n\t    np.testing.assert_allclose(path[:, ::10], path_steps_expected, rtol=1e-06)\n\t\nTestRayPathCalculations().test_compute_ray_paths()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/taup/tests/test_ray_paths.py"}], "method_code_mask": "import warnings\nimport numpy as np\nimport obspy.geodetics.base as geodetics\nfrom obspy.taup import TauPyModel\n\n\ndef get_ray_paths(inventory, catalog, phase_list=['P'], coordinate_system=\n    'XYZ', taup_model='iasp91'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "traces_almost_equal", "method_path": "../srcdata/Computation/obspy/obspy/core/util/testing.py", "response": "import difflib\nimport doctest\nimport inspect\nimport io\nimport os\nimport re\nimport numpy as np\nfrom lxml import etree\nimport obspy.core.event as ev\nfrom obspy import UTCDateTime\nfrom obspy import Catalog\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.trace import Stats\ndef traces_almost_equal(tr1, tr2, default_stats=True, rtol=1e-05, atol=\n    1e-08, equal_nan=True):\n    \"\"\"\n    Return True if the two traces are almost equal.\n\n    :param tr1: The first :class:`~obspy.core.trace.Trace` object.\n    :param tr2: The second :class:`~obspy.core.trace.Trace` object.\n    :param default_stats:\n        If True only compare the default stats on the traces, such as seed\n        identification codes, start/end times, sampling_rates, etc. If\n        False also compare extra stats attributes such as processing and\n        format specific information.\n    :param rtol: The relative tolerance parameter passed to\n        :func:`~numpy.allclose` for comparing time series.\n    :param atol: The absolute tolerance parameter passed to\n        :func:`~numpy.allclose` for comparing time series.\n    :param equal_nan:\n        If ``True`` NaNs are evaluated equal when comparing the time\n        series.\n    :return: bool\n    \"\"\"\n    from obspy.core.trace import Trace\n    if not isinstance(tr2, Trace) or len(tr1.data) != len(tr2.data):\n        return False\n    try:\n        all_close = np.allclose(tr1.data, tr2.data, rtol=rtol, atol=atol,\n            equal_nan=equal_nan)\n    except TypeError:\n        is_close = np.isclose(tr1.data, tr2.data, rtol=rtol, atol=atol)\n        if equal_nan:\n            isnan = np.isnan(tr1.data) & np.isnan(tr2.data)\n        else:\n            isnan = np.zeros(tr1.data.shape).astype(bool)\n        all_close = np.all(isnan | is_close)\n    stats1 = _make_stats_dict(tr1, default_stats)\n    stats2 = _make_stats_dict(tr2, default_stats)\n    return all_close and stats1 == stats2", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_identical_traces(self):\n\t    \"\"\"\n\t        Should return True on identical streams but false if a value is\n\t        greatly changed.\n\t        \"\"\"\n\t    tr1, tr2 = read()[0], read()[0]\n\t    assert traces_almost_equal(tr1, tr2)\n\t    tr1.data[0] = (tr1.data[0] + 1) * 1000\n\t    assert not traces_almost_equal(tr1, tr2)\n\t\nTestAlmostEqual().test_identical_traces()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_slightly_modified_data(self):\n\t    \"\"\"\n\t        Traces that are \"close\" should be considered almost equal.\n\t        \"\"\"\n\t    tr1, tr2 = read()[0], read()[0]\n\t    tr1.data *= 1.0 + 1e-06\n\t    assert traces_almost_equal(tr1, tr2)\n\t\nTestAlmostEqual().test_slightly_modified_data()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_empty_traces(self):\n\t    \"\"\"\n\t        Empty traces should be considered almost equal.\n\t        \"\"\"\n\t    tr1, tr2 = Trace(), Trace()\n\t    assert traces_almost_equal(tr1, tr2)\n\t\nTestAlmostEqual().test_empty_traces()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_different_stats_no_processing(self):\n\t    \"\"\"\n\t        If only the stats are different traces should not be considered almost\n\t        equal.\n\t        \"\"\"\n\t    tr1 = Trace(header=dict(network='UU', station='TMU', channel='HHZ'))\n\t    tr2 = Trace(header=dict(network='UU', station='TMU', channel='HHN'))\n\t    assert not traces_almost_equal(tr1, tr2)\n\t    assert not traces_almost_equal(tr2, tr1)\n\t\nTestAlmostEqual().test_different_stats_no_processing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_processing(self):\n\t    \"\"\"\n\t        Differences in processing attr of stats should only count if\n\t        processing is True.\n\t        \"\"\"\n\t    tr1, tr2 = read()[0], read()[0]\n\t    tr1.detrend()\n\t    tr2.detrend()\n\t    tr1.detrend()\n\t    assert traces_almost_equal(tr1, tr2, default_stats=True)\n\t    assert not traces_almost_equal(tr1, tr2, default_stats=False)\n\t\nTestAlmostEqual().test_processing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_nan(self):\n\t    \"\"\"\n\t        Ensure NaNs eval equal if equal_nan is used, else they do not.\n\t        \"\"\"\n\t    tr1, tr2 = read()[0], read()[0]\n\t    tr1.data[0], tr2.data[0] = np.nan, np.nan\n\t    assert traces_almost_equal(tr1, tr2, equal_nan=True)\n\t    assert not traces_almost_equal(tr1, tr2, equal_nan=False)\n\t\nTestAlmostEqual().test_nan()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_unequal_trace_lengths(self):\n\t    \"\"\"\n\t        Ensure traces with different lengths are not almost equal.\n\t        \"\"\"\n\t    tr1, tr2 = read()[0], read()[0]\n\t    tr2.data = tr2.data[:-1]\n\t    assert not traces_almost_equal(tr1, tr2)\n\t\nTestAlmostEqual().test_unequal_trace_lengths()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}, {"test_code": "import numpy as np\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.core.util.testing import traces_almost_equal\n\nclass TestAlmostEqual():\n\tdef test_not_a_trace(self):\n\t    \"\"\"\n\t        Ensure comparing to someething that is not a trace returns False.\n\t        \"\"\"\n\t    tr1 = read()[0]\n\t    assert not traces_almost_equal(tr1, 1)\n\t    assert not traces_almost_equal(tr1, None)\n\t    assert not traces_almost_equal(tr1, 'not a trace')\n\t\nTestAlmostEqual().test_not_a_trace()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_testing.py"}], "method_code_mask": "import difflib\nimport doctest\nimport inspect\nimport io\nimport os\nimport re\nimport numpy as np\nfrom lxml import etree\nimport obspy.core.event as ev\nfrom obspy import UTCDateTime\nfrom obspy import Catalog\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.trace import Stats\n\n\ndef traces_almost_equal(tr1, tr2, default_stats=True, rtol=1e-05, atol=\n    1e-08, equal_nan=True): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_get_default_eps", "method_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py", "response": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\ndef _get_default_eps(group, subgroup=None):\n    eps = _get_entry_points(group, subgroup=subgroup)\n    eps = {ep: f for ep, f in eps.items() if any(m in f.module_name for m in\n        DEFAULT_MODULES)}\n    return eps", "test_code_list": [{"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\tdef test_raise_on_empty_file(self):\n\t    \"\"\"\n\t        Test case ensures that empty files do raise warnings.\n\t        \"\"\"\n\t    with NamedTemporaryFile() as tf:\n\t        tmpfile = tf.name\n\t        open(tmpfile, 'wb').close()\n\t        formats_ep = _get_default_eps('obspy.plugin.waveform', 'readFormat')\n\t        for ep in formats_ep.values():\n\t            is_format = buffered_load_entry_point(ep.dist.key, \n\t                'obspy.plugin.waveform.' + ep.name, 'isFormat')\n\t            assert not False, is_format(tmpfile)\n\t\nTestWaveformPlugins().test_raise_on_empty_file()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}, {"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\tdef test_read_and_write(self):\n\t    \"\"\"\n\t        Tests read and write methods for all waveform plug-ins.\n\t        \"\"\"\n\t    np.random.seed(1234)\n\t    data = np.random.randint(-500, 500, 2000)\n\t    formats = _get_default_eps('obspy.plugin.waveform', 'writeFormat')\n\t    for format in formats:\n\t        start = UTCDateTime(2009, 1, 13, 12, 1, 2, 999000)\n\t        if format in ['SEGY', 'SU', 'SEG2']:\n\t            continue\n\t        elif format in ['GCF']:\n\t            start = UTCDateTime(2009, 1, 13, 12, 1, 3)\n\t        for native_byteorder in ['<', '>']:\n\t            for byteorder in (['<', '>', '='] if format in\n\t                WAVEFORM_ACCEPT_BYTEORDER else [None]):\n\t                if format == 'SAC' and byteorder == '=':\n\t                    continue\n\t                dt = np.dtype(np.int_).newbyteorder(native_byteorder)\n\t                if format in ('MSEED', 'GSE2'):\n\t                    dt = np.int32\n\t                tr = Trace(data=data.astype(dt))\n\t                tr.stats.network = 'BW'\n\t                tr.stats.station = 'MANZ1'\n\t                tr.stats.location = '00'\n\t                tr.stats.channel = 'EHE'\n\t                tr.stats.calib = 0.199999\n\t                tr.stats.delta = 0.25\n\t                tr.stats.starttime = start\n\t                with NamedTemporaryFile() as tf:\n\t                    outfile = tf.name\n\t                    if byteorder is None:\n\t                        tr.write(outfile, format=format)\n\t                    else:\n\t                        tr.write(outfile, format=format, byteorder=byteorder)\n\t                    if format == 'Q':\n\t                        outfile += '.QHD'\n\t                    st = read(outfile)\n\t                    assert len(st) == 1\n\t                    assert st[0].stats._format == format\n\t                    st = read(outfile, format=format)\n\t                    assert len(st) == 1\n\t                    assert st[0].stats._format == format\n\t                    if format not in ['Q']:\n\t                        with open(outfile, 'rb') as fp:\n\t                            st = read(fp)\n\t                        assert len(st) == 1\n\t                        assert st[0].stats._format == format\n\t                        with open(outfile, 'rb') as fp:\n\t                            st = read(fp, format=format)\n\t                        assert len(st) == 1\n\t                        assert st[0].stats._format == format\n\t                        with open(outfile, 'rb') as fp:\n\t                            temp = io.BytesIO(fp.read())\n\t                        st = read(temp)\n\t                        assert len(st) == 1\n\t                        assert st[0].stats._format == format\n\t                        with open(outfile, 'rb') as fp:\n\t                            temp = io.BytesIO(fp.read())\n\t                        st = read(temp, format=format)\n\t                        assert len(st) == 1\n\t                        assert st[0].stats._format == format\n\t                        for autodetect in (format, None):\n\t                            temp.seek(0)\n\t                            temp2 = io.BytesIO()\n\t                            dummy_bytes = b'123456'\n\t                            temp2.write(dummy_bytes)\n\t                            temp2.write(temp.read())\n\t                            temp2.seek(len(dummy_bytes))\n\t                            st = read(outfile, format=autodetect)\n\t                            assert len(st) == 1\n\t                            assert st[0].stats._format == format\n\t                    if format == 'Q':\n\t                        os.remove(outfile[:-4] + '.QBN')\n\t                        os.remove(outfile[:-4] + '.QHD')\n\t                if format == 'SAC':\n\t                    assert st[0].data.dtype.byteorder in ('=', byteorder)\n\t                else:\n\t                    assert st[0].data.dtype.byteorder == '='\n\t                if format not in ['MSEED', 'WAV', 'TSPAIR', 'SLIST', 'AH',\n\t                    'GCF']:\n\t                    assert round(abs(st[0].stats.calib - 0.199999), 5) == 0\n\t                else:\n\t                    assert st[0].stats.calib == 1.0\n\t                if format not in ['WAV']:\n\t                    assert st[0].stats.starttime == start\n\t                    assert st[0].stats.delta == 0.25\n\t                    assert st[0].stats.endtime == start + 499.75\n\t                    assert st[0].stats.sampling_rate == 4.0\n\t                if format in ['GCF']:\n\t                    assert st[0].id == '.MANZ..HHE'\n\t                elif format in ['Q', 'SH_ASC', 'AH']:\n\t                    assert st[0].id == '.MANZ1..EHE'\n\t                elif format == 'GSE2':\n\t                    assert st[0].id == 'BW.MANZ1..EHE'\n\t                elif format not in ['WAV']:\n\t                    assert st[0].id == 'BW.MANZ1.00.EHE'\n\t\nTestWaveformPlugins().test_read_and_write()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}, {"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\tdef test_read_thread_safe(self):\n\t    \"\"\"\n\t        Tests for race conditions. Reading n_threads (currently 30) times\n\t        the same waveform file in parallel and compare the results which must\n\t        be all the same.\n\t        \"\"\"\n\t    data = np.arange(0, 500)\n\t    formats = _get_default_eps('obspy.plugin.waveform', 'writeFormat')\n\t    for format in formats:\n\t        start = UTCDateTime(2009, 1, 13, 12, 1, 2, 999000)\n\t        if format in ['SEGY', 'SU', 'SEG2']:\n\t            continue\n\t        elif format in ['GCF']:\n\t            start = UTCDateTime(2009, 1, 13, 12, 1, 3)\n\t        dt = np.int_\n\t        if format in ('MSEED', 'GSE2'):\n\t            dt = np.int32\n\t        tr = Trace(data=data.astype(dt))\n\t        tr.stats.network = 'BW'\n\t        tr.stats.station = 'MANZ1'\n\t        tr.stats.location = '00'\n\t        tr.stats.channel = 'EHE'\n\t        tr.stats.calib = 0.999999\n\t        tr.stats.delta = 0.005\n\t        tr.stats.starttime = start\n\t        with NamedTemporaryFile() as tf:\n\t            outfile = tf.name\n\t            tr.write(outfile, format=format)\n\t            if format == 'Q':\n\t                outfile += '.QHD'\n\t            n_threads = 30\n\t            streams = []\n\t            timeout = 120\n\t            if 'TRAVIS' in os.environ:\n\t                timeout = 570\n\t            cond = threading.Condition()\n\t\n\t            def test_functions(streams, cond):\n\t                st = read(outfile, format=format)\n\t                streams.append(st)\n\t                with cond:\n\t                    cond.notify()\n\t            our_threads = []\n\t            for _i in range(n_threads):\n\t                thread = threading.Thread(target=test_functions, args=(\n\t                    streams, cond))\n\t                thread.start()\n\t                our_threads.append(thread)\n\t            our_threads = set(our_threads)\n\t            start = time.time()\n\t            while True:\n\t                with cond:\n\t                    cond.wait(1)\n\t                remaining_threads = set(threading.enumerate())\n\t                if len(remaining_threads & our_threads) == 0:\n\t                    break\n\t                elif time.time() - start >= timeout:\n\t                    msg = ('Not all threads finished after %d seconds!' %\n\t                        timeout)\n\t                    raise Warning(msg)\n\t            for st in streams:\n\t                np.testing.assert_array_equal(st[0].data, tr.data)\n\t            if format == 'Q':\n\t                os.remove(outfile[:-4] + '.QBN')\n\t                os.remove(outfile[:-4] + '.QHD')\n\t\nTestWaveformPlugins().test_read_thread_safe()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}, {"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\t@pytest.mark.filterwarnings('ignore:Detected non contiguous data array')\n\tdef test_issue_193(self):\n\t    \"\"\"\n\t        Test for issue #193: if non-contiguous array is written correctly.\n\t        \"\"\"\n\t    formats_write = set(_get_default_eps('obspy.plugin.waveform',\n\t        'writeFormat'))\n\t    formats_read = set(_get_default_eps('obspy.plugin.waveform', 'readFormat'))\n\t    formats = set.intersection(formats_write, formats_read)\n\t    data = np.arange(10, dtype=np.int32)\n\t    data = data[::2]\n\t    tr = Trace(data=data)\n\t    for format in formats:\n\t        if format in ['SEGY', 'SU', 'SEG2']:\n\t            continue\n\t        with NamedTemporaryFile() as tf:\n\t            tempfile = tf.name\n\t            tr.write(tempfile, format)\n\t            if format == 'Q':\n\t                tempfile = tempfile + '.QHD'\n\t            tr_test = read(tempfile, format)[0]\n\t            if format == 'Q':\n\t                os.remove(tempfile[:-4] + '.QBN')\n\t                os.remove(tempfile[:-4] + '.QHD')\n\t        np.testing.assert_array_equal(tr.data, tr_test.data)\n\t\nTestWaveformPlugins().test_issue_193()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}, {"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\tdef test_deepcopy(self):\n\t    \"\"\"\n\t        Test for issue #689: deepcopy did not work for segy. In order to\n\t        avoid complicated code to find test data for each waveform pluging,\n\t        which read OK and have no errors we simply test by first writing\n\t        the waveform and then reading it in. Thus test is limited to\n\t        formats which we can also write.\n\t        \"\"\"\n\t    formats_write = set(_get_default_eps('obspy.plugin.waveform',\n\t        'writeFormat'))\n\t    formats_read = set(_get_default_eps('obspy.plugin.waveform', 'readFormat'))\n\t    formats = set.intersection(formats_write, formats_read)\n\t    stream_orig = read()\n\t    for format in formats:\n\t        if format in ('SAC', 'SACXY', 'SEG2', 'Q', 'WAV'):\n\t            continue\n\t        stream = deepcopy(stream_orig)\n\t        dt = np.float32\n\t        if format in ('GSE2', 'MSEED'):\n\t            dt = np.int32\n\t        for tr in stream:\n\t            tr.data = np.arange(tr.stats.npts).astype(dt)\n\t        with NamedTemporaryFile() as tf:\n\t            tmpfile = tf.name\n\t            with warnings.catch_warnings():\n\t                warnings.simplefilter('ignore')\n\t                stream.write(format=format, filename=tmpfile)\n\t            st = read(tmpfile, format=format)\n\t        st.sort()\n\t        st_deepcopy = deepcopy(st)\n\t        st_deepcopy.sort()\n\t        msg = 'Error in wavform format=%s' % format\n\t        assert str(st) == str(st_deepcopy), msg\n\t\nTestWaveformPlugins().test_deepcopy()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}, {"test_code": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\nclass TestWaveformPlugins():\n\tdef test_auto_file_format_during_writing(self):\n\t    \"\"\"\n\t        The file format is either determined by directly specifying the\n\t        format or deduced from the filename. The former overwrites the latter.\n\t        \"\"\"\n\t    formats = [(key, value.module_name) for key, value in _get_default_eps(\n\t        'obspy.plugin.waveform', 'writeFormat').items() if value.dist.key ==\n\t        'obspy']\n\t    stream_trace = [read(), read()[0]]\n\t    mseed_name = 'obspy/obspy.plugin.waveform.MSEED/writeFormat'\n\t    mseed_func = _ENTRY_POINT_CACHE.get(mseed_name, _write_mseed)\n\t    for suffix, module_name in formats:\n\t        entry_point_list = ['obspy', 'obspy.plugin.waveform.%s' % suffix,\n\t            'writeFormat']\n\t        buffered_load_entry_point(*entry_point_list)\n\t        entry_point_name = '/'.join(entry_point_list)\n\t        for obj in stream_trace:\n\t            for s in [suffix.capitalize(), suffix.lower(), suffix.upper()]:\n\t                write_func = _ENTRY_POINT_CACHE[entry_point_name]\n\t                mocked_func = mock.MagicMock(write_func)\n\t                mock_dict = {entry_point_name: mocked_func}\n\t                with mock.patch.dict(_ENTRY_POINT_CACHE, mock_dict):\n\t                    obj.write('temp.' + s)\n\t                assert mocked_func.call_count == 1\n\t                mocked_mseed_func = mock.MagicMock(mseed_func)\n\t                mseed_mock_dict = {mseed_name: mocked_mseed_func}\n\t                with mock.patch.dict(_ENTRY_POINT_CACHE, mseed_mock_dict):\n\t                    obj.write('temp.' + s, format='mseed')\n\t                assert mocked_mseed_func.call_count == 1\n\t                assert mocked_func.call_count == 1\n\t    with pytest.raises(ValueError):\n\t        for obj in stream_trace:\n\t            obj.write('temp.random_suffix')\n\t\nTestWaveformPlugins().test_auto_file_format_during_writing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_waveform_plugins.py"}], "method_code_mask": "import io\nimport os\nimport threading\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Trace\nfrom obspy import read\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import DEFAULT_MODULES\nfrom obspy.core.util.base import WAVEFORM_ACCEPT_BYTEORDER\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\n\n\ndef _get_default_eps(group, subgroup=None): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "create_preview", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef create_preview(trace, delta=60):\n    \"\"\"\n    Creates a preview trace.\n\n    A preview trace consists of maximum minus minimum of all samples within\n    ``delta`` seconds. The parameter ``delta`` must be a multiple of the\n    sampling rate of the ``trace`` object.\n\n    :type delta: int, optional\n    :param delta: Difference between two preview points. Defaults to ``60``.\n    :rtype: :class:`~obspy.core.trace.Trace`\n    :return: New Trace object.\n\n    This method will modify the original Trace object. Create a copy of the\n    Trace object if you want to continue using the original data.\n    \"\"\"\n    if not isinstance(delta, int) or delta < 1:\n        msg = 'The delta values need to be an Integer and at least 1.'\n        raise TypeError(msg)\n    data = trace.data\n    start_time = trace.stats.starttime.timestamp\n    samples_per_slice = delta * int(trace.stats.sampling_rate)\n    if samples_per_slice < 1:\n        raise ValueError('samples_per_slice is less than 0 - skipping')\n    start = int((delta - start_time % delta) * int(trace.stats.sampling_rate))\n    start_time = start_time - start_time % delta\n    if start > delta / 2 and data[0:start].size:\n        first_diff = [data[0:start].max() - data[0:start].min()]\n    else:\n        first_diff = []\n        start_time += delta\n    number_of_slices = int((len(data) - start) / samples_per_slice)\n    end = samples_per_slice * number_of_slices + start\n    if end > delta / 2 and data[end:].size:\n        last_diff = [data[end:].max() - data[end:].min()]\n    else:\n        last_diff = []\n    if len(last_diff) and np.isnan(last_diff)[0]:\n        last_diff = -1\n    data = trace.data[start:end].reshape([number_of_slices, samples_per_slice])\n    diff = ptp(data, axis=1)\n    if isinstance(diff, np.ma.masked_array):\n        diff = np.ma.filled(diff, -1)\n    data = np.concatenate([first_diff, diff, last_diff])\n    data = np.require(data, dtype=np.float32)\n    tr = Trace(data=data, header=trace.stats)\n    tr.stats.delta = delta\n    tr.stats.npts = len(data)\n    tr.stats.starttime = UTCDateTime(start_time)\n    tr.stats.preview = True\n    return tr", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.preview import create_preview\nfrom obspy.core.preview import merge_previews\nfrom obspy.core.preview import resample_preview\nimport pytest\n\nclass TestUtil():\n\tdef test_create_preview(self):\n\t    \"\"\"\n\t        Test for creating preview.\n\t        \"\"\"\n\t    with pytest.raises(TypeError):\n\t        create_preview(Trace(data=np.arange(10)), 60.0)\n\t    with pytest.raises(TypeError):\n\t        create_preview(Trace(data=np.arange(10)), 0)\n\t    trace = Trace(data=np.array([0] * 28 + [0, 1] * 30 + [-1, 1] * 29))\n\t    trace.stats.starttime = UTCDateTime(32)\n\t    preview = create_preview(trace, delta=60)\n\t    assert preview.stats.starttime == UTCDateTime(60)\n\t    assert preview.stats.endtime == UTCDateTime(120)\n\t    assert preview.stats.delta == 60\n\t    np.testing.assert_array_equal(preview.data, np.array([1, 2]))\n\t    trace = Trace(data=np.arange(0, 30))\n\t    preview = create_preview(trace, delta=60)\n\t    assert preview.stats.starttime == UTCDateTime(0)\n\t    assert preview.stats.endtime == UTCDateTime(0)\n\t    assert preview.stats.delta == 60\n\t    np.testing.assert_array_equal(preview.data, np.array([29]))\n\t    trace = Trace(data=np.arange(0, 60))\n\t    preview = create_preview(trace, delta=60)\n\t    assert preview.stats.starttime == UTCDateTime(0)\n\t    assert preview.stats.endtime == UTCDateTime(0)\n\t    assert preview.stats.delta == 60\n\t    np.testing.assert_array_equal(preview.data, np.array([59]))\n\t    trace = Trace(data=np.arange(0, 90))\n\t    preview = create_preview(trace, delta=60)\n\t    assert preview.stats.starttime == UTCDateTime(0)\n\t    assert preview.stats.endtime == UTCDateTime(60)\n\t    assert preview.stats.delta == 60\n\t    np.testing.assert_array_equal(preview.data, np.array([59, 29]))\n\t\nTestUtil().test_create_preview()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_preview.py"}, {"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.preview import create_preview\nfrom obspy.core.preview import merge_previews\nfrom obspy.core.preview import resample_preview\nimport pytest\n\nclass TestUtil():\n\tdef test_create_preview_with_masked_arrays(self):\n\t    \"\"\"\n\t        Test for creating preview using masked arrays.\n\t        \"\"\"\n\t    trace = Trace(data=np.ma.ones(600))\n\t    preview = create_preview(trace, delta=60)\n\t    np.testing.assert_array_equal(preview.data, np.array(10 * [0]))\n\t    trace = Trace(data=np.ma.ones(600))\n\t    trace.data.mask = [False] * 600\n\t    trace.data.mask[200:400] = True\n\t    preview = create_preview(trace, delta=60)\n\t    np.testing.assert_array_equal(preview.data, np.array(4 * [0] + 2 * [-1] +\n\t        4 * [0]))\n\t\nTestUtil().test_create_preview_with_masked_arrays()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_preview.py"}], "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef create_preview(trace, delta=60): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "merge_previews", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef merge_previews(stream):\n    \"\"\"\n    Merges all preview traces in one Stream object. Does not change the\n    original stream because the data needs to be copied anyway.\n\n    :type stream: :class:`~obspy.core.stream.Stream`\n    :param stream: Stream object to be merged\n    :rtype: :class:`~obspy.core.stream.Stream`\n    :return: Merged Stream object.\n    \"\"\"\n    copied_traces = copy(stream.traces)\n    stream.sort()\n    traces = {}\n    dtypes = []\n    for trace in stream:\n        if trace.stats.npts == 0:\n            continue\n        if not hasattr(trace.stats, 'preview') or not trace.stats.preview:\n            msg = 'Trace\\n%s\\n is no preview file.' % str(trace)\n            raise Exception(msg)\n        traces.setdefault(trace.id, [])\n        traces[trace.id].append(trace)\n        dtypes.append(trace.data.dtype)\n    if len(traces) == 0:\n        return Stream()\n    new_stream = Stream()\n    for value in traces.values():\n        if len(value) == 1:\n            new_stream.append(value[0])\n            continue\n        sampling_rates = {tr.stats.sampling_rate for tr in value}\n        if len(sampling_rates) != 1:\n            msg = 'More than one sampling rate for traces with id %s.' % value[\n                0].id\n            raise Exception(msg)\n        delta = value[0].stats.delta\n        dtypes = {tr.data.dtype for tr in value}\n        if len(dtypes) > 1:\n            msg = 'Different dtypes for traces with id %s' % value[0].id\n            raise Exception(msg)\n        dtype = dtypes.pop()\n        min_starttime = min([tr.stats.starttime for tr in value])\n        max_endtime = max([tr.stats.endtime for tr in value])\n        samples = int(round((max_endtime - min_starttime) / delta)) + 1\n        data = np.empty(samples, dtype=dtype)\n        data[:] = -1\n        new_trace = Trace(data=data, header=value[0].stats)\n        for trace in value:\n            start_index = int((trace.stats.starttime - min_starttime) / delta)\n            end_index = start_index + len(trace.data)\n            data[start_index:end_index] = np.maximum(data[start_index:\n                end_index], trace.data)\n        new_trace.stats.npts = len(data)\n        new_stream.append(new_trace)\n    stream.traces = copied_traces\n    return new_stream", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.preview import create_preview\nfrom obspy.core.preview import merge_previews\nfrom obspy.core.preview import resample_preview\nimport pytest\n\nclass TestUtil():\n\tdef test_merge_previews(self):\n\t    \"\"\"\n\t        Tests the merging of Previews.\n\t        \"\"\"\n\t    st = Stream(traces=[Trace(data=np.empty(2)), Trace(data=np.empty(2))])\n\t    with pytest.raises(Exception):\n\t        merge_previews(st)\n\t    st = Stream()\n\t    stream_id = id(st)\n\t    st2 = merge_previews(st)\n\t    assert stream_id != id(st2)\n\t    assert len(st.traces) == 0\n\t    tr1 = Trace(data=np.empty(10))\n\t    tr1.stats.preview = True\n\t    tr1.stats.sampling_rate = 100\n\t    tr2 = Trace(data=np.empty(10))\n\t    tr2.stats.preview = True\n\t    st = Stream(traces=[tr1, tr2])\n\t    with pytest.raises(Exception):\n\t        merge_previews(st)\n\t    tr1 = Trace(data=np.empty(10, dtype=np.int32))\n\t    tr1.stats.preview = True\n\t    tr2 = Trace(data=np.empty(10, dtype=np.float64))\n\t    tr2.stats.preview = True\n\t    st = Stream(traces=[tr1, tr2])\n\t    with pytest.raises(Exception):\n\t        merge_previews(st)\n\t    tr1 = Trace(data=np.array([1, 2] * 100))\n\t    tr1.stats.preview = True\n\t    tr1.stats.starttime = UTCDateTime(500)\n\t    tr2 = Trace(data=np.array([3, 1] * 100))\n\t    tr2.stats.preview = True\n\t    tr2.stats.starttime = UTCDateTime(500)\n\t    st = Stream(traces=[tr1, tr2])\n\t    st2 = merge_previews(st)\n\t    assert len(st2.traces) == 1\n\t    assert st2[0].stats.starttime == UTCDateTime(500)\n\t    np.testing.assert_array_equal(st2[0].data, np.array([3, 2] * 100))\n\t    tr1 = Trace(data=np.array([1] * 10))\n\t    tr1.stats.preview = True\n\t    tr2 = Trace(data=np.array([2] * 9))\n\t    tr2.stats.starttime = tr2.stats.starttime + 20\n\t    tr2.stats.preview = True\n\t    st = Stream(traces=[tr1, tr2])\n\t    st2 = merge_previews(st)\n\t    assert len(st2.traces) == 1\n\t    assert st2[0].stats.starttime == tr1.stats.starttime\n\t    np.testing.assert_array_equal(st2[0].data, np.array([1] * 10 + [-1] * \n\t        10 + [2] * 9))\n\t\nTestUtil().test_merge_previews()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_preview.py"}, {"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.preview import create_preview\nfrom obspy.core.preview import merge_previews\nfrom obspy.core.preview import resample_preview\nimport pytest\n\nclass TestUtil():\n\tdef test_merge_previews_2(self):\n\t    \"\"\"\n\t        Test case for issue #84.\n\t        \"\"\"\n\t    tr1 = Trace(data=np.ones(2880))\n\t    tr1.stats.starttime = UTCDateTime('2010-01-01T00:00:00.670000Z')\n\t    tr1.stats.delta = 30.0\n\t    tr1.stats.preview = True\n\t    tr1.verify()\n\t    tr2 = Trace(data=np.ones(2881))\n\t    tr2.stats.starttime = UTCDateTime('2010-01-01T23:59:30.670000Z')\n\t    tr2.stats.delta = 30.0\n\t    tr2.stats.preview = True\n\t    tr2.verify()\n\t    st1 = Stream([tr1, tr2])\n\t    st1.verify()\n\t    st2 = merge_previews(st1)\n\t    st2.verify()\n\t    assert st2[0].stats.preview\n\t    assert st2[0].stats.starttime == tr1.stats.starttime\n\t    assert st2[0].stats.endtime == tr2.stats.endtime\n\t    assert st2[0].stats.npts == 5760\n\t    assert len(st2[0]) == 5760\n\t\nTestUtil().test_merge_previews_2()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_preview.py"}], "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef merge_previews(stream): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "resample_preview", "method_path": "../srcdata/Computation/obspy/obspy/core/preview.py", "response": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\ndef resample_preview(trace, samples, method='accurate'):\n    \"\"\"\n    Resamples a preview Trace to the chosen number of samples.\n\n    :type trace: :class:`~obspy.core.trace.Trace`\n    :param trace: Trace object to be resampled.\n    :type samples: int\n    :param samples: Desired number of samples.\n    :type method: str, optional\n    :param method: Resample method. Available are ``'fast'`` and\n        ``'accurate'``. Defaults to ``'accurate'``.\n\n    .. rubric:: Notes\n\n    This method will destroy the data in the original Trace object.\n    Deepcopy the Trace if you want to continue using the original data.\n\n    The fast method works by reshaping the data array to a\n    sample x int(npts/samples) matrix (npts are the number of samples in\n    the original trace) and taking the maximum of each row. Therefore\n    the last npts - int(npts/samples)*samples will be omitted. The worst\n    case scenario is resampling a 1999 samples array to 1000 samples. 999\n    samples, almost half the data will be omitted.\n\n    The accurate method has no such problems because it will move a window\n    over the whole array and take the maximum for each window. It loops\n    over each window and is up to 10 times slower than the fast method.\n    This of course is highly depended on the number of wished samples and\n    the original trace and usually the accurate method is still fast\n    enough.\n    \"\"\"\n    if not hasattr(trace.stats, 'preview') or not trace.stats.preview:\n        msg = 'Trace\\n%s\\n is no preview file.' % str(trace)\n        raise Exception(msg)\n    endtime = trace.stats.endtime\n    dtype = trace.data.dtype\n    npts = trace.stats.npts\n    if trace.stats.npts < samples:\n        msg = 'Can only downsample so far. Interpolation not yet implemented.'\n        raise NotImplementedError(msg)\n    elif trace.stats.npts == samples:\n        return 0\n    if method == 'fast':\n        data = trace.data[:int(npts / samples) * samples]\n        data = data.reshape(samples, len(data) // samples)\n        trace.data = data.max(axis=1)\n        trace.stats.delta = (endtime - trace.stats.starttime) / float(\n            samples - 1)\n        return npts - int(npts / samples) * samples\n    elif method == 'accurate':\n        new_data = np.empty(samples, dtype=dtype)\n        step = trace.stats.npts / float(samples)\n        for _i in range(samples):\n            new_data[_i] = trace.data[int(_i * step):int((_i + 1) * step)].max(\n                )\n        trace.data = new_data\n        trace.stats.delta = (endtime - trace.stats.starttime) / float(\n            samples - 1)\n        return npts - int(samples * step)\n    else:\n        raise NotImplementedError('Unknown method')", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.preview import create_preview\nfrom obspy.core.preview import merge_previews\nfrom obspy.core.preview import resample_preview\nimport pytest\n\nclass TestUtil():\n\tdef test_resample_previews(self):\n\t    \"\"\"\n\t        Test for resampling preview.\n\t        \"\"\"\n\t    tr = Trace(data=np.empty(100))\n\t    with pytest.raises(Exception):\n\t        resample_preview(tr, 5)\n\t    tr = Trace(data=np.empty(20))\n\t    tr.stats.preview = True\n\t    with pytest.raises(NotImplementedError):\n\t        resample_preview(tr, 100)\n\t    tr = Trace(data=np.array([1, 2, 3, 4] * 53 + [-1, 0, 1, 2] * 53))\n\t    endtime = tr.stats.endtime\n\t    tr.stats.preview = True\n\t    omitted_samples = resample_preview(tr, 100, method='fast')\n\t    assert tr.stats.endtime == endtime\n\t    assert tr.stats.npts == 100\n\t    assert omitted_samples == 24\n\t    np.testing.assert_array_equal(tr.data, np.array([4] * 53 + [2] * 47))\n\t    tr = Trace(data=np.array([1, 2, 3, 4] * 53 + [-1, 0, 1, 2] * 53))\n\t    endtime = tr.stats.endtime\n\t    tr.stats.preview = True\n\t    omitted_samples = resample_preview(tr, 100, method='accurate')\n\t    assert tr.stats.endtime == endtime\n\t    assert tr.stats.npts == 100\n\t    assert omitted_samples == 0\n\t    np.testing.assert_array_equal(tr.data, np.array([4] * 50 + [2] * 50))\n\t\nTestUtil().test_resample_previews()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_preview.py"}], "method_code_mask": "from copy import copy\nimport numpy as np\nfrom obspy.core.stream import Stream\nfrom obspy.core.trace import Trace\nfrom obspy.core.utcdatetime import UTCDateTime\n\n\ndef resample_preview(trace, samples, method='accurate'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "read_inventory", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/inventory.py", "response": "import copy\nimport fnmatch\nimport textwrap\nimport warnings\nimport obspy\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.base import _read_from_plugin\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nfrom obspy.imaging.maps import plot_map\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom obspy.core.inventory.response import _adjust_bode_plot_figure\nimport doctest\n@map_example_filename('path_or_file_object')\ndef read_inventory(path_or_file_object=None, format=None, level='response',\n    *args, **kwargs):\n    \"\"\"\n    Function to read inventory files.\n\n    :type path_or_file_object: str, pathlib.Path, or file-like object, optional\n    :param path_or_file_object: String containing a file name or a URL, a Path\n        object, or a open file-like object. Wildcards are allowed for a file\n        name. If this attribute is omitted, an example\n        :class:`~obspy.core.inventory.inventory.Inventory` object will be\n        returned.\n    :type format: str\n    :param format: Format of the file to read (e.g. ``\"STATIONXML\"``). See the\n        `Supported Formats`_ section below for a list of supported formats.\n    :type level: str\n    :param level: Level of detail to read from file. One of ``'response'``,\n        ``'channel'``, ``'station'`` or ``'network'``. Lower level of detail\n        can result in much shorter reading times for some file formats.\n    :rtype: :class:`~obspy.core.inventory.inventory.Inventory`\n    :return: An ObsPy :class:`~obspy.core.inventory.inventory.Inventory`\n        object.\n\n    Additional args and kwargs are passed on to the underlying ``_read_X()``\n    methods of the inventory plugins.\n\n    .. rubric:: _`Supported Formats`\n\n    Additional ObsPy modules extend the functionality of the\n    :func:`~obspy.core.inventory.inventory.read_inventory` function. The\n    following table summarizes all known file formats currently supported by\n    ObsPy.\n\n    Please refer to the `Linked Function Call`_ of each module for any extra\n    options available at the import stage.\n\n    %s\n\n    .. note::\n\n        For handling additional information not covered by the\n        StationXML standard and how to output it to StationXML\n        see the :ref:`ObsPy Tutorial <stationxml-extra>`.\n    \"\"\"\n    kwargs['level'] = level\n    if path_or_file_object is None:\n        return _create_example_inventory()\n    else:\n        return _generic_reader(path_or_file_object, _read, format=format,\n            **kwargs)", "test_code_list": [{"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_inventory_merging_metadata_update(self):\n\t    \"\"\"\n\t        Tests the metadata update during merging of inventory objects.\n\t        \"\"\"\n\t    inv_1 = read_inventory()\n\t    inv_2 = read_inventory()\n\t    inv_1 += inv_2\n\t    assert inv_1.source == inv_2.source\n\t    assert inv_1.sender == inv_2.sender\n\t    assert 'ObsPy' in inv_1.module\n\t    assert 'obspy.org' in inv_1.module_uri\n\t    assert UTCDateTime() - inv_1.created < 5\n\t    inv_1 = read_inventory()\n\t    inv_2 = read_inventory()\n\t    inv_1.source = 'B'\n\t    inv_2.source = 'A'\n\t    inv_1.sender = 'Random'\n\t    inv_2.sender = 'String'\n\t    inv_1 += inv_2\n\t    assert inv_1.source == 'A,B'\n\t    assert inv_1.sender == 'Random,String'\n\t    assert 'ObsPy' in inv_1.module\n\t    assert 'obspy.org' in inv_1.module_uri\n\t    assert UTCDateTime() - inv_1.created < 5\n\t    inv_1 = read_inventory()\n\t    inv_2 = read_inventory()\n\t    inv_1.source = None\n\t    inv_2.source = 'A'\n\t    inv_1.sender = 'Random'\n\t    inv_2.sender = None\n\t    inv_1 += inv_2\n\t    assert inv_1.source == 'A'\n\t    assert inv_1.sender == 'Random'\n\t    assert 'ObsPy' in inv_1.module\n\t    assert 'obspy.org' in inv_1.module_uri\n\t    assert UTCDateTime() - inv_1.created < 5\n\t\nTestInventory().test_inventory_merging_metadata_update()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_len(self):\n\t    \"\"\"\n\t        Tests the __len__ property.\n\t        \"\"\"\n\t    inv = read_inventory()\n\t    assert len(inv) == len(inv.networks)\n\t    assert len(inv) == 2\n\t\nTestInventory().test_len()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_inventory_remove(self):\n\t    \"\"\"\n\t        Test for the Inventory.remove() method.\n\t        \"\"\"\n\t    inv = read_inventory()\n\t    assert sum(len(sta) for net in inv for sta in net) == 30\n\t    inv_ = inv.remove()\n\t    assert len(inv_) == 0\n\t    for network in ['GR', 'G?', 'G*', '?R']:\n\t        inv_ = inv.remove(network=network)\n\t        assert len(inv_) == 1\n\t        assert inv_[0].code == 'BW'\n\t        assert len(inv_[0]) == 3\n\t        for sta in inv_[0]:\n\t            assert len(sta) == 3\n\t    for network in ['GR', 'G?', 'G*', '?R']:\n\t        for station in ['FUR', 'F*', 'F??', '*R']:\n\t            inv_ = inv.remove(network=network, station=station)\n\t            assert len(inv_) == 2\n\t            assert inv_[0].code == 'GR'\n\t            assert len(inv_[0]) == 1\n\t            for sta in inv_[0]:\n\t                assert len(sta) == 9\n\t                assert sta.code == 'WET'\n\t            assert inv_[1].code == 'BW'\n\t            assert len(inv_[1]) == 3\n\t            for sta in inv_[1]:\n\t                assert len(sta) == 3\n\t                assert sta.code == 'RJOB'\n\t    inv_ = inv.remove(channel='*Z')\n\t    assert len(inv_) == 2\n\t    assert inv_[0].code == 'GR'\n\t    assert len(inv_[0]) == 2\n\t    assert len(inv_[0][0]) == 8\n\t    assert len(inv_[0][1]) == 6\n\t    assert inv_[0][0].code == 'FUR'\n\t    assert inv_[0][1].code == 'WET'\n\t    assert inv_[1].code == 'BW'\n\t    assert len(inv_[1]) == 3\n\t    for sta in inv_[1]:\n\t        assert len(sta) == 2\n\t        assert sta.code == 'RJOB'\n\t    for net in inv_:\n\t        for sta in net:\n\t            for cha in sta:\n\t                assert cha.code[2] != 'Z'\n\t    inv_ = inv.remove(station='R*')\n\t    assert len(inv_) == 1\n\t    assert inv_[0].code == 'GR'\n\t    inv_ = inv.remove(station='R*', keep_empty=True)\n\t    assert len(inv_) == 2\n\t    assert inv_[0].code == 'GR'\n\t    assert inv_[1].code == 'BW'\n\t    assert len(inv_[1]) == 0\n\t    inv_ = inv.remove(channel='EH*')\n\t    assert len(inv_) == 1\n\t    assert inv_[0].code == 'GR'\n\t    inv_ = inv.remove(channel='EH*', keep_empty=True)\n\t    assert len(inv_) == 2\n\t    assert inv_[0].code == 'GR'\n\t    assert inv_[1].code == 'BW'\n\t    assert len(inv_[1]) == 3\n\t    for sta in inv_[1]:\n\t        assert sta.code == 'RJOB'\n\t        assert len(sta) == 0\n\t    for kwargs in [dict(network='AA'), dict(network='AA', station='FUR'),\n\t        dict(network='GR', station='ABCD'), dict(network='GR', channel='EHZ')]:\n\t        inv_ = inv.remove(**kwargs)\n\t        assert inv_ == inv\n\t\nTestInventory().test_inventory_remove()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_issue_2266(self):\n\t    \"\"\"\n\t        Ensure the remove method works for more than just channel level\n\t        inventories. See #2266.\n\t        \"\"\"\n\t    inv = read_inventory()\n\t    for net in inv:\n\t        for sta in net:\n\t            sta.channels = []\n\t    inv_net = copy.deepcopy(inv).remove(network='BW')\n\t    assert len(inv_net.networks) == 1\n\t    inv_sta = copy.deepcopy(inv).remove(station='RJOB')\n\t    assert len(inv_sta.networks) == 1\n\t    assert len(inv_sta.networks[0].stations) == 2\n\t    inv_sta = copy.deepcopy(inv).remove(station='RJOB', keep_empty=True)\n\t    assert len(inv_sta.networks) == 2\n\t\nTestInventory().test_issue_2266()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_inventory_select_with_empty_networks(self):\n\t    \"\"\"\n\t        Tests the behaviour of the Inventory.select() method with empty\n\t        Network objects.\n\t        \"\"\"\n\t    inv = read_inventory()\n\t    for net in inv:\n\t        net.stations = []\n\t    assert len(inv) == 2\n\t    assert sum(len(net) for net in inv) == 0\n\t    assert len(inv) == 2\n\t    assert len(inv.select(network='*')) == 2\n\t    assert len(inv.select(network='BW')) == 1\n\t    assert len(inv.select(network='G?')) == 1\n\t    assert len(inv.select(network='RR')) == 0\n\t\nTestInventory().test_inventory_select_with_empty_networks()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_inventory_can_be_initialized_with_no_arguments(self):\n\t    \"\"\"\n\t        Source and networks need not be specified.\n\t        \"\"\"\n\t    inv = Inventory()\n\t    assert inv.networks == []\n\t    assert inv.source == 'ObsPy %s' % obspy.__version__\n\t    with io.BytesIO() as buf:\n\t        inv.write(buf, format='stationxml')\n\t        buf.seek(0, 0)\n\t        inv2 = read_inventory(buf)\n\t    assert inv == inv2\n\t\nTestInventory().test_inventory_can_be_initialized_with_no_arguments()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_copy(self):\n\t    \"\"\"\n\t        Test for copying inventory.\n\t        \"\"\"\n\t    inv = read_inventory()\n\t    inv2 = inv.copy()\n\t    assert inv is not inv2\n\t    assert inv == inv2\n\t    original_latitude = inv2[0][0][0].latitude\n\t    inv2[0][0][0].latitude = original_latitude + 1\n\t    assert inv[0][0][0].latitude == original_latitude\n\t    assert inv2[0][0][0].latitude == original_latitude + 1\n\t    assert inv[0][0][0].latitude != inv2[0][0][0].latitude\n\t\nTestInventory().test_copy()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_add(self):\n\t    \"\"\"\n\t        Test shallow copies for inventory addition\n\t        \"\"\"\n\t    inv1 = read_inventory()\n\t    inv2 = read_inventory()\n\t    inv_sum = inv1 + inv2\n\t    assert {id(net) for net in inv_sum} == {id(net) for net in inv1} | {id(\n\t        net) for net in inv2}\n\t    ids1 = {id(net) for net in inv1}\n\t    inv1 += inv2\n\t    assert {id(net) for net in inv1} == ids1 | {id(net) for net in inv2}\n\t    net1 = Network('N1')\n\t    inv_sum = inv1 + net1\n\t    assert {id(net) for net in inv_sum} == {id(net) for net in inv1} | {id(\n\t        net1)}\n\t    net1 = Network('N1')\n\t    ids1 = {id(net) for net in inv1}\n\t    inv1 += net1\n\t    assert {id(net) for net in inv1} == ids1 | {id(net1)}\n\t\nTestInventory().test_add()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import warnings\nfrom copy import deepcopy\nfrom math import pi\nimport numpy as np\nimport pytest\nimport scipy.interpolate\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory.response import _pitick2latex\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import Response\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import InstrumentSensitivity\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.signal.invsim import evalresp\nfrom obspy.io.xseed import Parser\n\nclass TestResponse():\n\tdef test_recalculate_overall_sensitivity(self):\n\t    \"\"\"\n\t        Tests the recalculate_overall_sensitivity_method().\n\t\n\t        This is not yet an exhaustive test as responses are complicated...\n\t        \"\"\"\n\t    resp = read_inventory()[0][0][0].response\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.value, 943680000.0)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.frequency, 0.02)\n\t    resp.recalculate_overall_sensitivity(0.02)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.value, 943681500.0)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.frequency, 0.02)\n\t    resp = read_inventory()[0][0][0].response\n\t    resp.recalculate_overall_sensitivity()\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.value, \n\t        957562105.3939067)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.frequency, 1.0)\n\t    resp = read_inventory()[0][0][0].response\n\t    resp.recalculate_overall_sensitivity(1)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.value, \n\t        957562105.3939067)\n\t    np.testing.assert_allclose(resp.instrument_sensitivity.frequency, 1.0)\n\t\nTestResponse().test_recalculate_overall_sensitivity()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_response.py"}, {"test_code": "import math\nimport pickle\nimport warnings\nfrom copy import deepcopy\nfrom unittest import mock\nfrom packaging.version import parse as parse_version\nimport numpy as np\nimport numpy.ma as ma\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import __version__\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime as UTC\nfrom obspy.core import Stats\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.io.xseed import Parser\nimport pytest\nfrom matplotlib import __version__\n\nclass TestTrace():\n\tdef test_processing_info_remove_response_and_sensitivity(self):\n\t    \"\"\"\n\t        Tests adding processing info for remove_response() and\n\t        remove_sensitivity().\n\t\n\t        See #1247.\n\t        \"\"\"\n\t    tr = read()[0]\n\t    assert 'processing' not in tr.stats\n\t    tr.remove_sensitivity()\n\t    assert 'processing' in tr.stats\n\t    assert len(tr.stats.processing) == 1\n\t    assert tr.stats.processing[0].endswith('remove_sensitivity(inventory=None)'\n\t        )\n\t    tr = read()[0]\n\t    assert 'processing' not in tr.stats\n\t    tr.remove_sensitivity(inventory=read_inventory())\n\t    assert 'processing' in tr.stats\n\t    assert len(tr.stats.processing) == 1\n\t    assert 'remove_sensitivity(inventory=<obspy.core.inventory.inventory.Inventory object ' in tr.stats.processing[\n\t        0]\n\t    tr = read()[0]\n\t    assert 'processing' not in tr.stats\n\t    tr.remove_response()\n\t    assert 'processing' in tr.stats\n\t    assert len(tr.stats.processing) == 1\n\t    assert 'remove_response(' in tr.stats.processing[0]\n\t    assert 'inventory=None' in tr.stats.processing[0]\n\t    tr = read()[0]\n\t    assert 'processing' not in tr.stats\n\t    tr.remove_response(inventory=read_inventory())\n\t    assert 'processing' in tr.stats\n\t    assert len(tr.stats.processing) == 1\n\t    assert 'remove_response(' in tr.stats.processing[0]\n\t    assert 'inventory=<obspy.core.inventory.inventory.Inventory object' in tr.stats.processing[\n\t        0]\n\t\nTestTrace().test_processing_info_remove_response_and_sensitivity()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_trace.py"}, {"test_code": "import math\nimport pickle\nimport warnings\nfrom copy import deepcopy\nfrom unittest import mock\nfrom packaging.version import parse as parse_version\nimport numpy as np\nimport numpy.ma as ma\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import __version__\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime as UTC\nfrom obspy.core import Stats\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.io.xseed import Parser\nimport pytest\nfrom matplotlib import __version__\n\nclass TestTrace():\n\tdef test_remove_response_default_units(self):\n\t    \"\"\"\n\t        Tests remove_response() with default units for a hydrophone.\n\t        \"\"\"\n\t    tr = read('/path/to/1T_MONN_00_EDH.mseed')[0]\n\t    inv = read_inventory('/path/to/1T_MONN_00_EDH.xml')\n\t    tr.attach_response(inv)\n\t    tr.remove_response(output='DEF')\n\t    np.testing.assert_almost_equal(tr.max(), 54.833, decimal=3)\n\t\nTestTrace().test_remove_response_default_units()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_trace.py"}, {"test_code": "import math\nimport pickle\nimport warnings\nfrom copy import deepcopy\nfrom unittest import mock\nfrom packaging.version import parse as parse_version\nimport numpy as np\nimport numpy.ma as ma\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import __version__\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime as UTC\nfrom obspy.core import Stats\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.io.xseed import Parser\nimport pytest\nfrom matplotlib import __version__\n\nclass TestTrace():\n\tdef test_dtype_is_not_unnecessarily_changed(self):\n\t    \"\"\"\n\t        The dtype of the data should not change if not necessary. In general\n\t        this means that a float32 array should not become a float64 array\n\t        and vice-versa. Integer arrays will always be upcasted to float64\n\t        arrays when integer output makes no sense. Not all int32 numbers can be\n\t        accurately represented by float32 arrays so double precision is\n\t        required in order to not lose accuracy.\n\t\n\t        Exceptions are custom coded C routines where we usually opt to only\n\t        include either a single or a double precision version.\n\t        \"\"\"\n\t    tr = read()[0]\n\t    tr.data = tr.data[:100]\n\t    tr_int32 = tr.copy()\n\t    tr_int32.data = np.require(tr_int32.data, dtype=np.int32)\n\t    tr_int64 = tr.copy()\n\t    tr_int64.data = np.require(tr_int64.data, dtype=np.int64)\n\t    tr_float32 = tr.copy()\n\t    tr_float32.data = np.require(tr_float32.data, dtype=np.float32)\n\t    tr_float64 = tr.copy()\n\t    tr_float64.data = np.require(tr_float64.data, dtype=np.float64)\n\t    assert tr_int32.copy().trim(1, 2).data.dtype == np.int32\n\t    assert tr_int64.copy().trim(1, 2).data.dtype == np.int64\n\t    assert tr_float32.copy().trim(1, 2).data.dtype == np.float32\n\t    assert tr_float64.copy().trim(1, 2).data.dtype == np.float64\n\t    lowpass = tr_int32.copy().filter('lowpass', freq=2.0)\n\t    assert lowpass.data.dtype == np.float64\n\t    lowpass = tr_int64.copy().filter('lowpass', freq=2.0)\n\t    assert lowpass.data.dtype == np.float64\n\t    lowpass = tr_float32.copy().filter('lowpass', freq=2.0)\n\t    assert lowpass.data.dtype == np.float64\n\t    lowpass = tr_float64.copy().filter('lowpass', freq=2.0)\n\t    assert lowpass.data.dtype == np.float64\n\t    decimate = tr_int32.copy().decimate(factor=2, no_filter=True)\n\t    assert decimate.data.dtype == np.int32\n\t    decimate = tr_int64.copy().decimate(factor=2, no_filter=True)\n\t    assert decimate.data.dtype == np.int64\n\t    decimate = tr_float32.copy().decimate(factor=2, no_filter=True)\n\t    assert decimate.data.dtype == np.float32\n\t    decimate = tr_float64.copy().decimate(factor=2, no_filter=True)\n\t    assert decimate.data.dtype == np.float64\n\t    assert tr_int32.copy().detrend('simple').data.dtype == np.float64\n\t    assert tr_int64.copy().detrend('simple').data.dtype == np.float64\n\t    assert tr_float32.copy().detrend('simple').data.dtype == np.float32\n\t    assert tr_float64.copy().detrend('simple').data.dtype == np.float64\n\t    assert tr_int32.copy().detrend('linear').data.dtype == np.float64\n\t    assert tr_int64.copy().detrend('linear').data.dtype == np.float64\n\t    assert tr_float32.copy().detrend('linear').data.dtype == np.float32\n\t    assert tr_float64.copy().detrend('linear').data.dtype == np.float64\n\t    assert tr_int32.copy().detrend('constant').data.dtype == np.float64\n\t    assert tr_int64.copy().detrend('constant').data.dtype == np.float64\n\t    assert tr_float32.copy().detrend('constant').data.dtype == np.float32\n\t    assert tr_float64.copy().detrend('constant').data.dtype == np.float64\n\t    detrend = tr_int32.copy().detrend('polynomial', order=3)\n\t    assert detrend.data.dtype == np.float64\n\t    detrend = tr_int64.copy().detrend('polynomial', order=3)\n\t    assert detrend.data.dtype == np.float64\n\t    detrend = tr_float32.copy().detrend('polynomial', order=3)\n\t    assert detrend.data.dtype == np.float32\n\t    detrend = tr_float64.copy().detrend('polynomial', order=3)\n\t    assert detrend.data.dtype == np.float64\n\t    detrend = tr_int32.copy().detrend('spline', order=3, dspline=100)\n\t    assert detrend.data.dtype == np.float64\n\t    detrend = tr_int64.copy().detrend('spline', order=3, dspline=100)\n\t    assert detrend.data.dtype == np.float64\n\t    detrend = tr_float32.copy().detrend('spline', order=3, dspline=100)\n\t    assert detrend.data.dtype == np.float32\n\t    detrend = tr_float64.copy().detrend('spline', order=3, dspline=100)\n\t    assert detrend.data.dtype == np.float64\n\t    assert tr_int32.copy().taper(0.05, 'hann').data.dtype == np.float64\n\t    assert tr_int64.copy().taper(0.05, 'hann').data.dtype == np.float64\n\t    assert tr_float32.copy().taper(0.05, 'hann').data.dtype == np.float32\n\t    assert tr_float64.copy().taper(0.05, 'hann').data.dtype == np.float64\n\t    assert tr_int32.copy().normalize().data.dtype == np.float64\n\t    assert tr_int64.copy().normalize().data.dtype == np.float64\n\t    assert tr_float32.copy().normalize().data.dtype == np.float32\n\t    assert tr_float64.copy().normalize().data.dtype == np.float64\n\t    assert tr_int32.copy().differentiate().data.dtype == np.float64\n\t    assert tr_int64.copy().differentiate().data.dtype == np.float64\n\t    assert tr_float32.copy().differentiate().data.dtype == np.float32\n\t    assert tr_float64.copy().differentiate().data.dtype == np.float64\n\t    integrate = tr_int32.copy().integrate(method='cumtrapz')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_int64.copy().integrate(method='cumtrapz')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_float32.copy().integrate(method='cumtrapz')\n\t    assert integrate.data.dtype == np.float32\n\t    integrate = tr_float64.copy().integrate(method='cumtrapz')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_int32.copy().integrate(method='spline')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_int64.copy().integrate(method='spline')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_float32.copy().integrate(method='spline')\n\t    assert integrate.data.dtype == np.float64\n\t    integrate = tr_float64.copy().integrate(method='spline')\n\t    assert integrate.data.dtype == np.float64\n\t    paz_remove = {'poles': [-0.037004 + 0.037016j, -0.037004 - 0.037016j, -\n\t        251.33 + 0.0j], 'zeros': [0.0j, 0.0j], 'gain': 60077000.0,\n\t        'sensitivity': 2516778400.0}\n\t    sim = tr_int32.copy().simulate(paz_remove=paz_remove)\n\t    assert sim.data.dtype == np.float64\n\t    sim = tr_int64.copy().simulate(paz_remove=paz_remove)\n\t    assert sim.data.dtype == np.float64\n\t    sim = tr_float32.copy().simulate(paz_remove=paz_remove)\n\t    assert sim.data.dtype == np.float64\n\t    sim = tr_float64.copy().simulate(paz_remove=paz_remove)\n\t    assert sim.data.dtype == np.float64\n\t    assert tr_int32.copy().resample(2.0).data.dtype == np.float64\n\t    assert tr_int64.copy().resample(2.0).data.dtype == np.float64\n\t    assert tr_float32.copy().resample(2.0).data.dtype == np.float64\n\t    assert tr_float64.copy().resample(2.0).data.dtype == np.float64\n\t    inv = read_inventory()\n\t    dtype = tr_int32.copy().remove_response(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_int64.copy().remove_response(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_float32.copy().remove_response(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_float64.copy().remove_response(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_int32.copy().remove_sensitivity(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_int64.copy().remove_sensitivity(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    dtype = tr_float32.copy().remove_sensitivity(inventory=inv).data.dtype\n\t    assert dtype == np.float32\n\t    dtype = tr_float64.copy().remove_sensitivity(inventory=inv).data.dtype\n\t    assert dtype == np.float64\n\t    assert tr_int32.copy().interpolate(1.0, method='weighted_average_slopes'\n\t        ).data.dtype == np.float64\n\t    assert tr_int64.copy().interpolate(1.0, method='weighted_average_slopes'\n\t        ).data.dtype == np.float64\n\t    assert tr_float32.copy().interpolate(1.0, method='weighted_average_slopes'\n\t        ).data.dtype == np.float64\n\t    assert tr_float64.copy().interpolate(1.0, method='weighted_average_slopes'\n\t        ).data.dtype == np.float64\n\t    assert tr_int32.copy().interpolate(1.0, method='slinear'\n\t        ).data.dtype == np.float64\n\t    assert tr_int64.copy().interpolate(1.0, method='slinear'\n\t        ).data.dtype == np.float64\n\t    assert tr_float32.copy().interpolate(1.0, method='slinear'\n\t        ).data.dtype == np.float64\n\t    assert tr_float64.copy().interpolate(1.0, method='slinear'\n\t        ).data.dtype == np.float64\n\t    assert tr_int32.copy().interpolate(1.0, method='lanczos', a=2\n\t        ).data.dtype == np.float64\n\t    assert tr_int64.copy().interpolate(1.0, method='lanczos', a=2\n\t        ).data.dtype == np.float64\n\t    assert tr_float32.copy().interpolate(1.0, method='lanczos', a=2\n\t        ).data.dtype == np.float64\n\t    assert tr_float64.copy().interpolate(1.0, method='lanczos', a=2\n\t        ).data.dtype == np.float64\n\t\nTestTrace().test_dtype_is_not_unnecessarily_changed()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_trace.py"}, {"test_code": "import io\nimport warnings\nfrom unittest import mock\nimport numpy as np\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import CatchAndAssertWarnings\nimport matplotlib.pyplot as plt\n\nclass TestNetwork():\n\tdef test_len(self):\n\t    \"\"\"\n\t        Tests the __len__ property.\n\t        \"\"\"\n\t    net = read_inventory()[0]\n\t    assert len(net) == len(net.stations)\n\t    assert len(net) == 2\n\t\nTestNetwork().test_len()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_network.py"}, {"test_code": "import io\nimport warnings\nfrom unittest import mock\nimport numpy as np\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import CatchAndAssertWarnings\nimport matplotlib.pyplot as plt\n\nclass TestNetwork():\n\tdef test_network_select(self):\n\t    \"\"\"\n\t        Test for the select() method of the network class.\n\t        \"\"\"\n\t    net = read_inventory()[0]\n\t    assert len(net) == 2\n\t    assert len(net[0]) == 12\n\t    assert len(net[1]) == 9\n\t    assert sum(len(i) for i in net) == 21\n\t    net[0].start_date = UTCDateTime(1999, 1, 1)\n\t    assert sum(len(i) for i in net.select()) == 21\n\t    assert sum(len(i) for i in net.select(station='*')) == 21\n\t    assert sum(len(i) for i in net.select(location='*')) == 21\n\t    assert sum(len(i) for i in net.select(channel='*')) == 21\n\t    subsum = sum(len(i) for i in net.select(station='*', location='*',\n\t        channel='*'))\n\t    assert subsum == 21\n\t    assert sum(len(i) for i in net.select(station='RR')) == 0\n\t    sub = sum(len(i) for i in net.select(station='RR', keep_empty=True))\n\t    assert sub == 0\n\t    sub = sum(len(i) for i in net.select(station='FUR', keep_empty=True))\n\t    assert sub == 12\n\t    sub = sum(len(i) for i in net.select(station='F*', keep_empty=True))\n\t    assert sub == 12\n\t    sub = sum(len(i) for i in net.select(station='WET', keep_empty=True))\n\t    assert sub == 9\n\t    kwargs = dict(minlatitude=47.89, maxlatitude=48.39, minlongitude=10.88,\n\t        maxlongitude=11.98)\n\t    sub = sum(len(i) for i in net.select(**kwargs))\n\t    assert sub == 12\n\t    sub = sum(len(i) for i in net.select(latitude=48.12, longitude=12.24,\n\t        maxradius=1))\n\t    assert sub == 12\n\t    net_2 = net.select(time=UTCDateTime(2000, 1, 1))\n\t    assert len(net_2) == 0\n\t    assert sum(len(i) for i in net_2) == 0\n\t    net_2 = net.select(time=UTCDateTime(2000, 1, 1), keep_empty=True)\n\t    assert len(net_2) == 1\n\t    assert sum(len(i) for i in net_2) == 0\n\t    select_kwargs = {'location': '00', 'channel': 'EHE', 'time':\n\t        UTCDateTime(2001, 1, 1), 'sampling_rate': 123.0, 'starttime':\n\t        UTCDateTime(2002, 1, 1), 'endtime': UTCDateTime(2003, 1, 1),\n\t        'minlatitude': None, 'maxlatitude': None, 'minlongitude': None,\n\t        'maxlongitude': None, 'latitude': None, 'longitude': None,\n\t        'minradius': None, 'maxradius': None}\n\t    with mock.patch('obspy.core.inventory.station.Station.select') as p:\n\t        p.return_value = obspy.core.inventory.station.Station('FUR', 1, 2, 3)\n\t        net.select(**select_kwargs)\n\t    assert p.call_args[1] == select_kwargs\n\t\nTestNetwork().test_network_select()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_network.py"}, {"test_code": "import io\nimport warnings\nfrom unittest import mock\nimport numpy as np\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import CatchAndAssertWarnings\nimport matplotlib.pyplot as plt\n\nclass TestNetwork():\n\tdef test_writing_network_before_1990(self):\n\t    inv = obspy.Inventory(networks=[Network(code='XX', start_date=obspy.\n\t        UTCDateTime(1880, 1, 1))], source='')\n\t    with io.BytesIO() as buf:\n\t        inv.write(buf, format='stationxml')\n\t        buf.seek(0, 0)\n\t        inv2 = read_inventory(buf)\n\t    assert inv.networks[0] == inv2.networks[0]\n\t\nTestNetwork().test_writing_network_before_1990()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_network.py"}, {"test_code": "import io\nimport warnings\nfrom unittest import mock\nimport numpy as np\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import CatchAndAssertWarnings\nimport matplotlib.pyplot as plt\n\nclass TestNetwork():\n\tdef test_network_select_with_empty_stations(self):\n\t    \"\"\"\n\t        Tests the behaviour of the Network.select() method for empty stations.\n\t        \"\"\"\n\t    net = read_inventory()[0]\n\t    for sta in net:\n\t        sta.channels = []\n\t    assert len(net) == 2\n\t    assert sum(len(sta) for sta in net) == 0\n\t    assert len(net.select()) == 2\n\t    assert len(net.select(station='*')) == 2\n\t    assert len(net.select(station='FUR')) == 1\n\t    assert len(net.select(station='FU?')) == 1\n\t    assert len(net.select(station='W?T')) == 1\n\t    assert len(net.select(time=UTCDateTime(2006, 1, 1))) == 0\n\t    assert len(net.select(time=UTCDateTime(2007, 1, 1))) == 1\n\t    assert len(net.select(time=UTCDateTime(2008, 1, 1))) == 2\n\t\nTestNetwork().test_network_select_with_empty_stations()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_network.py"}, {"test_code": "import io\nimport warnings\nfrom unittest import mock\nimport numpy as np\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import CatchAndAssertWarnings\nimport matplotlib.pyplot as plt\n\nclass TestNetwork():\n\tdef test_empty_network_code(self):\n\t    \"\"\"\n\t        Tests that an empty sring is acceptabble.\n\t        \"\"\"\n\t    n = Network(code='')\n\t    assert n.code == ''\n\t    with pytest.raises(ValueError, match='A code is required'):\n\t        Network(code=None)\n\t    inv = Inventory(networks=[n])\n\t    with io.BytesIO() as buf:\n\t        inv.write(buf, format='stationxml', validate=True)\n\t        buf.seek(0, 0)\n\t        inv2 = read_inventory(buf)\n\t    assert inv == inv2\n\t\nTestNetwork().test_empty_network_code()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_network.py"}, {"test_code": "import pytest\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime\nfrom obspy.core.inventory import Station\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestStation():\n\tdef test_len(self):\n\t    \"\"\"\n\t        Tests the __len__ property.\n\t        \"\"\"\n\t    sta = read_inventory()[0][0]\n\t    assert len(sta) == len(sta.channels)\n\t    assert len(sta) == 12\n\t\nTestStation().test_len()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_station.py"}, {"test_code": "import pytest\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime\nfrom obspy.core.inventory import Station\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestStation():\n\tdef test_station_select(self):\n\t    \"\"\"\n\t        Tests the select() method on station objects.\n\t        \"\"\"\n\t    sta = read_inventory()[0][0]\n\t    assert len(sta) == 12\n\t    assert sta.code == 'FUR'\n\t    out = sorted([('%s.%s' % (_i.location_code, _i.code)) for _i in sta])\n\t    expected = ['.BHE', '.BHN', '.BHZ', '.HHE', '.HHN', '.HHZ', '.LHE',\n\t        '.LHN', '.LHZ', '.VHE', '.VHN', '.VHZ']\n\t    assert out == expected\n\t    assert sta[0].code == 'HHZ'\n\t    sta[0].end_date = UTCDateTime(2010, 1, 1)\n\t    sta_2 = sta.select()\n\t    assert len(sta_2) == 12\n\t    assert sta_2.code == 'FUR'\n\t    sta_2 = sta.select(channel='*Z')\n\t    assert len(sta_2) == 4\n\t    assert sta_2.code == 'FUR'\n\t    out = sorted([('%s.%s' % (_i.location_code, _i.code)) for _i in sta_2])\n\t    assert out == ['.BHZ', '.HHZ', '.LHZ', '.VHZ']\n\t    sta_2 = sta.select(channel='BH?')\n\t    assert len(sta_2) == 3\n\t    assert sta_2.code == 'FUR'\n\t    out = sorted([('%s.%s' % (_i.location_code, _i.code)) for _i in sta_2])\n\t    assert out == ['.BHE', '.BHN', '.BHZ']\n\t    sta_2 = sta.select(location='*')\n\t    assert len(sta_2) == 12\n\t    assert sta_2.code == 'FUR'\n\t    sta_2 = sta.select(location='')\n\t    assert len(sta_2) == 12\n\t    assert sta_2.code == 'FUR'\n\t    sta_2 = sta.select(location='10')\n\t    assert len(sta_2) == 0\n\t    assert sta_2.code == 'FUR'\n\t    assert len(sta.select(time=UTCDateTime(2005, 1, 1))) == 0\n\t    assert len(sta.select(time=UTCDateTime(2007, 1, 1))) == 12\n\t    assert len(sta.select(time=UTCDateTime(2006, 12, 15))) == 0\n\t    assert len(sta.select(time=UTCDateTime(2006, 12, 17))) == 12\n\t    assert len(sta.select(time=UTCDateTime(2012, 1, 1))) == 11\n\t    assert len(sta.select(starttime=UTCDateTime(2005, 1, 1))) == 12\n\t    assert len(sta.select(starttime=UTCDateTime(2009, 1, 1))) == 12\n\t    assert len(sta.select(starttime=UTCDateTime(2011, 1, 1))) == 11\n\t    assert len(sta.select(starttime=UTCDateTime(2016, 1, 1))) == 11\n\t    assert len(sta.select(endtime=UTCDateTime(2005, 1, 1))) == 0\n\t    assert len(sta.select(endtime=UTCDateTime(2009, 1, 1))) == 12\n\t    assert len(sta.select(endtime=UTCDateTime(2011, 1, 1))) == 12\n\t    assert len(sta.select(endtime=UTCDateTime(2016, 1, 1))) == 12\n\t    assert len(sta.select(sampling_rate=33.0)) == 0\n\t    assert len(sta.select(sampling_rate=100.0)) == 3\n\t    assert len(sta.select(sampling_rate=20.0)) == 3\n\t    assert len(sta.select(sampling_rate=1.0)) == 3\n\t    assert len(sta.select(sampling_rate=0.1)) == 3\n\t    out = sorted([('%s.%s' % (_i.location_code, _i.code)) for _i in sta.\n\t        select(sampling_rate=100.0)])\n\t    assert out == ['.HHE', '.HHN', '.HHZ']\n\t    assert len(sta.select(sampling_rate=33.0 + 1e-06)) == 0\n\t    assert len(sta.select(sampling_rate=100.0 + 1e-06)) == 3\n\t    assert len(sta.select(sampling_rate=20.0 - 1e-06)) == 3\n\t    assert len(sta.select(sampling_rate=1.0 + 1e-06)) == 3\n\t    assert len(sta.select(sampling_rate=0.1 - 1e-06)) == 3\n\t    sta = read_inventory()[1][0]\n\t    sta[0].latitude = 47.9\n\t    sta[0].longitude = 12.9\n\t    out = sta.select(minlatitude=47.8, maxlatitude=48, minlongitude=12.8,\n\t        maxlongitude=13)\n\t    assert len(out) == 1\n\t    assert len(sta.select(latitude=47.95, longitude=12.95, maxradius=0.1)) == 1\n\t    assert len(sta.select(latitude=47.95, longitude=12.95, minradius=0.1)) == 2\n\t    assert len(sta.select(latitude=47.95, longitude=12.95, minradius=0.08,\n\t        maxradius=0.1)) == 0\n\t\nTestStation().test_station_select()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_station.py"}, {"test_code": "import io\nimport pickle\nimport platform\nimport re\nimport warnings\nfrom copy import deepcopy\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Station\nfrom obspy.core.stream import _is_pickle\nfrom obspy.core.stream import _read_pickle\nfrom obspy.core.stream import _write_pickle\nfrom obspy.core.util.attribdict import AttribDict\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.testing import streams_almost_equal\nfrom obspy.io.xseed import Parser\n\nclass TestStream():\n\tdef test_rotate_to_zne(self):\n\t    \"\"\"\n\t        Tests rotating all traces in stream to ZNE given an inventory object.\n\t        \"\"\"\n\t    inv = read_inventory('/path/to/ffbx.stationxml', format='STATIONXML')\n\t    parser = Parser('/path/to/ffbx.dataless')\n\t    st_expected = read('/path/to/ffbx_rotated.slist', format='SLIST')\n\t    st_unrotated = read('/path/to/ffbx_unrotated_gaps.mseed', format='MSEED')\n\t    for tr in st_expected:\n\t        tr.stats.pop('ascii')\n\t        tr.stats.pop('_format')\n\t    for metadata in (inv, parser):\n\t        st = st_unrotated.copy()\n\t        st.rotate('->ZNE', inventory=metadata)\n\t        assert len(st) == 30\n\t        st.sort()\n\t        st_expected.sort()\n\t        for tr_got, tr_expected in zip(st, st_expected):\n\t            np.testing.assert_allclose(tr_got.data, tr_expected.data, rtol=\n\t                1e-07)\n\t        for tr_expected, tr_got in zip(st_expected, st):\n\t            tr_got.stats.pop('mseed')\n\t            tr_got.stats.pop('_format')\n\t            tr_got.stats.pop('processing')\n\t            assert tr_got.stats == tr_expected.stats\n\t    st = st_unrotated.copy()\n\t    result = st.rotate('->ZNE', inventory=inv, components='Z12')\n\t    assert set(tr.stats.channel[-1] for tr in result) == set('ZNE')\n\t\nTestStream().test_rotate_to_zne()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_stream.py"}, {"test_code": "import gzip\nimport io\nimport re\nimport warnings\nfrom copy import deepcopy\nimport numpy as np\nimport pytest\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import Inventory\nfrom obspy.core import Stats\nfrom obspy.core.inventory import Response\nfrom obspy.core.util import CatchAndAssertWarnings\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.io.xseed import Parser\nfrom obspy.signal.spectral_estimation import PPSD\nfrom obspy.signal.spectral_estimation import welch_taper\nfrom obspy.signal.spectral_estimation import welch_window\nfrom obspy.signal.spectral_estimation import earthquake_models\nfrom obspy.signal.spectral_estimation import get_idc_infra_low_noise\nfrom obspy.signal.spectral_estimation import get_idc_infra_hi_noise\nfrom matplotlib.mlab import psd\n\nclass TestPsd():\n\tdef test_exclude_last_sample(self):\n\t    start = UTCDateTime('2017-01-01T00:00:00')\n\t    header = {'starttime': start, 'network': 'GR', 'station': 'FUR',\n\t        'channel': 'BHZ'}\n\t    tr = Trace(data=np.arange(30 * 60 * 4, dtype=np.int32), header=header)\n\t    ppsd = PPSD(tr.stats, read_inventory())\n\t    ppsd.add(tr)\n\t    assert 3 == len(ppsd._times_processed)\n\t    assert 3600 == ppsd.len\n\t    for i, time in enumerate(ppsd._times_processed):\n\t        current = start.ns + i * 30 * 60 * 1000000000.0\n\t        assert time == current\n\t\nTestPsd().test_exclude_last_sample()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_spectral_estimation.py"}, {"test_code": "import gzip\nimport io\nimport re\nimport warnings\nfrom copy import deepcopy\nimport numpy as np\nimport pytest\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import Inventory\nfrom obspy.core import Stats\nfrom obspy.core.inventory import Response\nfrom obspy.core.util import CatchAndAssertWarnings\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.io.xseed import Parser\nfrom obspy.signal.spectral_estimation import PPSD\nfrom obspy.signal.spectral_estimation import welch_taper\nfrom obspy.signal.spectral_estimation import welch_window\nfrom obspy.signal.spectral_estimation import earthquake_models\nfrom obspy.signal.spectral_estimation import get_idc_infra_low_noise\nfrom obspy.signal.spectral_estimation import get_idc_infra_hi_noise\nfrom matplotlib.mlab import psd\n\nclass TestPsd():\n\tdef test_ppsd_uneven_sampling_rate(self):\n\t    \"\"\"\n\t        Regression test for #3387\n\t\n\t        Makes sure that with weird sampling rates that do not align with the\n\t        length of the PPSD slice at all, still no data slices are left out.\n\t        The fix for this was to make sure to insert the times used for slicing\n\t        into the processed times list and not the actual sample start time of\n\t        the trace that resulted from slicing based on these times.\n\t        \"\"\"\n\t    tr = read()[0]\n\t    inv = read_inventory()\n\t    tr.stats.sampling_rate = 100.1\n\t    ppsd = PPSD(tr.stats, inv, ppsd_length=8, overlap=0.0)\n\t    ppsd.add(tr)\n\t    assert len(ppsd._times_processed) == 3\n\t    assert ppsd._times_processed == [1251073203000000000, \n\t        1251073211000000000, 1251073219000000000]\n\t    tr.stats.sampling_rate = 99.99\n\t    ppsd = PPSD(tr.stats, inv, ppsd_length=8, overlap=0.0)\n\t    ppsd.add(tr)\n\t    assert len(ppsd._times_processed) == 3\n\t    assert ppsd._times_processed == [1251073203000000000, \n\t        1251073211000000000, 1251073219000000000]\n\t\nTestPsd().test_ppsd_uneven_sampling_rate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_spectral_estimation.py"}], "method_code_mask": "import copy\nimport fnmatch\nimport textwrap\nimport warnings\nimport obspy\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.base import _read_from_plugin\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nfrom obspy.imaging.maps import plot_map\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom obspy.core.inventory.response import _adjust_bode_plot_figure\nimport doctest\n\n\n@map_example_filename('path_or_file_object')\ndef read_inventory(path_or_file_object=None, format=None, level='response',\n    *args, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_unified_content_strings", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/util.py", "response": "import copy\nimport re\nimport warnings\nfrom textwrap import TextWrapper\nfrom obspy import UTCDateTime\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.decorator import deprecated_keywords\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesFixedUnit\nimport doctest\ndef _unified_content_strings(contents):\n    contents_unique = sorted(set(contents), key=_seed_id_keyfunction)\n    contents_counts = [(item, contents.count(item)) for item in contents_unique\n        ]\n    items = [(item if count == 1 else '{} ({}x)'.format(item, count)) for \n        item, count in contents_counts]\n    return items", "test_code_list": [{"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_util_unified_content_string(self):\n\t    \"\"\"\n\t        Tests helper routine that compresses inventory content lists.\n\t        \"\"\"\n\t    contents = [u'IU.ULN (Ulaanbaatar, Mongolia)',\n\t        u'IU.ULN (Ulaanbaatar, Mongolia)', u'IU.ULN (Ulaanbaatar, Mongolia)'\n\t        ], [u'IU.ULN.00.BH1', u'IU.ULN.00.BH2', u'IU.ULN.00.BHE',\n\t        u'IU.ULN.00.BHE', u'IU.ULN.00.BHE', u'IU.ULN.00.BHE',\n\t        u'IU.ULN.00.BHN', u'IU.ULN.00.BHN', u'IU.ULN.00.BHN',\n\t        u'IU.ULN.00.BHN', u'IU.ULN.00.BHZ', u'IU.ULN.00.BHZ',\n\t        u'IU.ULN.00.BHZ', u'IU.ULN.00.BHZ', u'IU.ULN.00.BHZ',\n\t        u'IU.ULN.00.LH1', u'IU.ULN.00.LH2', u'IU.ULN.00.LHE',\n\t        u'IU.ULN.00.LHE', u'IU.ULN.00.LHE', u'IU.ULN.00.LHE',\n\t        u'IU.ULN.00.LHN', u'IU.ULN.00.LHN', u'IU.ULN.00.LHN',\n\t        u'IU.ULN.00.LHN', u'IU.ULN.00.LHZ', u'IU.ULN.00.LHZ',\n\t        u'IU.ULN.00.LHZ', u'IU.ULN.00.LHZ', u'IU.ULN.00.LHZ',\n\t        u'IU.ULN.00.UHE', u'IU.ULN.00.UHE', u'IU.ULN.00.UHN',\n\t        u'IU.ULN.00.UHN', u'IU.ULN.00.UHZ', u'IU.ULN.00.UHZ',\n\t        u'IU.ULN.00.VE1', u'IU.ULN.00.VE1', u'IU.ULN.00.VH1',\n\t        u'IU.ULN.00.VH2', u'IU.ULN.00.VHE', u'IU.ULN.00.VHE',\n\t        u'IU.ULN.00.VHE', u'IU.ULN.00.VHE', u'IU.ULN.00.VHN',\n\t        u'IU.ULN.00.VHN', u'IU.ULN.00.VHN', u'IU.ULN.00.VHN',\n\t        u'IU.ULN.00.VHZ', u'IU.ULN.00.VHZ', u'IU.ULN.00.VHZ',\n\t        u'IU.ULN.00.VHZ', u'IU.ULN.00.VHZ', u'IU.ULN.00.VK1',\n\t        u'IU.ULN.00.VK1', u'IU.ULN.00.VM1', u'IU.ULN.00.VM2',\n\t        u'IU.ULN.00.VME', u'IU.ULN.00.VME', u'IU.ULN.00.VMN',\n\t        u'IU.ULN.00.VMN', u'IU.ULN.00.VMZ', u'IU.ULN.00.VMZ', u'IU.ULN.00.VMZ']\n\t    expected = [u'IU.ULN (Ulaanbaatar, Mongolia) (3x)'], [u'IU.ULN.00.BHZ (5x)'\n\t        , u'IU.ULN.00.BHN (4x)', u'IU.ULN.00.BHE (4x)', u'IU.ULN.00.BH1',\n\t        u'IU.ULN.00.BH2', u'IU.ULN.00.LHZ (5x)', u'IU.ULN.00.LHN (4x)',\n\t        u'IU.ULN.00.LHE (4x)', u'IU.ULN.00.LH1', u'IU.ULN.00.LH2',\n\t        u'IU.ULN.00.UHZ (2x)', u'IU.ULN.00.UHN (2x)', u'IU.ULN.00.UHE (2x)',\n\t        u'IU.ULN.00.VE1 (2x)', u'IU.ULN.00.VHZ (5x)', u'IU.ULN.00.VHN (4x)',\n\t        u'IU.ULN.00.VHE (4x)', u'IU.ULN.00.VH1', u'IU.ULN.00.VH2',\n\t        u'IU.ULN.00.VK1 (2x)', u'IU.ULN.00.VMZ (3x)', u'IU.ULN.00.VMN (2x)',\n\t        u'IU.ULN.00.VME (2x)', u'IU.ULN.00.VM1', u'IU.ULN.00.VM2']\n\t    for contents_, expected_ in zip(contents, expected):\n\t        assert expected_ == _unified_content_strings(contents_)\n\t\nTestInventory().test_util_unified_content_string()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}, {"test_code": "import copy\nimport io\nimport os\nimport re\nimport warnings\nfrom pathlib import Path\nfrom unittest import mock\nimport pytest\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy import read_events\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.inventory import Channel\nfrom obspy.core.inventory import Inventory\nfrom obspy.core.inventory import Network\nfrom obspy.core.inventory import Response\nfrom obspy.core.inventory import Station\nfrom obspy.core.inventory.util import _unified_content_strings\nimport matplotlib.pyplot as plt\n\nclass TestInventory():\n\tdef test_util_unified_content_string_with_dots_in_description(self):\n\t    \"\"\"\n\t        The unified content string might have dots in the station description.\n\t        Make sure it still works.\n\t        \"\"\"\n\t    contents = ['II.ABKT (Alibek, Turkmenistan)',\n\t        'II.ALE (Alert, N.W.T., Canada)'], [\n\t        u'IU.ULN (Ulaanbaatar, A.B.C., Mongolia)',\n\t        u'IU.ULN (Ulaanbaatar, A.B.C., Mongolia)',\n\t        u'IU.ULN (Ulaanbaatar, A.B.C., Mongolia)']\n\t    expected = ['II.ABKT (Alibek, Turkmenistan)',\n\t        'II.ALE (Alert, N.W.T., Canada)'], [\n\t        u'IU.ULN (Ulaanbaatar, A.B.C., Mongolia) (3x)']\n\t    for contents_, expected_ in zip(contents, expected):\n\t        assert expected_ == _unified_content_strings(contents_)\n\t\nTestInventory().test_util_unified_content_string_with_dots_in_description()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_inventory.py"}], "method_code_mask": "import copy\nimport re\nimport warnings\nfrom textwrap import TextWrapper\nfrom obspy import UTCDateTime\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.decorator import deprecated_keywords\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesFixedUnit\nimport doctest\n\n\ndef _unified_content_strings(contents): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "map_example_filename", "method_path": "../srcdata/Computation/obspy/obspy/core/util/decorator.py", "response": "import functools\nimport inspect\nfrom pathlib import Path\nimport re\nimport socket\nimport tarfile\nimport warnings\nimport zipfile\nimport numpy as np\nfrom decorator import decorator\nfrom obspy.core.util import get_example_file\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nimport pytest\nimport bz2\nimport gzip\nimport doctest\ndef map_example_filename(arg_kwarg_name):\n    \"\"\"\n    Decorator that replaces \"/path/to/filename\" patterns in the arg or kwarg\n    of the specified name with the correct file path. If the pattern is not\n    encountered nothing is done.\n\n    .. note::\n        Actually, this is not a decorator itself but a decorator factory,\n        returning the correct decorator for the specified options. It can be\n        used just like a decorator.\n\n    :type arg_kwarg_name: str\n    :param arg_kwarg_name: name of the arg/kwarg that should be (tried) to map\n    \"\"\"\n\n    @decorator\n    def _map_example_filename(func, *args, **kwargs):\n        prefix = '/path/to/'\n        if arg_kwarg_name in kwargs:\n            if isinstance(kwargs[arg_kwarg_name], str):\n                if re.match(prefix, kwargs[arg_kwarg_name]):\n                    try:\n                        kwargs[arg_kwarg_name] = get_example_file(kwargs[\n                            arg_kwarg_name][9:])\n                    except IOError:\n                        pass\n        else:\n            try:\n                inspected_args = [p.name for p in inspect.signature(func).\n                    parameters.values()]\n            except AttributeError:\n                inspected_args = inspect.getargspec(func).args\n            try:\n                ind = inspected_args.index(arg_kwarg_name)\n            except ValueError:\n                pass\n            else:\n                if ind < len(args) and isinstance(args[ind], str):\n                    if re.match(prefix, args[ind]):\n                        try:\n                            args = list(args)\n                            args[ind] = get_example_file(args[ind][9:])\n                            args = tuple(args)\n                        except IOError:\n                            pass\n        return func(*args, **kwargs)\n    return _map_example_filename", "test_code_list": [{"test_code": "from obspy.core.util import get_example_file\nfrom obspy.core.util.decorator import map_example_filename\n\nclass TestUtilDecorator():\n\tdef test_map_example_filename(self):\n\t    \"\"\"\n\t        Tests the @map_example_filename decorator\n\t        \"\"\"\n\t    dummy = 'abc'\n\t    example_file = 'example.npz'\n\t    path = '/path/to/' + example_file\n\t    path_mapped = get_example_file(example_file)\n\t\n\t    def unchanged(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t\n\t    @map_example_filename('a')\n\t    def changed1(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed1(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed1(path, dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(dummy, path) == unchanged(dummy, path)\n\t    assert changed1(a=path, b=dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(path, b=dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(path, b=path, x=path) == unchanged(path_mapped, path, x\n\t        =path)\n\t\n\t    @map_example_filename('b')\n\t    def changed2(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed2(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed2(path, dummy) == unchanged(path, dummy)\n\t    assert changed2(dummy, path) == unchanged(dummy, path_mapped)\n\t    assert changed2(a=path, b=dummy) == unchanged(path, dummy)\n\t    assert changed2(path, b=path) == unchanged(path, path_mapped)\n\t    assert changed2(path, b=path, x=path) == unchanged(path, path_mapped, x\n\t        =path)\n\t\n\t    @map_example_filename('x')\n\t    def changed3(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed3(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed3(path, dummy) == unchanged(path, dummy)\n\t    assert changed3(dummy, path) == unchanged(dummy, path)\n\t    assert changed3(a=path, b=dummy) == unchanged(path, dummy)\n\t    assert changed3(path, b=dummy) == unchanged(path, dummy)\n\t    assert changed3(path, b=path, x=path) == unchanged(path, path, x=\n\t        path_mapped)\n\t\nTestUtilDecorator().test_map_example_filename()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_decorator.py"}], "method_code_mask": "import functools\nimport inspect\nfrom pathlib import Path\nimport re\nimport socket\nimport tarfile\nimport warnings\nimport zipfile\nimport numpy as np\nfrom decorator import decorator\nfrom obspy.core.util import get_example_file\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nimport pytest\nimport bz2\nimport gzip\nimport doctest\n\n\ndef map_example_filename(arg_kwarg_name): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "get_example_file", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef get_example_file(filename):\n    \"\"\"\n    Function to find the absolute path of a data file\n\n    The ObsPy modules are installed to a custom installation directory.\n    That is the path cannot be predicted. This functions searches for all\n    installed ObsPy modules and checks whether the file is in any of\n    the \"tests/data/\" or \"data/\" subdirectories.\n\n    :param filename: A test file name to which the path should be returned.\n    :return: Full path to file.\n\n    .. rubric:: Example\n\n    >>> get_example_file('slist.ascii')  # doctest: +SKIP\n    /custom/path/to/obspy/io/ascii/tests/data/slist.ascii\n\n    >>> get_example_file('does.not.exists')  # doctest: +ELLIPSIS\n    Traceback (most recent call last):\n    ...\n    OSError: Could not find file does.not.exists ...\n    \"\"\"\n    for module in ALL_MODULES:\n        try:\n            mod = __import__('obspy.%s' % module, fromlist=['obspy'])\n        except ImportError:\n            continue\n        file_ = Path(mod.__path__[0]) / 'tests' / 'data' / filename\n        if file_.is_file():\n            return str(file_)\n        file_ = Path(mod.__path__[0]) / 'data' / filename\n        if file_.is_file():\n            return str(file_)\n    msg = (\n        'Could not find file %s in tests/data or data directory of ObsPy modules'\n         % filename)\n    raise OSError(msg)", "test_code_list": [{"test_code": "from obspy.core.util import get_example_file\nfrom obspy.core.util.decorator import map_example_filename\n\nclass TestUtilDecorator():\n\tdef test_map_example_filename(self):\n\t    \"\"\"\n\t        Tests the @map_example_filename decorator\n\t        \"\"\"\n\t    dummy = 'abc'\n\t    example_file = 'example.npz'\n\t    path = '/path/to/' + example_file\n\t    path_mapped = get_example_file(example_file)\n\t\n\t    def unchanged(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t\n\t    @map_example_filename('a')\n\t    def changed1(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed1(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed1(path, dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(dummy, path) == unchanged(dummy, path)\n\t    assert changed1(a=path, b=dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(path, b=dummy) == unchanged(path_mapped, dummy)\n\t    assert changed1(path, b=path, x=path) == unchanged(path_mapped, path, x\n\t        =path)\n\t\n\t    @map_example_filename('b')\n\t    def changed2(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed2(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed2(path, dummy) == unchanged(path, dummy)\n\t    assert changed2(dummy, path) == unchanged(dummy, path_mapped)\n\t    assert changed2(a=path, b=dummy) == unchanged(path, dummy)\n\t    assert changed2(path, b=path) == unchanged(path, path_mapped)\n\t    assert changed2(path, b=path, x=path) == unchanged(path, path_mapped, x\n\t        =path)\n\t\n\t    @map_example_filename('x')\n\t    def changed3(a, b='', **kwargs):\n\t        return list(map(str, (a, b, kwargs)))\n\t    assert changed3(dummy, dummy) == unchanged(dummy, dummy)\n\t    assert changed3(path, dummy) == unchanged(path, dummy)\n\t    assert changed3(dummy, path) == unchanged(dummy, path)\n\t    assert changed3(a=path, b=dummy) == unchanged(path, dummy)\n\t    assert changed3(path, b=dummy) == unchanged(path, dummy)\n\t    assert changed3(path, b=path, x=path) == unchanged(path, path, x=\n\t        path_mapped)\n\t\nTestUtilDecorator().test_map_example_filename()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_decorator.py"}, {"test_code": "import io\nimport pytest\nfrom obspy.core.event import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.core.util import get_example_file\nfrom obspy.io.zmap import core as zmap\n\nclass TestZMAP():\n\tdef test_is_zmap_binary_files(self):\n\t    \"\"\"\n\t        Test zmap format detection on non-ZMAP (e.g. binary) files, see #1022.\n\t        \"\"\"\n\t    for filename in ['test.mseed', 'test.sac']:\n\t        file_ = get_example_file(filename)\n\t        assert not zmap._is_zmap(file_)\n\t\nTestZMAP().test_is_zmap_binary_files()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/zmap/tests/test_zmap.py"}], "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef get_example_file(filename): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_pitick2latex", "method_path": "../srcdata/Computation/obspy/obspy/core/inventory/response.py", "response": "import copy\nimport ctypes as C\nimport collections.abc\nfrom collections import defaultdict\nfrom copy import deepcopy\nimport itertools\nfrom math import pi\nimport warnings\nimport numpy as np\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nimport scipy.interpolate\nimport obspy.signal.evrespwrapper as ew\nfrom obspy.signal.headers import clibevresp\nimport matplotlib.pyplot as plt\nfrom matplotlib.transforms import blended_transform_factory\nimport doctest\ndef _pitick2latex(x):\n    \"\"\"\n    Helper function to convert a float that is a multiple of pi/2\n    to a latex string.\n    \"\"\"\n    if x % (pi / 2) != 0:\n        return '%#.3g' % x\n    string = '$'\n    if x < 0:\n        string += '-'\n    if x / pi % 1 == 0:\n        x = abs(int(x / pi))\n        if x == 0:\n            return '$0$'\n        elif x == 1:\n            x = ''\n        string += '%s\\\\pi$' % x\n    else:\n        x = abs(int(2 * x / pi))\n        if x == 1:\n            x = ''\n        string += '\\\\frac{%s\\\\pi}{2}$' % x\n    return string", "test_code_list": [{"test_code": "import warnings\nfrom copy import deepcopy\nfrom math import pi\nimport numpy as np\nimport pytest\nimport scipy.interpolate\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.inventory.response import _pitick2latex\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import Response\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import InstrumentSensitivity\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.signal.invsim import evalresp\nfrom obspy.io.xseed import Parser\n\nclass TestResponse():\n\tdef test_pitick2latex(self):\n\t    assert _pitick2latex(3 * pi / 2) == '$\\\\frac{3\\\\pi}{2}$'\n\t    assert _pitick2latex(2 * pi / 2) == '$\\\\pi$'\n\t    assert _pitick2latex(1 * pi / 2) == '$\\\\frac{\\\\pi}{2}$'\n\t    assert _pitick2latex(0 * pi / 2) == '$0$'\n\t    assert _pitick2latex(-1 * pi / 2) == '$-\\\\frac{\\\\pi}{2}$'\n\t    assert _pitick2latex(-2 * pi / 2) == '$-\\\\pi$'\n\t    assert _pitick2latex(0.5) == '0.500'\n\t    assert _pitick2latex(3 * pi + 0.01) == '9.43'\n\t    assert _pitick2latex(30 * pi + 0.01) == '94.3'\n\t    assert _pitick2latex(300 * pi + 0.01) == '942.'\n\t    assert _pitick2latex(3000 * pi + 0.01) == '9.42e+03'\n\t\nTestResponse().test_pitick2latex()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_response.py"}], "method_code_mask": "import copy\nimport ctypes as C\nimport collections.abc\nfrom collections import defaultdict\nfrom copy import deepcopy\nimport itertools\nfrom math import pi\nimport warnings\nimport numpy as np\nfrom obspy.core.util.base import ComparingObject\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.util.obspy_types import ObsPyException\nfrom obspy.core.util.obspy_types import ZeroSamplingRate\nimport scipy.interpolate\nimport obspy.signal.evrespwrapper as ew\nfrom obspy.signal.headers import clibevresp\nimport matplotlib.pyplot as plt\nfrom matplotlib.transforms import blended_transform_factory\nimport doctest\n\n\ndef _pitick2latex(x): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "get_dependency_version", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef get_dependency_version(package_name, raw_string=False):\n    \"\"\"\n    Get version information of a dependency package.\n\n    :type package_name: str\n    :param package_name: Name of package to return version info for\n    :returns: Package version as a list of three integers or ``None`` if\n        import fails. With option ``raw_string=True`` returns raw version\n        string instead (or ``None`` if import fails).\n        The last version number can indicate different things like it being a\n        version from the old svn trunk, the latest git repo, some release\n        candidate version, ...\n        If the last number cannot be converted to an integer it will be set to\n        0.\n    \"\"\"\n    try:\n        version_string = pkg_resources.get_distribution(package_name).version\n    except pkg_resources.DistributionNotFound:\n        return []\n    if raw_string:\n        return version_string\n    version_list = version_string.split('rc')[0].strip('~')\n    version_list = list(map(to_int_or_zero, version_list.split('.')))\n    return version_list", "test_code_list": [{"test_code": "import os\nimport copy\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom requests import HTTPError\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import get_dependency_version\nfrom obspy.core.util.base import download_to_file\nfrom obspy.core.util.base import sanitize_filename\nfrom obspy.core.util.base import create_empty_data_chunk\nfrom obspy.core.util.base import ComparingObject\n\nclass TestUtilBase():\n\tdef test_get_matplotlib_version(self):\n\t    \"\"\"\n\t        Tests for the get_matplotlib_version() function as it continues to\n\t        cause problems.\n\t        \"\"\"\n\t    versions = ('1.2.3', [1, 2, 3]), ('0.9.11', [0, 9, 11]), ('0.9.svn', [0,\n\t        9, 0]), ('1.1.1~rc1-1', [1, 1, 1]), ('1.2.x', [1, 2, 0]), ('1.3.1rc2',\n\t        [1, 3, 1])\n\t    for version_string, expected in versions:\n\t        with mock.patch('pkg_resources.get_distribution') as p:\n\t\n\t\n\t            class _D(object):\n\t                version = version_string\n\t            p.return_value = _D()\n\t            got = get_dependency_version('matplotlib')\n\t        assert expected == got\n\t\nTestUtilBase().test_get_matplotlib_version()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_base.py"}], "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef get_dependency_version(package_name, raw_string=False): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "sanitize_filename", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef sanitize_filename(filename):\n    \"\"\"\n    Adapted from Django's slugify functions.\n\n    :param filename: The filename.\n    \"\"\"\n    try:\n        filename = filename.decode()\n    except AttributeError:\n        pass\n    value = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore'\n        ).decode('ascii')\n    value = re.sub('[^\\\\w\\\\.\\\\s-]', '', value).strip()\n    return re.sub('[-\\\\s]+', '-', value)", "test_code_list": [{"test_code": "import os\nimport copy\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom requests import HTTPError\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import get_dependency_version\nfrom obspy.core.util.base import download_to_file\nfrom obspy.core.util.base import sanitize_filename\nfrom obspy.core.util.base import create_empty_data_chunk\nfrom obspy.core.util.base import ComparingObject\n\nclass TestUtilBase():\n\tdef test_sanitize_filename(self):\n\t    assert sanitize_filename('example.mseed') == 'example.mseed'\n\t    assert sanitize_filename('Example.mseed') == 'Example.mseed'\n\t    assert sanitize_filename('example.mseed?raw=True'\n\t        ) == 'example.mseedrawTrue'\n\t    assert sanitize_filename('Example.mseed?raw=true'\n\t        ) == 'Example.mseedrawtrue'\n\t\nTestUtilBase().test_sanitize_filename()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_base.py"}], "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef sanitize_filename(filename): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "create_empty_data_chunk", "method_path": "../srcdata/Computation/obspy/obspy/core/util/base.py", "response": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\ndef create_empty_data_chunk(delta, dtype, fill_value=None):\n    \"\"\"\n    Creates an NumPy array depending on the given data type and fill value.\n\n    If no ``fill_value`` is given a masked array will be returned.\n\n    :param delta: Number of samples for data chunk\n    :param dtype: NumPy dtype for returned data chunk\n    :param fill_value: If ``None``, masked array is returned, else the\n        array is filled with the corresponding value\n\n    .. rubric:: Example\n\n    >>> create_empty_data_chunk(3, 'int', 10)\n    array([10, 10, 10])\n\n    >>> create_empty_data_chunk(\n    ...     3, 'f')  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n    masked_array(data = [-- -- --],\n                 mask = ...,\n                 ...)\n    \"\"\"\n    if fill_value is None:\n        temp = np.ma.masked_all(delta, dtype=np.dtype(dtype))\n        if issubclass(temp.data.dtype.type, np.integer):\n            temp.data[:] = np.iinfo(temp.data.dtype).min\n        else:\n            temp.data[:] = np.nan\n    elif (isinstance(fill_value, list) or isinstance(fill_value, tuple)\n        ) and len(fill_value) == 2:\n        ls = fill_value[0]\n        rs = fill_value[1]\n        interpolation = np.linspace(ls, rs, delta + 2)\n        temp = np.require(interpolation[1:-1], dtype=np.dtype(dtype))\n    else:\n        temp = np.ones(delta, dtype=np.dtype(dtype))\n        temp *= fill_value\n    return temp", "test_code_list": [{"test_code": "import os\nimport copy\nfrom unittest import mock\nimport numpy as np\nimport pytest\nfrom requests import HTTPError\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import get_dependency_version\nfrom obspy.core.util.base import download_to_file\nfrom obspy.core.util.base import sanitize_filename\nfrom obspy.core.util.base import create_empty_data_chunk\nfrom obspy.core.util.base import ComparingObject\n\nclass TestUtilBase():\n\tdef test_create_empty_data_chunk(self):\n\t    out = create_empty_data_chunk(3, 'int', 10)\n\t    assert isinstance(out, np.ndarray)\n\t    assert out.dtype in (np.int32, np.int64)\n\t    np.testing.assert_allclose(out, [10, 10, 10])\n\t    out = create_empty_data_chunk(6, np.complex128, 0)\n\t    assert isinstance(out, np.ndarray)\n\t    assert out.dtype == np.complex128\n\t    np.testing.assert_allclose(out, np.zeros(6, dtype=np.complex128))\n\t    out = create_empty_data_chunk(3, 'f')\n\t    assert isinstance(out, np.ma.MaskedArray)\n\t    assert out.dtype == np.float32\n\t    np.testing.assert_allclose(out.mask, [True, True, True])\n\t\nTestUtilBase().test_create_empty_data_chunk()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_base.py"}], "method_code_mask": "import glob\nimport importlib\nimport inspect\nimport io\nimport os\nfrom contextlib import contextmanager\nfrom io import IOBase\nfrom io import TextIOBase\nfrom io import TextIOWrapper\nfrom pathlib import Path\nimport re\nimport sys\nimport tempfile\nimport unicodedata\nimport warnings\nfrom collections import OrderedDict\nfrom pathlib import PurePath\nimport numpy as np\nimport pkg_resources\nfrom pkg_resources import get_entry_info\nfrom pkg_resources import iter_entry_points\nfrom obspy.core.util.misc import to_int_or_zero\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom argparse import Action\nimport requests\nimport doctest\n\n\ndef create_empty_data_chunk(delta, dtype, fill_value=None): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_yield_obj_parent_attr", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef _yield_obj_parent_attr(obj, cls=None, is_attr=None, has_attr=None):\n    \"\"\"\n    Recurse an object, yield a tuple of object, parent, attr.\n\n    Can be used, for example, to yield all ResourceIdentifier instances\n    contained in any obspy.core.event class instances and attached instances,\n    as well as the objects they are attached to (parents) and the attribute\n    name in which they are stored (attr).\n\n    :param obj:\n        The object to recurse through attributes of lists, tuples, and other\n        instances.\n    :param cls:\n        Only return instances of cls if not None, else return all instances.\n    :param is_attr:\n        Only return objects stored as attr_name, if None return all.\n    :param has_attr:\n        Only return objects that have attribute has_attr, if None return all.\n\n    .. rubric:: General Usage\n\n    Get a list of all resource_ids contained in an event, the objects they\n    are attached to, and the attribute name on the parent object.\n\n    >>> import obspy\n    >>> from obspy.core.event import ResourceIdentifier\n    >>> cat = obspy.read_events()\n    >>> resource_tuple = list(_yield_obj_parent_attr(cat, ResourceIdentifier))\n    \"\"\"\n    ids = set()\n\n    def func(obj, attr=None, parent=None):\n        id_tuple = id(obj), id(parent)\n        if id_tuple not in ids:\n            ids.add(id_tuple)\n            is_attribute = is_attr is None or attr == is_attr\n            has_attribute = has_attr is None or hasattr(obj, has_attr)\n            is_instance = cls is None or isinstance(obj, cls)\n            if is_attribute and has_attribute and is_instance:\n                yield obj, parent, attr\n            if isinstance(obj, (list, tuple)):\n                for val in obj:\n                    for out in func(val, attr=attr, parent=obj):\n                        yield out\n            elif isinstance(obj, dict):\n                for item, val in obj.items():\n                    for out in func(val, attr=item, parent=obj):\n                        yield out\n            elif hasattr(obj, '__slots__'):\n                for attr in obj.__slots__:\n                    val = getattr(obj, attr)\n                    for out in func(val, attr=attr, parent=obj):\n                        yield out\n            elif hasattr(obj, '__dict__'):\n                for item, val in obj.__dict__.items():\n                    for out in func(val, attr=item, parent=obj):\n                        yield out\n    return func(obj)", "test_code_list": [{"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_yield_obj_parent_attr(self):\n\t    \"\"\"\n\t        Setup a complex data structure and ensure recursive search function\n\t        finds all target objects.\n\t        \"\"\"\n\t\n\t\n\t    class Slots(object):\n\t        \"\"\"\n\t            A simple class with slots\n\t            \"\"\"\n\t        __slots__ = 'right',\n\t\n\t        def __init__(self, init):\n\t            self.right = init\n\t    slotted = Slots((ResId('1'), AttributeError, [ResId('2')]))\n\t    nested = {'not_right': 'nope', 'good': {'right': ResId('3'), 'wrong': [\n\t        1, [()]]}, 'right': [[[[[[[[ResId('4')]]], ResId('5')]]]]]}\n\t    base = dict(right=ResId('6'), slotted=slotted, nested=nested)\n\t    out = list(_yield_obj_parent_attr(base, ResId))\n\t    assert len(out) == 6\n\t    for obj, parent, attr in out:\n\t        assert attr == 'right'\n\t        assert isinstance(obj, ResId)\n\t\nTestUtilMisc().test_yield_obj_parent_attr()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}], "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef _yield_obj_parent_attr(obj, cls=None, is_attr=None, has_attr=None): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "read_events", "method_path": "../srcdata/Computation/obspy/obspy/core/event/catalog.py", "response": "import copy\nimport warnings\nimport numpy as np\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import _read_from_plugin\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.imaging.maps import plot_map\nfrom obspy.imaging.maps import _plot_cartopy_into_axes\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.imaging.cm import obspy_sequential\nimport doctest\n@map_example_filename('pathname_or_url')\ndef read_events(pathname_or_url=None, format=None, **kwargs):\n    \"\"\"\n    Read event files into an ObsPy\n    :class:`~obspy.core.event.catalog.Catalog` object.\n\n    The :func:`~obspy.core.event.read_events` function opens either one or\n    multiple event files given via file name or URL using the\n    ``pathname_or_url`` attribute.\n\n    :type pathname_or_url: str, pathlib.Path, or file-like object, optional\n    :param pathname_or_url: String containing a file name or a URL, Path\n        object, or an open file-like object. Wildcards are allowed for a file\n        name. If this attribute is omitted, an example\n        :class:`~obspy.core.event.Catalog` object will be returned.\n    :type format: str\n    :param format: Format of the file to read (e.g. ``\"QUAKEML\"``). See the\n        `Supported Formats`_ section below for a list of supported formats.\n    :rtype: :class:`~obspy.core.event.Catalog`\n    :return: An ObsPy :class:`~obspy.core.event.Catalog` object.\n\n    .. rubric:: _`Supported Formats`\n\n    Additional ObsPy modules extend the functionality of the\n    :func:`~obspy.core.event.read_events` function. The following table\n    summarizes all known file formats currently supported by ObsPy.\n\n    Please refer to the `Linked Function Call`_ of each module for any extra\n    options available at the import stage.\n\n    %s\n\n    Next to the :func:`~obspy.core.event.read_events` function the\n    :meth:`~obspy.core.event.catalog.Catalog.write` method of the returned\n    :class:`~obspy.core.event.catalog.Catalog` object can be used to export the\n    data to the file system.\n    \"\"\"\n    if pathname_or_url is None:\n        return _create_example_catalog()\n    else:\n        return _generic_reader(pathname_or_url, _read, format=format, **kwargs)", "test_code_list": [{"test_code": "import copy\nimport gc\nimport io\nimport itertools\nimport multiprocessing.pool\nimport pickle\nimport sys\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core import event as event\nfrom obspy.core.event.resourceid import ResourceIdentifier\nfrom obspy.core.event.resourceid import _ResourceKey\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.testing import create_diverse_catalog\n\nclass TestResourceIdentifier():\n\tdef test_event_copying_does_not_raise_duplicate_resource_id_warning(self):\n\t    \"\"\"\n\t        Tests that copying an event does not raise a duplicate resource id\n\t        warning.\n\t        \"\"\"\n\t    ev = read_events()[0]\n\t    with warnings.catch_warnings(record=True) as w:\n\t        warnings.simplefilter('always')\n\t        ev2 = copy.copy(ev)\n\t        assert len(w) == 0\n\t        ev3 = copy.deepcopy(ev)\n\t        assert len(w) == 0\n\t    assert ev == ev2\n\t    assert ev == ev3\n\t    rid1 = ev.resource_id\n\t    rid2 = ev2.resource_id\n\t    rid3 = ev3.resource_id\n\t    rob1 = rid1.get_referred_object()\n\t    rob2 = rid2.get_referred_object()\n\t    rob3 = rid3.get_referred_object()\n\t    assert rid1 is rid2\n\t    assert rid1 is not rid3\n\t    assert rid1 == rid3\n\t    assert rob1 is rob2\n\t    assert rob1 is not rob3\n\t    assert rob1 == rob3\n\t\nTestResourceIdentifier().test_event_copying_does_not_raise_duplicate_resource_id_warning()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_resource_identifier.py"}, {"test_code": "import copy\nimport gc\nimport io\nimport itertools\nimport multiprocessing.pool\nimport pickle\nimport sys\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core import event as event\nfrom obspy.core.event.resourceid import ResourceIdentifier\nfrom obspy.core.event.resourceid import _ResourceKey\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.core.util.testing import create_diverse_catalog\n\nclass TestResourceIdentifier():\n\tdef test_catalog_resource_ids(self):\n\t    \"\"\"\n\t        Basic tests on the catalog resource ids.\n\t        \"\"\"\n\t    cat1 = read_events()\n\t    assert cat1[0] is cat1[0].resource_id.get_referred_object()\n\t    cat2 = cat1.copy()\n\t    cat3 = read_events()\n\t    assert cat1[0] is cat1[0].resource_id.get_referred_object()\n\t    assert cat2[0] is cat2[0].resource_id.get_referred_object()\n\t    assert cat3[0] is cat3[0].resource_id.get_referred_object()\n\t    del cat1\n\t    assert cat2[0] is cat2[0].resource_id.get_referred_object()\n\t    assert cat3[0] is cat3[0].resource_id.get_referred_object()\n\t    new_id = cat2[0].resource_id.id\n\t    rid = ResourceIdentifier(new_id)\n\t    assert rid.get_referred_object() is cat3[0]\n\t    del cat3\n\t    gc.collect()\n\t    with CatchAndAssertWarnings():\n\t        assert rid.get_referred_object() is cat2[0]\n\t        del cat2\n\t        assert rid.get_referred_object() is None\n\t\nTestResourceIdentifier().test_catalog_resource_ids()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_resource_identifier.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestEvent():\n\tdef test_str(self):\n\t    \"\"\"\n\t        Testing the __str__ method of the Event object.\n\t        \"\"\"\n\t    event = read_events()[1]\n\t    s = event.short_str()\n\t    expected = ('2012-04-04T14:18:37.000000Z | +39.342,  +41.044' +\n\t        ' | 4.3  ML | manual')\n\t    assert s == expected\n\t\nTestEvent().test_str()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_read_events_without_parameters(self):\n\t    \"\"\"\n\t        Calling read_events w/o any parameter will create an example catalog.\n\t        \"\"\"\n\t    catalog = read_events()\n\t    assert len(catalog) == 3\n\t\nTestCatalog().test_read_events_without_parameters()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_str(self):\n\t    \"\"\"\n\t        Testing the __str__ method of the Catalog object.\n\t        \"\"\"\n\t    catalog = read_events()\n\t    assert catalog.__str__().startswith('3 Event(s) in Catalog:')\n\t    assert catalog.__str__().endswith('37.736 | 3.0  ML | manual')\n\t\nTestCatalog().test_str()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_count_and_len(self):\n\t    \"\"\"\n\t        Tests the count and __len__ methods of the Catalog object.\n\t        \"\"\"\n\t    catalog = Catalog()\n\t    assert len(catalog) == 0\n\t    assert catalog.count() == 0\n\t    catalog = read_events()\n\t    assert len(catalog) == 3\n\t    assert catalog.count() == 3\n\t\nTestCatalog().test_count_and_len()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_get_item(self):\n\t    \"\"\"\n\t        Tests the __getitem__ method of the Catalog object.\n\t        \"\"\"\n\t    catalog = read_events()\n\t    assert catalog[0] == catalog.events[0]\n\t    assert catalog[-1] == catalog.events[-1]\n\t    assert catalog[2] == catalog.events[2]\n\t    with pytest.raises(IndexError):\n\t        catalog.__getitem__(3)\n\t    with pytest.raises(IndexError):\n\t        catalog.__getitem__(-99)\n\t\nTestCatalog().test_get_item()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_slicing(self):\n\t    \"\"\"\n\t        Tests the __getslice__ method of the Catalog object.\n\t        \"\"\"\n\t    catalog = read_events()\n\t    assert catalog[0:] == catalog[0:]\n\t    assert catalog[:2] == catalog[:2]\n\t    assert catalog[:] == catalog[:]\n\t    assert len(catalog) == 3\n\t    new_catalog = catalog[1:3]\n\t    assert isinstance(new_catalog, Catalog)\n\t    assert len(new_catalog) == 2\n\t\nTestCatalog().test_slicing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_copy(self):\n\t    \"\"\"\n\t        Testing the copy method of the Catalog object.\n\t        \"\"\"\n\t    cat = read_events()\n\t    cat2 = cat.copy()\n\t    assert cat == cat2\n\t    assert cat2 == cat\n\t    assert not cat is cat2\n\t    assert not cat2 is cat\n\t    assert cat.events[0] == cat2.events[0]\n\t    assert not cat.events[0] is cat2.events[0]\n\t\nTestCatalog().test_copy()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_filter(self):\n\t    \"\"\"\n\t        Testing the filter method of the Catalog object.\n\t        \"\"\"\n\t\n\t    def getattrs(event, attr):\n\t        if attr == 'magnitude':\n\t            obj = event.magnitudes[0]\n\t            attr = 'mag'\n\t        else:\n\t            obj = event.origins[0]\n\t        for a in attr.split('.'):\n\t            obj = getattr(obj, a)\n\t        return obj\n\t    cat = read_events()\n\t    assert all(event.magnitudes[0].mag < 4.0 for event in cat.filter(\n\t        'magnitude < 4.'))\n\t    attrs = ('magnitude', 'latitude', 'longitude', 'depth', 'time',\n\t        'quality.standard_error', 'quality.azimuthal_gap',\n\t        'quality.used_station_count', 'quality.used_phase_count')\n\t    values = 4.0, 40.0, 50.0, 10.0, UTCDateTime('2012-04-04 14:20:00'\n\t        ), 1.0, 50, 40, 20\n\t    for attr, value in zip(attrs, values):\n\t        attr_filter = attr.split('.')[-1]\n\t        cat_smaller = cat.filter('%s < %s' % (attr_filter, value))\n\t        cat_bigger = cat.filter('%s >= %s' % (attr_filter, value))\n\t        assert all(True if a is None else a < value for event in\n\t            cat_smaller for a in [getattrs(event, attr)])\n\t        assert all(False if a is None else a >= value for event in\n\t            cat_bigger for a in [getattrs(event, attr)])\n\t        assert all(event in cat for event in cat_smaller + cat_bigger)\n\t        cat_smaller_inverse = cat.filter('%s < %s' % (attr_filter, value),\n\t            inverse=True)\n\t        assert all(event in cat_bigger for event in cat_smaller_inverse)\n\t        cat_bigger_inverse = cat.filter('%s >= %s' % (attr_filter, value),\n\t            inverse=True)\n\t        assert all(event in cat_smaller for event in cat_bigger_inverse)\n\t\nTestCatalog().test_filter()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_can_pickle(self):\n\t    \"\"\"\n\t        Ensure a catalog can be pickled and unpickled and that the results are\n\t        equal.\n\t        \"\"\"\n\t    cat = read_events()\n\t    cat_bytes = pickle.dumps(cat)\n\t    cat2 = pickle.loads(cat_bytes)\n\t    assert cat == cat2\n\t\nTestCatalog().test_can_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestCatalog():\n\tdef test_issue_2173(self):\n\t    \"\"\"\n\t        Ensure events with empty origins are equal after round-trip to disk.\n\t        See #2173.\n\t        \"\"\"\n\t    origin = Origin(time=UTCDateTime('2016-01-01'))\n\t    event1 = Event(origins=[origin])\n\t    bio = io.BytesIO()\n\t    event1.write(bio, 'quakeml')\n\t    bio.seek(0)\n\t    event2 = read_events(bio)[0]\n\t    assert event1 == event2\n\t\nTestCatalog().test_issue_2173()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestBase():\n\tdef test_issue3105(self):\n\t    evs = read_events()\n\t    evs[0].magnitudes[0].mag = 0\n\t    assert len(evs) == 3\n\t    assert len(evs.filter('magnitude < 3.5')) == 2\n\t\nTestBase().test_issue3105()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}, {"test_code": "import io\nimport math\nimport warnings\nimport pytest\nfrom lxml import etree\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import read_events\nfrom obspy.core.event import EventDescription\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.testing import compare_xml_strings\nfrom obspy.io.quakeml.core import Pickler\nfrom obspy.io.quakeml.core import _read_quakeml\nfrom obspy.io.quakeml.core import _write_quakeml\nfrom lxml.etree import parse\nfrom obspy.core.event import header as event_header\nfrom obspy.core.util import Enum\n\nclass TestQuakeML():\n\tdef test_native_namespace_in_extra(self):\n\t    \"\"\"\n\t        Make sure that QuakeML tags that are not the same as the document\n\t        root's namespaces still are handled as custom tags (coming\n\t        after any expected/mandatory tags) and get parsed into extras section\n\t        properly.\n\t        \"\"\"\n\t    custom1 = {'value': u'11111', 'namespace':\n\t        'http://quakeml.org/xmlns/bed/9.99'}\n\t    custom2 = {'value': u'22222', 'namespace':\n\t        'http://quakeml.org/xmlns/quakeml/8.87'}\n\t    extra = {'custom1': custom1, 'custom2': custom2}\n\t    cat = Catalog()\n\t    cat.extra = extra\n\t    with io.BytesIO() as buf:\n\t        cat.write(buf, format='QUAKEML')\n\t        buf.seek(0)\n\t        cat2 = read_events(buf, format='QUAKEML')\n\t    assert extra == cat2.extra\n\t    assert ('custom1', custom1) in cat2.extra.items()\n\t    assert ('custom2', custom2) in cat2.extra.items()\n\t\nTestQuakeML().test_native_namespace_in_extra()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/quakeml/tests/test_quakeml.py"}, {"test_code": "import warnings\nfrom obspy import read_events\nfrom obspy import read_inventory\nfrom obspy import UTCDateTime\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.io.hypodd import pha\nimport pytest\n\nclass TestPHA():\n\tdef test_write_pha_minimal(self):\n\t    ori = Origin(time=UTCDateTime(0), latitude=42, longitude=43, depth=10000)\n\t    pick = Pick(time=UTCDateTime(10), phase_hint='S', waveform_id=\n\t        WaveformStreamID(station_code='STA'))\n\t    del ori.latitude_errors\n\t    del ori.longitude_errors\n\t    del ori.depth_errors\n\t    cat = Catalog([Event(origins=[ori], picks=[pick])])\n\t    with NamedTemporaryFile() as tf:\n\t        tempfile = tf.name\n\t        with pytest.warns(UserWarning, match='Missing mag'):\n\t            cat.write(tempfile, 'HYPODDPHA')\n\t        cat2 = read_events(tempfile)\n\t    assert len(cat2) == 1\n\t    assert len(cat2[0].picks) == 1\n\t\nTestPHA().test_write_pha_minimal()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/hypodd/tests/test_pha.py"}], "method_code_mask": "import copy\nimport warnings\nimport numpy as np\nfrom obspy.core.utcdatetime import UTCDateTime\nfrom obspy.core.util import _read_from_plugin\nfrom obspy.core.util.base import ENTRY_POINTS\nfrom obspy.core.util.base import _generic_reader\nfrom obspy.core.util.decorator import map_example_filename\nfrom obspy.core.util.decorator import uncompress_file\nfrom obspy.core.util.misc import buffered_load_entry_point\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.imaging.maps import plot_map\nfrom obspy.imaging.maps import _plot_cartopy_into_axes\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.imaging.cm import obspy_sequential\nimport doctest\n\n\n@map_example_filename('pathname_or_url')\ndef read_events(pathname_or_url=None, format=None, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "farfield", "method_path": "../srcdata/Computation/obspy/obspy/core/event/source.py", "response": "import numpy as np\nfrom obspy.core.event.base import _event_type_class_factory\nfrom obspy.core.event.base import CreationInfo\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event.header import EvaluationMode\nfrom obspy.core.event.header import EvaluationStatus\nfrom obspy.core.event.header import MomentTensorCategory\nfrom obspy.core.event.header import MTInversionType\nfrom obspy.core.event.header import SourceTimeFunctionType\nfrom obspy.core.event.header import ATTRIBUTE_HAS_ERRORS\nimport doctest\ndef farfield(mt, points, type):\n    \"\"\"\n    Returns the P/S farfield radiation pattern\n    based on [Aki1980]_ eq. 4.29.\n\n    :param mt: Focal mechanism NM x 6 (Mxx, Myy, Mzz, Mxy, Mxz, Myz - the\n               six independent components of the moment tensor)\n\n    :param points: 3D vector array with shape [3,npts] (x,y,z) or [2,npts]\n                   (theta,phi) The normalized displacement of the moment\n                   tensor source is computed at these points.\n    :type type: str\n    :param type: 'P' or 'S' (P or S wave).\n\n    :return: 3D vector array with shape [3,npts] that contains the\n             displacement vector for each grid point\n    \"\"\"\n    type = type.upper()\n    if type not in ('P', 'S'):\n        msg = \"type must be 'P' or 'S'\"\n        raise ValueError(msg)\n    is_p_wave = type == 'P'\n    ndim, npoints = points.shape\n    if ndim == 2:\n        _points = np.empty((3, npoints))\n        _points[0] = np.sin(points[0]) * np.cos(points[1])\n        _points[1] = np.sin(points[0]) * np.sin(points[1])\n        _points[2] = np.cos(points[0])\n        points = _points\n        ndim = 3\n    elif ndim == 3:\n        pass\n    else:\n        raise ValueError('points should have shape 2 x npoints or 3 x npoints')\n    m_pq = _fullmt(mt)\n    dists = np.sqrt(points[0] * points[0] + points[1] * points[1] + points[\n        2] * points[2])\n    gammas = points / dists\n    disp = np.empty((ndim, npoints))\n    if is_p_wave:\n        for ipoint in range(npoints):\n            gamma = gammas[:, ipoint]\n            gammapq = np.outer(gamma, gamma)\n            gammatimesmt = gammapq * m_pq\n            for n in range(ndim):\n                disp[n, ipoint] = gamma[n] * np.sum(gammatimesmt.flatten())\n    else:\n        for ipoint in range(npoints):\n            gamma = gammas[:, ipoint]\n            m_p = np.dot(m_pq, gamma)\n            for n in range(ndim):\n                psum = 0.0\n                for p in range(ndim):\n                    deltanp = int(n == p)\n                    psum += (gamma[n] * gamma[p] - deltanp) * m_p[p]\n                disp[n, ipoint] = psum\n    return disp", "test_code_list": [{"test_code": "import io\nimport os\nimport pickle\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import Event\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Pick\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event.source import farfield\nfrom obspy.core.util import CARTOPY_VERSION\nfrom obspy.core.util.base import _get_entry_points\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.core.event.base import QuantityError\n\nclass TestEvent():\n\tdef test_farfield_2xn_input(self):\n\t    \"\"\"\n\t        Tests to compute P/S wave farfield radiation pattern using (theta,phi)\n\t        pairs as input\n\t        \"\"\"\n\t    mt = [-0.547, -1.698, 2.245, -1.444, 1.339, 3.728]\n\t    theta = np.arange(0, 360, 60)\n\t    phi = np.zeros(len(theta))\n\t    rays = np.array([theta, phi]) * np.pi / 180.0\n\t    result = farfield(mt, rays, 'P')\n\t    ref = np.array([[0.0, 1.13501984, -0.873480164, 2.749332e-16, -\n\t        1.13501984, 0.873480164], [0, 0, -0, 0, -0, 0], [2.245, 0.655304008,\n\t        0.504304008, -2.245, -0.655304008, -0.504304008]])\n\t    np.testing.assert_allclose(result, ref, rtol=1e-05, atol=1e-08)\n\t\nTestEvent().test_farfield_2xn_input()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_event.py"}], "method_code_mask": "import numpy as np\nfrom obspy.core.event.base import _event_type_class_factory\nfrom obspy.core.event.base import CreationInfo\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event.header import EvaluationMode\nfrom obspy.core.event.header import EvaluationStatus\nfrom obspy.core.event.header import MomentTensorCategory\nfrom obspy.core.event.header import MTInversionType\nfrom obspy.core.event.header import SourceTimeFunctionType\nfrom obspy.core.event.header import ATTRIBUTE_HAS_ERRORS\nimport doctest\n\n\ndef farfield(mt, points, type): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "get_window_times", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef get_window_times(starttime, endtime, window_length, step, offset,\n    include_partial_windows):\n    \"\"\"\n    Function calculating a list of times making up equal length windows from\n    within a given time interval.\n\n    :param starttime: The start time of the whole time interval.\n    :type starttime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param endtime: The end time of the whole time interval.\n    :type endtime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param window_length: The length of each window in seconds.\n    :type window_length: float\n    :param step: The step between the start times of two successive\n        windows in seconds. Can be negative if an offset is given.\n    :type step: float\n    :param offset: The offset of the first window in seconds relative to\n        the start time of the whole interval.\n    :type offset: float\n    :param include_partial_windows: Determines if windows that are\n        shorter then 99.9 % of the desired length are returned.\n    :type include_partial_windows: bool\n    \"\"\"\n    if step > 0:\n        end = endtime.timestamp - 0.001 * step\n    else:\n        end = starttime.timestamp - 0.001 * abs(step)\n    indices = np.arange(start=starttime.timestamp + offset, stop=end, step=\n        step, dtype=np.float64)\n    if step > 0:\n        windows = [(_i, min(_i + window_length, endtime.timestamp)) for _i in\n            indices]\n    else:\n        windows = [(max(_i - window_length, starttime.timestamp), _i) for\n            _i in indices]\n    if not include_partial_windows:\n        windows = [_i for _i in windows if abs(_i[1] - _i[0]) > 0.999 *\n            window_length]\n    t = type(starttime)\n    return [(t(_i[0]), t(_i[1])) for _i in windows]", "test_code_list": [{"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_1(self):\n\t    \"\"\"\n\t        Basic windows. 4 pieces.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(0), UTCDateTime(5)), (UTCDateTime(5),\n\t        UTCDateTime(10)), (UTCDateTime(10), UTCDateTime(15)), (UTCDateTime(\n\t        15), UTCDateTime(20))],\n\t    windows = get_window_times(starttime=UTCDateTime(0), endtime=\n\t        UTCDateTime(20), window_length=5.0, step=5.0, offset=0.0,\n\t        include_partial_windows=False),\n\t    assert expected == windows\n\t\nTestUtilMisc().test_get_window_times_1()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_2(self):\n\t    \"\"\"\n\t        # Different step size.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(0), UTCDateTime(5)), (UTCDateTime(10),\n\t        UTCDateTime(15))],\n\t    windows = get_window_times(starttime=UTCDateTime(0), endtime=\n\t        UTCDateTime(20), window_length=5.0, step=10.0, offset=0.0,\n\t        include_partial_windows=False),\n\t    assert expected == windows\n\t\nTestUtilMisc().test_get_window_times_2()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_3(self):\n\t    \"\"\"\n\t        Window times with offset.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(8.5), UTCDateTime(13.5)), (UTCDateTime(15),\n\t        UTCDateTime(20))],\n\t    windows = get_window_times(starttime=UTCDateTime(0), endtime=\n\t        UTCDateTime(20), window_length=5.0, step=6.5, offset=8.5,\n\t        include_partial_windows=False),\n\t    assert expected == windows\n\t\nTestUtilMisc().test_get_window_times_3()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_4(self):\n\t    \"\"\"\n\t        Test for not returning partial windows.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(0), UTCDateTime(15))]\n\t    windows = get_window_times(starttime=UTCDateTime(0), endtime=\n\t        UTCDateTime(20), window_length=15.0, step=15.0, offset=0.0,\n\t        include_partial_windows=False)\n\t    assert windows == expected\n\t\nTestUtilMisc().test_get_window_times_4()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_5(self):\n\t    \"\"\"\n\t        Test for partial windows.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(0), UTCDateTime(15)), (UTCDateTime(15),\n\t        UTCDateTime(20))],\n\t    windows = get_window_times(starttime=UTCDateTime(0), endtime=\n\t        UTCDateTime(20), window_length=15.0, step=15.0, offset=0.0,\n\t        include_partial_windows=True),\n\t    assert windows == expected\n\t\nTestUtilMisc().test_get_window_times_5()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_6(self):\n\t    \"\"\"\n\t        Negative step length has to be used together with an offset.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(15), UTCDateTime(20)), (UTCDateTime(10),\n\t        UTCDateTime(15)), (UTCDateTime(5), UTCDateTime(10)), (UTCDateTime(0\n\t        ), UTCDateTime(5))]\n\t    window = get_window_times(starttime=UTCDateTime(0), endtime=UTCDateTime\n\t        (20), window_length=5.0, step=-5.0, offset=20.0,\n\t        include_partial_windows=False)\n\t    assert window == expected\n\t\nTestUtilMisc().test_get_window_times_6()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_7(self):\n\t    \"\"\"\n\t        Negative step length and not partial windows.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(5), UTCDateTime(20))]\n\t    window = get_window_times(starttime=UTCDateTime(0), endtime=UTCDateTime\n\t        (20), window_length=15.0, step=-15.0, offset=20.0,\n\t        include_partial_windows=False)\n\t    assert window == expected\n\t\nTestUtilMisc().test_get_window_times_7()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_8(self):\n\t    \"\"\"\n\t        Negative step length with partial windows.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(5), UTCDateTime(20)), (UTCDateTime(0),\n\t        UTCDateTime(5))]\n\t    window = get_window_times(starttime=UTCDateTime(0), endtime=UTCDateTime\n\t        (20), window_length=15.0, step=-15.0, offset=20.0,\n\t        include_partial_windows=True)\n\t    assert window == expected\n\t\nTestUtilMisc().test_get_window_times_8()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}, {"test_code": "import sys\nimport tempfile\nimport warnings\nfrom unittest import mock\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import ResourceIdentifier as ResId\nfrom obspy.core.util.misc import CatchOutput\nfrom obspy.core.util.misc import get_window_times\nfrom obspy.core.util.misc import _ENTRY_POINT_CACHE\nfrom obspy.core.util.misc import _yield_obj_parent_attr\nfrom obspy.core.util.base import CatchAndAssertWarnings\n\nclass TestUtilMisc():\n\tdef test_get_window_times_9(self):\n\t    \"\"\"\n\t        Smaller step than window.\n\t        \"\"\"\n\t    expected = [(UTCDateTime(0), UTCDateTime(1)), (UTCDateTime(0.25),\n\t        UTCDateTime(1.25)), (UTCDateTime(0.5), UTCDateTime(1.5)), (\n\t        UTCDateTime(0.75), UTCDateTime(1.75)), (UTCDateTime(1.0),\n\t        UTCDateTime(2.0))],\n\t    window = get_window_times(starttime=UTCDateTime(0), endtime=UTCDateTime\n\t        (2), window_length=1.0, step=0.25, offset=0.0,\n\t        include_partial_windows=False),\n\t    assert window == expected\n\t\nTestUtilMisc().test_get_window_times_9()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/core/tests/test_util_misc.py"}], "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef get_window_times(starttime, endtime, window_length, step, offset,\n    include_partial_windows): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "filter_channel_priority", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/mass_downloader/utils.py", "response": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\ndef filter_channel_priority(channels, key, priorities=None):\n    \"\"\"\n    This function takes a dictionary containing channels keys and returns a new\n    one filtered with the given priorities list.\n\n    All channels matching the first pattern in the list will be retrieved. If\n    one or more channels are found it stops. Otherwise it will attempt to\n    retrieve channels matching the next pattern. And so on.\n\n    :type channels: list\n    :param channels: A list containing channel names.\n    :type priorities: list of unicode or None\n    :param priorities: The desired channels with descending priority. Channels\n    will be matched by fnmatch.fnmatch() so wildcards and sequences are\n    supported. The advisable form to request the three standard components\n    of a channel is \"HH[ZNE]\" to avoid getting e.g. rotated components.\n    :returns: A new list containing only the filtered channels.\n    \"\"\"\n    if priorities is None:\n        return channels\n    filtered_channels = []\n    for pattern in priorities:\n        if filtered_channels:\n            break\n        for channel in channels:\n            if fnmatch.fnmatch(getattr(channel, key), pattern):\n                filtered_channels.append(channel)\n                continue\n    return filtered_channels", "test_code_list": [{"test_code": "import collections\nimport copy\nimport logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nfrom socket import timeout as socket_timeout\nfrom unittest import mock\nimport pytest\nfrom http.client import HTTPException\nimport numpy as np\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn import Client\nfrom obspy.clients.fdsn.mass_downloader import domain\nfrom obspy.clients.fdsn.mass_downloader import Restrictions\nfrom obspy.clients.fdsn.mass_downloader import MassDownloader\nfrom obspy.clients.fdsn.mass_downloader.utils import filter_channel_priority\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_mseed_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_contents\nfrom obspy.clients.fdsn.mass_downloader.utils import SphericalNearestNeighbour\nfrom obspy.clients.fdsn.mass_downloader.utils import safe_delete\nfrom obspy.clients.fdsn.mass_downloader.utils import download_stationxml\nfrom obspy.clients.fdsn.mass_downloader.utils import download_and_split_mseed_bulk\nfrom obspy.clients.fdsn.mass_downloader.utils import _get_stationxml_contents_slow\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Channel\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import TimeInterval\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Station\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import STATUS\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import ClientDownloadHelper\n\nclass TestDownloadHelpersUtil():\n\tdef test_channel_priority_filtering(self):\n\t    \"\"\"\n\t        Tests the channel priority filtering.\n\t        \"\"\"\n\t    st = obspy.UTCDateTime(2015, 1, 1)\n\t    time_intervals = [TimeInterval(st + _i * 60, st + (_i + 1) * 60) for _i in\n\t        range(10)]\n\t    c1 = Channel('', 'BHE', time_intervals)\n\t    c2 = Channel('10', 'SHE', time_intervals)\n\t    c3 = Channel('00', 'BHZ', time_intervals)\n\t    c4 = Channel('', 'HHE', time_intervals)\n\t    c5 = Channel('', 'ELZ', time_intervals)\n\t    channels = [c1, c2, c3, c4, c5]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['HH[ZNE]', 'BH[ZNE]', 'MH[ZNE]', 'EH[ZNE]', 'LH[ZNE]'])\n\t    assert filtered_channels == [c4]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['BH[ZNE]', 'MH[ZNE]', 'EH[ZNE]', 'LH[ZNE]'])\n\t    assert filtered_channels == [c1, c3]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['LH[ZNE]'])\n\t    assert filtered_channels == []\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['*'])\n\t    assert filtered_channels == channels\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['BH*', 'MH[ZNE]', 'EH[ZNE]', 'LH[ZNE]'])\n\t    assert filtered_channels == [c1, c3]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['BH[NZ]', 'MH[ZNE]', 'EH[ZNE]', 'LH[ZNE]'])\n\t    assert filtered_channels == [c3]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['S*', 'BH*'])\n\t    assert filtered_channels == [c2]\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=['*'])\n\t    assert filtered_channels == channels\n\t    filtered_channels = filter_channel_priority(channels, key='channel',\n\t        priorities=None)\n\t    assert filtered_channels == channels\n\t\nTestDownloadHelpersUtil().test_channel_priority_filtering()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/tests/test_mass_downloader.py"}, {"test_code": "import collections\nimport copy\nimport logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nfrom socket import timeout as socket_timeout\nfrom unittest import mock\nimport pytest\nfrom http.client import HTTPException\nimport numpy as np\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn import Client\nfrom obspy.clients.fdsn.mass_downloader import domain\nfrom obspy.clients.fdsn.mass_downloader import Restrictions\nfrom obspy.clients.fdsn.mass_downloader import MassDownloader\nfrom obspy.clients.fdsn.mass_downloader.utils import filter_channel_priority\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_mseed_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_contents\nfrom obspy.clients.fdsn.mass_downloader.utils import SphericalNearestNeighbour\nfrom obspy.clients.fdsn.mass_downloader.utils import safe_delete\nfrom obspy.clients.fdsn.mass_downloader.utils import download_stationxml\nfrom obspy.clients.fdsn.mass_downloader.utils import download_and_split_mseed_bulk\nfrom obspy.clients.fdsn.mass_downloader.utils import _get_stationxml_contents_slow\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Channel\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import TimeInterval\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Station\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import STATUS\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import ClientDownloadHelper\n\nclass TestDownloadHelpersUtil():\n\tdef test_location_priority_filtering(self):\n\t    \"\"\"\n\t        Tests the channel priority filtering.\n\t        \"\"\"\n\t    st = obspy.UTCDateTime(2015, 1, 1)\n\t    time_intervals = [TimeInterval(st + _i * 60, st + (_i + 1) * 60) for _i in\n\t        range(10)]\n\t    c1 = Channel('', 'BHE', time_intervals)\n\t    c2 = Channel('10', 'SHE', time_intervals)\n\t    c3 = Channel('00', 'BHZ', time_intervals)\n\t    c4 = Channel('', 'HHE', time_intervals)\n\t    channels = [c1, c2, c3, c4]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['*0'])\n\t    assert filtered_channels == [c2, c3]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['00'])\n\t    assert filtered_channels == [c3]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=[''])\n\t    assert filtered_channels == [c1, c4]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['1?'])\n\t    assert filtered_channels == [c2]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['', '*0'])\n\t    assert filtered_channels == [c1, c4]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['*0', ''])\n\t    assert filtered_channels == [c2, c3]\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=['*'])\n\t    assert filtered_channels == channels\n\t    filtered_channels = filter_channel_priority(channels, key='location',\n\t        priorities=None)\n\t    assert filtered_channels == channels\n\t\nTestDownloadHelpersUtil().test_location_priority_filtering()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/tests/test_mass_downloader.py"}], "method_code_mask": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\n\n\ndef filter_channel_priority(channels, key, priorities=None): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "download_stationxml", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/mass_downloader/utils.py", "response": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\ndef download_stationxml(client, client_name, bulk, filename, logger):\n    \"\"\"\n    Download all channels for a station in the already prepared bulk list.\n\n    :param client: An active client instance.\n    :param client_name: The name of the client mainly used for logging\n        purposes.\n    :param bulk: An already prepared bulk download list for all channels and\n        time intervals for the given station. All items in there are assumed\n        to come from the same station.\n    :param filename: The filename to download to.\n    :param logger: The logger instance to use for logging.\n\n    :returns: A tuple with the network and station id and the filename upon\n        success\n    \"\"\"\n    network = bulk[0][0]\n    station = bulk[0][1]\n    try:\n        client.get_stations_bulk(bulk=bulk, level='response', filename=filename\n            )\n    except Exception:\n        logger.info(\n            \"Failed to download StationXML from '%s' for station '%s.%s'.\" %\n            (client_name, network, station))\n        return None\n    logger.info(\"Client '%s' - Successfully downloaded '%s'.\" % (\n        client_name, filename))\n    return (network, station), filename", "test_code_list": [{"test_code": "import collections\nimport copy\nimport logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nfrom socket import timeout as socket_timeout\nfrom unittest import mock\nimport pytest\nfrom http.client import HTTPException\nimport numpy as np\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn import Client\nfrom obspy.clients.fdsn.mass_downloader import domain\nfrom obspy.clients.fdsn.mass_downloader import Restrictions\nfrom obspy.clients.fdsn.mass_downloader import MassDownloader\nfrom obspy.clients.fdsn.mass_downloader.utils import filter_channel_priority\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_mseed_filename\nfrom obspy.clients.fdsn.mass_downloader.utils import get_stationxml_contents\nfrom obspy.clients.fdsn.mass_downloader.utils import SphericalNearestNeighbour\nfrom obspy.clients.fdsn.mass_downloader.utils import safe_delete\nfrom obspy.clients.fdsn.mass_downloader.utils import download_stationxml\nfrom obspy.clients.fdsn.mass_downloader.utils import download_and_split_mseed_bulk\nfrom obspy.clients.fdsn.mass_downloader.utils import _get_stationxml_contents_slow\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Channel\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import TimeInterval\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import Station\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import STATUS\nfrom obspy.clients.fdsn.mass_downloader.download_helpers import ClientDownloadHelper\n\nclass TestDownloadHelpersUtil():\n\tdef test_download_stationxml(self):\n\t    \"\"\"\n\t        Mock test for the StationXML downloading.\n\t\n\t        Does not do much and is not a proper test but it's something and\n\t        makes sure there is not obvious logic error.\n\t        \"\"\"\n\t    bulk = [['BW', 'ALTM'], ['BW', 'ALTM']]\n\t    filename = 'temp.xml'\n\t    client_name = 'mock'\n\t    client = mock.MagicMock()\n\t    logger = mock.MagicMock()\n\t    ret_val = download_stationxml(client, client_name, bulk, filename, logger)\n\t    assert ret_val == (('BW', 'ALTM'), filename)\n\t    assert logger.info.call_count == 1\n\t    assert logger.info.call_args[0][0\n\t        ] == \"Client 'mock' - Successfully downloaded 'temp.xml'.\"\n\t    assert client.get_stations_bulk.call_count == 1\n\t    assert client.get_stations_bulk.call_args[1]['bulk'] == bulk\n\t    assert client.get_stations_bulk.call_args[1]['level'] == 'response'\n\t    assert client.get_stations_bulk.call_args[1]['filename'] == filename\n\t    client.reset_mock()\n\t    logger.reset_mock()\n\t\n\t    def raise_exception():\n\t        raise ValueError('Test')\n\t    client.get_stations_bulk.side_effect = raise_exception\n\t    ret_val = download_stationxml(client, client_name, bulk, filename, logger)\n\t    assert ret_val is None\n\t    assert logger.info.call_count == 1\n\t    assert logger.info.call_args[0][0\n\t        ] == \"Failed to download StationXML from 'mock' for station 'BW.ALTM'.\"\n\t    assert client.get_stations_bulk.call_count == 1\n\t    assert client.get_stations_bulk.call_args[1]['bulk'] == bulk\n\t    assert client.get_stations_bulk.call_args[1]['level'] == 'response'\n\t    assert client.get_stations_bulk.call_args[1]['filename'] == filename\n\t\nTestDownloadHelpersUtil().test_download_stationxml()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/tests/test_mass_downloader.py"}], "method_code_mask": "import collections\nimport fnmatch\nimport itertools\nimport os\nfrom http.client import HTTPException\nfrom socket import timeout as socket_timeout\nfrom urllib.error import HTTPError\nfrom urllib.error import URLError\nimport numpy as np\nfrom lxml import etree\nfrom scipy.spatial import cKDTree\nimport obspy\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.clients.fdsn.client import FDSNException\nfrom obspy.io.mseed.util import get_record_information\n\n\ndef download_stationxml(client, client_name, bulk, filename, logger): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "locations2degrees", "method_path": "../srcdata/Computation/obspy/obspy/geodetics/base.py", "response": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\ndef locations2degrees(lat1, long1, lat2, long2):\n    \"\"\"\n    Convenience function to calculate the great circle distance between two\n    points on a spherical Earth.\n\n    This method uses the Vincenty formula in the special case of a spherical\n    Earth. For more accurate values use the geodesic distance calculations of\n    geopy (https://github.com/geopy/geopy).\n\n    :type lat1: float or :class:`numpy.ndarray`\n    :param lat1: Latitude(s) of point 1 in degrees\n    :type long1: float or :class:`numpy.ndarray`\n    :param long1: Longitude(s) of point 1 in degrees\n    :type lat2: float or :class:`numpy.ndarray`\n    :param lat2: Latitude(s) of point 2 in degrees\n    :type long2: float or :class:`numpy.ndarray`\n    :param long2: Longitude(s) of point 2 in degrees\n    :rtype: float or :class:`numpy.ndarray`\n    :return: Distance in degrees as a floating point number,\n        or numpy array of element-wise distances in degrees\n\n    .. rubric:: Example\n\n    >>> from obspy.geodetics import locations2degrees\n    >>> locations2degrees(5, 5, 10, 10) # doctest: +ELLIPSIS\n    7.03970141917538...\n    \"\"\"\n    lat1, lat2, long1, long2 = np.broadcast_arrays(lat1, lat2, long1, long2)\n    lat1 = np.radians(np.asarray(lat1))\n    lat2 = np.radians(np.asarray(lat2))\n    long1 = np.radians(np.asarray(long1))\n    long2 = np.radians(np.asarray(long2))\n    long_diff = long2 - long1\n    gd = np.degrees(np.arctan2(np.sqrt((np.cos(lat2) * np.sin(long_diff)) **\n        2 + (np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np\n        .cos(long_diff)) ** 2), np.sin(lat1) * np.sin(lat2) + np.cos(lat1) *\n        np.cos(lat2) * np.cos(long_diff)))\n    return gd", "test_code_list": [{"test_code": "import math\nimport warnings\nimport numpy as np\nfrom obspy.geodetics import calc_vincenty_inverse\nfrom obspy.geodetics import degrees2kilometers\nfrom obspy.geodetics import gps2dist_azimuth\nfrom obspy.geodetics import inside_geobounds\nfrom obspy.geodetics import kilometer2degrees\nfrom obspy.geodetics import locations2degrees\nfrom obspy.geodetics.base import HAS_GEOGRAPHICLIB\nfrom obspy.core import AttribDict\nimport pytest\n\nclass TestUtilGeodetics():\n\tdef test_locations2degrees(self):\n\t    \"\"\"\n\t        Test the location 2 degree conversion.\n\t        \"\"\"\n\t\n\t    def assert_loc(lat1, long1, lat2, long2, approx_distance):\n\t        assert abs(math.radians(locations2degrees(lat1, long1, lat2, long2)\n\t            ) * 6371 - approx_distance) <= 20\n\t    assert_loc(36.12, -86.67, 33.94, -118.4, 2893)\n\t    assert_loc(11.11, 22.22, 33.33, 44.44, 3346)\n\t    assert_loc(-11.11, -22.22, -33.33, -44.44, 3346)\n\t    assert_loc(11.11, 22.22, -33.33, -44.44, 8596)\n\t    assert_loc(-11.11, -22.22, 33.33, 44.44, 8596)\n\t    assert_loc(11.11, -22.22, 33.33, -44.44, 3346)\n\t    assert_loc(-11.11, 22.22, 33.33, 44.44, 5454)\n\t    assert_loc(11.11, -22.22, 33.33, 44.44, 7177)\n\t    assert_loc(11.11, 22.22, -33.33, 44.44, 5454)\n\t    assert_loc(11.11, 22.22, 33.33, -44.44, 7177)\n\t    assert_loc(90, 0, 0, 0, 10018)\n\t    assert_loc(180, 0, 0, 0, 20004)\n\t    assert_loc(0, 90, 0, 0, 10018)\n\t    assert_loc(0, 180, 0, 0, 20004)\n\t    assert_loc(0, 0, 90, 0, 10018)\n\t    assert_loc(0, 0, 180, 0, 20004)\n\t    assert_loc(0, 0, 0, 90, 10018)\n\t    assert_loc(0, 0, 0, 180, 20004)\n\t    assert_loc(11, 55, 11, 55, 0)\n\t\n\t    def assert_loc_np(lat1, long1, lat2, long2, approx_distance,\n\t        expected_output_len):\n\t        loc2deg = locations2degrees(np.array(lat1), np.array(long1), np.\n\t            array(lat2), np.array(long2))\n\t        assert (np.abs(np.radians(loc2deg) * 6371 - approx_distance) <= 20\n\t            ).all()\n\t        assert np.isscalar(loc2deg) if expected_output_len == 0 else len(\n\t            loc2deg) == expected_output_len\n\t    assert_loc_np(36.12, -86.67, 33.94, -118.4, 2893, 0)\n\t    assert_loc_np([36.12, 36.12], -86.67, 33.94, -118.4, 2893, 2)\n\t    assert_loc_np(36.12, [-86.67, -86.67], 33.94, -118.4, 2893, 2)\n\t    assert_loc_np(36.12, -86.67, [33.94, 33.94], -118.4, 2893, 2)\n\t    assert_loc_np(36.12, -86.67, 33.94, [-118.4, -118.4], 2893, 2)\n\t    assert_loc_np([36.12, 36.12], [-86.67, -86.67], 33.94, -118.4, 2893, 2)\n\t    assert_loc_np([36.12, 36.12], -86.67, [33.94, 33.94], -118.4, 2893, 2)\n\t    assert_loc_np([36.12, 36.12], -86.67, 33.94, [-118.4, -118.4], 2893, 2)\n\t    assert_loc_np([36.12, 36.12], [-86.67, -86.67], [33.94, 33.94], -118.4,\n\t        2893, 2)\n\t    assert_loc_np([36.12, 36.12], -86.67, [33.94, 33.94], [-118.4, -118.4],\n\t        2893, 2)\n\t    assert_loc_np(36.12, [-86.67, -86.67], [33.94, 33.94], [-118.4, -118.4],\n\t        2893, 2)\n\t    assert_loc_np([36.12, 36.12], [-86.67, -86.67], [33.94, 33.94], [-118.4,\n\t        -118.4], 2893, 2)\n\t    with pytest.raises(ValueError):\n\t        locations2degrees(1, 2, [3, 4], [5, 6, 7])\n\t\nTestUtilGeodetics().test_locations2degrees()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/geodetics/tests/test_util_geodetics.py"}], "method_code_mask": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\n\n\ndef locations2degrees(lat1, long1, lat2, long2): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "build_url", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/client.py", "response": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\ndef build_url(base_url, service, major_version, resource_type, parameters=\n    None, service_mappings=None, subpath='fdsnws'):\n    \"\"\"\n    URL builder for the FDSN webservices.\n\n    Built as a separate function to enhance testability.\n\n    >>> print(build_url(\"http://service.iris.edu\", \"dataselect\", 1,                         \"application.wadl\"))\n    http://service.iris.edu/fdsnws/dataselect/1/application.wadl\n\n    >>> print(build_url(\"http://service.iris.edu\", \"dataselect\", 1,                         \"query\", {\"cha\": \"EHE\"}))\n    http://service.iris.edu/fdsnws/dataselect/1/query?cha=EHE\n    \"\"\"\n    if parameters is None:\n        parameters = {}\n    if service_mappings is None:\n        service_mappings = {}\n    if service not in ['dataselect', 'event', 'station']:\n        msg = \"Resource type '%s' not allowed. Allowed types: \\n%s\" % (service,\n            ','.join(('dataselect', 'event', 'station')))\n        raise ValueError(msg)\n    if 'location' in parameters:\n        loc = parameters['location'].replace(' ', '')\n        if not loc:\n            loc = '--'\n        if loc.startswith(','):\n            loc = '--' + loc\n        if loc.endswith(','):\n            loc += '--'\n        loc = loc.replace(',,', ',--,')\n        parameters['location'] = loc\n    if service in service_mappings:\n        url = '/'.join((service_mappings[service], resource_type))\n    else:\n        if subpath is None:\n            parts = base_url, service, str(major_version), resource_type\n        else:\n            parts = base_url, subpath.lstrip('/'), service, str(major_version\n                ), resource_type\n        url = '/'.join(parts)\n    if parameters:\n        for key, value in parameters.items():\n            try:\n                parameters[key] = value.strip()\n            except Exception:\n                pass\n        url = '?'.join((url, urlencode(parameters)))\n    return url", "test_code_list": [{"test_code": "import io\nimport re\nimport sys\nimport warnings\nfrom difflib import Differ\nfrom unittest import mock\nimport urllib.request as urllib_request\nimport lxml\nimport numpy as np\nimport pytest\nimport requests\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.clients.fdsn import Client\nfrom obspy.clients.fdsn import RoutingClient\nfrom obspy.clients.fdsn.client import build_url\nfrom obspy.clients.fdsn.client import parse_simple_xml\nfrom obspy.clients.fdsn.client import get_bulk_string\nfrom obspy.clients.fdsn.client import _cleanup_earthscope\nfrom obspy.clients.fdsn.header import DEFAULT_USER_AGENT\nfrom obspy.clients.fdsn.header import URL_MAPPINGS\nfrom obspy.clients.fdsn.header import FDSNException\nfrom obspy.clients.fdsn.header import FDSNRedirectException\nfrom obspy.clients.fdsn.header import FDSNNoDataException\nfrom obspy.clients.fdsn.header import FDSNRequestTooLargeException\nfrom obspy.clients.fdsn.header import FDSNBadRequestException\nfrom obspy.clients.fdsn.header import FDSNNoAuthenticationServiceException\nfrom obspy.clients.fdsn.header import FDSNTimeoutException\nfrom obspy.clients.fdsn.header import FDSNNoServiceException\nfrom obspy.clients.fdsn.header import FDSNInternalServerException\nfrom obspy.clients.fdsn.header import FDSNTooManyRequestsException\nfrom obspy.clients.fdsn.header import FDSNNotImplementedException\nfrom obspy.clients.fdsn.header import FDSNBadGatewayException\nfrom obspy.clients.fdsn.header import FDSNServiceUnavailableException\nfrom obspy.clients.fdsn.header import FDSNUnauthorizedException\nfrom obspy.clients.fdsn.header import FDSNForbiddenException\nfrom obspy.clients.fdsn.header import FDSNDoubleAuthenticationException\nfrom obspy.clients.fdsn.header import FDSNInvalidRequestException\nfrom obspy.clients.fdsn.header import DEFAULT_SERVICES\nfrom obspy.core.inventory import Response\nfrom obspy.geodetics import locations2degrees\n\nclass TestClientNoNetwork():\n\tdef test_url_building(self):\n\t    \"\"\"\n\t        Tests the build_url() functions.\n\t        \"\"\"\n\t    assert build_url('http://service.iris.edu', 'dataselect', 1,\n\t        'application.wadl'\n\t        ) == 'http://service.iris.edu/fdsnws/dataselect/1/application.wadl'\n\t    assert build_url('http://service.iris.edu', 'event', 1, 'application.wadl'\n\t        ) == 'http://service.iris.edu/fdsnws/event/1/application.wadl'\n\t    assert build_url('http://service.iris.edu', 'station', 1,\n\t        'application.wadl'\n\t        ) == 'http://service.iris.edu/fdsnws/station/1/application.wadl'\n\t    assert build_url('http://service.iris.edu', 'dataselect', 1, 'query', {\n\t        'network': 'BW'}\n\t        ) == 'http://service.iris.edu/fdsnws/dataselect/1/query?network=BW'\n\t    assert build_url('http://service.iris.edu', 'dataselect', 1,\n\t        'queryauth', {'network': 'BW'}\n\t        ) == 'http://service.iris.edu/fdsnws/dataselect/1/queryauth?network=BW'\n\t    assert build_url('http://service.iris.edu', 'dataselect', 1, 'query', {\n\t        'net': 'A', 'sta': 'BC'}) in (\n\t        'http://service.iris.edu/fdsnws/dataselect/1/query?net=A&sta=BC',\n\t        'http://service.iris.edu/fdsnws/dataselect/1/query?sta=BC&net=A')\n\t    with pytest.raises(ValueError):\n\t        build_url('http://service.iris.edu', 'obspy', 1, 'query')\n\t\nTestClientNoNetwork().test_url_building()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/tests/test_client.py"}], "method_code_mask": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\n\n\ndef build_url(base_url, service, major_version, resource_type, parameters=\n    None, service_mappings=None, subpath='fdsnws'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "parse_simple_xml", "method_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/client.py", "response": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\ndef parse_simple_xml(xml_string):\n    \"\"\"\n    Simple helper function for parsing the Catalog and Contributor availability\n    files.\n\n    Parses XMLs of the form::\n\n        <Bs>\n            <total>4</total>\n            <B>1</B>\n            <B>2</B>\n            <B>3</B>\n            <B>4</B>\n        </Bs>\n\n    and return a dictionary with a single item::\n\n        {\"Bs\": set((\"1\", \"2\", \"3\", \"4\"))}\n    \"\"\"\n    root = etree.fromstring(xml_string.strip())\n    if not root.tag.endswith('s'):\n        msg = 'Could not parse the XML.'\n        raise ValueError(msg)\n    child_tag = root.tag[:-1]\n    children = [i.text for i in root if i.tag == child_tag]\n    return {root.tag.lower(): set(children)}", "test_code_list": [{"test_code": "import io\nimport re\nimport sys\nimport warnings\nfrom difflib import Differ\nfrom unittest import mock\nimport urllib.request as urllib_request\nimport lxml\nimport numpy as np\nimport pytest\nimport requests\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import read_inventory\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom obspy.clients.fdsn import Client\nfrom obspy.clients.fdsn import RoutingClient\nfrom obspy.clients.fdsn.client import build_url\nfrom obspy.clients.fdsn.client import parse_simple_xml\nfrom obspy.clients.fdsn.client import get_bulk_string\nfrom obspy.clients.fdsn.client import _cleanup_earthscope\nfrom obspy.clients.fdsn.header import DEFAULT_USER_AGENT\nfrom obspy.clients.fdsn.header import URL_MAPPINGS\nfrom obspy.clients.fdsn.header import FDSNException\nfrom obspy.clients.fdsn.header import FDSNRedirectException\nfrom obspy.clients.fdsn.header import FDSNNoDataException\nfrom obspy.clients.fdsn.header import FDSNRequestTooLargeException\nfrom obspy.clients.fdsn.header import FDSNBadRequestException\nfrom obspy.clients.fdsn.header import FDSNNoAuthenticationServiceException\nfrom obspy.clients.fdsn.header import FDSNTimeoutException\nfrom obspy.clients.fdsn.header import FDSNNoServiceException\nfrom obspy.clients.fdsn.header import FDSNInternalServerException\nfrom obspy.clients.fdsn.header import FDSNTooManyRequestsException\nfrom obspy.clients.fdsn.header import FDSNNotImplementedException\nfrom obspy.clients.fdsn.header import FDSNBadGatewayException\nfrom obspy.clients.fdsn.header import FDSNServiceUnavailableException\nfrom obspy.clients.fdsn.header import FDSNUnauthorizedException\nfrom obspy.clients.fdsn.header import FDSNForbiddenException\nfrom obspy.clients.fdsn.header import FDSNDoubleAuthenticationException\nfrom obspy.clients.fdsn.header import FDSNInvalidRequestException\nfrom obspy.clients.fdsn.header import DEFAULT_SERVICES\nfrom obspy.core.inventory import Response\nfrom obspy.geodetics import locations2degrees\n\nclass TestClientNoNetwork():\n\tdef test_simple_xml_parser(self):\n\t    \"\"\"\n\t        Tests the simple XML parsing helper function.\n\t        \"\"\"\n\t    catalogs = parse_simple_xml(\n\t        \"\"\"\n\t            <?xml version=\"1.0\"?>\n\t            <Catalogs>\n\t              <total>6</total>\n\t              <Catalog>ANF</Catalog>\n\t              <Catalog>GCMT</Catalog>\n\t              <Catalog>TEST</Catalog>\n\t              <Catalog>ISC</Catalog>\n\t              <Catalog>UofW</Catalog>\n\t              <Catalog>NEIC PDE</Catalog>\n\t            </Catalogs>\"\"\"\n\t        )\n\t    assert catalogs == {'catalogs': set(('ANF', 'GCMT', 'TEST', 'ISC',\n\t        'UofW', 'NEIC PDE'))}\n\t\nTestClientNoNetwork().test_simple_xml_parser()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/clients/fdsn/tests/test_client.py"}], "method_code_mask": "import collections.abc\nimport copy\nimport gzip\nimport io\nimport os\nimport re\nfrom socket import timeout as socket_timeout\nimport textwrap\nimport threading\nimport warnings\nfrom collections import OrderedDict\nfrom http.client import HTTPException\nfrom http.client import IncompleteRead\nfrom urllib.parse import urlparse\nfrom lxml import etree\nimport obspy\nfrom obspy import UTCDateTime\nfrom obspy import read_inventory\nfrom obspy.core.util.deprecation_helpers import ObsPyDeprecationWarning\nfrom urllib.parse import urlencode\nimport urllib.request as urllib_request\nimport queue\nimport doctest\n\n\ndef parse_simple_xml(xml_string): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "strike_dip", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef strike_dip(n, e, u):\n    \"\"\"\n    Finds strike and dip of plane given normal vector having components n, e,\n    and u.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    r2d = 180 / np.pi\n    if u < 0:\n        n = -n\n        e = -e\n        u = -u\n    strike = np.arctan2(e, n) * r2d\n    strike = strike - 90\n    while strike >= 360:\n        strike = strike - 360\n    while strike < 0:\n        strike = strike + 360\n    x = np.sqrt(np.power(n, 2) + np.power(e, 2))\n    dip = np.arctan2(x, u) * r2d\n    return strike, dip", "test_code_list": [{"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_strike_dip(self):\n\t    \"\"\"\n\t        Test strike_dip function - all values are taken from MatLab.\n\t        \"\"\"\n\t    sl1 = -0.048901208623019\n\t    sl2 = 0.178067035725425\n\t    sl3 = 0.982802524713469\n\t    strike, dip = strike_dip(sl2, sl1, sl3)\n\t    assert round(abs(strike - 254.643860910074), 7) == 0\n\t    assert round(abs(dip - 10.641291652406172), 7) == 0\n\t\nTestBeachballPlot().test_strike_dip()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}], "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef strike_dip(n, e, u): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "aux_plane", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef aux_plane(s1, d1, r1):\n    \"\"\"\n    Get Strike and dip of second plane.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    r2d = 180 / np.pi\n    z = (s1 + 90) / r2d\n    z2 = d1 / r2d\n    z3 = r1 / r2d\n    sl1 = -np.cos(z3) * np.cos(z) - np.sin(z3) * np.sin(z) * np.cos(z2)\n    sl2 = np.cos(z3) * np.sin(z) - np.sin(z3) * np.cos(z) * np.cos(z2)\n    sl3 = np.sin(z3) * np.sin(z2)\n    strike, dip = strike_dip(sl2, sl1, sl3)\n    n1 = np.sin(z) * np.sin(z2)\n    n2 = np.cos(z) * np.sin(z2)\n    h1 = -sl2\n    h2 = sl1\n    z = h1 * n1 + h2 * n2\n    z = z / np.sqrt(h1 * h1 + h2 * h2)\n    float64epsilon = 2.220446049250313e-16\n    if 1.0 < abs(z) < 1.0 + 100 * float64epsilon:\n        z = np.copysign(1.0, z)\n    z = np.arccos(z)\n    rake = 0\n    if sl3 > 0:\n        rake = z * r2d\n    if sl3 <= 0:\n        rake = -z * r2d\n    return strike, dip, rake", "test_code_list": [{"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_aux_plane(self):\n\t    \"\"\"\n\t        Test aux_plane function - all values are taken from MatLab.\n\t        \"\"\"\n\t    s1 = 132.1800525721546\n\t    d1 = 84.24098719437659\n\t    r1 = 98.96337264103879\n\t    s2, d2, r2 = aux_plane(s1, d1, r1)\n\t    assert round(abs(s2 - 254.643860910074), 7) == 0\n\t    assert round(abs(d2 - 10.641291652406172), 7) == 0\n\t    assert round(abs(r2 - 32.91557842245438), 7) == 0\n\t    s1 = 160.55\n\t    d1 = 76.0\n\t    r1 = -46.78\n\t    s2, d2, r2 = aux_plane(s1, d1, r1)\n\t    assert round(abs(s2 - 264.98676854650216), 7) == 0\n\t    assert round(abs(d2 - 45.00190694241562), 7) == 0\n\t    assert round(abs(r2 - -159.99404307049076), 7) == 0\n\t\nTestBeachballPlot().test_aux_plane()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}, {"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_aux_plane_735(self):\n\t    \"\"\"\n\t        Test aux_plane precision issue #735\n\t        \"\"\"\n\t    s, d, r = aux_plane(164, 90, -32)\n\t    assert round(abs(s - 254.0), 7) == 0\n\t    assert round(abs(d - 58.0), 7) == 0\n\t    assert round(abs(r - -180.0), 7) == 0\n\t\nTestBeachballPlot().test_aux_plane_735()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}], "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef aux_plane(s1, d1, r1): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "tdl", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef tdl(an, bn):\n    \"\"\"\n    Helper function for mt2plane.\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    xn = an[0]\n    yn = an[1]\n    zn = an[2]\n    xe = bn[0]\n    ye = bn[1]\n    ze = bn[2]\n    aaa = 1.0 / 1000000\n    con = 57.2957795\n    if np.fabs(zn) < aaa:\n        fd = 90.0\n        axn = np.fabs(xn)\n        if axn > 1.0:\n            axn = 1.0\n        ft = np.arcsin(axn) * con\n        st = -xn\n        ct = yn\n        if st >= 0.0 and ct < 0:\n            ft = 180.0 - ft\n        if st < 0.0 and ct <= 0:\n            ft = 180.0 + ft\n        if st < 0.0 and ct > 0:\n            ft = 360.0 - ft\n        fl = np.arcsin(abs(ze)) * con\n        sl = -ze\n        if np.fabs(xn) < aaa:\n            cl = xe / yn\n        else:\n            cl = -ye / xn\n        if sl >= 0.0 and cl < 0:\n            fl = 180.0 - fl\n        if sl < 0.0 and cl <= 0:\n            fl = fl - 180.0\n        if sl < 0.0 and cl > 0:\n            fl = -fl\n    else:\n        if -zn > 1.0:\n            zn = -1.0\n        fdh = np.arccos(-zn)\n        fd = fdh * con\n        sd = np.sin(fdh)\n        if sd == 0:\n            return\n        st = -xn / sd\n        ct = yn / sd\n        sx = np.fabs(st)\n        if sx > 1.0:\n            sx = 1.0\n        ft = np.arcsin(sx) * con\n        if st >= 0.0 and ct < 0:\n            ft = 180.0 - ft\n        if st < 0.0 and ct <= 0:\n            ft = 180.0 + ft\n        if st < 0.0 and ct > 0:\n            ft = 360.0 - ft\n        sl = -ze / sd\n        sx = np.fabs(sl)\n        if sx > 1.0:\n            sx = 1.0\n        fl = np.arcsin(sx) * con\n        if st == 0:\n            cl = xe / ct\n        else:\n            xxx = yn * zn * ze / sd / sd + ye\n            cl = -sd * xxx / xn\n            if ct == 0:\n                cl = ye / st\n        if sl >= 0.0 and cl < 0:\n            fl = 180.0 - fl\n        if sl < 0.0 and cl <= 0:\n            fl = fl - 180.0\n        if sl < 0.0 and cl > 0:\n            fl = -fl\n    return ft, fd, fl", "test_code_list": [{"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_tdl(self):\n\t    \"\"\"\n\t        Test tdl function - all values are taken from MatLab.\n\t        \"\"\"\n\t    an = [0.737298200871146, -0.668073596186761, -0.100344571703004]\n\t    bn = [-0.178067035261159, -0.048901208638715, -0.982802524796805]\n\t    ft, fd, fl = tdl(an, bn)\n\t    assert round(abs(ft - 227.8199474278454), 7) == 0\n\t    assert round(abs(fd - 84.24098719437659), 7) == 0\n\t    assert round(abs(fl - 81.03662735896121), 7) == 0\n\t\nTestBeachballPlot().test_tdl()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}], "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef tdl(an, bn): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "mt2plane", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef mt2plane(mt):\n    \"\"\"\n    Calculates a nodal plane of a given moment tensor.\n\n    :param mt: :class:`~MomentTensor`\n    :return: :class:`~NodalPlane`\n\n    Adapted from MATLAB script\n    `bb.m <http://www.ceri.memphis.edu/people/olboyd/Software/Software.html>`_\n    written by Andy Michael, Chen Ji and Oliver Boyd.\n    \"\"\"\n    d, v = np.linalg.eig(mt.mt)\n    d = np.array([d[1], d[0], d[2]])\n    v = np.array([[v[1, 1], -v[1, 0], -v[1, 2]], [v[2, 1], -v[2, 0], -v[2, \n        2]], [-v[0, 1], v[0, 0], v[0, 2]]])\n    imax = d.argmax()\n    imin = d.argmin()\n    ae = (v[:, imax] + v[:, imin]) / np.sqrt(2.0)\n    an = (v[:, imax] - v[:, imin]) / np.sqrt(2.0)\n    aer = np.sqrt(np.power(ae[0], 2) + np.power(ae[1], 2) + np.power(ae[2], 2))\n    anr = np.sqrt(np.power(an[0], 2) + np.power(an[1], 2) + np.power(an[2], 2))\n    ae = ae / aer\n    if not anr:\n        an = np.array([np.nan, np.nan, np.nan])\n    else:\n        an = an / anr\n    if an[2] <= 0.0:\n        an1 = an\n        ae1 = ae\n    else:\n        an1 = -an\n        ae1 = -ae\n    ft, fd, fl = tdl(an1, ae1)\n    return NodalPlane(360 - ft, fd, 180 - fl)", "test_code_list": [{"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_mt2plane(self):\n\t    \"\"\"\n\t        Tests mt2plane.\n\t        \"\"\"\n\t    mt = MomentTensor((0.91, -0.89, -0.02, 1.78, -1.55, 0.47), 0)\n\t    np = mt2plane(mt)\n\t    assert round(abs(np.strike - 129.8626267208001), 7) == 0\n\t    assert round(abs(np.dip - 79.02270090665473), 7) == 0\n\t    assert round(abs(np.rake - 97.76925518551519), 7) == 0\n\t\nTestBeachballPlot().test_mt2plane()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}], "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef mt2plane(mt): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "mt2axes", "method_path": "../srcdata/Computation/obspy/obspy/imaging/beachball.py", "response": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\ndef mt2axes(mt):\n    \"\"\"\n    Calculates the principal axes of a given moment tensor.\n\n    :param mt: :class:`~MomentTensor`\n    :return: tuple of :class:`~PrincipalAxis` T, N and P\n\n    Adapted from ps_tensor / utilmeca.c /\n    `Generic Mapping Tools (GMT) <https://www.generic-mapping-tools.org>`_.\n    \"\"\"\n    d, v = np.linalg.eigh(mt.mt)\n    pl = np.arcsin(-v[0])\n    az = np.arctan2(v[2], -v[1])\n    for i in range(0, 3):\n        if pl[i] <= 0:\n            pl[i] = -pl[i]\n            az[i] += np.pi\n        if az[i] < 0:\n            az[i] += 2 * np.pi\n        if az[i] > 2 * np.pi:\n            az[i] -= 2 * np.pi\n    pl *= R2D\n    az *= R2D\n    t = PrincipalAxis(d[2], az[2], pl[2])\n    n = PrincipalAxis(d[1], az[1], pl[1])\n    p = PrincipalAxis(d[0], az[0], pl[0])\n    return t, n, p", "test_code_list": [{"test_code": "import warnings\nimport matplotlib.pyplot as plt\nimport pytest\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.imaging.beachball import tdl\nfrom obspy.imaging.beachball import aux_plane\nfrom obspy.imaging.beachball import beach\nfrom obspy.imaging.beachball import beachball\nfrom obspy.imaging.beachball import MomentTensor\nfrom obspy.imaging.beachball import mt2axes\nfrom obspy.imaging.beachball import mt2plane\nfrom obspy.imaging.beachball import strike_dip\n\nclass TestBeachballPlot():\n\tdef test_mt2axes(self):\n\t    \"\"\"\n\t        Tests mt2axes.\n\t        \"\"\"\n\t    mt = MomentTensor((0.91, -0.89, -0.02, 1.78, -1.55, 0.47), 0)\n\t    t, n, p = mt2axes(mt)\n\t    assert round(abs(t.val - 2.52461359), 7) == 0\n\t    assert round(abs(t.dip - 55.33018576), 7) == 0\n\t    assert round(abs(t.strike - 49.53656116), 7) == 0\n\t    assert round(abs(n.val - 0.08745048), 7) == 0\n\t    assert round(abs(n.dip - 7.62624529), 7) == 0\n\t    assert round(abs(n.strike - 308.37440488), 7) == 0\n\t    assert round(abs(p.val - -2.61206406), 7) == 0\n\t    assert round(abs(p.dip - 33.5833323), 7) == 0\n\t    assert round(abs(p.strike - 213.273886), 7) == 0\n\t\nTestBeachballPlot().test_mt2axes()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_beachball.py"}], "method_code_mask": "import io\nimport warnings\nimport numpy as np\nfrom decorator import decorator\nfrom matplotlib import collections\nfrom matplotlib import transforms\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nfrom matplotlib import path as mplpath\nimport doctest\n\n\ndef mt2axes(mt): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_create_stream", "method_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_waveform.py", "response": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\ndef _create_stream(starttime, endtime, sampling_rate):\n    \"\"\"\n    Helper method to create a Stream object that can be used for testing\n    waveform plotting.\n\n    Takes the time frame of the Stream to be created and a sampling rate.\n    Any other header information will have to be adjusted on a case by case\n    basis. Please remember to use the same sampling rate for one Trace as\n    merging and plotting will not work otherwise.\n\n    This method will create a single sine curve to a first approximation\n    with superimposed 10 smaller sine curves on it.\n\n    :return: Stream object\n    \"\"\"\n    time_delta = endtime - starttime\n    number_of_samples = int(time_delta * sampling_rate) + 1\n    curve = np.linspace(0, 2 * np.pi, number_of_samples // 2)\n    curve = np.sin(curve) + 0.2 * np.sin(10 * curve)\n    data = np.empty(number_of_samples)\n    if number_of_samples % 2 == 0:\n        data[0::2] = curve\n        data[1::2] = curve + 0.2\n    else:\n        data[-1] = 0.0\n        data[0:-1][0::2] = curve\n        data[0:-1][1::2] = curve + 0.2\n    tr = Trace()\n    tr.stats.starttime = starttime\n    tr.stats.sampling_rate = float(sampling_rate)\n    tr.stats.network = 'BW'\n    tr.stats.station = 'OBSPY'\n    tr.stats.channel = 'TEST'\n    tr.data = data\n    return Stream(traces=[tr])", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\n\nclass TestWaveformPlot():\n\tdef test_data_remains_unchanged(self):\n\t    \"\"\"\n\t        Data should not be changed when plotting.\n\t        \"\"\"\n\t    st = _create_stream(UTCDateTime(0), UTCDateTime(1000), 1)\n\t    st[0].stats.calib = 0.2343\n\t    org_st = st.copy()\n\t    st.plot(format='png')\n\t    assert st == org_st\n\t    st = _create_stream(UTCDateTime(0), UTCDateTime(600000), 1)\n\t    st[0].stats.calib = 0.2343\n\t    org_st = st.copy()\n\t    st.plot(format='png')\n\t    assert st == org_st\n\t    st.plot(format='png', starrtime=UTCDateTime(10000), endtime=UTCDateTime\n\t        (20000))\n\t    assert st == org_st\n\t\nTestWaveformPlot().test_data_remains_unchanged()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_waveform.py"}, {"test_code": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\n\nclass TestWaveformPlot():\n\tdef test_section_max_npts(self):\n\t    \"\"\"\n\t        Check that plotting with method='full' is respected for type='section'\n\t        if points are greater than max_npts.\n\t        \"\"\"\n\t    starttime = UTCDateTime(0)\n\t    endtime = starttime + 10009\n\t    st = _create_stream(starttime, endtime, 1)\n\t    st[0].stats.distance = 0\n\t    fig = st.plot(type='section', method='full')\n\t    assert fig.axes[0].lines[0].get_xdata().size == 10010\n\t\nTestWaveformPlot().test_section_max_npts()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/imaging/tests/test_waveform.py"}], "method_code_mask": "import numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.event import read_events\nfrom obspy.core.stream import read\nfrom obspy.core.util import AttribDict\nimport pytest\n\n\ndef _create_stream(starttime, endtime, sampling_rate): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "calculate_lanczos_kernel", "method_path": "../srcdata/Computation/obspy/obspy/signal/interpolation.py", "response": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\ndef calculate_lanczos_kernel(x, a, window):\n    \"\"\"\n    Helper function to get the actually used kernel for a specific value of\n    a. Useful to analyse the behaviour of different tapers and different values\n    of a.\n\n    :type x: :class:`numpy.ndarray`\n    :param x: The x values at which to calculate the kernel.\n    :type a: int\n    :param a: The width of the window in samples on either side.\n    :type window: str\n    :param window: The window used to multiply the sinc function with. One\n        of ``\"lanczos\"``, ``\"hanning\"``, ``\"blackman\"``.\n\n    Returns a dictionary of arrays:\n\n    * ``\"full_kernel\"``: The tapered sinc function evaluated at samples ``x``.\n    * ``\"only_sinc\"``: The sinc function evaluated at samples ``x``.\n    * ``\"only_taper\"``: The taper function evaluated at samples ``x``.\n    \"\"\"\n    window = window.lower()\n    if window not in _LANCZOS_KERNEL_MAP:\n        msg = 'Invalid window. Valid windows: %s' % ', '.join(sorted(\n            _LANCZOS_KERNEL_MAP.keys()))\n        raise ValueError(msg)\n    x = np.require(x, dtype=np.float64)\n    y0 = np.zeros(x.shape, dtype=np.float64)\n    y1 = np.zeros(x.shape, dtype=np.float64)\n    y2 = np.zeros(x.shape, dtype=np.float64)\n    clibsignal.calculate_kernel(x, y0, len(x), a, 0, _LANCZOS_KERNEL_MAP[\n        window])\n    clibsignal.calculate_kernel(x, y1, len(x), a, 1, _LANCZOS_KERNEL_MAP[\n        window])\n    clibsignal.calculate_kernel(x, y2, len(x), a, 2, _LANCZOS_KERNEL_MAP[\n        window])\n    ret_val = {'full_kernel': y0, 'only_sinc': y1, 'only_taper': y2}\n    return ret_val", "test_code_list": [{"test_code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy.signal.interpolation import lanczos_interpolation\nfrom obspy.signal.interpolation import calculate_lanczos_kernel\nfrom obspy.signal.interpolation import plot_lanczos_windows\n\nclass TestInterpolation():\n\tdef test_calculate_lanczos_kernel(self):\n\t    \"\"\"\n\t        Tests the kernels implemented in C against their numpy counterpart.\n\t        \"\"\"\n\t    x = np.linspace(-5, 5, 11)\n\t    values = calculate_lanczos_kernel(x, 5, 'hanning')\n\t    np.testing.assert_allclose(values['only_sinc'], np.sinc(x), atol=1e-09)\n\t    np.testing.assert_allclose(values['only_taper'], np.hanning(len(x)),\n\t        atol=1e-09)\n\t    np.testing.assert_allclose(values['full_kernel'], np.sinc(x) * np.\n\t        hanning(len(x)), atol=1e-09)\n\t    values = calculate_lanczos_kernel(x, 5, 'blackman')\n\t    np.testing.assert_allclose(values['only_sinc'], np.sinc(x), atol=1e-09)\n\t    np.testing.assert_allclose(values['only_taper'], np.blackman(len(x)),\n\t        atol=1e-09)\n\t    np.testing.assert_allclose(values['full_kernel'], np.sinc(x) * np.\n\t        blackman(len(x)), atol=1e-09)\n\t    values = calculate_lanczos_kernel(x, 5, 'lanczos')\n\t    np.testing.assert_allclose(values['only_sinc'], np.sinc(x), atol=1e-09)\n\t    np.testing.assert_allclose(values['only_taper'], np.sinc(x / 5.0), atol\n\t        =1e-09)\n\t    np.testing.assert_allclose(values['full_kernel'], np.sinc(x) * np.sinc(\n\t        x / 5.0), atol=1e-09)\n\t\nTestInterpolation().test_calculate_lanczos_kernel()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_interpolation.py"}], "method_code_mask": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef calculate_lanczos_kernel(x, a, window): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "lanczos_interpolation", "method_path": "../srcdata/Computation/obspy/obspy/signal/interpolation.py", "response": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\ndef lanczos_interpolation(data, old_start, old_dt, new_start, new_dt,\n    new_npts, a, window='lanczos', *args, **kwargs):\n    \"\"\"\n    Function performing Lanczos resampling, see\n    https://en.wikipedia.org/wiki/Lanczos_resampling for details. Essentially a\n    finite support version of sinc resampling (the ideal reconstruction\n    filter). For large values of ``a`` it converges towards sinc resampling. If\n    used for downsampling, make sure to apply an appropriate anti-aliasing\n    lowpass filter first.\n\n    .. note::\n\n        In most cases you do not want to call this method directly but invoke\n        it via either the :meth:`obspy.core.stream.Stream.interpolate` or\n        :meth:`obspy.core.trace.Trace.interpolate` method. These offer a nicer\n        API that naturally integrates with the rest of ObsPy. Use\n        ``method=\"lanczos\"`` to use this interpolation method. In that case the\n        only additional parameters of interest are ``a`` and ``window``.\n\n    :type data: array_like\n    :param data: Array to interpolate.\n    :type old_start: float\n    :param old_start: The start of the array as a number.\n    :type old_start: float\n    :param old_dt: The time delta of the current array.\n    :type new_start: float\n    :param new_start: The start of the interpolated array. Must be greater\n        or equal to the current start of the array.\n    :type new_dt: float\n    :param new_dt: The desired new time delta.\n    :type new_npts: int\n    :param new_npts: The new number of samples.\n    :type a: int\n    :param a: The width of the window in samples on either side. Runtime\n        scales linearly with the value of ``a`` but the interpolation also gets\n        better.\n    :type window: str\n    :param window: The window used to taper the sinc function. One of\n        ``\"lanczos\"``, ``\"hanning\"``, ``\"blackman\"``. The window determines\n        the trade-off between \"sharpness\" and the amplitude of the wiggles in\n        the pass and stop band. Please use the\n        :func:`~obspy.signal.interpolation.plot_lanczos_windows` function to\n        judge these for any given application.\n\n    Values of ``a`` >= 20 show good results even for data that has\n    energy close to the Nyquist frequency. If your data is extremely\n    oversampled you can get away with much smaller ``a``'s.\n\n    To get an idea of the response of the filter and the effect of the\n    different windows, please use the\n    :func:`~obspy.signal.interpolation.plot_lanczos_windows` function.\n\n    Also be aware of any boundary effects. All values outside the data\n    range are assumed to be zero which matters when calculating interpolated\n    values at the boundaries. At each side the area with potential boundary\n    effects is ``a`` * ``old_dt``. If you want to avoid any boundary effects\n    you will have to remove these values.\n\n    **Mathematical Details:**\n\n    The :math:`\\\\operatorname{sinc}` function is defined as\n\n    .. math::\n\n        \\\\operatorname{sinc}(t) = \\\\frac{\\\\sin(\\\\pi t)}{\\\\pi t}.\n\n    The Lanczos kernel is then given by a multiplication of the\n    :math:`\\\\operatorname{sinc}` function with an additional window function\n    resulting in a finite support kernel.\n\n    .. math::\n\n        \\\\begin{align}\n            L(t) =\n            \\\\begin{cases}\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\operatorname{sinc}(t/a)\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{lanczos}\\\\\\\\\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\frac{1}{2}\n                (1 + \\\\cos(\\\\pi\\\\, t/a))\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{hanning}\\\\\\\\\n                \\\\operatorname{sinc}(t)\\\\, \\\\cdot \\\\left( \\\\frac{21}{50} +\n                \\\\frac{1}{2}\n                \\\\cos(\\\\pi\\\\, t/a) + \\\\frac{2}{25} \\\\cos (2\\\\pi\\\\, t/a) \\\\right)\n                    & \\\\text{if } t \\\\in [-a, a]\n                    \\\\text{ and } \\\\texttt{window} = \\\\texttt{blackman}\\\\\\\\\n                0                     & \\\\text{else}\n            \\\\end{cases}\n        \\\\end{align}\n\n\n    Finally interpolation is performed by convolving the discrete signal\n    :math:`s_i` with that kernel and evaluating it at the new time samples\n    :math:`t_j`:\n\n    .. math::\n\n        \\\\begin{align}\n            S(t_j) =\n                \\\\sum_{i = \\\\left \\\\lfloor{t_j / \\\\Delta t}\\\\right \\\\rfloor -a + 1}\n                    ^{\\\\left \\\\lfloor{t_j / \\\\Delta t}\\\\right \\\\rfloor + a}\n            s_i L(t_j/\\\\Delta t - i),\n        \\\\end{align}\n\n    where :math:`\\\\lfloor \\\\cdot \\\\rfloor` denotes the floor function. For more\n    details and justification please see [Burger2009]_ and [vanDriel2015]_.\n    \"\"\"\n    _validate_parameters(data, old_start, old_dt, new_start, new_dt, new_npts)\n    dt_factor = float(new_dt) / old_dt\n    offset = (new_start - old_start) / float(old_dt)\n    if offset < 0:\n        raise ValueError(\n            'Cannot extrapolate. Make sure to only interpolate within the time range of the original signal.'\n            )\n    if a < 1:\n        raise ValueError('a must be at least 1.')\n    return_data = np.zeros(new_npts, dtype=np.float64)\n    clibsignal.lanczos_resample(np.require(data, dtype=np.float64),\n        return_data, dt_factor, offset, len(data), len(return_data), int(a), 0)\n    return return_data", "test_code_list": [{"test_code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy.signal.interpolation import lanczos_interpolation\nfrom obspy.signal.interpolation import calculate_lanczos_kernel\nfrom obspy.signal.interpolation import plot_lanczos_windows\n\nclass TestInterpolation():\n\tdef test_lanczos_interpolation(self):\n\t    \"\"\"\n\t        Tests against the instaseis implementation which should work well\n\t        enough.\n\t        \"\"\"\n\t    data = np.array([0.92961609, 0.31637555, 0.18391881, 0.20456028, \n\t        0.56772503, 0.5955447, 0.96451452, 0.6531771, 0.74890664, 0.65356987])\n\t    dt = 1.0\n\t    new_dt = 0.45\n\t    a = 1\n\t    expected_output = np.array([0.92961609, 0.55712768, 0.31720733, \n\t        0.24275977, 0.17825931, 0.16750234, 0.17561933, 0.20626905, \n\t        0.37726064, 0.5647072, 0.47145546, 0.59222238, 0.58665834, \n\t        0.91241347, 0.79909224, 0.61631275, 0.61258393, 0.61611633, \n\t        0.73239733, 0.56371682, 0.65356987])\n\t    output = lanczos_interpolation(data, old_dt=dt, new_start=0.0,\n\t        old_start=0.0, new_dt=new_dt, new_npts=21, a=a)\n\t    np.testing.assert_allclose(output, expected_output, atol=1e-09)\n\t    new_dt = 0.72\n\t    a = 12\n\t    expected_output = np.array([0.92961609, 0.54632548, 0.14335148, \n\t        0.19675436, 0.19030867, 0.41722415, 0.60644459, 0.6018648, \n\t        0.88751628, 0.90970863, 0.58602723, 0.71521445, 0.83288791])\n\t    output = lanczos_interpolation(data, old_dt=dt, new_start=0.0,\n\t        old_start=0.0, new_dt=new_dt, new_npts=13, a=a)\n\t    np.testing.assert_allclose(output, expected_output, atol=1e-09)\n\t\nTestInterpolation().test_lanczos_interpolation()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_interpolation.py"}, {"test_code": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom obspy.signal.interpolation import lanczos_interpolation\nfrom obspy.signal.interpolation import calculate_lanczos_kernel\nfrom obspy.signal.interpolation import plot_lanczos_windows\n\nclass TestInterpolation():\n\tdef test_lanczos_interpolation_units(self):\n\t    \"\"\"\n\t        Regression test for a bug that manifested when the original sampling\n\t        rate is not 1 Hertz and new and old start times are not identical.\n\t        \"\"\"\n\t    original_dt = 13.333\n\t    new_dt = 17.23\n\t    data = np.sin(np.linspace(0, 2 * np.pi, 1000))\n\t    output = lanczos_interpolation(data, old_dt=original_dt, new_start=10 *\n\t        original_dt, old_start=0.0, a=20, new_dt=new_dt, new_npts=int(990 *\n\t        original_dt / new_dt))\n\t    output = lanczos_interpolation(output, old_dt=new_dt, new_start=10 *\n\t        original_dt, old_start=0.0, a=20, new_dt=original_dt, new_npts=int(\n\t        980 * original_dt / new_dt) - 1)\n\t    np.testing.assert_allclose(data[220:620], output[200:600], atol=0.0001,\n\t        rtol=0.0001)\n\t\nTestInterpolation().test_lanczos_interpolation_units()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_interpolation.py"}], "method_code_mask": "import numpy as np\nimport scipy.interpolate\nfrom obspy.signal.headers import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef lanczos_interpolation(data, old_start, old_dt, new_start, new_dt,\n    new_npts, a, window='lanczos', *args, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "konno_ohmachi_smoothing_window", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "response": "import warnings\nimport numpy as np\ndef konno_ohmachi_smoothing_window(frequencies, center_frequency, bandwidth\n    =40.0, normalize=False):\n    \"\"\"\n    Returns the Konno & Ohmachi Smoothing window for every frequency in\n    frequencies.\n\n    Returns the smoothing window around the center frequency with one value per\n    input frequency defined as follows (see [Konno1998]_)::\n\n        [sin(b * log_10(f/f_c)) / (b * log_10(f/f_c)]^4\n            b   = bandwidth\n            f   = frequency\n            f_c = center frequency\n\n    The bandwidth of the smoothing function is constant on a logarithmic scale.\n    A small value will lead to a strong smoothing, while a large value of will\n    lead to a low smoothing of the Fourier spectra.\n    The default (and generally used) value for the bandwidth is 40. (From the\n    `Geopsy documentation <http://www.geopsy.org>`_)\n\n    All parameters need to be positive. This is not checked due to performance\n    reasons and therefore any negative parameters might have unexpected\n    results.\n\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        All frequencies for which the smoothing window will be returned.\n    :type center_frequency: float\n    :param center_frequency:\n        The frequency around which the smoothing is performed. Must be greater\n        or equal to 0.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    if frequencies.dtype != np.float32 and frequencies.dtype != np.float64:\n        msg = 'frequencies needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if center_frequency == 0:\n        smoothing_window = np.zeros(len(frequencies), dtype=frequencies.dtype)\n        smoothing_window[frequencies == 0.0] = 1.0\n        return smoothing_window\n    with np.errstate(divide='ignore', invalid='ignore'):\n        smoothing_window = bandwidth * np.log10(frequencies / center_frequency)\n        smoothing_window[:] = (np.sin(smoothing_window) / smoothing_window\n            ) ** 4\n    smoothing_window[frequencies == center_frequency] = 1.0\n    smoothing_window[frequencies == 0.0] = 0.0\n    if normalize:\n        smoothing_window /= smoothing_window.sum()\n    return smoothing_window", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom obspy.signal.konnoohmachismoothing import calculate_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import apply_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing_window\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing\nimport pytest\n\nclass TestKonnoOhmachi():\n\tdef test_smoothing_matrix(self):\n\t    \"\"\"\n\t        Tests some aspects of the matrix.\n\t        \"\"\"\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float32)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0)\n\t    assert matrix.dtype == np.float32\n\t    for _i, freq in enumerate(frequencies):\n\t        np.testing.assert_array_equal(matrix[_i],\n\t            konno_ohmachi_smoothing_window(frequencies, freq, 20.0))\n\t        if freq >= 10.0:\n\t            assert matrix[_i].sum() > 1.0\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float64)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0)\n\t    assert matrix.dtype == np.float64\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float32)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0, normalize=True)\n\t    assert matrix.dtype == np.float32\n\t    for _i, freq in enumerate(frequencies):\n\t        np.testing.assert_array_equal(matrix[_i],\n\t            konno_ohmachi_smoothing_window(frequencies, freq, 20.0,\n\t            normalize=True))\n\t        assert round(abs(matrix[_i].sum() - 1.0), 5) == 0\n\t\nTestKonnoOhmachi().test_smoothing_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_konnoohmachi.py"}], "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef konno_ohmachi_smoothing_window(frequencies, center_frequency, bandwidth\n    =40.0, normalize=False): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "calculate_smoothing_matrix", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "response": "import warnings\nimport numpy as np\ndef calculate_smoothing_matrix(frequencies, bandwidth=40.0, normalize=False):\n    \"\"\"\n    Calculates a len(frequencies) x len(frequencies) matrix with the Konno &\n    Ohmachi window for each frequency as the center frequency.\n\n    Any spectrum with the same frequency bins as this matrix can later be\n    smoothed by using\n    :func:`~obspy.signal.konnoohmachismoothing.apply_smoothing_matrix`.\n\n    This also works for many spectra stored in one large matrix and is even\n    more efficient.\n\n    This makes it very efficient for smoothing the same spectra again and again\n    but it comes with a high memory consumption for larger frequency arrays!\n\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        The input frequencies.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    sm_matrix = np.empty((len(frequencies), len(frequencies)), frequencies.\n        dtype)\n    for _i, freq in enumerate(frequencies):\n        sm_matrix[_i, :] = konno_ohmachi_smoothing_window(frequencies, freq,\n            bandwidth, normalize=normalize)\n    return sm_matrix", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom obspy.signal.konnoohmachismoothing import calculate_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import apply_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing_window\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing\nimport pytest\n\nclass TestKonnoOhmachi():\n\tdef test_smoothing_matrix(self):\n\t    \"\"\"\n\t        Tests some aspects of the matrix.\n\t        \"\"\"\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float32)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0)\n\t    assert matrix.dtype == np.float32\n\t    for _i, freq in enumerate(frequencies):\n\t        np.testing.assert_array_equal(matrix[_i],\n\t            konno_ohmachi_smoothing_window(frequencies, freq, 20.0))\n\t        if freq >= 10.0:\n\t            assert matrix[_i].sum() > 1.0\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float64)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0)\n\t    assert matrix.dtype == np.float64\n\t    frequencies = np.array([0.0, 1.0, 2.0, 10.0, 25.0, 50.0, 100.0], dtype=\n\t        np.float32)\n\t    matrix = calculate_smoothing_matrix(frequencies, 20.0, normalize=True)\n\t    assert matrix.dtype == np.float32\n\t    for _i, freq in enumerate(frequencies):\n\t        np.testing.assert_array_equal(matrix[_i],\n\t            konno_ohmachi_smoothing_window(frequencies, freq, 20.0,\n\t            normalize=True))\n\t        assert round(abs(matrix[_i].sum() - 1.0), 5) == 0\n\t\nTestKonnoOhmachi().test_smoothing_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_konnoohmachi.py"}, {"test_code": "import warnings\nimport numpy as np\nfrom obspy.signal.konnoohmachismoothing import calculate_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import apply_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing_window\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing\nimport pytest\n\nclass TestKonnoOhmachi():\n\tdef test_konno_ohmachi_smoothing(self):\n\t    \"\"\"\n\t        Tests the actual smoothing matrix.\n\t        \"\"\"\n\t    np.random.seed(1111)\n\t    spectra = np.random.ranf((5, 200)) * 50\n\t    frequencies = np.logspace(-3.0, 2.0, 200)\n\t    spectra = np.require(spectra, dtype=np.float32)\n\t    frequencies = np.require(frequencies, dtype=np.float64)\n\t    with pytest.raises(ValueError):\n\t        konno_ohmachi_smoothing(spectra, np.arange(200))\n\t    with warnings.catch_warnings(record=True):\n\t        warnings.simplefilter('error', UserWarning)\n\t        with pytest.raises(UserWarning):\n\t            konno_ohmachi_smoothing(spectra, frequencies)\n\t    frequencies = np.require(frequencies, dtype=np.float32)\n\t    smoothed_1 = konno_ohmachi_smoothing(spectra, frequencies, count=3)\n\t    smoothed_2 = konno_ohmachi_smoothing(spectra, frequencies, count=3,\n\t        max_memory_usage=0)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_2, 3)\n\t    smoothing_matrix = calculate_smoothing_matrix(frequencies)\n\t    smoothed_3 = apply_smoothing_matrix(spectra, smoothing_matrix, count=3)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_3, 3)\n\t    smoothed_4 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64))\n\t    smoothed_5 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64), normalize=True)\n\t    assert not np.all(smoothed_4 == smoothed_5)\n\t    assert smoothed_4.dtype == np.float64\n\t\nTestKonnoOhmachi().test_konno_ohmachi_smoothing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_konnoohmachi.py"}], "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef calculate_smoothing_matrix(frequencies, bandwidth=40.0, normalize=False): [\n    MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "apply_smoothing_matrix", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "response": "import warnings\nimport numpy as np\ndef apply_smoothing_matrix(spectra, smoothing_matrix, count=1):\n    \"\"\"\n    Smooths a matrix containing one spectra per row with the Konno-Ohmachi\n    smoothing window, using a smoothing matrix pre-computed through the\n    :func:`~obspy.signal.konnoohmachismoothing.calculate_smoothing_matrix`\n    function.\n    This function is useful if one needs to smooth the same type of spectrum\n    (same shape) through different function calls.\n\n    All spectra need to have frequency bins corresponding to the same\n    frequencies.\n    \"\"\"\n    if spectra.dtype not in (np.float32, np.float64):\n        msg = '`spectra` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    new_spec = np.dot(spectra, smoothing_matrix)\n    for _i in range(count - 1):\n        new_spec = np.dot(new_spec, smoothing_matrix)\n    return new_spec", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom obspy.signal.konnoohmachismoothing import calculate_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import apply_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing_window\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing\nimport pytest\n\nclass TestKonnoOhmachi():\n\tdef test_konno_ohmachi_smoothing(self):\n\t    \"\"\"\n\t        Tests the actual smoothing matrix.\n\t        \"\"\"\n\t    np.random.seed(1111)\n\t    spectra = np.random.ranf((5, 200)) * 50\n\t    frequencies = np.logspace(-3.0, 2.0, 200)\n\t    spectra = np.require(spectra, dtype=np.float32)\n\t    frequencies = np.require(frequencies, dtype=np.float64)\n\t    with pytest.raises(ValueError):\n\t        konno_ohmachi_smoothing(spectra, np.arange(200))\n\t    with warnings.catch_warnings(record=True):\n\t        warnings.simplefilter('error', UserWarning)\n\t        with pytest.raises(UserWarning):\n\t            konno_ohmachi_smoothing(spectra, frequencies)\n\t    frequencies = np.require(frequencies, dtype=np.float32)\n\t    smoothed_1 = konno_ohmachi_smoothing(spectra, frequencies, count=3)\n\t    smoothed_2 = konno_ohmachi_smoothing(spectra, frequencies, count=3,\n\t        max_memory_usage=0)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_2, 3)\n\t    smoothing_matrix = calculate_smoothing_matrix(frequencies)\n\t    smoothed_3 = apply_smoothing_matrix(spectra, smoothing_matrix, count=3)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_3, 3)\n\t    smoothed_4 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64))\n\t    smoothed_5 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64), normalize=True)\n\t    assert not np.all(smoothed_4 == smoothed_5)\n\t    assert smoothed_4.dtype == np.float64\n\t\nTestKonnoOhmachi().test_konno_ohmachi_smoothing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_konnoohmachi.py"}], "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef apply_smoothing_matrix(spectra, smoothing_matrix, count=1): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "konno_ohmachi_smoothing", "method_path": "../srcdata/Computation/obspy/obspy/signal/konnoohmachismoothing.py", "response": "import warnings\nimport numpy as np\ndef konno_ohmachi_smoothing(spectra, frequencies, bandwidth=40, count=1,\n    enforce_no_matrix=False, max_memory_usage=512, normalize=False):\n    \"\"\"\n    Smooths a matrix containing one spectra per row with the Konno-Ohmachi\n    smoothing window.\n\n    All spectra need to have frequency bins corresponding to the same\n    frequencies.\n\n    This method first will estimate the memory usage and then either use a fast\n    and memory intensive method or a slow one with a better memory usage.\n\n    :type spectra: :class:`numpy.ndarray` (float32 or float64)\n    :param spectra:\n        One or more spectra per row. If more than one the first spectrum has to\n        be accessible via spectra[0], the next via spectra[1], ...\n    :type frequencies: :class:`numpy.ndarray` (float32 or float64)\n    :param frequencies:\n        Contains the frequencies for the spectra.\n    :type bandwidth: float\n    :param bandwidth:\n        Determines the width of the smoothing peak. Lower values result in a\n        broader peak. Must be greater than 0. Defaults to 40.\n    :type count: int, optional\n    :param count:\n        How often the apply the filter. For very noisy spectra it is useful to\n        apply is more than once. Defaults to 1.\n    :type enforce_no_matrix: bool, optional\n    :param enforce_no_matrix:\n        An efficient but memory intensive matrix-multiplication algorithm is\n        used in case more than one spectra is to be smoothed or one spectrum is\n        to be smoothed more than once if enough memory is available. This flag\n        disables the matrix algorithm altogether. Defaults to False\n    :type max_memory_usage: int, optional\n    :param max_memory_usage:\n        Set the maximum amount of extra memory in MB for this method. Decides\n        whether or not the matrix multiplication method is used. Defaults to\n        512 MB.\n    :type normalize: bool, optional\n    :param normalize:\n        The Konno-Ohmachi smoothing window is normalized on a logarithmic\n        scale. Set this parameter to True to normalize it on a normal scale.\n        Default to False.\n    \"\"\"\n    if spectra.dtype not in (np.float32, np.float64):\n        msg = '`spectra` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if frequencies.dtype not in (np.float32, np.float64):\n        msg = '`frequencies` needs to have a dtype of float32/64.'\n        raise ValueError(msg)\n    if frequencies.dtype != spectra.dtype:\n        frequencies = np.require(frequencies, np.float64)\n        spectra = np.require(spectra, np.float64)\n        msg = (\n            '`frequencies` and `spectra` should have the same dtype. It ' +\n            'will be changed to np.float64 for both.')\n        warnings.warn(msg)\n    if frequencies.dtype == np.float32:\n        size = 4.0\n    elif frequencies.dtype == np.float64:\n        size = 8.0\n    length = len(frequencies)\n    approx_mem_usage = (length * length + 2 * len(spectra) + length\n        ) * size / 1048576.0\n    if enforce_no_matrix is False and (len(spectra.shape) > 1 or count > 1\n        ) and approx_mem_usage < max_memory_usage:\n        smoothing_matrix = calculate_smoothing_matrix(frequencies,\n            bandwidth, normalize=normalize)\n        return apply_smoothing_matrix(spectra, smoothing_matrix, count=count)\n    else:\n        new_spec = np.empty(spectra.shape, spectra.dtype)\n        if len(new_spec.shape) == 1:\n            for _i in range(len(frequencies)):\n                window = konno_ohmachi_smoothing_window(frequencies,\n                    frequencies[_i], bandwidth, normalize=normalize)\n                new_spec[_i] = (window * spectra).sum()\n        else:\n            for _i in range(len(frequencies)):\n                window = konno_ohmachi_smoothing_window(frequencies,\n                    frequencies[_i], bandwidth, normalize=normalize)\n                for _j, spec in enumerate(spectra):\n                    new_spec[_j, _i] = (window * spec).sum()\n        for _i in range(count - 1):\n            new_spec = konno_ohmachi_smoothing(new_spec, frequencies,\n                bandwidth, enforce_no_matrix=True, normalize=normalize)\n        return new_spec", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom obspy.signal.konnoohmachismoothing import calculate_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import apply_smoothing_matrix\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing_window\nfrom obspy.signal.konnoohmachismoothing import konno_ohmachi_smoothing\nimport pytest\n\nclass TestKonnoOhmachi():\n\tdef test_konno_ohmachi_smoothing(self):\n\t    \"\"\"\n\t        Tests the actual smoothing matrix.\n\t        \"\"\"\n\t    np.random.seed(1111)\n\t    spectra = np.random.ranf((5, 200)) * 50\n\t    frequencies = np.logspace(-3.0, 2.0, 200)\n\t    spectra = np.require(spectra, dtype=np.float32)\n\t    frequencies = np.require(frequencies, dtype=np.float64)\n\t    with pytest.raises(ValueError):\n\t        konno_ohmachi_smoothing(spectra, np.arange(200))\n\t    with warnings.catch_warnings(record=True):\n\t        warnings.simplefilter('error', UserWarning)\n\t        with pytest.raises(UserWarning):\n\t            konno_ohmachi_smoothing(spectra, frequencies)\n\t    frequencies = np.require(frequencies, dtype=np.float32)\n\t    smoothed_1 = konno_ohmachi_smoothing(spectra, frequencies, count=3)\n\t    smoothed_2 = konno_ohmachi_smoothing(spectra, frequencies, count=3,\n\t        max_memory_usage=0)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_2, 3)\n\t    smoothing_matrix = calculate_smoothing_matrix(frequencies)\n\t    smoothed_3 = apply_smoothing_matrix(spectra, smoothing_matrix, count=3)\n\t    np.testing.assert_almost_equal(smoothed_1, smoothed_3, 3)\n\t    smoothed_4 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64))\n\t    smoothed_5 = konno_ohmachi_smoothing(np.require(spectra[0], dtype=np.\n\t        float64), np.require(frequencies, dtype=np.float64), normalize=True)\n\t    assert not np.all(smoothed_4 == smoothed_5)\n\t    assert smoothed_4.dtype == np.float64\n\t\nTestKonnoOhmachi().test_konno_ohmachi_smoothing()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_konnoohmachi.py"}], "method_code_mask": "import warnings\nimport numpy as np\n\n\ndef konno_ohmachi_smoothing(spectra, frequencies, bandwidth=40, count=1,\n    enforce_no_matrix=False, max_memory_usage=512, normalize=False): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "correlate", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate(a, b, shift, demean=True, normalize='naive', method='auto'):\n    \"\"\"\n    Cross-correlation of two signals up to a specified maximal shift.\n\n    This function only allows 'naive' normalization with the overall\n    standard deviations. This is a reasonable approximation for signals of\n    similar length and a relatively small shift parameter\n    (e.g. noise cross-correlation).\n    If you are interested in the full cross-correlation function better use\n    :func:`~obspy.signal.cross_correlation.correlate_template` which also\n    provides correct normalization.\n\n    :type a: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param a: first signal\n    :type b: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param b: second signal to correlate with first signal\n    :param int shift: Number of samples to shift for cross correlation.\n        The cross-correlation will consist of ``2*shift+1`` or\n        ``2*shift`` samples. The sample with zero shift will be in the middle.\n    :param bool demean: Demean data beforehand.\n    :param normalize: Method for normalization of cross-correlation.\n        One of ``'naive'`` or ``None``\n        (``True`` and ``False`` are supported for backwards compatibility).\n        ``'naive'`` normalizes by the overall standard deviation.\n        ``None`` does not normalize.\n    :param str method: Method to use to calculate the correlation.\n         ``'direct'``: The correlation is determined directly from sums,\n         the definition of correlation.\n         ``'fft'`` The Fast Fourier Transform is used to perform the\n         correlation more quickly.\n         ``'auto'`` Automatically chooses direct or Fourier method based on an\n         estimate of which is faster. (Only availlable for SciPy versions >=\n         0.19. For older Scipy version method defaults to ``'fft'``.)\n\n    :return: cross-correlation function.\n\n    To calculate shift and value of the maximum of the returned\n    cross-correlation function use\n    :func:`~obspy.signal.cross_correlation.xcorr_max`.\n\n    .. note::\n\n        For most input parameters cross-correlation using the FFT is much\n        faster.\n        Only for small values of ``shift`` (approximately less than 100)\n        direct time domain cross-correlation migth save some time.\n\n    .. note::\n\n        If the signals have different length, they will be aligned around\n        their middle. The sample with zero shift in the cross-correlation\n        function corresponds to this correlation:\n\n        ::\n\n            --aaaa--\n            bbbbbbbb\n\n        For odd ``len(a)-len(b)`` the cross-correlation function will\n        consist of only ``2*shift`` samples because a shift of 0\n        corresponds to the middle between two samples.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> a = read()[0][450:550]\n    >>> b = a[:-2]\n    >>> cc = correlate(a, b, 2)\n    >>> cc\n    array([ 0.62390515,  0.99630851,  0.62187106, -0.05864797, -0.41496995])\n    >>> shift, value = xcorr_max(cc)\n    >>> shift\n    -1\n    >>> round(value, 3)\n    0.996\n    \"\"\"\n    if normalize is False:\n        normalize = None\n    if normalize is True:\n        normalize = 'naive'\n    if isinstance(a, Trace):\n        a = a.data\n    if isinstance(b, Trace):\n        b = b.data\n    a = np.asarray(a)\n    b = np.asarray(b)\n    if demean:\n        a = a - np.mean(a)\n        b = b - np.mean(b)\n    _xcorr = _xcorr_padzeros if method == 'direct' else _xcorr_slice\n    cc = _xcorr(a, b, shift, method)\n    if normalize == 'naive':\n        norm = (np.sum(a ** 2) * np.sum(b ** 2)) ** 0.5\n        if norm <= np.finfo(float).eps:\n            cc[:] = 0\n        elif cc.dtype == float:\n            cc /= norm\n        else:\n            cc = cc / norm\n    elif normalize is not None:\n        raise ValueError(\"normalize has to be one of (None, 'naive'))\")\n    return cc", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_normalize_true_false(self):\n\t    a = read()[0].data[500:]\n\t    b = a[10:]\n\t    shift = 100\n\t    cc1 = correlate(a, b, shift, normalize='naive')\n\t    cc2 = correlate(a, b, shift, normalize=True)\n\t    cc3 = correlate(a, b, shift, normalize=None)\n\t    cc4 = correlate(a, b, shift, normalize=False)\n\t    np.testing.assert_allclose(cc1, cc2, rtol=1e-06)\n\t    np.testing.assert_allclose(cc3, cc4, rtol=1e-06)\n\t\nTestCrossCorrelation().test_correlate_normalize_true_false()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate(self):\n\t    a, b = [0, 1], [20, 10]\n\t    cc = correlate(a, b, 1, demean=False, normalize=False)\n\t    shift, value = xcorr_max(cc)\n\t    assert shift == 1\n\t    assert round(abs(value - 20.0), 7) == 0\n\t    np.testing.assert_allclose(cc, [0.0, 10.0, 20.0], atol=1e-14)\n\t    a, b = [0, 1, 2], [20, 10]\n\t    cc1 = correlate(a, b, 1, demean=False, normalize=False, method='fft')\n\t    cc2 = correlate(a, b, 1, demean=False, normalize=False, method='direct')\n\t    cc3 = correlate(b, a, 1, demean=False, normalize=False, method='fft')\n\t    cc4 = correlate(b, a, 1, demean=False, normalize=False, method='direct')\n\t    shift1, _ = xcorr_max(cc1)\n\t    shift2, _ = xcorr_max(cc2)\n\t    shift3, _ = xcorr_max(cc3)\n\t    shift4, _ = xcorr_max(cc4)\n\t    assert shift1 == 0.5\n\t    assert shift2 == 0.5\n\t    assert shift3 == -0.5\n\t    assert shift4 == -0.5\n\t    np.testing.assert_allclose(cc1, cc2)\n\t    np.testing.assert_allclose(cc3, cc4)\n\t    np.testing.assert_allclose(cc1, cc3[::-1])\n\t    a, b = [0, 1, 2, 3, 4, 5, 6, 7], [20, 10]\n\t    cc1 = correlate(a, b, 2, method='direct')\n\t    cc2 = correlate(b, a, 2, method='direct')\n\t    np.testing.assert_allclose(cc1, cc2[::-1])\n\t\nTestCrossCorrelation().test_correlate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_extreme_shifts_for_freq_xcorr(self):\n\t    \"\"\"\n\t        Also test shift=None\n\t        \"\"\"\n\t    a, b = [1, 2, 3], [1, 2, 3]\n\t    n = len(a) + len(b) - 1\n\t    cc1 = correlate(a, b, 2, method='fft')\n\t    cc2 = correlate(a, b, 3, method='fft')\n\t    cc3 = correlate(a, b, None, method='fft')\n\t    cc4 = correlate(a, b, None, method='direct')\n\t    assert len(cc1) == n\n\t    assert len(cc2) == 2 + n\n\t    assert len(cc3) == n\n\t    assert len(cc4) == n\n\t    a, b = [1, 2, 3], [1, 2]\n\t    n = len(a) + len(b) - 1\n\t    cc1 = correlate(a, b, 2, method='fft')\n\t    cc2 = correlate(a, b, 3, method='fft')\n\t    cc3 = correlate(a, b, None, method='fft')\n\t    cc4 = correlate(a, b, None, method='direct')\n\t    assert len(cc1) == n\n\t    assert len(cc2) == 2 + n\n\t    assert len(cc3) == n\n\t    assert len(cc4) == n\n\t\nTestCrossCorrelation().test_correlate_extreme_shifts_for_freq_xcorr()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_versus_correlate(self):\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    xcorr1 = correlate_template(data, template, normalize='naive')\n\t    xcorr2 = correlate(data, template, 20)\n\t    np.testing.assert_equal(xcorr1, xcorr2)\n\t\nTestCrossCorrelation().test_correlate_template_versus_correlate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_integer_input_equals_float_input(self):\n\t    a = [-3, 0, 4]\n\t    b = [-3, 4]\n\t    c = np.array(a, dtype=float)\n\t    d = np.array(b, dtype=float)\n\t    for demean in (True, False):\n\t        for normalize in (None, 'naive'):\n\t            cc1 = correlate(a, b, 3, demean=demean, normalize=normalize,\n\t                method='direct')\n\t            cc2 = correlate(c, d, 3, demean=demean, normalize=normalize)\n\t            np.testing.assert_allclose(cc1, cc2)\n\t        for normalize in (None, 'naive', 'full'):\n\t            cc3 = correlate_template(a, b, demean=demean, normalize=\n\t                normalize, method='direct')\n\t            cc4 = correlate_template(c, d, demean=demean, normalize=normalize)\n\t            np.testing.assert_allclose(cc3, cc4)\n\t\nTestCrossCorrelation().test_integer_input_equals_float_input()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate(a, b, shift, demean=True, normalize='naive', method='auto'): [M\n    ASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_load_cdll", "method_path": "../srcdata/Computation/obspy/obspy/core/util/libnames.py", "response": "import ctypes\nimport importlib.machinery\nfrom pathlib import Path\nimport re\nimport doctest\ndef _load_cdll(name):\n    \"\"\"\n    Helper function to load a shared library built during ObsPy installation\n    with ctypes.\n\n    :type name: str\n    :param name: Name of the library to load (e.g. 'mseed').\n    :rtype: :class:`ctypes.CDLL`\n    \"\"\"\n    errors = []\n    libdir = Path(__file__).parent.parent.parent / 'lib'\n    for ext in importlib.machinery.EXTENSION_SUFFIXES:\n        libpath = (libdir / (name + ext)).resolve()\n        try:\n            cdll = ctypes.CDLL(str(libpath))\n        except Exception as e:\n            errors.append(f'    {str(e)}')\n        else:\n            return cdll\n    raise ImportError('\\n  '.join([\n        f'Could not load shared library \"{name}\"', *errors, \n        'Current directory: %s' % Path().resolve(),\n        'Directory listing of lib directory:', *(f'    {str(d)}' for d in\n        sorted(libpath.parent.iterdir()))]))", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_srl_xcorr(self):\n\t    \"\"\"\n\t        Tests if example in ObsPy paper submitted to the Electronic\n\t        Seismologist section of SRL is still working. The test shouldn't be\n\t        changed because the reference gets wrong.\n\t        \"\"\"\n\t    np.random.seed(815)\n\t    data1 = np.random.randn(1000).astype(np.float32)\n\t    data2 = data1.copy()\n\t    window_len = 100\n\t    corp = np.empty(2 * window_len + 1, dtype=np.float64)\n\t    lib = _load_cdll('signal')\n\t    shift = C.c_int()\n\t    coe_p = C.c_double()\n\t    res = lib.X_corr(data1.ctypes.data_as(C.c_void_p), data2.ctypes.data_as\n\t        (C.c_void_p), corp.ctypes.data_as(C.c_void_p), window_len, len(\n\t        data1), len(data2), C.byref(shift), C.byref(coe_p))\n\t    assert 0 == res\n\t    assert round(abs(0.0 - shift.value), 7) == 0\n\t    assert round(abs(1.0 - coe_p.value), 7) == 0\n\t\nTestCrossCorrelation().test_srl_xcorr()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "import ctypes\nimport importlib.machinery\nfrom pathlib import Path\nimport re\nimport doctest\n\n\ndef _load_cdll(name): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "xcorr_max", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef xcorr_max(fct, abs_max=True):\n    \"\"\"\n    Return shift and value of the maximum of the cross-correlation function.\n\n    :type fct: :class:`~numpy.ndarray`\n    :param fct: Cross-correlation function e.g. returned by correlate.\n    :param bool abs_max: Determines if the largest value of the correlation\n        function is returned, independent of it being positive (correlation) or\n        negative (anti-correlation). Defaults to `True`. If `False` the maximum\n        returned is positive only.\n    :return: **shift, value** - Shift and value of maximum of\n        cross-correlation.\n\n    .. rubric:: Example\n\n    >>> fct = np.zeros(101)\n    >>> fct[50] = -1.0\n    >>> xcorr_max(fct)\n    (0, -1.0)\n    >>> fct[50], fct[60] = 0.0, 1.0\n    >>> xcorr_max(fct)\n    (10, 1.0)\n    >>> fct[60], fct[40] = 0.0, -1.0\n    >>> xcorr_max(fct)\n    (-10, -1.0)\n    >>> fct[60], fct[40] = 0.5, -1.0\n    >>> xcorr_max(fct, abs_max=True)\n    (-10, -1.0)\n    >>> xcorr_max(fct, abs_max=False)\n    (10, 0.5)\n    >>> xcorr_max(fct[:-1], abs_max=False)\n    (10.5, 0.5)\n    \"\"\"\n    mid = (len(fct) - 1) / 2\n    if len(fct) % 2 == 1:\n        mid = int(mid)\n    index = np.argmax(np.abs(fct) if abs_max else fct)\n    return index - mid, float(fct[index])", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate(self):\n\t    a, b = [0, 1], [20, 10]\n\t    cc = correlate(a, b, 1, demean=False, normalize=False)\n\t    shift, value = xcorr_max(cc)\n\t    assert shift == 1\n\t    assert round(abs(value - 20.0), 7) == 0\n\t    np.testing.assert_allclose(cc, [0.0, 10.0, 20.0], atol=1e-14)\n\t    a, b = [0, 1, 2], [20, 10]\n\t    cc1 = correlate(a, b, 1, demean=False, normalize=False, method='fft')\n\t    cc2 = correlate(a, b, 1, demean=False, normalize=False, method='direct')\n\t    cc3 = correlate(b, a, 1, demean=False, normalize=False, method='fft')\n\t    cc4 = correlate(b, a, 1, demean=False, normalize=False, method='direct')\n\t    shift1, _ = xcorr_max(cc1)\n\t    shift2, _ = xcorr_max(cc2)\n\t    shift3, _ = xcorr_max(cc3)\n\t    shift4, _ = xcorr_max(cc4)\n\t    assert shift1 == 0.5\n\t    assert shift2 == 0.5\n\t    assert shift3 == -0.5\n\t    assert shift4 == -0.5\n\t    np.testing.assert_allclose(cc1, cc2)\n\t    np.testing.assert_allclose(cc3, cc4)\n\t    np.testing.assert_allclose(cc1, cc3[::-1])\n\t    a, b = [0, 1, 2, 3, 4, 5, 6, 7], [20, 10]\n\t    cc1 = correlate(a, b, 2, method='direct')\n\t    cc2 = correlate(b, a, 2, method='direct')\n\t    np.testing.assert_allclose(cc1, cc2[::-1])\n\t\nTestCrossCorrelation().test_correlate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_xcorr_max(self):\n\t    shift, value = xcorr_max((1, 3, -5))\n\t    assert shift == 1\n\t    assert value == -5\n\t    shift, value = xcorr_max((3.0, -5.0), abs_max=False)\n\t    assert shift == -0.5\n\t    assert value == 3.0\n\t\nTestCrossCorrelation().test_xcorr_max()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_eqcorrscan(self):\n\t    \"\"\"\n\t        Test for moving window correlations with \"full\" normalisation.\n\t\n\t        Comparison result is from EQcorrscan v.0.2.7, using the following:\n\t\n\t        from eqcorrscan.utils.correlate import get_array_xcorr\n\t        from obspy import read\n\t\n\t        data = read()[0].data\n\t        template = data[400:600]\n\t        data = data[380:620]\n\t        eqcorrscan_func = get_array_xcorr(\"fftw\")\n\t        result = eqcorrscan_func(\n\t            stream=data, templates=template.reshape(1, len(template)),\n\t            pads=[0])[0][0]\n\t        \"\"\"\n\t    result = [-0.224548906, 0.0710350871, 0.268642932, 0.275941312, \n\t        0.166854098, 0.0166086946, -0.129057273, -0.196172655, -0.141613603,\n\t        -0.00683271606, 0.145768464, 0.242143899, 0.198310092, \n\t        0.000216377302, -0.24157688, -0.400586188, -0.432240069, -\n\t        0.288735539, 0.126461715, 0.709268868, 0.99999994, 0.722769439, \n\t        0.175955653, -0.246459037, -0.43402788, -0.432590246, -0.267131507,\n\t        -0.000678363896, 0.208171085, 0.232197508, 0.0864804164, -\n\t        0.114158235, -0.253621429, -0.262945205, -0.140505865, 0.0335594788,\n\t        0.177415669, 0.272263527, 0.281718552, 0.138080209, -0.127307668]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    cc = correlate_template(data, template)\n\t    np.testing.assert_allclose(cc, result, atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert round(abs(corr - 1.0), 7) == 0\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_eqcorrscan()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_eqcorrscan_time(self):\n\t    \"\"\"\n\t        Test full normalization for method='direct'.\n\t        \"\"\"\n\t    result = [-0.224548906, 0.0710350871, 0.268642932, 0.275941312, \n\t        0.166854098, 0.0166086946, -0.129057273, -0.196172655, -0.141613603,\n\t        -0.00683271606, 0.145768464, 0.242143899, 0.198310092, \n\t        0.000216377302, -0.24157688, -0.400586188, -0.432240069, -\n\t        0.288735539, 0.126461715, 0.709268868, 0.99999994, 0.722769439, \n\t        0.175955653, -0.246459037, -0.43402788, -0.432590246, -0.267131507,\n\t        -0.000678363896, 0.208171085, 0.232197508, 0.0864804164, -\n\t        0.114158235, -0.253621429, -0.262945205, -0.140505865, 0.0335594788,\n\t        0.177415669, 0.272263527, 0.281718552, 0.138080209, -0.127307668]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    cc = correlate_template(data, template, method='direct')\n\t    np.testing.assert_allclose(cc, result, atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert round(abs(corr - 1.0), 7) == 0\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_eqcorrscan_time()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_nodemean_fastmatchedfilter(self):\n\t    \"\"\"\n\t        Compare non-demeaned result against FMF derived result.\n\t\n\t        FMF result obtained by the following:\n\t\n\t        import copy\n\t        import numpy as np\n\t        from fast_matched_filter import matched_filter\n\t        from obspy import read\n\t\n\t        data = read()[0].data\n\t        template = copy.deepcopy(data[400:600])\n\t        data = data[380:620]\n\t        result = matched_filter(\n\t            templates=template.reshape(1, 1, 1, len(template)),\n\t            moveouts=np.array(0).reshape(1, 1, 1),\n\t            weights=np.array(1).reshape(1, 1, 1),\n\t            data=data.reshape(1, 1, len(data)),\n\t            step=1, arch='cpu')[0]\n\t\n\t        .. note::\n\t            FastMatchedFilter doesn't use semver, but result generated by Calum\n\t            Chamberlain on 18 Jan 2018 using up-to-date code, with the patch\n\t            in https://github.com/beridel/fast_matched_filter/pull/12\n\t        \"\"\"\n\t    result = [-0.148108244, 0.047153227, 0.182797655, 0.192574233, \n\t        0.118700281, 0.0118958903, -0.0923405439, -0.140047163, -\n\t        0.100863703, -0.00486961426, 0.104124829, 0.172662303, 0.141110823,\n\t        0.000153776666, -0.171214968, -0.283201426, -0.304899812, -\n\t        0.203215942, 0.0888349637, 0.500749528, 0.718140483, 0.529728174, \n\t        0.130591258, -0.183402568, -0.322406143, -0.320676118, -0.19805418,\n\t        -0.000506028766, 0.156253457, 0.174580097, 0.0649696961, -\n\t        0.0856237561, -0.189858019, -0.19650431, -0.10496819, 0.0251029599,\n\t        0.132686019, 0.203692451, 0.211983219, 0.0, 0.0]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    template = template - template.mean()\n\t    cc = correlate_template(data, template, demean=False)\n\t    np.testing.assert_allclose(cc[0:-2], result[0:-2], atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_nodemean_fastmatchedfilter()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef xcorr_max(fct, abs_max=True): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "xcorr_3c", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef xcorr_3c(st1, st2, shift_len, components=['Z', 'N', 'E'], full_xcorr=\n    False, abs_max=True):\n    \"\"\"\n    Calculates the cross correlation on each of the specified components\n    separately, stacks them together and estimates the maximum and shift of\n    maximum on the stack.\n\n    Basically the same as `~obspy.signal.cross_correlation.correlate` but\n    for (normally) three components, please also take a look at the\n    documentation of that function. Useful e.g. for estimation of waveform\n    similarity on a three component seismogram.\n\n    :type st1: :class:`~obspy.core.stream.Stream`\n    :param st1: Stream 1, containing one trace for Z, N, E component (other\n        component_id codes are ignored)\n    :type st2: :class:`~obspy.core.stream.Stream`\n    :param st2: Stream 2, containing one trace for Z, N, E component (other\n        component_id codes are ignored)\n    :type shift_len: int\n    :param shift_len: Total length of samples to shift for cross correlation.\n    :type components: list[str]\n    :param components: List of components to use in cross-correlation, defaults\n        to ``['Z', 'N', 'E']``.\n    :type full_xcorr: bool\n    :param full_xcorr: If ``True``, the complete xcorr function will be\n        returned as :class:`~numpy.ndarray`.\n    :param bool abs_max: *shift* will be calculated for maximum or\n        absolute maximum.\n    :return: **index, value[, fct]** - index of maximum xcorr value and the\n        value itself. The complete xcorr function is returned only if\n        ``full_xcorr=True``.\n    \"\"\"\n    streams = [st1, st2]\n    for st in streams:\n        if not isinstance(st, Stream):\n            raise TypeError('Expected Stream object but got %s.' % type(st))\n        for component in components:\n            if not len(st.select(component=component)) == 1:\n                msg = ('Expected exactly one %s trace in stream' %\n                    component + ' but got %s.' % len(st.select(component=\n                    component)))\n                raise ValueError(msg)\n    ndat = len(streams[0].select(component=components[0])[0])\n    if False in [(len(st.select(component=component)[0]) == ndat) for st in\n        streams for component in components]:\n        raise ValueError('All traces have to be the same length.')\n    corp = np.zeros(2 * shift_len + 1, dtype=np.float64, order='C')\n    for component in components:\n        xx = correlate(streams[0].select(component=component)[0], streams[1\n            ].select(component=component)[0], shift_len)\n        corp += xx\n    corp /= len(components)\n    shift, value = xcorr_max(corp, abs_max=abs_max)\n    if full_xcorr:\n        return shift, value, corp\n    else:\n        return shift, value", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_xcorr_3c(self):\n\t    st = read()\n\t    st2 = read()\n\t    for tr in st2:\n\t        tr.data = -5 * np.roll(tr.data, 50)\n\t    shift, value, x = xcorr_3c(st, st2, 200, full_xcorr=True)\n\t    assert shift == -50\n\t    assert round(abs(value - -0.998), 3) == 0\n\t\nTestCrossCorrelation().test_xcorr_3c()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef xcorr_3c(st1, st2, shift_len, components=['Z', 'N', 'E'], full_xcorr=\n    False, abs_max=True): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "correlate_template", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate_template(data, template, mode='valid', normalize='full',\n    demean=True, method='auto'):\n    \"\"\"\n    Normalized cross-correlation of two signals with specified mode.\n\n    If you are interested only in a part of the cross-correlation function\n    around zero shift consider using function\n    :func:`~obspy.signal.cross_correlation.correlate` which allows to\n    explicetly specify the maximum shift.\n\n    :type data: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param data: first signal\n    :type template: :class:`~numpy.ndarray`, :class:`~obspy.core.trace.Trace`\n    :param template: second signal to correlate with first signal.\n        Its length must be smaller or equal to the length of ``data``.\n    :param str mode: correlation mode to use.\n        It is passed to the used correlation function.\n        See :func:`scipy.signal.correlate` for possible options.\n        The parameter determines the length of the correlation function.\n    :param normalize:\n        One of ``'naive'``, ``'full'`` or ``None``.\n        ``'full'`` normalizes every correlation properly,\n        whereas ``'naive'`` normalizes by the overall standard deviations.\n        ``None`` does not normalize.\n    :param demean: Demean data beforehand. For ``normalize='full'`` data is\n        demeaned in different windows for each correlation value.\n    :param str method: Method to use to calculate the correlation.\n         ``'direct'``: The correlation is determined directly from sums,\n         the definition of correlation.\n         ``'fft'`` The Fast Fourier Transform is used to perform the\n         correlation more quickly.\n         ``'auto'`` Automatically chooses direct or Fourier method based on an\n         estimate of which is faster. (Only availlable for SciPy versions >=\n         0.19. For older Scipy version method defaults to ``'fft'``.)\n\n    :return: cross-correlation function.\n\n    .. note::\n        Calling the function with ``demean=True, normalize='full'`` (default)\n        returns the zero-normalized cross-correlation function.\n        Calling the function with ``demean=False, normalize='full'``\n        returns the normalized cross-correlation function.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> data = read()[0]\n    >>> template = data[450:550]\n    >>> cc = correlate_template(data, template)\n    >>> index = np.argmax(cc)\n    >>> index\n    450\n    >>> round(cc[index], 9)\n    1.0\n    \"\"\"\n    if isinstance(data, Trace):\n        data = data.data\n    if isinstance(template, Trace):\n        template = template.data\n    data = np.asarray(data)\n    template = np.asarray(template)\n    lent = len(template)\n    if len(data) < lent:\n        raise ValueError('Data must not be shorter than template.')\n    if demean:\n        template = template - np.mean(template)\n        if normalize != 'full':\n            data = data - np.mean(data)\n    cc = scipy.signal.correlate(data, template, mode=mode, method=method)\n    if normalize is not None:\n        tnorm = np.sum(template ** 2)\n        if normalize == 'naive':\n            norm = (tnorm * np.sum(data ** 2)) ** 0.5\n            if norm <= np.finfo(float).eps:\n                cc[:] = 0\n            elif cc.dtype == float:\n                cc /= norm\n            else:\n                cc = cc / norm\n        elif normalize == 'full':\n            pad = len(cc) - len(data) + lent\n            if mode == 'same':\n                pad1, pad2 = (pad + 2) // 2, (pad - 1) // 2\n            else:\n                pad1, pad2 = (pad + 1) // 2, pad // 2\n            data = _pad_zeros(data, pad1, pad2)\n            if demean:\n                norm = _window_sum(data, lent) ** 2\n                if norm.dtype == float:\n                    norm /= lent\n                else:\n                    norm = norm / lent\n                np.subtract(_window_sum(data ** 2, lent), norm, out=norm)\n            else:\n                norm = _window_sum(data ** 2, lent)\n            norm *= tnorm\n            if norm.dtype == float:\n                np.sqrt(norm, out=norm)\n            else:\n                norm = np.sqrt(norm)\n            mask = norm <= np.finfo(float).eps\n            if cc.dtype == float:\n                cc[~mask] /= norm[~mask]\n            else:\n                cc = cc / norm\n            cc[mask] = 0\n        else:\n            msg = \"normalize has to be one of (None, 'naive', 'full')\"\n            raise ValueError(msg)\n    return cc", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_eqcorrscan(self):\n\t    \"\"\"\n\t        Test for moving window correlations with \"full\" normalisation.\n\t\n\t        Comparison result is from EQcorrscan v.0.2.7, using the following:\n\t\n\t        from eqcorrscan.utils.correlate import get_array_xcorr\n\t        from obspy import read\n\t\n\t        data = read()[0].data\n\t        template = data[400:600]\n\t        data = data[380:620]\n\t        eqcorrscan_func = get_array_xcorr(\"fftw\")\n\t        result = eqcorrscan_func(\n\t            stream=data, templates=template.reshape(1, len(template)),\n\t            pads=[0])[0][0]\n\t        \"\"\"\n\t    result = [-0.224548906, 0.0710350871, 0.268642932, 0.275941312, \n\t        0.166854098, 0.0166086946, -0.129057273, -0.196172655, -0.141613603,\n\t        -0.00683271606, 0.145768464, 0.242143899, 0.198310092, \n\t        0.000216377302, -0.24157688, -0.400586188, -0.432240069, -\n\t        0.288735539, 0.126461715, 0.709268868, 0.99999994, 0.722769439, \n\t        0.175955653, -0.246459037, -0.43402788, -0.432590246, -0.267131507,\n\t        -0.000678363896, 0.208171085, 0.232197508, 0.0864804164, -\n\t        0.114158235, -0.253621429, -0.262945205, -0.140505865, 0.0335594788,\n\t        0.177415669, 0.272263527, 0.281718552, 0.138080209, -0.127307668]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    cc = correlate_template(data, template)\n\t    np.testing.assert_allclose(cc, result, atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert round(abs(corr - 1.0), 7) == 0\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_eqcorrscan()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_eqcorrscan_time(self):\n\t    \"\"\"\n\t        Test full normalization for method='direct'.\n\t        \"\"\"\n\t    result = [-0.224548906, 0.0710350871, 0.268642932, 0.275941312, \n\t        0.166854098, 0.0166086946, -0.129057273, -0.196172655, -0.141613603,\n\t        -0.00683271606, 0.145768464, 0.242143899, 0.198310092, \n\t        0.000216377302, -0.24157688, -0.400586188, -0.432240069, -\n\t        0.288735539, 0.126461715, 0.709268868, 0.99999994, 0.722769439, \n\t        0.175955653, -0.246459037, -0.43402788, -0.432590246, -0.267131507,\n\t        -0.000678363896, 0.208171085, 0.232197508, 0.0864804164, -\n\t        0.114158235, -0.253621429, -0.262945205, -0.140505865, 0.0335594788,\n\t        0.177415669, 0.272263527, 0.281718552, 0.138080209, -0.127307668]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    cc = correlate_template(data, template, method='direct')\n\t    np.testing.assert_allclose(cc, result, atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert round(abs(corr - 1.0), 7) == 0\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_eqcorrscan_time()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_correct_alignment_of_normalization(self):\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    for i1, i2 in ((0, 0), (0, 1), (1, 1), (1, 0)):\n\t        for mode in ('valid', 'same', 'full'):\n\t            for demean in (True, False):\n\t                xcorr = correlate_template(data[i1:], template[i2:], mode=\n\t                    mode, demean=demean)\n\t                assert round(abs(np.max(xcorr) - 1), 7) == 0\n\t\nTestCrossCorrelation().test_correlate_template_correct_alignment_of_normalization()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_versus_correlate(self):\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    xcorr1 = correlate_template(data, template, normalize='naive')\n\t    xcorr2 = correlate(data, template, 20)\n\t    np.testing.assert_equal(xcorr1, xcorr2)\n\t\nTestCrossCorrelation().test_correlate_template_versus_correlate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_zeros_in_input(self):\n\t    template = np.zeros(10)\n\t    data = read()[0].data[380:420]\n\t    xcorr = correlate_template(data, template)\n\t    np.testing.assert_equal(xcorr, np.zeros(len(xcorr)))\n\t    template[:] = data[:10]\n\t    data[5:20] = 0\n\t    xcorr = correlate_template(data, template)\n\t    np.testing.assert_equal(xcorr[5:11], np.zeros(6))\n\t    data[:] = 0\n\t    xcorr = correlate_template(data, template)\n\t    np.testing.assert_equal(xcorr, np.zeros(len(xcorr)))\n\t    xcorr = correlate_template(data, template, normalize='naive')\n\t    np.testing.assert_equal(xcorr, np.zeros(len(xcorr)))\n\t\nTestCrossCorrelation().test_correlate_template_zeros_in_input()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_different_amplitudes(self):\n\t    \"\"\"\n\t        Check that correlations are the same independent of template amplitudes\n\t        \"\"\"\n\t    data = np.random.randn(20000)\n\t    template = data[1000:1200]\n\t    template_large = template * 100000000000.0\n\t    template_small = template * 1e-09\n\t    cc = correlate_template(data, template)\n\t    cc_large = correlate_template(data, template_large)\n\t    cc_small = correlate_template(data, template_small)\n\t    np.testing.assert_allclose(cc, cc_large)\n\t    np.testing.assert_allclose(cc, cc_small)\n\t\nTestCrossCorrelation().test_correlate_template_different_amplitudes()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_template_nodemean_fastmatchedfilter(self):\n\t    \"\"\"\n\t        Compare non-demeaned result against FMF derived result.\n\t\n\t        FMF result obtained by the following:\n\t\n\t        import copy\n\t        import numpy as np\n\t        from fast_matched_filter import matched_filter\n\t        from obspy import read\n\t\n\t        data = read()[0].data\n\t        template = copy.deepcopy(data[400:600])\n\t        data = data[380:620]\n\t        result = matched_filter(\n\t            templates=template.reshape(1, 1, 1, len(template)),\n\t            moveouts=np.array(0).reshape(1, 1, 1),\n\t            weights=np.array(1).reshape(1, 1, 1),\n\t            data=data.reshape(1, 1, len(data)),\n\t            step=1, arch='cpu')[0]\n\t\n\t        .. note::\n\t            FastMatchedFilter doesn't use semver, but result generated by Calum\n\t            Chamberlain on 18 Jan 2018 using up-to-date code, with the patch\n\t            in https://github.com/beridel/fast_matched_filter/pull/12\n\t        \"\"\"\n\t    result = [-0.148108244, 0.047153227, 0.182797655, 0.192574233, \n\t        0.118700281, 0.0118958903, -0.0923405439, -0.140047163, -\n\t        0.100863703, -0.00486961426, 0.104124829, 0.172662303, 0.141110823,\n\t        0.000153776666, -0.171214968, -0.283201426, -0.304899812, -\n\t        0.203215942, 0.0888349637, 0.500749528, 0.718140483, 0.529728174, \n\t        0.130591258, -0.183402568, -0.322406143, -0.320676118, -0.19805418,\n\t        -0.000506028766, 0.156253457, 0.174580097, 0.0649696961, -\n\t        0.0856237561, -0.189858019, -0.19650431, -0.10496819, 0.0251029599,\n\t        0.132686019, 0.203692451, 0.211983219, 0.0, 0.0]\n\t    data = read()[0].data\n\t    template = data[400:600]\n\t    data = data[380:620]\n\t    template = template - template.mean()\n\t    cc = correlate_template(data, template, demean=False)\n\t    np.testing.assert_allclose(cc[0:-2], result[0:-2], atol=1e-07)\n\t    shift, corr = xcorr_max(cc)\n\t    assert shift == 0\n\t\nTestCrossCorrelation().test_correlate_template_nodemean_fastmatchedfilter()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}, {"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_integer_input_equals_float_input(self):\n\t    a = [-3, 0, 4]\n\t    b = [-3, 4]\n\t    c = np.array(a, dtype=float)\n\t    d = np.array(b, dtype=float)\n\t    for demean in (True, False):\n\t        for normalize in (None, 'naive'):\n\t            cc1 = correlate(a, b, 3, demean=demean, normalize=normalize,\n\t                method='direct')\n\t            cc2 = correlate(c, d, 3, demean=demean, normalize=normalize)\n\t            np.testing.assert_allclose(cc1, cc2)\n\t        for normalize in (None, 'naive', 'full'):\n\t            cc3 = correlate_template(a, b, demean=demean, normalize=\n\t                normalize, method='direct')\n\t            cc4 = correlate_template(c, d, demean=demean, normalize=normalize)\n\t            np.testing.assert_allclose(cc3, cc4)\n\t\nTestCrossCorrelation().test_integer_input_equals_float_input()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate_template(data, template, mode='valid', normalize='full',\n    demean=True, method='auto'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "correlate_stream_template", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef correlate_stream_template(stream, template, template_time=None, **kwargs):\n    \"\"\"\n    Calculate cross-correlation of traces in stream with traces in template.\n\n    Only matching seed ids are correlated, other traces are silently discarded.\n    The template stream and data stream might have traces of different\n    length and different start times.\n    The data stream must not have gaps and will be sliced as necessary.\n\n    :param stream: Stream with data traces.\n    :param template: Stream with template traces (should be shorter than data).\n    :param template_time: UTCDateTime associated with template event\n        (e.g. origin time, default is the start time of the template stream).\n        The start times of the returned Stream will be shifted by the given\n        template time minus the template start time.\n    :param kwargs: kwargs are passed to\n        :func:`~obspy.signal.cross_correlation.correlate_template` function.\n\n    :return: Stream with cross-correlations.\n\n    .. note::\n\n        Use :func:`~obspy.signal.cross_correlation.correlation_detector`\n        for detecting events based on their similarity.\n        The returned stream of cross-correlations is suitable for\n        use with :func:`~obspy.signal.trigger.coincidence_trigger`, though.\n\n    .. rubric:: Example\n\n    >>> from obspy import read, UTCDateTime\n    >>> data = read().filter('highpass', freq=5)\n    >>> pick = UTCDateTime('2009-08-24T00:20:07.73')\n    >>> template = data.slice(pick, pick + 10)\n    >>> ccs = correlate_stream_template(data, template)\n    >>> print(ccs)  # doctest: +ELLIPSIS\n    3 Trace(s) in Stream:\n    BW.RJOB..EHE | 2009-08-24T00:20:03.000000Z - ... | 100.0 Hz, 2000 samples\n    BW.RJOB..EHN | 2009-08-24T00:20:03.000000Z - ... | 100.0 Hz, 2000 samples\n    BW.RJOB..EHZ | ... - 2009-08-24T00:20:22.990000Z | 100.0 Hz, 2000 samples\n    \"\"\"\n    stream, template = _prep_streams_correlate(stream, template,\n        template_time=template_time)\n    return _correlate_prepared_stream_template(stream, template, **kwargs)", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_stream_template_and_correlation_detector(self):\n\t    template = read().filter('highpass', freq=5).normalize()\n\t    pick = UTCDateTime('2009-08-24T00:20:07.73')\n\t    template.trim(pick, pick + 10)\n\t    n1 = len(template[0])\n\t    n2 = 100 * 3600\n\t    dt = template[0].stats.delta\n\t    template[1].stats.starttime += 5\n\t    stream = template.copy()\n\t    np.random.seed(42)\n\t    for tr, trt in zip(stream, template):\n\t        tr.stats.starttime += 24 * 3600\n\t        tr.data = np.random.random(n2) - 0.5\n\t        if tr.stats.channel[-1] == 'Z':\n\t            tr.data[n1:2 * n1] += 10 * trt.data\n\t            tr.data = tr.data[:-n1]\n\t        tr.data[5 * n1:6 * n1] += 100 * trt.data\n\t        tr.data[20 * n1:21 * n1] += 2 * trt.data\n\t    template[2].data = template[2].data[:-n1 // 5]\n\t    stream[0].trim(5, None)\n\t    stream[1].trim(1, 20)\n\t    pick2 = stream[0].stats.starttime + 20 * n1 * dt\n\t    template2 = stream.slice(pick2 - 5, pick2 + 5)\n\t    stream_orig = stream.copy()\n\t    template_orig = template.copy()\n\t    ccs = correlate_stream_template(stream, template)\n\t    assert len(ccs) == len(stream)\n\t    assert stream[1].stats.starttime == ccs[0].stats.starttime\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs = correlate_stream_template(stream[:2], template[1:])\n\t    assert len(ccs) == 1\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs1 = correlate_stream_template(stream, template)\n\t    template_time = template[0].stats.starttime + 100\n\t    ccs2 = correlate_stream_template(stream, template, template_time=\n\t        template_time)\n\t    assert len(ccs2) == len(ccs1)\n\t    delta = ccs2[0].stats.starttime - ccs1[0].stats.starttime\n\t    assert round(abs(delta - 100), 7) == 0\n\t    detections, sims = correlation_detector(stream, template, 0.2, 30)\n\t    assert len(detections) == 3\n\t    dtime = pick + n1 * dt + 24 * 3600\n\t    assert round(abs(detections[0]['time'] - dtime), 7) == 0\n\t    assert len(sims) == 1\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs = correlate_stream_template(stream, template)\n\t    triggers = coincidence_trigger(None, 0.2, -1, ccs, 2,\n\t        max_trigger_length=30, details=True)\n\t    assert len(triggers) == 2\n\t    for d, t in zip(detections[1:], triggers):\n\t        assert round(abs(np.mean(t['cft_peaks']) - d['similarity']), 7) == 0\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_magnitudes=1)\n\t    assert abs(detections[1]['amplitude_ratio'] - 100) < 1\n\t    assert abs(detections[1]['magnitude'] - (1 + 8 / 3)) < 0.01\n\t    assert abs(detections[2]['amplitude_ratio'] - 2) < 2\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_magnitudes=True)\n\t    assert abs(detections[1]['amplitude_ratio'] - 100) < 1\n\t    assert 'magnitude' not in detections[1]\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_names='eq')\n\t    assert detections[0]['template_name'] == 'eq'\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_names=['eq'], plot=True)\n\t    assert detections[0]['template_name'] == 'eq'\n\t\n\t    def simf(ccs):\n\t        ccmatrix = np.array([tr.data for tr in ccs])\n\t        comp_thres = np.sum(ccmatrix > 0.2, axis=0) > 1\n\t        similarity = ccs[0].copy()\n\t        similarity.data = np.mean(ccmatrix, axis=0) * comp_thres\n\t        return similarity\n\t    detections, _ = correlation_detector(stream, template, 0.1, 30,\n\t        similarity_func=simf, details=True)\n\t    assert len(detections) == 2\n\t    for d in detections:\n\t        mean_val = np.mean(list(d['cc_values'].values()))\n\t        assert round(abs(mean_val - d['similarity']), 7) == 0\n\t    detections, sims = correlation_detector(stream, template, 0.1, 30,\n\t        threshold=0.16, details=True, similarity_func=simf)\n\t    try:\n\t        from scipy.signal import find_peaks\n\t    except ImportError:\n\t        assert len(detections) == 2\n\t        assert 'left_threshold' not in detections[0]\n\t    else:\n\t        assert len(detections) == 1\n\t        assert 'left_threshold' in detections[0]\n\t    distance = int(round(30 / sims[0].stats.delta))\n\t    indices = _find_peaks(sims[0].data, 0.1, distance, distance)\n\t    assert len(indices) == 2\n\t    detections, _ = correlation_detector(stream, template, 0.2, 500)\n\t    assert len(detections) == 1\n\t    templates = template, template2\n\t    templatetime2 = pick2 - 10\n\t    template_times = template[0].stats.starttime, templatetime2\n\t    detections, _ = correlation_detector(stream, templates, (0.2, 0.3), 30,\n\t        plot=stream, template_times=template_times, template_magnitudes=(2, 5))\n\t    assert len(detections) > 0\n\t    assert 'template_id' in detections[0]\n\t    detections0 = [d for d in detections if d['template_id'] == 0]\n\t    assert len(detections0) == 2\n\t    assert len(detections) == 3\n\t    assert round(abs(detections[2]['similarity'] - 1), 7) == 0\n\t    assert round(abs(detections[2]['magnitude'] - 5), 7) == 0\n\t    assert detections[2]['time'] == templatetime2\n\t    templates = template, template2[2:]\n\t    with warnings.catch_warnings():\n\t        warnings.simplefilter('ignore')\n\t        detections, sims = correlation_detector(stream[:1], templates, 0.2,\n\t            30, plot=True, template_times=templatetime2, template_magnitudes=2)\n\t    detections0 = [d for d in detections if d['template_id'] == 0]\n\t    assert len(detections0) == 3\n\t    assert len(detections) == 3\n\t    assert len(sims) == 2\n\t    assert isinstance(sims[0], Trace)\n\t    assert sims[1] is None\n\t\nTestCrossCorrelation().test_correlate_stream_template_and_correlation_detector()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef correlate_stream_template(stream, template, template_time=None, **kwargs\n    ): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_find_peaks", "method_path": "../srcdata/Computation/obspy/obspy/signal/cross_correlation.py", "response": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\ndef _find_peaks(data, height, holdon_samples, holdoff_samples):\n    \"\"\"\n    Peak finding function used for Scipy versions smaller than 1.1.\n    \"\"\"\n    cond = data >= height\n    similarity_cond = data[cond]\n    cindices = np.nonzero(cond)[0]\n    detections_index = []\n    i = 0\n    while True:\n        try:\n            cindex = cindices[i]\n        except IndexError:\n            break\n        j = bisect_left(cindices, cindex + holdon_samples, lo=i)\n        k = i + np.argmax(similarity_cond[i:j])\n        cindex = cindices[k]\n        detections_index.append(cindex)\n        i = bisect_left(cindices, cindex + holdoff_samples, lo=j)\n    return detections_index", "test_code_list": [{"test_code": "import ctypes as C\nimport numpy as np\nimport warnings\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.libnames import _load_cdll\nfrom obspy.signal.cross_correlation import correlate\nfrom obspy.signal.cross_correlation import correlate_template\nfrom obspy.signal.cross_correlation import correlate_stream_template\nfrom obspy.signal.cross_correlation import correlation_detector\nfrom obspy.signal.cross_correlation import xcorr_pick_correction\nfrom obspy.signal.cross_correlation import xcorr_3c\nfrom obspy.signal.cross_correlation import xcorr_max\nfrom obspy.signal.cross_correlation import _xcorr_padzeros\nfrom obspy.signal.cross_correlation import _xcorr_slice\nfrom obspy.signal.cross_correlation import _find_peaks\nfrom obspy.signal.trigger import coincidence_trigger\nfrom scipy.signal import find_peaks\n\nclass TestCrossCorrelation():\n\tdef test_correlate_stream_template_and_correlation_detector(self):\n\t    template = read().filter('highpass', freq=5).normalize()\n\t    pick = UTCDateTime('2009-08-24T00:20:07.73')\n\t    template.trim(pick, pick + 10)\n\t    n1 = len(template[0])\n\t    n2 = 100 * 3600\n\t    dt = template[0].stats.delta\n\t    template[1].stats.starttime += 5\n\t    stream = template.copy()\n\t    np.random.seed(42)\n\t    for tr, trt in zip(stream, template):\n\t        tr.stats.starttime += 24 * 3600\n\t        tr.data = np.random.random(n2) - 0.5\n\t        if tr.stats.channel[-1] == 'Z':\n\t            tr.data[n1:2 * n1] += 10 * trt.data\n\t            tr.data = tr.data[:-n1]\n\t        tr.data[5 * n1:6 * n1] += 100 * trt.data\n\t        tr.data[20 * n1:21 * n1] += 2 * trt.data\n\t    template[2].data = template[2].data[:-n1 // 5]\n\t    stream[0].trim(5, None)\n\t    stream[1].trim(1, 20)\n\t    pick2 = stream[0].stats.starttime + 20 * n1 * dt\n\t    template2 = stream.slice(pick2 - 5, pick2 + 5)\n\t    stream_orig = stream.copy()\n\t    template_orig = template.copy()\n\t    ccs = correlate_stream_template(stream, template)\n\t    assert len(ccs) == len(stream)\n\t    assert stream[1].stats.starttime == ccs[0].stats.starttime\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs = correlate_stream_template(stream[:2], template[1:])\n\t    assert len(ccs) == 1\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs1 = correlate_stream_template(stream, template)\n\t    template_time = template[0].stats.starttime + 100\n\t    ccs2 = correlate_stream_template(stream, template, template_time=\n\t        template_time)\n\t    assert len(ccs2) == len(ccs1)\n\t    delta = ccs2[0].stats.starttime - ccs1[0].stats.starttime\n\t    assert round(abs(delta - 100), 7) == 0\n\t    detections, sims = correlation_detector(stream, template, 0.2, 30)\n\t    assert len(detections) == 3\n\t    dtime = pick + n1 * dt + 24 * 3600\n\t    assert round(abs(detections[0]['time'] - dtime), 7) == 0\n\t    assert len(sims) == 1\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    ccs = correlate_stream_template(stream, template)\n\t    triggers = coincidence_trigger(None, 0.2, -1, ccs, 2,\n\t        max_trigger_length=30, details=True)\n\t    assert len(triggers) == 2\n\t    for d, t in zip(detections[1:], triggers):\n\t        assert round(abs(np.mean(t['cft_peaks']) - d['similarity']), 7) == 0\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_magnitudes=1)\n\t    assert abs(detections[1]['amplitude_ratio'] - 100) < 1\n\t    assert abs(detections[1]['magnitude'] - (1 + 8 / 3)) < 0.01\n\t    assert abs(detections[2]['amplitude_ratio'] - 2) < 2\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_magnitudes=True)\n\t    assert abs(detections[1]['amplitude_ratio'] - 100) < 1\n\t    assert 'magnitude' not in detections[1]\n\t    assert stream_orig == stream\n\t    assert template_orig == template\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_names='eq')\n\t    assert detections[0]['template_name'] == 'eq'\n\t    detections, _ = correlation_detector(stream, template, 0.2, 30,\n\t        template_names=['eq'], plot=True)\n\t    assert detections[0]['template_name'] == 'eq'\n\t\n\t    def simf(ccs):\n\t        ccmatrix = np.array([tr.data for tr in ccs])\n\t        comp_thres = np.sum(ccmatrix > 0.2, axis=0) > 1\n\t        similarity = ccs[0].copy()\n\t        similarity.data = np.mean(ccmatrix, axis=0) * comp_thres\n\t        return similarity\n\t    detections, _ = correlation_detector(stream, template, 0.1, 30,\n\t        similarity_func=simf, details=True)\n\t    assert len(detections) == 2\n\t    for d in detections:\n\t        mean_val = np.mean(list(d['cc_values'].values()))\n\t        assert round(abs(mean_val - d['similarity']), 7) == 0\n\t    detections, sims = correlation_detector(stream, template, 0.1, 30,\n\t        threshold=0.16, details=True, similarity_func=simf)\n\t    try:\n\t        from scipy.signal import find_peaks\n\t    except ImportError:\n\t        assert len(detections) == 2\n\t        assert 'left_threshold' not in detections[0]\n\t    else:\n\t        assert len(detections) == 1\n\t        assert 'left_threshold' in detections[0]\n\t    distance = int(round(30 / sims[0].stats.delta))\n\t    indices = _find_peaks(sims[0].data, 0.1, distance, distance)\n\t    assert len(indices) == 2\n\t    detections, _ = correlation_detector(stream, template, 0.2, 500)\n\t    assert len(detections) == 1\n\t    templates = template, template2\n\t    templatetime2 = pick2 - 10\n\t    template_times = template[0].stats.starttime, templatetime2\n\t    detections, _ = correlation_detector(stream, templates, (0.2, 0.3), 30,\n\t        plot=stream, template_times=template_times, template_magnitudes=(2, 5))\n\t    assert len(detections) > 0\n\t    assert 'template_id' in detections[0]\n\t    detections0 = [d for d in detections if d['template_id'] == 0]\n\t    assert len(detections0) == 2\n\t    assert len(detections) == 3\n\t    assert round(abs(detections[2]['similarity'] - 1), 7) == 0\n\t    assert round(abs(detections[2]['magnitude'] - 5), 7) == 0\n\t    assert detections[2]['time'] == templatetime2\n\t    templates = template, template2[2:]\n\t    with warnings.catch_warnings():\n\t        warnings.simplefilter('ignore')\n\t        detections, sims = correlation_detector(stream[:1], templates, 0.2,\n\t            30, plot=True, template_times=templatetime2, template_magnitudes=2)\n\t    detections0 = [d for d in detections if d['template_id'] == 0]\n\t    assert len(detections0) == 3\n\t    assert len(detections) == 3\n\t    assert len(sims) == 2\n\t    assert isinstance(sims[0], Trace)\n\t    assert sims[1] is None\n\t\nTestCrossCorrelation().test_correlate_stream_template_and_correlation_detector()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_cross_correlation.py"}], "method_code_mask": "from bisect import bisect_left\nfrom copy import copy\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy.core.util.misc import MatplotlibBackend\nfrom obspy.signal.invsim import cosine_taper\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom obspy.imaging.util import _set_xaxis_obspy_dates\nimport doctest\n\n\ndef _find_peaks(data, height, holdon_samples, holdoff_samples): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "aic_simple", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef aic_simple(a):\n    \"\"\"\n    Simple Akaike Information Criterion [Maeda1985]_.\n\n    It's computed directly from input data :math:`a` and defined as\n\n    .. math::\n        \\\\text{AIC}(k) = k\\\\log(\\\\text{Var}(a_{1..k})) +\n                        (N-k-1)\\\\log(\\\\text{Var}(a_{k+1..N}))\n\n    which variance denoted as :math:`\\\\text{Var}`.\n\n    The true output is one data sample less. To make it convenient with other\n    metrics in this module, where the output length is preserved, the last\n    element is appended to the output: ``aic[-2] == aic[-1]``.\n\n    :type a: :class:`numpy.ndarray` or :class:`list`\n    :param a: Input time series\n    :rtype: :class:`numpy.ndarray`\n    :return: aic - Akaike Information Criterion array\n    \"\"\"\n    n = len(a)\n    if n <= 2:\n        return np.zeros(n, dtype=np.float64)\n    a = np.ascontiguousarray(a, np.float64)\n    aic_res = np.empty(n, dtype=np.float64)\n    clibsignal.aic_simple(aic_res, a, n)\n    return aic_res", "test_code_list": [{"test_code": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\nclass TestTrigger():\n\tdef test_aic_simple_constant_data(self):\n\t    data = [1] * 10\n\t    assert_array_equal(aic_simple(data), -np.inf)\n\t\nTestTrigger().test_aic_simple_constant_data()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py"}, {"test_code": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\nclass TestTrigger():\n\tdef test_aic_simple_small_size(self):\n\t    data = [3, 4]\n\t    assert_array_equal(aic_simple(data), [0, 0])\n\t\nTestTrigger().test_aic_simple_small_size()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py"}], "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef aic_simple(a): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "aic_simple_python", "method_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py", "response": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\ndef aic_simple_python(a):\n    if len(a) <= 2:\n        return np.zeros(len(a), dtype=np.float64)\n    a = np.asarray(a)\n    aic_cf = np.zeros(a.size - 1, dtype=np.float64)\n    with np.errstate(divide='ignore'):\n        aic_cf[0] = (a.size - 2) * np.log(np.var(a[1:]))\n        aic_cf[-1] = (a.size - 1) * np.log(np.var(a[:-1]))\n        for ii in range(2, a.size - 1):\n            var1 = np.log(np.var(a[:ii]))\n            var2 = np.log(np.var(a[ii:]))\n            val1 = ii * var1\n            val2 = (a.size - ii - 1) * var2\n            aic_cf[ii - 1] = val1 + val2\n    aic_cf = np.r_[aic_cf, aic_cf[-1]]\n    return aic_cf", "test_code_list": [{"test_code": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\nclass TestTrigger():\n\tdef test_aic_simple(self):\n\t    np.random.seed(0)\n\t    data = np.random.rand(100)\n\t    aic = aic_simple(data)\n\t    assert len(aic) == len(data)\n\t    aic_true = aic_simple_python(data)\n\t    assert_array_almost_equal(aic, aic_true)\n\t\nTestTrigger().test_aic_simple()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py"}], "method_code_mask": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\n\ndef aic_simple_python(a): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "trigger_onset", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef trigger_onset(charfct, thres1, thres2, max_len=9e+99, max_len_delete=False\n    ):\n    \"\"\"\n    Calculate trigger on and off times.\n\n    Given thres1 and thres2 calculate trigger on and off times from\n    characteristic function.\n\n    This method is written in pure Python and gets slow as soon as there\n    are more then 1e6 triggerings (\"on\" AND \"off\") in charfct --- normally\n    this does not happen.\n\n    :type charfct: NumPy :class:`~numpy.ndarray`\n    :param charfct: Characteristic function of e.g. STA/LTA trigger\n    :type thres1: float\n    :param thres1: Value above which trigger (of characteristic function)\n                   is activated (higher threshold)\n    :type thres2: float\n    :param thres2: Value below which trigger (of characteristic function)\n        is deactivated (lower threshold)\n    :type max_len: int\n    :param max_len: Maximum length of triggered event in samples. A new\n                    event will be triggered as soon as the signal reaches\n                    again above thres1.\n    :type max_len_delete: bool\n    :param max_len_delete: Do not write events longer than max_len into\n                           report file.\n    :rtype: List\n    :return: Nested List of trigger on and of times in samples\n    \"\"\"\n    ind1 = np.where(charfct >= thres1)[0]\n    if len(ind1) == 0:\n        return []\n    ind2 = np.where(charfct >= thres2)[0]\n    on = deque([ind1[0]])\n    of = deque([-1])\n    ind2_ = np.empty_like(ind2, dtype=bool)\n    ind2_[:-1] = np.diff(ind2) > 1\n    ind2_[-1] = True\n    of.extend(ind2[ind2_].tolist())\n    on.extend(ind1[np.where(np.diff(ind1) > 1)[0] + 1].tolist())\n    if max_len_delete:\n        of.extend([1e+99])\n        on.extend([on[-1]])\n    else:\n        of.extend([ind2[-1]])\n    of.append(len(charfct))\n    pick = []\n    while on[-1] > of[0]:\n        while on[0] <= of[0]:\n            on.popleft()\n        while of[0] < on[0]:\n            of.popleft()\n        if of[0] - on[0] > max_len:\n            if max_len_delete:\n                on.popleft()\n                continue\n            of.appendleft(on[0] + max_len)\n        pick.append([on[0], of[0]])\n    return np.array(pick, dtype=np.int64)", "test_code_list": [{"test_code": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\nclass TestTrigger():\n\tdef test_trigger_onset(self):\n\t    \"\"\"\n\t        Test trigger onset function\n\t        \"\"\"\n\t    on_of = np.array([[6.0, 31], [69, 94], [131, 181], [215, 265], [278, \n\t        315], [480, 505], [543, 568], [605, 631]])\n\t    cft = np.concatenate((np.sin(np.arange(0, 5 * np.pi, 0.1)) + 1, np.sin(\n\t        np.arange(0, 5 * np.pi, 0.1)) + 2.1, np.sin(np.arange(0, 5 * np.pi,\n\t        0.1)) + 0.4, np.sin(np.arange(0, 5 * np.pi, 0.1)) + 1))\n\t    picks = trigger_onset(cft, 1.5, 1.0, max_len=50)\n\t    np.testing.assert_array_equal(picks, on_of)\n\t    picks_del = trigger_onset(cft, 1.5, 1.0, max_len=50, max_len_delete=True)\n\t    np.testing.assert_array_equal(picks_del, on_of[np.array([0, 1, 5, 6, 7])])\n\t    if False:\n\t        import matplotlib.pyplot as plt\n\t        plt.plot(cft)\n\t        plt.hlines([1.5, 1.0], 0, len(cft))\n\t        on_of = np.array(on_of)\n\t        plt.vlines(picks[:, 0], 1.0, 2.0, color='g', linewidth=2, label=\n\t            'ON max_len')\n\t        plt.vlines(picks[:, 1], 0.5, 1.5, color='r', linewidth=2, label=\n\t            'OF max_len')\n\t        plt.vlines(picks_del[:, 0] + 2, 1.0, 2.0, color='y', linewidth=2,\n\t            label='ON max_len_delete')\n\t        plt.vlines(picks_del[:, 1] + 2, 0.5, 1.5, color='b', linewidth=2,\n\t            label='OF max_len_delete')\n\t        plt.legend()\n\t        plt.show()\n\t\nTestTrigger().test_trigger_onset()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py"}], "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef trigger_onset(charfct, thres1, thres2, max_len=9e+99, max_len_delete=False\n    ): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "energy_ratio", "method_path": "../srcdata/Computation/obspy/obspy/signal/trigger.py", "response": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\ndef energy_ratio(a, nsta):\n    \"\"\"\n    Energy ratio detector.\n\n    Energy ratio defined as\n\n    .. math::\n        \\\\text{er}(i) = \\\\frac{\\\\sum_{j=i}^{i+L}{a_j^2}}{\\\\sum_{j=i-L}^{i}{a_j^2}}\n\n    where :math:`L` is ``nsta``.\n\n    :type a: NumPy :class:`~numpy.ndarray`\n    :param a: Seismic Trace\n    :type nsta: int\n    :param nsta: Length of the energy ratio window in samples. It's the same\n                 length as ``nsta`` in the classical STA/LTA methods.\n    :rtype: NumPy :class:`~numpy.ndarray`\n    :return: Energy Ratio\n\n    .. seealso:: [Han2009]_\n    \"\"\"\n    if nsta > len(a) // 2:\n        msg = (\n            f'nsta ({nsta}) must not be larger than half the length of the data ({len(a)} samples).'\n            )\n        raise ValueError(msg)\n    if nsta <= 0:\n        msg = f'nsta ({nsta}) must not be equal to or less than zero.'\n        raise ValueError(msg)\n    sig_power = np.r_[0, np.cumsum(a ** 2, dtype=np.float64)]\n    energy_diff = sig_power[nsta:] - sig_power[:len(sig_power) - nsta]\n    er = np.zeros(len(a), dtype=np.float64)\n    np.divide(energy_diff[nsta:], energy_diff[:len(energy_diff) - nsta],\n        where=energy_diff[:len(energy_diff) - nsta] != 0, out=er[nsta:len(\n        er) - nsta + 1])\n    return er", "test_code_list": [{"test_code": "import gzip\nimport re\nimport warnings\nfrom ctypes import ArgumentError\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom obspy import Stream\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.trigger import ar_pick\nfrom obspy.signal.trigger import classic_sta_lta\nfrom obspy.signal.trigger import classic_sta_lta_py\nfrom obspy.signal.trigger import coincidence_trigger\nfrom obspy.signal.trigger import pk_baer\nfrom obspy.signal.trigger import recursive_sta_lta\nfrom obspy.signal.trigger import recursive_sta_lta_py\nfrom obspy.signal.trigger import trigger_onset\nfrom obspy.signal.trigger import aic_simple\nfrom obspy.signal.util import clibsignal\nimport matplotlib.pyplot as plt\n\nclass TestEnergyRatio():\n\tdef test_arange(self):\n\t    self.a = np.arange(10)\n\t    er = energy_ratio(self.a, nsta=3)\n\t    er_expected = [0.0, 0.0, 0.0, 10.0, 5.5, 3.793103, 2.98, 2.519481, 0.0, 0.0\n\t        ]\n\t    assert_array_almost_equal(er, er_expected)\n\t\nTestEnergyRatio().test_arange()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trigger.py"}], "method_code_mask": "from collections import deque\nimport ctypes as C\nimport warnings\nimport numpy as np\nimport scipy\nfrom obspy import UTCDateTime\nfrom obspy.signal.cross_correlation import templates_max_similarity\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.headers import head_stalta_t\nimport matplotlib.pyplot as plt\n\n\ndef energy_ratio(a, nsta): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "bandpass", "method_path": "../srcdata/Computation/obspy/obspy/signal/filter.py", "response": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\ndef bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False, rp=\n    None, rs=None, ftype='butter', axis=-1):\n    \"\"\"\n    Bandpass Filter.\n\n    Filter data from ``freqmin`` to ``freqmax`` using ``corners``\n    corners.\n    The filter uses :func:`scipy.signal.iirfilter` (for design)\n    and :func:`scipy.signal.sosfilt` (for applying the filter).\n\n    :type data: numpy.ndarray\n    :param data: Data to filter.\n    :param freqmin: Pass band low corner frequency.\n    :param freqmax: Pass band high corner frequency.\n    :param df: Sampling rate in Hz.\n    :param corners: Filter corners / order.\n    :param zerophase: If True, apply filter once forwards and once backwards.\n        This results in twice the filter order but zero phase shift in\n        the resulting filtered trace.\n    :param rp:\n        For Chebyshev and elliptic filters, provides the maximum ripple\n        in the passband. (dB)\n    :param rs:\n        For Chebyshev and elliptic filters, provides the minimum attenuation\n        in the stop band. (dB)\n    :param ftype:\n        The type of filter\n            - Butterworth   : 'butter' (default)\n            - Chebyshev I   : 'cheby1'\n            - Chebyshev II  : 'cheby2'\n            - Cauer/elliptic: 'ellip'\n            - Bessel/Thomson: 'bessel'\n    :param axis: The axis of the input data array along which to apply the\n        linear filter. The filter is applied to each subarray along this axis.\n        Default is -1.\n    :return: Filtered data.\n    \"\"\"\n    fe = 0.5 * df\n    low = freqmin / fe\n    high = freqmax / fe\n    if high - 1.0 > -1e-06:\n        msg = (\n            'Selected high corner frequency ({}) of bandpass is at or above Nyquist ({}). Applying a high-pass instead.'\n            .format(freqmax, fe))\n        warnings.warn(msg)\n        return highpass(data, freq=freqmin, df=df, corners=corners, ftype=\n            ftype, zerophase=zerophase)\n    if low > 1:\n        msg = 'Selected low corner frequency is above Nyquist.'\n        raise ValueError(msg)\n    return _filter(data, (freqmin, freqmax), df, rp=rp, rs=rs, btype='band',\n        ftype=ftype, corners=corners, zerophase=zerophase, axis=axis)", "test_code_list": [{"test_code": "import gzip\nimport warnings\nimport numpy as np\nimport scipy.signal as sg\nfrom obspy import read\nfrom obspy.signal.filter import bandpass\nfrom obspy.signal.filter import bandstop\nfrom obspy.signal.filter import highpass\nfrom obspy.signal.filter import lowpass\nfrom obspy.signal.filter import envelope\nfrom obspy.signal.filter import lowpass_cheby_2\n\nclass TestFilter():\n\tdef test_bandpass_high_corner_at_nyquist(self):\n\t    \"\"\"\n\t        Check that using exactly Nyquist for high corner gives correct results.\n\t        See #1451.\n\t        \"\"\"\n\t    tr = read()[0]\n\t    data = tr.data[:1000]\n\t    df = tr.stats.sampling_rate\n\t    nyquist = df / 2.0\n\t    for low_corner in (6.0, 8.55, 8.59):\n\t        for corners in (3, 4, 5, 6):\n\t            with warnings.catch_warnings(record=True) as w:\n\t                warnings.simplefilter('always')\n\t                expected = bandpass(data, low_corner, nyquist * (1 - \n\t                    1.1e-06), df=df, corners=corners)\n\t                assert len(w) == 0\n\t            with warnings.catch_warnings(record=True) as w:\n\t                warnings.simplefilter('always')\n\t                got1 = bandpass(data, low_corner, nyquist * (1 - 9e-07), df\n\t                    =df, corners=corners)\n\t                got2 = bandpass(data, low_corner, nyquist, df=df, corners=\n\t                    corners)\n\t                got3 = bandpass(data, low_corner, nyquist + 1.78, df=df,\n\t                    corners=corners)\n\t                numwarn = 0\n\t                for w_ in w:\n\t                    if 'Selected high corner frequency ' in str(w_.message\n\t                        ) and 'Applying a high-pass instead.' in str(w_.message\n\t                        ):\n\t                        numwarn += 1\n\t                assert numwarn == 3\n\t            for got in (got1, got2, got3):\n\t                np.testing.assert_allclose(got, expected, rtol=0.001, atol=0.9)\n\t\nTestFilter().test_bandpass_high_corner_at_nyquist()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_filter.py"}], "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\n\n\ndef bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False, rp=\n    None, rs=None, ftype='butter', axis=-1): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "lowpass_cheby_2", "method_path": "../srcdata/Computation/obspy/obspy/signal/filter.py", "response": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\ndef lowpass_cheby_2(data, freq, df, maxorder=12, ba=False, freq_passband=False\n    ):\n    \"\"\"\n    Cheby2-Lowpass Filter\n\n    Filter data by passing data only below a certain frequency.\n    The main purpose of this cheby2 filter is downsampling.\n    #318 shows some plots of this filter design itself.\n\n    This method will iteratively design a filter, whose pass\n    band frequency is determined dynamically, such that the\n    values above the stop band frequency are lower than -96dB.\n\n    :type data: numpy.ndarray\n    :param data: Data to filter.\n    :param freq: The frequency above which signals are attenuated\n        with 95 dB\n    :param df: Sampling rate in Hz.\n    :param maxorder: Maximal order of the designed cheby2 filter\n    :param ba: If True return only the filter coefficients (b, a) instead\n        of filtering\n    :param freq_passband: If True return additionally to the filtered data,\n        the iteratively determined pass band frequency\n    :return: Filtered data.\n    \"\"\"\n    nyquist = df * 0.5\n    rp, rs, order = 1, 96, 1e+99\n    ws = freq / nyquist\n    wp = ws\n    if ws > 1:\n        ws = 1.0\n        msg = ('Selected corner frequency is above Nyquist. ' +\n            'Setting Nyquist as high corner.')\n        warnings.warn(msg)\n    while True:\n        if order <= maxorder:\n            break\n        wp = wp * 0.99\n        order, wn = cheb2ord(wp, ws, rp, rs, analog=0)\n    if ba:\n        return cheby2(order, rs, wn, btype='low', analog=0, output='ba')\n    sos = cheby2(order, rs, wn, btype='low', analog=0, output='sos')\n    if freq_passband:\n        return sosfilt(sos, data), wp * nyquist\n    return sosfilt(sos, data)", "test_code_list": [{"test_code": "import gzip\nimport warnings\nimport numpy as np\nimport scipy.signal as sg\nfrom obspy import read\nfrom obspy.signal.filter import bandpass\nfrom obspy.signal.filter import bandstop\nfrom obspy.signal.filter import highpass\nfrom obspy.signal.filter import lowpass\nfrom obspy.signal.filter import envelope\nfrom obspy.signal.filter import lowpass_cheby_2\n\nclass TestFilter():\n\tdef test_lowpass_cheby_2(self):\n\t    \"\"\"\n\t        Check magnitudes of basic lowpass cheby2\n\t        \"\"\"\n\t    df = 200\n\t    b, a = lowpass_cheby_2(data=None, freq=50, df=df, maxorder=12, ba=True)\n\t    nyquist = 100\n\t    w, h = sg.freqz(b, a, nyquist)\n\t    freq = w / np.pi * nyquist\n\t    h_db = 20 * np.log10(abs(h))\n\t    assert -96 > h_db[freq > 50].max()\n\t    assert h_db[freq < 25].min() > -1\n\t\nTestFilter().test_lowpass_cheby_2()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_filter.py"}, {"test_code": "from copy import deepcopy\nimport numpy as np\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.filter import bandpass\nfrom obspy.signal.filter import bandstop\nfrom obspy.signal.filter import highpass\nfrom obspy.signal.filter import lowpass\nfrom obspy.signal.filter import lowpass_cheby_2\nfrom obspy.signal.invsim import simulate_seismometer\nimport pytest\n\nclass TestTrace():\n\tdef test_decimate(self):\n\t    \"\"\"\n\t        Tests the decimate method of the Trace object.\n\t        \"\"\"\n\t    tr = Trace(data=np.arange(20))\n\t    tr_bkp = deepcopy(tr)\n\t    with pytest.raises(ValueError):\n\t        tr.decimate(7, strict_length=True)\n\t    with pytest.raises(ValueError):\n\t        tr.decimate(9, strict_length=True)\n\t    with pytest.raises(ArithmeticError):\n\t        tr.decimate(18)\n\t    tr.decimate(4, no_filter=True)\n\t    np.testing.assert_array_equal(tr.data, np.arange(0, 20, 4))\n\t    assert tr.stats.npts == 5\n\t    assert tr.stats.sampling_rate == 0.25\n\t    assert 'decimate' in tr.stats.processing[0]\n\t    assert 'factor=4' in tr.stats.processing[0]\n\t    tr = tr_bkp.copy()\n\t    tr.decimate(10, no_filter=True)\n\t    np.testing.assert_array_equal(tr.data, np.arange(0, 20, 10))\n\t    assert tr.stats.npts == 2\n\t    assert tr.stats.sampling_rate == 0.1\n\t    assert 'decimate' in tr.stats.processing[0]\n\t    assert 'factor=10' in tr.stats.processing[0]\n\t    tr = tr_bkp.copy()\n\t    tr2 = tr_bkp.copy()\n\t    tr.decimate(4)\n\t    df = tr2.stats.sampling_rate\n\t    tr2.data, fp = lowpass_cheby_2(data=tr2.data, freq=df * 0.5 / 4.0, df=\n\t        df, maxorder=12, ba=False, freq_passband=True)\n\t    assert round(abs(0.0811378285461 - fp), 7) == 0\n\t    tr2.decimate(4, no_filter=True)\n\t    np.testing.assert_array_equal(tr.data, tr2.data)\n\t\nTestTrace().test_decimate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_trace.py"}], "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy.fftpack import hilbert\nfrom scipy.signal import cheb2ord\nfrom scipy.signal import cheby2\nfrom scipy.signal import convolve\nfrom scipy.signal import get_window\nfrom scipy.signal import iirfilter\nfrom scipy.signal import remez\nfrom scipy.signal import sosfilt\n\n\ndef lowpass_cheby_2(data, freq, df, maxorder=12, ba=False, freq_passband=False\n    ): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "ptp", "method_path": "../srcdata/Computation/obspy/obspy/core/util/misc.py", "response": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\ndef ptp(a, *args, **kwargs):\n    \"\"\"\n    Replacement for :meth:`numpy.ndarray.ptp()` and the corresponding method on\n    `MaskedArray` objects which are being removed in numpy 2.0\n    Basically just makes sure we call the correct replacement function numpy\n    put in place for regular and masked arrays.\n\n    :type a: :class:`numpy.ndarray` or :class:`numpy.ma.MaskedArray`\n    \"\"\"\n    if isinstance(a, np.ma.MaskedArray):\n        return np.ma.ptp(a, *args, **kwargs)\n    return np.ptp(a, *args, **kwargs)", "test_code_list": [{"test_code": "from copy import deepcopy\nimport platform\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.signal.filter import bandpass\nfrom obspy.signal.filter import bandstop\nfrom obspy.signal.filter import highpass\nfrom obspy.signal.filter import lowpass\nimport pytest\n\nclass TestStream():\n\tdef test_simulate(self):\n\t    \"\"\"\n\t        Tests if calling simulate of stream gives the same result as calling\n\t        simulate on every trace manually.\n\t        \"\"\"\n\t    st1 = read()\n\t    st2 = read()\n\t    paz_sts2 = {'poles': [-0.037004 + 0.037016j, -0.037004 - 0.037016j, -\n\t        251.33 + 0.0j, -131.04 - 467.29j, -131.04 + 467.29j], 'zeros': [\n\t        0.0j, 0.0j], 'gain': 60077000.0, 'sensitivity': 2516778400.0}\n\t    paz_le3d1s = {'poles': [-4.44 + 4.44j, -4.44 - 4.44j, -1.083 + 0.0j],\n\t        'zeros': [0.0 + 0.0j, 0.0 + 0.0j, 0.0 + 0.0j], 'gain': 0.4,\n\t        'sensitivity': 1.0}\n\t    st1.simulate(paz_remove=paz_sts2, paz_simulate=paz_le3d1s)\n\t    for tr in st2:\n\t        tr.simulate(paz_remove=paz_sts2, paz_simulate=paz_le3d1s)\n\t    if platform.system() == 'Windows':\n\t        for tr1, tr2 in zip(st1, st2):\n\t            assert tr1.stats == tr2.stats\n\t            np.testing.assert_allclose(tr1.data, tr2.data, rtol=1e-06, atol\n\t                =1e-06 * ptp(tr1.data))\n\t    else:\n\t        for tr1, tr2 in zip(st1.sort(), st2.sort()):\n\t            assert tr1.stats == tr2.stats\n\t            np.testing.assert_allclose(tr1.data, tr2.data)\n\t        assert st1 == st2\n\t\nTestStream().test_simulate()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_stream.py"}, {"test_code": "import numpy as np\nimport obspy\nfrom obspy.signal.detrend import polynomial\nfrom obspy.signal.detrend import spline\n\nclass TestDetrend():\n\tdef test_polynomial_detrend(self):\n\t    \"\"\"\n\t        Simple test removing polynomial detrends.\n\t        \"\"\"\n\t    coeffs = [(1, 2, 3), (2, -4), (-3, 2, -5, 15), (-10, 20, -1, 2, 15)]\n\t    data = np.linspace(-5, 5, 100)\n\t    for c in coeffs:\n\t        d = np.polyval(c, data)\n\t        original_ptp = ptp(d)\n\t        detrended = polynomial(d, order=len(c) - 1)\n\t        assert ptp(detrended) * 10000000000.0 < original_ptp\n\t\nTestDetrend().test_polynomial_detrend()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_detrend.py"}, {"test_code": "import numpy as np\nimport obspy\nfrom obspy.signal.detrend import polynomial\nfrom obspy.signal.detrend import spline\n\nclass TestDetrend():\n\tdef test_spline_detrend(self):\n\t    \"\"\"\n\t        Simple test for the spline detrending.\n\t        \"\"\"\n\t    coeffs = [(1, 2, 3), (2, -4), (-3, 2, -5, 15), (-10, 20, -1, 2, 15)]\n\t    data = np.linspace(-5, 5, 100)\n\t    for c in coeffs:\n\t        d = np.polyval(c, data)\n\t        original_ptp = ptp(d)\n\t        detrended = spline(d, order=len(c) - 1, dspline=10)\n\t        assert ptp(detrended) * 10000.0 < original_ptp\n\t\nTestDetrend().test_spline_detrend()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_detrend.py"}], "method_code_mask": "import contextlib\nimport inspect\nimport io\nimport itertools\nimport math\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport warnings\nfrom subprocess import STDOUT\nfrom subprocess import CalledProcessError\nfrom subprocess import check_output\nimport numpy as np\nfrom pkg_resources import load_entry_point\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom obspy.core.event import ResourceIdentifier\nimport doctest\n\n\ndef ptp(a, *args, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "peak_ground_motion", "method_path": "../srcdata/Computation/obspy/obspy/signal/freqattributes.py", "response": "from operator import itemgetter\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom scipy import sparse\nfrom obspy.signal import util\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom obspy.signal.invsim import simulate_seismometer\ndef peak_ground_motion(data, delta, freq, damp=0.1):\n    \"\"\"\n    Peak ground motion parameters\n\n    Compute the maximal displacement, velocity, acceleration and the peak\n    ground acceleration at a certain frequency (standard periods for\n    ShakeMaps are 0.3/1.0/3.0 seconds. Note that the above input is expected as\n    frequency in Hertz.).\n\n    Data must be displacement\n\n    :type data: :class:`~numpy.ndarray`\n    :param data: Data in displacement to convolve with pendulum at freq.\n    :type delta: float\n    :param delta: Sampling interval\n    :type freq: float\n    :param freq: Frequency in Hz.\n    :type damp: float\n    :param damp: damping factor. Default is set to 0.1\n    :rtype: (float, float, float, float)\n    :return: Peak Ground Acceleration, maximal displacement, velocity,\n        acceleration\n    \"\"\"\n    data = data.copy()\n    if abs(max(data)) >= abs(min(data)):\n        m_dis = abs(max(data))\n    else:\n        m_dis = abs(min(data))\n    data = np.gradient(data, delta)\n    if abs(max(data)) >= abs(min(data)):\n        m_vel = abs(max(data))\n    else:\n        m_vel = abs(min(data))\n    data = np.gradient(data, delta)\n    if abs(max(data)) >= abs(min(data)):\n        m_acc = abs(max(data))\n    else:\n        m_acc = abs(min(data))\n    samp_rate = 1.0 / delta\n    t = freq * 1.0\n    d = damp\n    omega = (2 * 3.14159 * t) ** 2\n    paz_sa = corn_freq_2_paz(t, damp=d)\n    paz_sa['sensitivity'] = omega\n    paz_sa['zeros'] = []\n    data = simulate_seismometer(data, samp_rate, paz_remove=None,\n        paz_simulate=paz_sa, taper=True, simulate_sensitivity=True,\n        taper_fraction=0.05)\n    if abs(max(data)) >= abs(min(data)):\n        pga = abs(max(data))\n    else:\n        pga = abs(min(data))\n    return pga, m_dis, m_vel, m_acc", "test_code_list": [{"test_code": "from math import pi\nimport numpy as np\nimport pytest\nfrom scipy import signal\nfrom obspy.signal import freqattributes\nfrom obspy.signal import util\n\nclass TestFreqTrace():\n\tdef test_pgm(self):\n\t    \"\"\"\n\t        \"\"\"\n\t    data = np.zeros(100)\n\t    pgm = peak_ground_motion(data, 1.0, 1.0)\n\t    assert pgm == (0.0, 0.0, 0.0, 0.0)\n\t    data[50] = 1.0\n\t    pg, m_dis, m_vel, m_acc = peak_ground_motion(data, 1.0, 1.0)\n\t    assert round(abs(pg - 0.537443503597), 6) == 0\n\t    assert m_dis == 1.0\n\t    assert m_vel == 0.5\n\t    assert m_acc == 0.5\n\t    data = np.zeros(400)\n\t    for i in range(360):\n\t        data[i + 20] = np.sin(i * pi / 180)\n\t    pg, m_dis, m_vel, m_acc = peak_ground_motion(data, 1.0, 1.0)\n\t    assert round(abs(pg - 0.00902065171505), 6) == 0\n\t    assert m_dis == 1.0\n\t    assert round(abs(m_vel - 0.0174524064373), 6) == 0\n\t    assert round(abs(m_acc - 0.00872487417563), 6) == 0\n\t\nTestFreqTrace().test_pgm()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_freqattributes.py"}], "method_code_mask": "from operator import itemgetter\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom scipy import sparse\nfrom obspy.signal import util\nfrom obspy.signal.invsim import corn_freq_2_paz\nfrom obspy.signal.invsim import simulate_seismometer\n\n\ndef peak_ground_motion(data, delta, freq, damp=0.1): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "get_spoint", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef get_spoint(stream, stime, etime):\n    \"\"\"\n    Calculates start and end offsets relative to stime and etime for each\n    trace in stream in samples.\n\n    :type stime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param stime: Start time\n    :type etime: :class:`~obspy.core.utcdatetime.UTCDateTime`\n    :param etime: End time\n    :returns: start and end sample offset arrays\n    \"\"\"\n    spoint = np.empty(len(stream), dtype=np.int32, order='C')\n    epoint = np.empty(len(stream), dtype=np.int32, order='C')\n    for i, tr in enumerate(stream):\n        if tr.stats.starttime > stime:\n            msg = 'Specified stime %s is smaller than starttime %s in stream'\n            raise ValueError(msg % (stime, tr.stats.starttime))\n        if tr.stats.endtime < etime:\n            msg = 'Specified etime %s is bigger than endtime %s in stream'\n            raise ValueError(msg % (etime, tr.stats.endtime))\n        spoint[i] = int((stime - tr.stats.starttime) * tr.stats.\n            sampling_rate + 0.5)\n        epoint[i] = int((tr.stats.endtime - etime) * tr.stats.sampling_rate +\n            0.5)\n    return spoint, epoint", "test_code_list": [{"test_code": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.signal.array_analysis import array_processing\nfrom obspy.signal.array_analysis import array_transff_freqslowness\nfrom obspy.signal.array_analysis import array_transff_wavenumber\nfrom obspy.signal.array_analysis import get_spoint\nfrom obspy.signal.util import util_lon_lat\n\nclass TestSonic():\n\tdef test_get_spoint(self):\n\t    stime = UTCDateTime(1970, 1, 1, 0, 0)\n\t    etime = UTCDateTime(1970, 1, 1, 0, 0) + 10\n\t    data = np.empty(20)\n\t    st = Stream([Trace(data, {'starttime': stime - 1}), Trace(data, {\n\t        'starttime': stime - 4}), Trace(data, {'starttime': stime - 2})])\n\t    spoint, epoint = get_spoint(st, stime, etime)\n\t    assert np.allclose([1, 4, 2], spoint)\n\t    assert np.allclose([8, 5, 7], epoint)\n\t\nTestSonic().test_get_spoint()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_sonic.py"}], "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef get_spoint(stream, stime, etime): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "util_lon_lat", "method_path": "../srcdata/Computation/obspy/obspy/signal/util.py", "response": "import ctypes as C\nimport math\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom obspy.core.util.misc import factorize_int\nfrom obspy.signal.headers import clibsignal\nfrom scipy.signal import hilbert\nfrom scipy.fftpack import next_fast_len\nimport doctest\ndef util_lon_lat(orig_lon, orig_lat, x, y):\n    \"\"\"\n    Transform x, y [km] to decimal degree in reference to orig_lon and orig_lat\n\n    >>> util_lon_lat(12.0, 48.0, 0.0, 0.0)\n    (12.0, 48.0)\n    >>> lon, lat = util_lon_lat(12.0, 48.0, 73.9041, 111.1908)\n    >>> print(\"%.4f, %.4f\" % (lon, lat))\n    13.0000, 49.0000\n\n    :param orig_lon: Longitude of reference origin\n    :param orig_lat: Latitude of reference origin\n    :param x: value [km] to calculate relative coordinate in degree\n    :param y: value [km] to calculate relative coordinate in degree\n    :return: lon, lat coordinate in degree (absolute)\n    \"\"\"\n    clibsignal.utl_lonlat.argtypes = [C.c_double, C.c_double, C.c_double, C\n        .c_double, C.POINTER(C.c_double), C.POINTER(C.c_double)]\n    clibsignal.utl_lonlat.restype = C.c_void_p\n    lon = C.c_double()\n    lat = C.c_double()\n    clibsignal.utl_lonlat(orig_lon, orig_lat, x, y, C.byref(lon), C.byref(lat))\n    return lon.value, lat.value", "test_code_list": [{"test_code": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.signal.array_analysis import array_processing\nfrom obspy.signal.array_analysis import array_transff_freqslowness\nfrom obspy.signal.array_analysis import array_transff_wavenumber\nfrom obspy.signal.array_analysis import get_spoint\nfrom obspy.signal.util import util_lon_lat\n\nclass TestSonic():\n\tdef test_array_transff_freqslowness(self):\n\t    coords = np.array([[10.0, 60.0, 0.0], [200.0, 50.0, 0.0], [-120.0, \n\t        170.0, 0.0], [-100.0, -150.0, 0.0], [30.0, -220.0, 0.0]])\n\t    coords /= 1000.0\n\t    coordsll = np.zeros(coords.shape)\n\t    for i in np.arange(len(coords)):\n\t        coordsll[i, 0], coordsll[i, 1] = util_lon_lat(0.0, 0.0, coords[i, 0\n\t            ], coords[i, 1])\n\t    slim = 40.0\n\t    fmin = 1.0\n\t    fmax = 10.0\n\t    fstep = 1.0\n\t    sstep = slim / 2.0\n\t    transff = array_transff_freqslowness(coords, slim, sstep, fmin, fmax,\n\t        fstep, coordsys='xy')\n\t    transffll = array_transff_freqslowness(coordsll, slim, sstep, fmin,\n\t        fmax, fstep, coordsys='lonlat')\n\t    transffth = np.array([[0.41915119, 0.33333333, 0.32339525, 0.24751548, \n\t        0.67660475], [0.25248452, 0.41418215, 0.34327141, 0.65672859, \n\t        0.33333333], [0.24751548, 0.25248452, 1.0, 0.25248452, 0.24751548],\n\t        [0.33333333, 0.65672859, 0.34327141, 0.41418215, 0.25248452], [\n\t        0.67660475, 0.24751548, 0.32339525, 0.33333333, 0.41915119]])\n\t    np.testing.assert_array_almost_equal(transff, transffth, decimal=6)\n\t    np.testing.assert_array_almost_equal(transffll, transffth, decimal=6)\n\t\nTestSonic().test_array_transff_freqslowness()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_sonic.py"}, {"test_code": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.signal.array_analysis import array_processing\nfrom obspy.signal.array_analysis import array_transff_freqslowness\nfrom obspy.signal.array_analysis import array_transff_wavenumber\nfrom obspy.signal.array_analysis import get_spoint\nfrom obspy.signal.util import util_lon_lat\n\nclass TestSonic():\n\tdef test_array_transff_wavenumber(self):\n\t    coords = np.array([[10.0, 60.0, 0.0], [200.0, 50.0, 0.0], [-120.0, \n\t        170.0, 0.0], [-100.0, -150.0, 0.0], [30.0, -220.0, 0.0]])\n\t    coords /= 1000.0\n\t    coordsll = np.zeros(coords.shape)\n\t    for i in np.arange(len(coords)):\n\t        coordsll[i, 0], coordsll[i, 1] = util_lon_lat(0.0, 0.0, coords[i, 0\n\t            ], coords[i, 1])\n\t    klim = 40.0\n\t    kstep = klim / 2.0\n\t    transff = array_transff_wavenumber(coords, klim, kstep, coordsys='xy')\n\t    transffll = array_transff_wavenumber(coordsll, klim, kstep, coordsys=\n\t        'lonlat')\n\t    transffth = np.array([[0.31336036, 0.0423775796, 0.673650243, \n\t        0.480470652, 0.000816891615], [0.298941684, 0.247377842, \n\t        0.0996352135, 0.0684732871, 0.557078203], [0.126523678, 0.291010683,\n\t        1.0, 0.291010683, 0.126523678], [0.557078203, 0.0684732871, \n\t        0.0996352135, 0.247377842, 0.298941684], [0.000816891615, \n\t        0.480470652, 0.673650243, 0.0423775796, 0.31336036]])\n\t    np.testing.assert_array_almost_equal(transff, transffth, decimal=6)\n\t    np.testing.assert_array_almost_equal(transffll, transffth, decimal=6)\n\t\nTestSonic().test_array_transff_wavenumber()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_sonic.py"}], "method_code_mask": "import ctypes as C\nimport math\nimport numpy as np\nfrom scipy import fftpack\nfrom scipy import signal\nfrom obspy.core.util.misc import factorize_int\nfrom obspy.signal.headers import clibsignal\nfrom scipy.signal import hilbert\nfrom scipy.fftpack import next_fast_len\nimport doctest\n\n\ndef util_lon_lat(orig_lon, orig_lat, x, y): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "array_transff_freqslowness", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef array_transff_freqslowness(coords, slim, sstep, fmin, fmax, fstep,\n    coordsys='lonlat'):\n    \"\"\"\n    Returns array transfer function as a function of slowness difference and\n    frequency.\n\n    :type coords: numpy.ndarray\n    :param coords: coordinates of stations in longitude and latitude in degrees\n        elevation in km, or x, y, z in km\n    :type coordsys: str\n    :param coordsys: valid values: 'lonlat' and 'xy', choose which coordinates\n        to use\n    :param slim: either a float to use symmetric limits for slowness\n        differences or the tupel (sxmin, sxmax, symin, symax)\n    :type fmin: float\n    :param fmin: minimum frequency in signal\n    :type fmax: float\n    :param fmax: maximum frequency in signal\n    :type fstep: float\n    :param fstep: frequency sample distance\n    \"\"\"\n    coords = get_geometry(coords, coordsys)\n    if isinstance(slim, float):\n        sxmin = -slim\n        sxmax = slim\n        symin = -slim\n        symax = slim\n    elif isinstance(slim, tuple):\n        if len(slim) == 4:\n            sxmin = slim[0]\n            sxmax = slim[1]\n            symin = slim[2]\n            symax = slim[3]\n    else:\n        raise TypeError('slim must either be a float or a tuple of length 4')\n    nsx = int(np.ceil((sxmax + sstep / 10.0 - sxmin) / sstep))\n    nsy = int(np.ceil((symax + sstep / 10.0 - symin) / sstep))\n    nf = int(np.ceil((fmax + fstep / 10.0 - fmin) / fstep))\n    transff = np.empty((nsx, nsy))\n    buff = np.zeros(nf)\n    for i, sx in enumerate(np.arange(sxmin, sxmax + sstep / 10.0, sstep)):\n        for j, sy in enumerate(np.arange(symin, symax + sstep / 10.0, sstep)):\n            for k, f in enumerate(np.arange(fmin, fmax + fstep / 10.0, fstep)):\n                _sum = 0.0j\n                for l in np.arange(len(coords)):\n                    _sum += np.exp(complex(0.0, (coords[l, 0] * sx + coords\n                        [l, 1] * sy) * 2 * np.pi * f))\n                buff[k] = abs(_sum) ** 2\n            transff[i, j] = cumulative_trapezoid(buff, dx=fstep)[-1]\n    transff /= transff.max()\n    return transff", "test_code_list": [{"test_code": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.signal.array_analysis import array_processing\nfrom obspy.signal.array_analysis import array_transff_freqslowness\nfrom obspy.signal.array_analysis import array_transff_wavenumber\nfrom obspy.signal.array_analysis import get_spoint\nfrom obspy.signal.util import util_lon_lat\n\nclass TestSonic():\n\tdef test_array_transff_freqslowness(self):\n\t    coords = np.array([[10.0, 60.0, 0.0], [200.0, 50.0, 0.0], [-120.0, \n\t        170.0, 0.0], [-100.0, -150.0, 0.0], [30.0, -220.0, 0.0]])\n\t    coords /= 1000.0\n\t    coordsll = np.zeros(coords.shape)\n\t    for i in np.arange(len(coords)):\n\t        coordsll[i, 0], coordsll[i, 1] = util_lon_lat(0.0, 0.0, coords[i, 0\n\t            ], coords[i, 1])\n\t    slim = 40.0\n\t    fmin = 1.0\n\t    fmax = 10.0\n\t    fstep = 1.0\n\t    sstep = slim / 2.0\n\t    transff = array_transff_freqslowness(coords, slim, sstep, fmin, fmax,\n\t        fstep, coordsys='xy')\n\t    transffll = array_transff_freqslowness(coordsll, slim, sstep, fmin,\n\t        fmax, fstep, coordsys='lonlat')\n\t    transffth = np.array([[0.41915119, 0.33333333, 0.32339525, 0.24751548, \n\t        0.67660475], [0.25248452, 0.41418215, 0.34327141, 0.65672859, \n\t        0.33333333], [0.24751548, 0.25248452, 1.0, 0.25248452, 0.24751548],\n\t        [0.33333333, 0.65672859, 0.34327141, 0.41418215, 0.25248452], [\n\t        0.67660475, 0.24751548, 0.32339525, 0.33333333, 0.41915119]])\n\t    np.testing.assert_array_almost_equal(transff, transffth, decimal=6)\n\t    np.testing.assert_array_almost_equal(transffll, transffth, decimal=6)\n\t\nTestSonic().test_array_transff_freqslowness()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_sonic.py"}], "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef array_transff_freqslowness(coords, slim, sstep, fmin, fmax, fstep,\n    coordsys='lonlat'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "array_transff_wavenumber", "method_path": "../srcdata/Computation/obspy/obspy/signal/array_analysis.py", "response": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\ndef array_transff_wavenumber(coords, klim, kstep, coordsys='lonlat'):\n    \"\"\"\n    Returns array transfer function as a function of wavenumber difference\n\n    :type coords: numpy.ndarray\n    :param coords: coordinates of stations in longitude and latitude in degrees\n        elevation in km, or x, y, z in km\n    :type coordsys: str\n    :param coordsys: valid values: 'lonlat' and 'xy', choose which coordinates\n        to use\n    :param klim: either a float to use symmetric limits for wavenumber\n        differences or the tuple (kxmin, kxmax, kymin, kymax)\n    \"\"\"\n    coords = get_geometry(coords, coordsys)\n    if isinstance(klim, float):\n        kxmin = -klim\n        kxmax = klim\n        kymin = -klim\n        kymax = klim\n    elif isinstance(klim, tuple):\n        if len(klim) == 4:\n            kxmin = klim[0]\n            kxmax = klim[1]\n            kymin = klim[2]\n            kymax = klim[3]\n    else:\n        raise TypeError('klim must either be a float or a tuple of length 4')\n    nkx = int(np.ceil((kxmax + kstep / 10.0 - kxmin) / kstep))\n    nky = int(np.ceil((kymax + kstep / 10.0 - kymin) / kstep))\n    kygrid, kxgrid = np.meshgrid(np.linspace(kymin, kymax, nky), np.\n        linspace(kxmin, kxmax, nkx))\n    ks = np.transpose(np.vstack((kxgrid.flatten(), kygrid.flatten())))\n    if np.__version__ == '1.14.0':\n        k_dot_r = np.einsum('ni,mi->nm', ks, coords[:, :2], optimize=False)\n    else:\n        k_dot_r = np.einsum('ni,mi->nm', ks, coords[:, :2])\n    transff = np.abs(np.sum(np.exp(1.0j * k_dot_r), axis=1)) ** 2 / len(coords\n        ) ** 2\n    return transff.reshape(nkx, nky)", "test_code_list": [{"test_code": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core.util import AttribDict\nfrom obspy.signal.array_analysis import array_processing\nfrom obspy.signal.array_analysis import array_transff_freqslowness\nfrom obspy.signal.array_analysis import array_transff_wavenumber\nfrom obspy.signal.array_analysis import get_spoint\nfrom obspy.signal.util import util_lon_lat\n\nclass TestSonic():\n\tdef test_array_transff_wavenumber(self):\n\t    coords = np.array([[10.0, 60.0, 0.0], [200.0, 50.0, 0.0], [-120.0, \n\t        170.0, 0.0], [-100.0, -150.0, 0.0], [30.0, -220.0, 0.0]])\n\t    coords /= 1000.0\n\t    coordsll = np.zeros(coords.shape)\n\t    for i in np.arange(len(coords)):\n\t        coordsll[i, 0], coordsll[i, 1] = util_lon_lat(0.0, 0.0, coords[i, 0\n\t            ], coords[i, 1])\n\t    klim = 40.0\n\t    kstep = klim / 2.0\n\t    transff = array_transff_wavenumber(coords, klim, kstep, coordsys='xy')\n\t    transffll = array_transff_wavenumber(coordsll, klim, kstep, coordsys=\n\t        'lonlat')\n\t    transffth = np.array([[0.31336036, 0.0423775796, 0.673650243, \n\t        0.480470652, 0.000816891615], [0.298941684, 0.247377842, \n\t        0.0996352135, 0.0684732871, 0.557078203], [0.126523678, 0.291010683,\n\t        1.0, 0.291010683, 0.126523678], [0.557078203, 0.0684732871, \n\t        0.0996352135, 0.247377842, 0.298941684], [0.000816891615, \n\t        0.480470652, 0.673650243, 0.0423775796, 0.31336036]])\n\t    np.testing.assert_array_almost_equal(transff, transffth, decimal=6)\n\t    np.testing.assert_array_almost_equal(transffll, transffth, decimal=6)\n\t\nTestSonic().test_array_transff_wavenumber()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_sonic.py"}], "method_code_mask": "import math\nimport warnings\nfrom matplotlib.dates import datestr2num\nimport numpy as np\nfrom scipy.integrate import cumulative_trapezoid\nfrom obspy.core import Stream\nfrom obspy.signal.headers import clibsignal\nfrom obspy.signal.invsim import cosine_taper\nfrom obspy.signal.util import next_pow_2\nfrom obspy.signal.util import util_geo_km\n\n\ndef array_transff_wavenumber(coords, klim, kstep, coordsys='lonlat'): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "rotate_ne_rt", "method_path": "../srcdata/Computation/obspy/obspy/signal/rotate.py", "response": "import warnings\nfrom math import cos\nfrom math import sin\nfrom math import radians\nimport numpy as np\nimport doctest\ndef rotate_ne_rt(n, e, ba):\n    \"\"\"\n    Rotates horizontal components of a seismogram.\n\n    The North- and East-Component of a seismogram will be rotated in Radial\n    and Transversal Component. The angle is given as the back-azimuth, that is\n    defined as the angle measured between the vector pointing from the station\n    to the source and the vector pointing from the station to the North.\n\n    :type n: :class:`~numpy.ndarray`\n    :param n: Data of the North component of the seismogram.\n    :type e: :class:`~numpy.ndarray`\n    :param e: Data of the East component of the seismogram.\n    :type ba: float\n    :param ba: The back azimuth from station to source in degrees.\n    :return: Radial and Transversal component of seismogram.\n    \"\"\"\n    if len(n) != len(e):\n        raise TypeError('North and East component have different length.')\n    if ba < 0 or ba > 360:\n        raise ValueError('Back Azimuth should be between 0 and 360 degrees.')\n    ba = radians(ba)\n    r = -e * sin(ba) - n * cos(ba)\n    t = -e * cos(ba) + n * sin(ba)\n    return r, t", "test_code_list": [{"test_code": "import gzip\nimport itertools\nimport numpy as np\nfrom obspy.signal.rotate import rotate_lqt_zne\nfrom obspy.signal.rotate import rotate_ne_rt\nfrom obspy.signal.rotate import rotate_rt_ne\nfrom obspy.signal.rotate import rotate_zne_lqt\nfrom obspy.signal.rotate import _dip_azimuth2zne_base_vector\nfrom obspy.signal.rotate import rotate2zne\nimport pytest\n\nclass TestRotate():\n\tdef test_rotate2zne_against_rotate_ne_rt(self):\n\t    np.random.seed(123)\n\t    z = np.random.random(10)\n\t    n = np.random.random(10)\n\t    e = np.random.random(10)\n\t    for ba in [0.0, 14.325, 38.234, 78.1, 90.0, 136.3435, 265.4, 351.35]:\n\t        r, t = rotate_ne_rt(n=n, e=e, ba=ba)\n\t        z_new, n_new, e_new = rotate2zne(z, 0, -90, r, ba + 180, 0, t, ba +\n\t            270, 0)\n\t        np.testing.assert_allclose(z_new, z)\n\t        np.testing.assert_allclose(n_new, n)\n\t        np.testing.assert_allclose(e_new, e)\n\t\nTestRotate().test_rotate2zne_against_rotate_ne_rt()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_rotate.py"}, {"test_code": "import gzip\nimport itertools\nimport numpy as np\nfrom obspy.signal.rotate import rotate_lqt_zne\nfrom obspy.signal.rotate import rotate_ne_rt\nfrom obspy.signal.rotate import rotate_rt_ne\nfrom obspy.signal.rotate import rotate_zne_lqt\nfrom obspy.signal.rotate import _dip_azimuth2zne_base_vector\nfrom obspy.signal.rotate import rotate2zne\nimport pytest\n\nclass TestRotate():\n\tdef test_rotate2zne_against_ne_rt_picking_any_two_horizontal_comps(self):\n\t    \"\"\"\n\t        This also tests non-orthogonal configurations to some degree.\n\t        \"\"\"\n\t    np.random.seed(456)\n\t    z = np.random.random(10)\n\t    n = np.random.random(10)\n\t    e = np.random.random(10)\n\t    for ba in [14.325, 38.234, 78.1, 136.3435, 265.4, 351.35]:\n\t        r, t = rotate_ne_rt(n=n, e=e, ba=ba)\n\t        _r = [r, ba + 180, 0]\n\t        _t = [t, ba + 270, 0]\n\t        _n = [n, 0, 0]\n\t        _e = [e, 90, 0]\n\t        for a, b in itertools.permutations([_r, _t, _n, _e], 2):\n\t            z_new, n_new, e_new = rotate2zne(z, 0, -90, a[0], a[1], a[2], b\n\t                [0], b[1], b[2])\n\t            np.testing.assert_allclose(z_new, z)\n\t            np.testing.assert_allclose(n_new, n)\n\t            np.testing.assert_allclose(e_new, e)\n\t\nTestRotate().test_rotate2zne_against_ne_rt_picking_any_two_horizontal_comps()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/signal/tests/test_rotate.py"}], "method_code_mask": "import warnings\nfrom math import cos\nfrom math import sin\nfrom math import radians\nimport numpy as np\nimport doctest\n\n\ndef rotate_ne_rt(n, e, ba): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_parse_date_time", "method_path": "../srcdata/Computation/obspy/obspy/io/ndk/core.py", "response": "import math\nimport re\nimport traceback\nimport uuid\nimport warnings\nfrom itertools import zip_longest\nfrom obspy import UTCDateTime\nfrom obspy.core.event import Axis\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import DataUsed\nfrom obspy.core.event import Event\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import Origin\nfrom obspy.core.event import PrincipalAxes\nfrom obspy.core.event import SourceTimeFunction\nfrom obspy.core.event import Tensor\nfrom obspy.geodetics import FlinnEngdahl\ndef _parse_date_time(date, time):\n    \"\"\"\n    Function taking a tuple of date and time string from an NDK file and\n    converting it to an UTCDateTime object.\n\n    In particular it is able to deal with a time string specifying 60\n    seconds which is not a valid ISO time string but occurs a lot in NDK\n    files.\n    \"\"\"\n    add_minute = False\n    if ':60.0' in time:\n        time = time.replace(':60.0', ':0.0')\n        add_minute = True\n    try:\n        dt = UTCDateTime(date.replace('/', '-') + 'T' + time)\n    except (TypeError, ValueError):\n        msg = (\n            \"Could not parse date/time string '%s' and '%s' to a valid time\" %\n            (date, time))\n        raise ObsPyNDKException(msg)\n    if add_minute:\n        dt += 60.0\n    return dt", "test_code_list": [{"test_code": "import io\nimport warnings\nfrom obspy import UTCDateTime\nfrom obspy import read_events\nfrom obspy.io.ndk.core import ObsPyNDKException\nfrom obspy.io.ndk.core import _parse_date_time\nfrom obspy.io.ndk.core import _is_ndk\nfrom obspy.io.ndk.core import _read_ndk\nimport pytest\n\nclass TestNDK():\n\tdef test_parse_date_time_function(self):\n\t    \"\"\"\n\t        Tests the _parse_date_time() function.\n\t        \"\"\"\n\t    date, time = '1997/11/03', '19:17:33.8'\n\t    assert _parse_date_time(date, time) == UTCDateTime(1997, 11, 3, 19, 17,\n\t        33, int(800000.0))\n\t    date, time = '1996/11/20', '19:42:56.1'\n\t    assert _parse_date_time(date, time) == UTCDateTime(1996, 11, 20, 19, 42,\n\t        56, int(100000.0))\n\t    date, time = '2005/01/01', '01:20:05.4'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2005, 1, 1, 1, 20, 5,\n\t        int(400000.0))\n\t    date, time = '2013/03/01', '03:29:46.8'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2013, 3, 1, 3, 29, \n\t        46, int(800000.0))\n\t    date, time = '2013/03/02', '07:53:43.8'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2013, 3, 2, 7, 53, \n\t        43, int(800000.0))\n\t    date, time = '1998/09/27', '00:57:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(1998, 9, 27, 0, 58)\n\t    date, time = '2000/12/22', '16:29:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2000, 12, 22, 16, 30)\n\t    date, time = '2003/06/19', '23:04:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2003, 6, 19, 23, 5)\n\t    date, time = '2005/06/20', '02:32:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2005, 6, 20, 2, 33)\n\t    date, time = '2006/03/02', '17:16:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2006, 3, 2, 17, 17)\n\t    date, time = '2006/05/26', '10:25:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2006, 5, 26, 10, 26)\n\t    date, time = '2006/08/20', '13:34:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2006, 8, 20, 13, 35)\n\t    date, time = '2007/04/20', '00:30:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2007, 4, 20, 0, 31)\n\t    date, time = '2007/07/02', '00:54:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2007, 7, 2, 0, 55)\n\t    date, time = '2007/08/27', '17:11:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2007, 8, 27, 17, 12)\n\t    date, time = '2008/09/24', '01:36:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2008, 9, 24, 1, 37)\n\t    date, time = '2008/10/05', '10:44:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2008, 10, 5, 10, 45)\n\t    date, time = '2009/04/17', '04:09:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2009, 4, 17, 4, 10)\n\t    date, time = '2009/06/03', '14:30:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2009, 6, 3, 14, 31)\n\t    date, time = '2009/07/20', '10:44:60.0'\n\t    assert _parse_date_time(date, time) == UTCDateTime(2009, 7, 20, 10, 45)\n\t\nTestNDK().test_parse_date_time_function()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/ndk/tests/test_ndk.py"}], "method_code_mask": "import math\nimport re\nimport traceback\nimport uuid\nimport warnings\nfrom itertools import zip_longest\nfrom obspy import UTCDateTime\nfrom obspy.core.event import Axis\nfrom obspy.core.event import Catalog\nfrom obspy.core.event import Comment\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import DataUsed\nfrom obspy.core.event import Event\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import Origin\nfrom obspy.core.event import PrincipalAxes\nfrom obspy.core.event import SourceTimeFunction\nfrom obspy.core.event import Tensor\nfrom obspy.geodetics import FlinnEngdahl\n\n\ndef _parse_date_time(date, time): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_read_segy", "method_path": "../srcdata/Computation/obspy/obspy/io/segy/core.py", "response": "import warnings\nfrom copy import deepcopy\nfrom struct import unpack\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import AttribDict\nimport doctest\ndef _read_segy(filename, headonly=False, byteorder=None,\n    textual_header_encoding=None, unpack_trace_headers=False, **kwargs):\n    \"\"\"\n    Reads a SEG Y file and returns an ObsPy Stream object.\n\n    .. warning::\n        This function should NOT be called directly, it registers via the\n        ObsPy :func:`~obspy.core.stream.read` function, call this instead.\n\n    :type filename: str\n    :param filename: SEG Y rev1 file to be read.\n    :type headonly: bool, optional\n    :param headonly: If set to True, read only the header and omit the waveform\n        data.\n    :type byteorder: str or ``None``\n    :param byteorder: Determines the endianness of the file. Either ``'>'`` for\n        big endian or ``'<'`` for little endian. If it is ``None``, it will try\n        to autodetect the endianness. The endianness is always valid for the\n        whole file. Defaults to ``None``.\n    :type textual_header_encoding: str or ``None``\n    :param textual_header_encoding: The encoding of the textual header. Can be\n        ``'EBCDIC'``, ``'ASCII'`` or ``None``. If it is ``None``, autodetection\n        will be attempted. Defaults to ``None``.\n    :type unpack_trace_headers: bool, optional\n    :param unpack_trace_headers: Determines whether or not all trace header\n        values will be unpacked during reading. If ``False`` it will greatly\n        enhance performance and especially memory usage with large files. The\n        header values can still be accessed and will be calculated on the fly\n        but tab completion will no longer work. Look in the headers.py for a\n        list of all possible trace header values. Defaults to ``False``.\n    :returns: A ObsPy :class:`~obspy.core.stream.Stream` object.\n\n    .. rubric:: Example\n\n    >>> from obspy import read\n    >>> st = read(\"/path/to/00001034.sgy_first_trace\")\n    >>> st  # doctest: +ELLIPSIS\n    <obspy.core.stream.Stream object at 0x...>\n    >>> print(st)  # doctest: +ELLIPSIS\n    1 Trace(s) in Stream:\n    Seq. No. in line:    1 | 2009-06-22T14:47:37.000000Z - ... 2001 samples\n    \"\"\"\n    segy_object = _read_segyrev1(filename, endian=byteorder,\n        textual_header_encoding=textual_header_encoding, unpack_headers=\n        unpack_trace_headers)\n    stream = Stream()\n    stream.stats = AttribDict()\n    textual_file_header = segy_object.textual_file_header\n    binary_file_header = AttribDict()\n    for key, value in segy_object.binary_file_header.__dict__.items():\n        setattr(binary_file_header, key, value)\n    data_encoding = segy_object.traces[0].data_encoding\n    endian = segy_object.traces[0].endian\n    textual_file_header_encoding = segy_object.textual_header_encoding.upper()\n    stream.stats.textual_file_header = textual_file_header\n    stream.stats.binary_file_header = binary_file_header\n    stream.stats.data_encoding = data_encoding\n    stream.stats.endian = endian\n    stream.stats.textual_file_header_encoding = textual_file_header_encoding\n    for tr in segy_object.traces:\n        stream.append(tr.to_obspy_trace(headonly=headonly,\n            unpack_trace_headers=unpack_trace_headers))\n    return stream", "test_code_list": [{"test_code": "import io\nimport os\nfrom struct import unpack\nimport warnings\nimport numpy as np\nimport pytest\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy import Trace\nfrom obspy import Stream\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.core.util import AttribDict\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.io.segy.core import SEGYCoreWritingError\nfrom obspy.io.segy.core import SEGYSampleIntervalError\nfrom obspy.io.segy.core import _is_segy\nfrom obspy.io.segy.core import _is_su\nfrom obspy.io.segy.core import _read_segy\nfrom obspy.io.segy.core import _read_su\nfrom obspy.io.segy.core import _write_segy\nfrom obspy.io.segy.core import _write_su\nfrom obspy.io.segy.segy import _read_segy as _read_segy_internal\nfrom obspy.io.segy.segy import SEGYError\nfrom obspy.io.segy.segy import SEGYFile\nfrom obspy.io.segy.segy import SEGYTrace\nfrom obspy.io.segy.segy import SEGYBinaryFileHeader\nfrom obspy.io.segy.tests import _patch_header\nfrom obspy.io.segy.tests.header import FILES\n\nclass TestSEGYCore():\n\tdef test_writing_text_and_binary_textual_file_headers(self):\n\t    \"\"\"\n\t        Make sure the textual file header can be written if has been passed\n\t        either as text or as a bytestring.\n\t        \"\"\"\n\t    for textual_file_header in [b'12345', '12345']:\n\t        for encoding in ['ASCII', 'EBCDIC']:\n\t            st = read()\n\t            for tr in st:\n\t                tr.data = np.require(tr.data, dtype=np.float32)\n\t            st.stats = AttribDict()\n\t            st.stats.textual_file_header = textual_file_header\n\t            with io.BytesIO() as buf:\n\t                with pytest.warns(UserWarning):\n\t                    st.write(buf, format='SEGY', data_encoding=5,\n\t                        textual_header_encoding=encoding)\n\t                buf.seek(0, 0)\n\t                st2 = _read_segy(buf)\n\t            assert st2.stats.textual_file_header.decode().split()[0] == '12345'\n\t\nTestSEGYCore().test_writing_text_and_binary_textual_file_headers()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/segy/tests/test_core.py"}], "method_code_mask": "import warnings\nfrom copy import deepcopy\nfrom struct import unpack\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import AttribDict\nimport doctest\n\n\ndef _read_segy(filename, headonly=False, byteorder=None,\n    textual_header_encoding=None, unpack_trace_headers=False, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "from_buffer", "method_path": "../srcdata/Computation/obspy/obspy/core/compatibility.py", "response": "import numpy as np\ndef from_buffer(data, dtype):\n    try:\n        data = data.encode()\n    except Exception:\n        pass\n    return np.array(memoryview(data)).view(dtype).copy()", "test_code_list": [{"test_code": "import ctypes as C\nimport io\nimport multiprocessing\nimport os\nimport platform\nimport random\nimport re\nimport signal\nimport sys\nimport warnings\nfrom unittest import mock\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.core.util.attribdict import AttribDict\nfrom obspy.core.util.base import CatchAndAssertWarnings\nfrom obspy.io.mseed import InternalMSEEDError\nfrom obspy.io.mseed import InternalMSEEDWarning\nfrom obspy.io.mseed import ObsPyMSEEDFilesizeTooSmallError\nfrom obspy.io.mseed import ObsPyMSEEDFilesizeTooLargeError\nfrom obspy.io.mseed import util\nfrom obspy.io.mseed.core import _read_mseed\nfrom obspy.io.mseed.core import _write_mseed\nfrom obspy.io.mseed.headers import clibmseed\nfrom obspy.io.mseed.msstruct import _MSStruct\nimport pytest\n\nclass TestMSEEDSpecialIssue():\n\tdef test_bug_write_read_float32_seed_win32(self):\n\t    \"\"\"\n\t        Test case for issue #64.\n\t        \"\"\"\n\t    data = np.array([395.07809448, 395.0782, 1060.28112793, -1157.37487793,\n\t        -1236.56237793, 355.07028198, -1181.42175293], dtype=np.float32)\n\t    st = Stream([Trace(data=data)])\n\t    with NamedTemporaryFile() as tf:\n\t        tempfile = tf.name\n\t        _write_mseed(st, tempfile, format='MSEED')\n\t        with open(tempfile, 'rb') as fp:\n\t            fp.seek(56)\n\t            dtype = np.dtype('>f4')\n\t            bin_data = from_buffer(fp.read(7 * dtype.itemsize), dtype=dtype)\n\t        np.testing.assert_array_equal(data, bin_data)\n\t        st2 = _read_mseed(tempfile)\n\t    np.testing.assert_array_equal(data, st2[0].data)\n\t\nTestMSEEDSpecialIssue().test_bug_write_read_float32_seed_win32()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/mseed/tests/test_mseed_special_issues.py"}], "method_code_mask": "import numpy as np\n\n\ndef from_buffer(data, dtype): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_nortoevmag", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _nortoevmag(mag_type):\n    \"\"\"\n    Switch from nordic type magnitude notation to obspy event magnitudes.\n\n    >>> print(_nortoevmag('B'))  # doctest: +SKIP\n    mB\n    >>> print(_nortoevmag('bob'))  # doctest: +SKIP\n    <BLANKLINE>\n    \"\"\"\n    if mag_type.upper() == 'L':\n        return 'ML'\n    mag = INV_MAG_MAPPING.get(mag_type, '')\n    if mag == '':\n        warnings.warn(mag_type + ' is not convertible')\n    return mag", "test_code_list": [{"test_code": "import io\nimport os\nimport warnings\nfrom itertools import cycle\nimport numpy as np\nfrom obspy import read_events\nfrom obspy import Catalog\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import Arrival\nfrom obspy.core.event import Amplitude\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import OriginQuality\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import OriginUncertainty\nfrom obspy.core.event import ConfidenceEllipsoid\nfrom obspy.core.event import QuantityError\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.misc import TemporaryWorkingDirectory\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.io.nordic.core import _is_sfile\nfrom obspy.io.nordic.core import read_spectral_info\nfrom obspy.io.nordic.core import read_nordic\nfrom obspy.io.nordic.core import readwavename\nfrom obspy.io.nordic.core import blanksfile\nfrom obspy.io.nordic.core import _write_nordic\nfrom obspy.io.nordic.core import nordpick\nfrom obspy.io.nordic.core import readheader\nfrom obspy.io.nordic.core import _readheader\nfrom obspy.io.nordic.core import write_select\nfrom obspy.io.nordic.utils import _int_conv\nfrom obspy.io.nordic.utils import _float_conv\nfrom obspy.io.nordic.utils import _str_conv\nfrom obspy.io.nordic.utils import _nortoevmag\nfrom obspy.io.nordic.utils import _evmagtonor\nfrom obspy.io.nordic.utils import _get_line_tags\nfrom obspy.io.nordic.ellipse import Ellipse\nimport pytest\nimport matplotlib.pyplot as plt\n\nclass TestNordicMethods():\n\tdef test_mag_conv(self):\n\t    \"\"\"\n\t        Check that we convert magnitudes as we should!\n\t        \"\"\"\n\t    magnitude_map = [('L', 'ML'), ('B', 'mB'), ('S', 'MS'), ('W', 'MW'), (\n\t        'G', 'MbLg'), ('C', 'Mc'), ('s', 'Ms')]\n\t    for magnitude in magnitude_map:\n\t        assert magnitude[0] == _evmagtonor(magnitude[1])\n\t        assert _nortoevmag(magnitude[0]) == magnitude[1]\n\t\nTestNordicMethods().test_mag_conv()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/nordic/tests/test_nordic.py"}], "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _nortoevmag(mag_type): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_evmagtonor", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _evmagtonor(mag_type):\n    \"\"\"\n    Switch from obspy event magnitude types to seisan syntax.\n\n    >>> print(_evmagtonor('mB'))  # doctest: +SKIP\n    B\n    >>> print(_evmagtonor('M'))  # doctest: +SKIP\n    W\n    >>> print(_evmagtonor('bob'))  # doctest: +SKIP\n    <BLANKLINE>\n    \"\"\"\n    if mag_type == 'M' or mag_type is None:\n        warnings.warn('Converting generic magnitude to moment magnitude')\n        return 'W'\n    mag = MAG_MAPPING.get(mag_type, '')\n    if mag == '':\n        warnings.warn(mag_type + ' is not convertible')\n        return ' '\n    return mag", "test_code_list": [{"test_code": "import io\nimport os\nimport warnings\nfrom itertools import cycle\nimport numpy as np\nfrom obspy import read_events\nfrom obspy import Catalog\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import Arrival\nfrom obspy.core.event import Amplitude\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import OriginQuality\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import OriginUncertainty\nfrom obspy.core.event import ConfidenceEllipsoid\nfrom obspy.core.event import QuantityError\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.misc import TemporaryWorkingDirectory\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.io.nordic.core import _is_sfile\nfrom obspy.io.nordic.core import read_spectral_info\nfrom obspy.io.nordic.core import read_nordic\nfrom obspy.io.nordic.core import readwavename\nfrom obspy.io.nordic.core import blanksfile\nfrom obspy.io.nordic.core import _write_nordic\nfrom obspy.io.nordic.core import nordpick\nfrom obspy.io.nordic.core import readheader\nfrom obspy.io.nordic.core import _readheader\nfrom obspy.io.nordic.core import write_select\nfrom obspy.io.nordic.utils import _int_conv\nfrom obspy.io.nordic.utils import _float_conv\nfrom obspy.io.nordic.utils import _str_conv\nfrom obspy.io.nordic.utils import _nortoevmag\nfrom obspy.io.nordic.utils import _evmagtonor\nfrom obspy.io.nordic.utils import _get_line_tags\nfrom obspy.io.nordic.ellipse import Ellipse\nimport pytest\nimport matplotlib.pyplot as plt\n\nclass TestNordicMethods():\n\tdef test_mag_conv(self):\n\t    \"\"\"\n\t        Check that we convert magnitudes as we should!\n\t        \"\"\"\n\t    magnitude_map = [('L', 'ML'), ('B', 'mB'), ('S', 'MS'), ('W', 'MW'), (\n\t        'G', 'MbLg'), ('C', 'Mc'), ('s', 'Ms')]\n\t    for magnitude in magnitude_map:\n\t        assert magnitude[0] == _evmagtonor(magnitude[1])\n\t        assert _nortoevmag(magnitude[0]) == magnitude[1]\n\t\nTestNordicMethods().test_mag_conv()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/nordic/tests/test_nordic.py"}], "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _evmagtonor(mag_type): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_float_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _float_conv(string):\n    \"\"\"\n    Convenience tool to convert from string to float.\n\n    If empty string return None rather than an error.\n\n    >>> _float_conv('12')\n    12.0\n    >>> _float_conv('')\n    >>> _float_conv('12.324')\n    12.324\n    \"\"\"\n    try:\n        floatstring = float(string)\n    except Exception:\n        floatstring = None\n    return floatstring", "test_code_list": [{"test_code": "import io\nimport os\nimport warnings\nfrom itertools import cycle\nimport numpy as np\nfrom obspy import read_events\nfrom obspy import Catalog\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import Arrival\nfrom obspy.core.event import Amplitude\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import OriginQuality\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import OriginUncertainty\nfrom obspy.core.event import ConfidenceEllipsoid\nfrom obspy.core.event import QuantityError\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.misc import TemporaryWorkingDirectory\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.io.nordic.core import _is_sfile\nfrom obspy.io.nordic.core import read_spectral_info\nfrom obspy.io.nordic.core import read_nordic\nfrom obspy.io.nordic.core import readwavename\nfrom obspy.io.nordic.core import blanksfile\nfrom obspy.io.nordic.core import _write_nordic\nfrom obspy.io.nordic.core import nordpick\nfrom obspy.io.nordic.core import readheader\nfrom obspy.io.nordic.core import _readheader\nfrom obspy.io.nordic.core import write_select\nfrom obspy.io.nordic.utils import _int_conv\nfrom obspy.io.nordic.utils import _float_conv\nfrom obspy.io.nordic.utils import _str_conv\nfrom obspy.io.nordic.utils import _nortoevmag\nfrom obspy.io.nordic.utils import _evmagtonor\nfrom obspy.io.nordic.utils import _get_line_tags\nfrom obspy.io.nordic.ellipse import Ellipse\nimport pytest\nimport matplotlib.pyplot as plt\n\nclass TestNordicMethods():\n\tdef test_str_conv(self):\n\t    \"\"\"\n\t        Test the simple string conversions.\n\t        \"\"\"\n\t    assert _int_conv('albert') is None\n\t    assert _float_conv('albert') is None\n\t    assert _str_conv('albert') == 'albert'\n\t    assert _int_conv('1') == 1\n\t    assert _float_conv('1') == 1.0\n\t    assert _str_conv(1) == '1'\n\t    assert _int_conv('1.0256') is None\n\t    assert _float_conv('1.0256') == 1.0256\n\t    assert _str_conv(1.0256) == '1.0256'\n\t\nTestNordicMethods().test_str_conv()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/nordic/tests/test_nordic.py"}], "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _float_conv(string): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_int_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _int_conv(string):\n    \"\"\"\n    Convenience tool to convert from string to integer.\n\n    If empty string return None rather than an error.\n\n    >>> _int_conv('12')\n    12\n    >>> _int_conv('')\n\n    \"\"\"\n    try:\n        intstring = int(string)\n    except Exception:\n        intstring = None\n    return intstring", "test_code_list": [{"test_code": "import io\nimport os\nimport warnings\nfrom itertools import cycle\nimport numpy as np\nfrom obspy import read_events\nfrom obspy import Catalog\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import Arrival\nfrom obspy.core.event import Amplitude\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import OriginQuality\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import OriginUncertainty\nfrom obspy.core.event import ConfidenceEllipsoid\nfrom obspy.core.event import QuantityError\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.misc import TemporaryWorkingDirectory\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.io.nordic.core import _is_sfile\nfrom obspy.io.nordic.core import read_spectral_info\nfrom obspy.io.nordic.core import read_nordic\nfrom obspy.io.nordic.core import readwavename\nfrom obspy.io.nordic.core import blanksfile\nfrom obspy.io.nordic.core import _write_nordic\nfrom obspy.io.nordic.core import nordpick\nfrom obspy.io.nordic.core import readheader\nfrom obspy.io.nordic.core import _readheader\nfrom obspy.io.nordic.core import write_select\nfrom obspy.io.nordic.utils import _int_conv\nfrom obspy.io.nordic.utils import _float_conv\nfrom obspy.io.nordic.utils import _str_conv\nfrom obspy.io.nordic.utils import _nortoevmag\nfrom obspy.io.nordic.utils import _evmagtonor\nfrom obspy.io.nordic.utils import _get_line_tags\nfrom obspy.io.nordic.ellipse import Ellipse\nimport pytest\nimport matplotlib.pyplot as plt\n\nclass TestNordicMethods():\n\tdef test_str_conv(self):\n\t    \"\"\"\n\t        Test the simple string conversions.\n\t        \"\"\"\n\t    assert _int_conv('albert') is None\n\t    assert _float_conv('albert') is None\n\t    assert _str_conv('albert') == 'albert'\n\t    assert _int_conv('1') == 1\n\t    assert _float_conv('1') == 1.0\n\t    assert _str_conv(1) == '1'\n\t    assert _int_conv('1.0256') is None\n\t    assert _float_conv('1.0256') == 1.0256\n\t    assert _str_conv(1.0256) == '1.0256'\n\t\nTestNordicMethods().test_str_conv()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/nordic/tests/test_nordic.py"}], "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _int_conv(string): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_str_conv", "method_path": "../srcdata/Computation/obspy/obspy/io/nordic/utils.py", "response": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\ndef _str_conv(number, rounded=False):\n    \"\"\"\n    Convenience tool to convert a number, either float or int into a string.\n\n    If the int or float is None, returns empty string.\n\n    >>> print(_str_conv(12.3))\n    12.3\n    >>> print(_str_conv(12.34546, rounded=1))\n    12.3\n    >>> print(_str_conv(None))\n    <BLANKLINE>\n    >>> print(_str_conv(1123040))\n    11.2e5\n    \"\"\"\n    if not number and number != 0:\n        return str(' ')\n    if not rounded and isinstance(number, (float, int)):\n        if number < 100000:\n            string = str(number)\n        else:\n            exponent = int('{0:.2E}'.format(number).split('E+')[-1]) - 1\n            divisor = 10 ** exponent\n            string = '{0:.1f}'.format(number / divisor) + 'e' + str(exponent)\n    elif rounded and isinstance(number, (float, int)):\n        if number < 100000:\n            string = '{:.{precision}f}'.format(number, precision=rounded)\n        else:\n            exponent = int('{0:.2E}'.format(number).split('E+')[-1]) - 1\n            divisor = 10 ** exponent\n            string = '{:.{precision}f}'.format(number / divisor, precision=\n                rounded) + 'e' + str(exponent)\n    else:\n        return str(number)\n    return string", "test_code_list": [{"test_code": "import io\nimport os\nimport warnings\nfrom itertools import cycle\nimport numpy as np\nfrom obspy import read_events\nfrom obspy import Catalog\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.event import Pick\nfrom obspy.core.event import WaveformStreamID\nfrom obspy.core.event import Arrival\nfrom obspy.core.event import Amplitude\nfrom obspy.core.event import Event\nfrom obspy.core.event import Origin\nfrom obspy.core.event import Magnitude\nfrom obspy.core.event import OriginQuality\nfrom obspy.core.event import EventDescription\nfrom obspy.core.event import CreationInfo\nfrom obspy.core.event import OriginUncertainty\nfrom obspy.core.event import ConfidenceEllipsoid\nfrom obspy.core.event import QuantityError\nfrom obspy.core.event import FocalMechanism\nfrom obspy.core.event import MomentTensor\nfrom obspy.core.event import NodalPlane\nfrom obspy.core.event import NodalPlanes\nfrom obspy.core.event import ResourceIdentifier\nfrom obspy.core.event import Tensor\nfrom obspy.core.util.base import NamedTemporaryFile\nfrom obspy.core.util.misc import TemporaryWorkingDirectory\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.io.nordic.core import _is_sfile\nfrom obspy.io.nordic.core import read_spectral_info\nfrom obspy.io.nordic.core import read_nordic\nfrom obspy.io.nordic.core import readwavename\nfrom obspy.io.nordic.core import blanksfile\nfrom obspy.io.nordic.core import _write_nordic\nfrom obspy.io.nordic.core import nordpick\nfrom obspy.io.nordic.core import readheader\nfrom obspy.io.nordic.core import _readheader\nfrom obspy.io.nordic.core import write_select\nfrom obspy.io.nordic.utils import _int_conv\nfrom obspy.io.nordic.utils import _float_conv\nfrom obspy.io.nordic.utils import _str_conv\nfrom obspy.io.nordic.utils import _nortoevmag\nfrom obspy.io.nordic.utils import _evmagtonor\nfrom obspy.io.nordic.utils import _get_line_tags\nfrom obspy.io.nordic.ellipse import Ellipse\nimport pytest\nimport matplotlib.pyplot as plt\n\nclass TestNordicMethods():\n\tdef test_str_conv(self):\n\t    \"\"\"\n\t        Test the simple string conversions.\n\t        \"\"\"\n\t    assert _int_conv('albert') is None\n\t    assert _float_conv('albert') is None\n\t    assert _str_conv('albert') == 'albert'\n\t    assert _int_conv('1') == 1\n\t    assert _float_conv('1') == 1.0\n\t    assert _str_conv(1) == '1'\n\t    assert _int_conv('1.0256') is None\n\t    assert _float_conv('1.0256') == 1.0256\n\t    assert _str_conv(1.0256) == '1.0256'\n\t\nTestNordicMethods().test_str_conv()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/nordic/tests/test_nordic.py"}], "method_code_mask": "import warnings\nfrom collections import defaultdict\nfrom obspy.io.nordic import NordicParsingError\nfrom obspy.geodetics.base import kilometers2degrees\nfrom numpy import cos\nfrom numpy import radians\nimport doctest\n\n\ndef _str_conv(number, rounded=False): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_convert_datetime_to_mstime", "method_path": "../srcdata/Computation/obspy/obspy/io/mseed/util.py", "response": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\ndef _convert_datetime_to_mstime(dt):\n    \"\"\"\n    Takes a obspy.util.UTCDateTime object and returns an epoch time in ms.\n\n    :param dt: obspy.util.UTCDateTime object.\n    \"\"\"\n    rest = dt._ns % 10 ** 3 >= 500 and 1 or 0\n    return dt._ns // 10 ** 3 + rest", "test_code_list": [{"test_code": "import copy\nimport io\nimport os\nimport random\nimport shutil\nimport sys\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.io.mseed import util\nfrom obspy.io.mseed.core import _read_mseed\nfrom obspy.io.mseed.headers import FIXED_HEADER_ACTIVITY_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_DATA_QUAL_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_IO_CLOCK_FLAGS\nfrom obspy.io.mseed.util import set_flags_in_fixed_headers\nimport pytest\n\nclass TestMSEEDUtil():\n\tdef test_convert_datetime(self):\n\t    \"\"\"\n\t        Tests all time conversion methods.\n\t        \"\"\"\n\t    timesdict = {(1234567890): UTCDateTime(2009, 2, 13, 23, 31, 30), (\n\t        1111111111): UTCDateTime(2005, 3, 18, 1, 58, 31), (1212121212):\n\t        UTCDateTime(2008, 5, 30, 4, 20, 12), (1313131313): UTCDateTime(2011,\n\t        8, 12, 6, 41, 53), (100000): UTCDateTime(1970, 1, 2, 3, 46, 40), (\n\t        100000.111112): UTCDateTime(1970, 1, 2, 3, 46, 40, 111112), (\n\t        200000000): UTCDateTime(1976, 5, 3, 19, 33, 20), (1388479508.871572\n\t        ): UTCDateTime(1388479508.8715718)}\n\t    for ts, dt in timesdict.items():\n\t        assert dt == util._convert_mstime_to_datetime(ts * 1000000)\n\t        assert ts * 1000000 == _convert_datetime_to_mstime(dt)\n\t    dt = UTCDateTime(2017, 3, 6, 4, 12, 16, 260696)\n\t    assert dt == util._convert_mstime_to_datetime(util.\n\t        _convert_datetime_to_mstime(dt))\n\t    random.seed(815)\n\t    timestring = random.randint(0, 2000000) * 1000000.0\n\t    assert timestring == _convert_datetime_to_mstime(util.\n\t        _convert_mstime_to_datetime(timestring))\n\t\nTestMSEEDUtil().test_convert_datetime()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/mseed/tests/test_mseed_util.py"}, {"test_code": "import copy\nimport io\nimport os\nimport random\nimport shutil\nimport sys\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.io.mseed import util\nfrom obspy.io.mseed.core import _read_mseed\nfrom obspy.io.mseed.headers import FIXED_HEADER_ACTIVITY_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_DATA_QUAL_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_IO_CLOCK_FLAGS\nfrom obspy.io.mseed.util import set_flags_in_fixed_headers\nimport pytest\n\nclass TestMSEEDUtil():\n\tdef test_convert_datetime2(self):\n\t    \"\"\"\n\t        Some failing test discovered in #1670\n\t        \"\"\"\n\t    dt = UTCDateTime(ns=1487021451935737333)\n\t    assert str(dt) == '2017-02-13T21:30:51.935737Z'\n\t    assert _convert_datetime_to_mstime(dt) == 1487021451935737\n\t    assert dt == util._convert_mstime_to_datetime(util.\n\t        _convert_datetime_to_mstime(dt))\n\t    dt = UTCDateTime(ns=1487021451935736449)\n\t    assert str(dt) == '2017-02-13T21:30:51.935736Z'\n\t    assert _convert_datetime_to_mstime(dt) == 1487021451935736\n\t    assert dt == util._convert_mstime_to_datetime(util.\n\t        _convert_datetime_to_mstime(dt))\n\t    dt = UTCDateTime(ns=1487021451935736501)\n\t    assert str(dt) == '2017-02-13T21:30:51.935737Z'\n\t    assert _convert_datetime_to_mstime(dt) == 1487021451935737\n\t    assert dt == util._convert_mstime_to_datetime(util.\n\t        _convert_datetime_to_mstime(dt))\n\t\nTestMSEEDUtil().test_convert_datetime2()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/mseed/tests/test_mseed_util.py"}], "method_code_mask": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\n\n\ndef _convert_datetime_to_mstime(dt): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_convert_flags_to_raw_byte", "method_path": "../srcdata/Computation/obspy/obspy/io/mseed/util.py", "response": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\ndef _convert_flags_to_raw_byte(expected_flags, user_flags, recstart, recend):\n    \"\"\"\n    Converts a flag dictionary to a byte, ready to be encoded in a MiniSEED\n    header.\n\n    This is a utility function for set_flags_in_fixed_headers and is not\n    designed to be called by someone else.\n\n    expected_signals describes all the possible bit names for the user flags\n    and their place in the result byte. Expected: dict { exponent: bit_name }.\n    The fixed header flags are available in obspy.io.mseed.headers as\n    FIXED_HEADER_ACTIVITY_FLAGS, FIXED_HEADER_DATA_QUAL_FLAGS and\n    FIXED_HEADER_IO_CLOCK_FLAGS.\n\n    This expects a user_flags as a dictionary { bit_name : value }. bit_name is\n    compared to the expected_signals, and its value is converted to bool.\n    Missing values are considered false.\n\n    :type expected_flags: dict\n    :param expected_flags: every possible flag in this field, with its offset.\n        Structure: {int: str}.\n    :type user_flags: dict\n    :param user_flags: user defined flags and its value.\n        Structure: {str: bool}.\n    :type recstart: UTCDateTime\n    :param recstart: date of the first sample of the current record\n    :type recstart: UTCDateTime\n    :param recend: date of the last sample of the current record\n    :return: raw int value for the flag group\n    \"\"\"\n    flag_byte = 0\n    for bit, key in expected_flags.items():\n        use_in_this_record = False\n        if key in user_flags:\n            if isinstance(user_flags[key], bool) and user_flags[key]:\n                use_in_this_record = True\n            elif isinstance(user_flags[key], collections.abc.Sequence):\n                use_in_this_record = False\n                for tuple_value in user_flags[key]:\n                    event_start = tuple_value[0]\n                    event_end = tuple_value[1]\n                    if event_start < recend and recstart <= event_end:\n                        use_in_this_record = True\n                        break\n        if use_in_this_record:\n            flag_byte += 2 ** bit\n    return flag_byte", "test_code_list": [{"test_code": "import copy\nimport io\nimport os\nimport random\nimport shutil\nimport sys\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.io.mseed import util\nfrom obspy.io.mseed.core import _read_mseed\nfrom obspy.io.mseed.headers import FIXED_HEADER_ACTIVITY_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_DATA_QUAL_FLAGS\nfrom obspy.io.mseed.headers import FIXED_HEADER_IO_CLOCK_FLAGS\nfrom obspy.io.mseed.util import set_flags_in_fixed_headers\nimport pytest\n\nclass TestMSEEDUtil():\n\tdef test_convert_flags_to_raw_bytes(self):\n\t    \"\"\"\n\t        Test case for obspy.io.mseed._convert_flags_to_raw_byte\n\t        \"\"\"\n\t    recstart = UTCDateTime('2009-12-25T06:00:00.0')\n\t    recend = UTCDateTime('2009-12-26T06:00:00.0')\n\t    user_flags = {'calib_signal': True, 'time_correction': False,\n\t        'begin_event': [(UTCDateTime('2009-12-25T07:00:00.0'), UTCDateTime(\n\t        '2009-12-25T07:00:00.0'))], 'end_event': [(UTCDateTime(\n\t        '2009-12-25T07:00:00.0'), UTCDateTime('2009-12-25T07:04:00.0'))],\n\t        'positive_leap': [(UTCDateTime('2009-12-26T06:00:00.0'),\n\t        UTCDateTime('2009-12-26T06:00:00.0'))], 'negative_leap': [(\n\t        UTCDateTime('2001-12-25T06:00:00.0'), UTCDateTime(\n\t        '2001-12-25T06:00:00.0'))], 'event_in_progress': [(UTCDateTime(\n\t        '2020-12-25T06:00:00.0'), UTCDateTime('2020-12-25T06:00:00.0'))]}\n\t    act_flags = _convert_flags_to_raw_byte(FIXED_HEADER_ACTIVITY_FLAGS,\n\t        user_flags, recstart, recend)\n\t    assert act_flags == 13\n\t    user_flags = {'sta_vol_parity_error_possible': [(UTCDateTime(\n\t        '2009-12-25T00:00:00.0'), UTCDateTime('2009-12-26T00:00:00.0'))],\n\t        'long_record_read': [(UTCDateTime('2009-12-26T00:00:00.0'),\n\t        UTCDateTime('2009-12-27T00:00:00.0'))], 'short_record_read': [(\n\t        UTCDateTime('2009-12-25T00:00:00.0'), UTCDateTime(\n\t        '2009-12-27T00:00:00.0'))], 'start_of_time_series': [(UTCDateTime(\n\t        '2008-12-25T00:00:00.0'), UTCDateTime('2008-12-27T00:00:00.0')), (\n\t        UTCDateTime('2009-12-26T00:00:00.0'), UTCDateTime(\n\t        '2009-12-26T00:00:00.0')), (UTCDateTime('2010-12-25T00:00:00.0'),\n\t        UTCDateTime('2010-12-27T00:00:00.0'))]}\n\t    io_clock = _convert_flags_to_raw_byte(FIXED_HEADER_IO_CLOCK_FLAGS,\n\t        user_flags, recstart, recend)\n\t    assert io_clock == 15\n\t    user_flags = {'amplifier_sat_detected': True,\n\t        'digitizer_clipping_detected': False, 'spikes_detected': True,\n\t        'glitches_detected': False, 'missing_padded_data_present': True,\n\t        'telemetry_sync_error': False, 'digital_filter_maybe_charging': \n\t        True, 'time_tag_questionable': False}\n\t    data_qual = _convert_flags_to_raw_byte(FIXED_HEADER_DATA_QUAL_FLAGS,\n\t        user_flags, recstart, recend)\n\t    assert data_qual == 85\n\t\nTestMSEEDUtil().test_convert_flags_to_raw_bytes()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/mseed/tests/test_mseed_util.py"}], "method_code_mask": "import collections\nimport ctypes as C\nimport os\nfrom pathlib import Path\nimport sys\nimport warnings\nfrom datetime import datetime\nfrom struct import pack\nfrom struct import unpack\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core.compatibility import from_buffer\nfrom obspy.core.util.decorator import ObsPyDeprecationWarning\nimport doctest\n\n\ndef _convert_flags_to_raw_byte(expected_flags, user_flags, recstart, recend): [\n    MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "utcdatetime_to_sac_nztimes", "method_path": "../srcdata/Computation/obspy/obspy/io/sac/util.py", "response": "import sys\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\ndef utcdatetime_to_sac_nztimes(utcdt):\n    nztimes = {}\n    nztimes['nzyear'] = utcdt.year\n    nztimes['nzjday'] = utcdt.julday\n    nztimes['nzhour'] = utcdt.hour\n    nztimes['nzmin'] = utcdt.minute\n    nztimes['nzsec'] = utcdt.second\n    millisecond, microsecond = split_microseconds(utcdt.microsecond)\n    nztimes['nzmsec'] = millisecond\n    return nztimes, microsecond", "test_code_list": [{"test_code": "import copy\nimport io\nimport warnings\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.core.util import NamedTemporaryFile\nfrom obspy.core.util import CatchAndAssertWarnings\nfrom obspy.core import AttribDict\nfrom obspy.io.sac import SacError\nfrom obspy.io.sac import SACTrace\nfrom obspy.io.sac import SacIOError\nfrom obspy.io.sac.core import _is_sac\nfrom obspy.io.sac.core import _is_sac_xy\nfrom obspy.io.sac.core import _read_sac\nfrom obspy.io.sac.core import _read_sac_xy\nfrom obspy.io.sac.core import _write_sac\nfrom obspy.io.sac.core import _write_sac_xy\nfrom obspy.io.sac.util import utcdatetime_to_sac_nztimes\nimport pytest\n\nclass TestCore():\n\tdef test_valid_sac_from_minimal_existing_sac_header(self):\n\t    \"\"\"\n\t        An incomplete manually-produced SAC header should still produce a\n\t        valid SAC file, including values from the ObsPy header.  Issue 1204.\n\t        \"\"\"\n\t    tr = Trace(np.arange(100))\n\t    t = UTCDateTime()\n\t    tr.stats.starttime = t\n\t    tr.stats.station = 'AAA'\n\t    tr.stats.network = 'XX'\n\t    tr.stats.channel = 'BHZ'\n\t    tr.stats.location = '00'\n\t    tr.stats.sac = AttribDict()\n\t    tr.stats.sac.iztype = 9\n\t    tr.stats.sac.nvhdr = 6\n\t    tr.stats.sac.leven = 1\n\t    tr.stats.sac.lovrok = 1\n\t    tr.stats.sac.iftype = 1\n\t    tr.stats.sac.stla = 1.0\n\t    tr.stats.sac.stlo = 2.0\n\t    with NamedTemporaryFile() as tf:\n\t        tempfile = tf.name\n\t        tr.write(tempfile, format='SAC')\n\t        tr1 = read(tempfile)[0]\n\t    nztimes, microsecond = utcdatetime_to_sac_nztimes(t)\n\t    assert tr1.stats.sac.nzyear == nztimes['nzyear']\n\t    assert tr1.stats.sac.nzjday == nztimes['nzjday']\n\t    assert tr1.stats.sac.nzhour == nztimes['nzhour']\n\t    assert tr1.stats.sac.nzmin == nztimes['nzmin']\n\t    assert tr1.stats.sac.nzsec == nztimes['nzsec']\n\t    assert tr1.stats.sac.nzmsec == nztimes['nzmsec']\n\t    assert tr1.stats.sac.kstnm == 'AAA'\n\t    assert tr1.stats.sac.knetwk == 'XX'\n\t    assert tr1.stats.sac.kcmpnm == 'BHZ'\n\t    assert tr1.stats.sac.khole == '00'\n\t    assert tr1.stats.sac.iztype == 9\n\t    assert tr1.stats.sac.nvhdr == 6\n\t    assert tr1.stats.sac.leven == 1\n\t    assert tr1.stats.sac.lovrok == 1\n\t    assert tr1.stats.sac.iftype == 1\n\t    assert tr1.stats.sac.stla == 1.0\n\t    assert tr1.stats.sac.stlo == 2.0\n\t\nTestCore().test_valid_sac_from_minimal_existing_sac_header()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/sac/tests/test_core.py"}], "method_code_mask": "import sys\nimport warnings\nimport numpy as np\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\n\n\ndef utcdatetime_to_sac_nztimes(utcdt): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_determine_dtype", "method_path": "../srcdata/Computation/obspy/obspy/io/ascii/core.py", "response": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\nfrom obspy.core.util import AttribDict\nimport doctest\ndef _determine_dtype(custom_fmt):\n    \"\"\"\n    :type custom_fmt: str\n    :param custom_fmt: Python string formatter.\n    :rtype: str\n    :return: Datatype string for writing in header. Currently supported\n        are 'INTEGER', 'FLOAT' and `CUSTOM`.\n    :raises ValueError: if provided string is empty.\n    \"\"\"\n    floats = 'e', 'f', 'g'\n    ints = 'd', 'i'\n    try:\n        if custom_fmt[-1].lower() in floats:\n            return 'FLOAT'\n        elif custom_fmt[-1].lower() in ints:\n            return 'INTEGER'\n        else:\n            return 'CUSTOM'\n    except IndexError:\n        raise ValueError('Provided string is not valid for determining ' +\n            'datatype. Provide a proper Python string formatter')", "test_code_list": [{"test_code": "import numpy as np\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy import read\nfrom obspy.io.ascii.core import _determine_dtype\nfrom obspy.io.ascii.core import _is_slist\nfrom obspy.io.ascii.core import _is_tspair\nfrom obspy.io.ascii.core import _read_slist\nfrom obspy.io.ascii.core import _read_tspair\nfrom obspy.io.ascii.core import _write_slist\nfrom obspy.io.ascii.core import _write_tspair\nfrom obspy.core.util import NamedTemporaryFile\nimport pytest\n\nclass TestASCII():\n\tdef test_determine_dtype(self):\n\t    \"\"\"\n\t        Tests _determine_dtype for properly returned types\n\t        \"\"\"\n\t    float_formats = ['%+10.10e', '%+.10e', '%.3e', '%+10.10E', '%+.10E',\n\t        '%.3E', '%+10.10f', '%+.10f', '%.3f', '%+10.10F', '%+.10F', '%.3F',\n\t        '%+10.10g', '%+.10g', '%.3g', '%+10.10G', '%+.10G', '%.3G']\n\t    int_formats = ['%+10.10i', '%+.10i', '%.3i', '%+10.10I', '%+.10I',\n\t        '%.3I', '%+10.10d', '%+.10d', '%.3d', '%+10.10D', '%+.10D', '%.3D']\n\t    custom_formats = ['%+10.10s', '%+.10s', '%.3s', '%+10.10x', '%+.10x',\n\t        '%.3x', '%+10.10k', '%+.10k', '%.3k', '%+10.10z', '%+.10z', '%.3z',\n\t        '%+10.10w', '%+.10w', '%.3w', '%+10.10q', '%+.10q', '%.3q']\n\t    for format in float_formats:\n\t        assert 'FLOAT' == _determine_dtype(format)\n\t    for format in int_formats:\n\t        assert 'INTEGER' == _determine_dtype(format)\n\t    for format in custom_formats:\n\t        assert 'CUSTOM' == _determine_dtype(format)\n\t    with pytest.raises(ValueError):\n\t        _determine_dtype('')\n\t\nTestASCII().test_determine_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/ascii/tests/test_ascii.py"}], "method_code_mask": "import io\nimport numpy as np\nfrom obspy import Stream\nfrom obspy import Trace\nfrom obspy import UTCDateTime\nfrom obspy.core import Stats\nfrom obspy.core.util import AttribDict\nimport doctest\n\n\ndef _determine_dtype(custom_fmt): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "to_tag", "method_path": "../srcdata/Computation/obspy/obspy/io/xseed/utils.py", "response": "import warnings\nfrom obspy import UTCDateTime\ndef to_tag(name):\n    \"\"\"\n    Creates a XML tag from a given string.\n    \"\"\"\n    temp = name.lower().replace(' ', '_')\n    temp = temp.replace('fir_', 'FIR_')\n    temp = temp.replace('a0_', 'A0_')\n    return temp", "test_code_list": [{"test_code": "from obspy import UTCDateTime\nfrom obspy.io.xseed.utils import datetime_2_string\nfrom obspy.io.xseed.utils import to_tag\nfrom obspy.io.xseed.core import _is_resp\n\nclass TestUtils():\n\tdef test_to_tag(self):\n\t    name = 'Hello World'\n\t    assert 'hello_world' == to_tag(name)\n\t\nTestUtils().test_to_tag()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/xseed/tests/test_utils.py"}], "method_code_mask": "import warnings\nfrom obspy import UTCDateTime\n\n\ndef to_tag(name): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "datetime_2_string", "method_path": "../srcdata/Computation/obspy/obspy/io/xseed/utils.py", "response": "import warnings\nfrom obspy import UTCDateTime\ndef datetime_2_string(dt, compact=False):\n    \"\"\"\n    Generates a valid SEED time string from a UTCDateTime object.\n    \"\"\"\n    if isinstance(dt, UTCDateTime):\n        return dt.format_seed(compact)\n    elif isinstance(dt, str):\n        dt = dt.strip()\n    if not dt:\n        return ''\n    try:\n        dt = UTCDateTime(dt)\n        return dt.format_seed(compact)\n    except Exception:\n        raise Exception('Invalid datetime %s: %s' % (type(dt), str(dt)))", "test_code_list": [{"test_code": "from obspy import UTCDateTime\nfrom obspy.io.xseed.utils import datetime_2_string\nfrom obspy.io.xseed.utils import to_tag\nfrom obspy.io.xseed.core import _is_resp\n\nclass TestUtils():\n\tdef test_datetime_to_string(self):\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 123456)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:22.1234'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 98765)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:22.0987'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 1234)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:22.0012'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 123)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:22.0001'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 9)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:22.0000'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 21)\n\t    assert datetime_2_string(dt) == '2008,358,01:30:21.0000'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 0, 0, 0)\n\t    assert datetime_2_string(dt) == '2008,358,01:00:00.0000'\n\t    dt = UTCDateTime(2008, 12, 23)\n\t    assert datetime_2_string(dt) == '2008,358'\n\t\nTestUtils().test_datetime_to_string()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/xseed/tests/test_utils.py"}, {"test_code": "from obspy import UTCDateTime\nfrom obspy.io.xseed.utils import datetime_2_string\nfrom obspy.io.xseed.utils import to_tag\nfrom obspy.io.xseed.core import _is_resp\n\nclass TestUtils():\n\tdef test_datetime_to_string_compact(self):\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22, 123456)\n\t    assert datetime_2_string(dt, True) == '2008,358,01:30:22.1234'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30, 22)\n\t    assert datetime_2_string(dt, True) == '2008,358,01:30:22'\n\t    dt = UTCDateTime(2008, 12, 23, 1, 30)\n\t    assert datetime_2_string(dt, True) == '2008,358,01:30'\n\t    dt = UTCDateTime(2008, 12, 23, 1)\n\t    assert datetime_2_string(dt, True) == '2008,358,01'\n\t    dt = UTCDateTime(2008, 12, 23)\n\t    assert datetime_2_string(dt, True) == '2008,358'\n\t\nTestUtils().test_datetime_to_string_compact()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/xseed/tests/test_utils.py"}], "method_code_mask": "import warnings\nfrom obspy import UTCDateTime\n\n\ndef datetime_2_string(dt, compact=False): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_parse_list_of_complex_string", "method_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/inventory.py", "response": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\ndef _parse_list_of_complex_string(complex_string):\n    \"\"\"\n    Returns a list of complex numbers, parsed from a string (formatted\n    according to SeisComp XML schema type \"ComplexArray\").\n    \"\"\"\n    count = _count_complex(complex_string)\n    numbers = re.findall('\\\\(\\\\s*([^,\\\\s]+)\\\\s*,\\\\s*([^)\\\\s]+)\\\\s*\\\\)',\n        complex_string)\n    if len(numbers) != count:\n        msg = (\n            \"\"\"Unexpected count of complex numbers parsed from string:\n  Raw string: '%s'\n  Expected count of complex numbers: %s\n  Parsed complex numbers: %s\"\"\"\n             % (complex_string, count, numbers))\n        raise ValueError(msg)\n    return numbers", "test_code_list": [{"test_code": "import io\nimport re\nimport warnings\nimport pytest\nfrom obspy.core.inventory import read_inventory\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.io.seiscomp.inventory import _count_complex\nfrom obspy.io.seiscomp.inventory import _parse_list_of_complex_string\nfrom obspy.io.seiscomp.inventory import SCHEMA_NAMESPACE_BASE\n\nclass TestSC3ML():\n\tdef test_parse_complex_list(self):\n\t    \"\"\"\n\t        Tests parsing list of complex numbers from seiscomp3 xml.\n\t        \"\"\"\n\t    complex_string = (\n\t        '  (   -0.037 ,     0.037 )  (-0.037,-0.037)(-6909,     9208)( -6909  ,-9208)  '\n\t        )\n\t    assert _count_complex(complex_string) == 4\n\t    parsed = _parse_list_of_complex_string(complex_string)\n\t    assert parsed == [('-0.037', '0.037'), ('-0.037', '-0.037'), ('-6909',\n\t        '9208'), ('-6909', '-9208')]\n\t    complex_string = '  (   -0.037 ,     0.037 )  (-0.037,-0.037'\n\t    with pytest.raises(ValueError):\n\t        _count_complex(complex_string)\n\t    with pytest.raises(ValueError):\n\t        _parse_list_of_complex_string(complex_string)\n\t\nTestSC3ML().test_parse_complex_list()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/tests/test_inventory.py"}], "method_code_mask": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\n\n\ndef _parse_list_of_complex_string(complex_string): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_count_complex", "method_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/inventory.py", "response": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\ndef _count_complex(complex_string):\n    \"\"\"\n    Returns number of complex numbers in string (formatted according to\n    SeisComp XML schema type \"ComplexArray\"). Raises an Exception if string\n    seems invalid.\n    \"\"\"\n    counts = set()\n    for char in '(,)':\n        counts.add(complex_string.count(char))\n    if len(counts) != 1:\n        msg = (\"Invalid string for list of complex numbers:\\n'%s'\" %\n            complex_string)\n        raise ValueError(msg)\n    return counts.pop()", "test_code_list": [{"test_code": "import io\nimport re\nimport warnings\nimport pytest\nfrom obspy.core.inventory import read_inventory\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.io.seiscomp.inventory import _count_complex\nfrom obspy.io.seiscomp.inventory import _parse_list_of_complex_string\nfrom obspy.io.seiscomp.inventory import SCHEMA_NAMESPACE_BASE\n\nclass TestSC3ML():\n\tdef test_parse_complex_list(self):\n\t    \"\"\"\n\t        Tests parsing list of complex numbers from seiscomp3 xml.\n\t        \"\"\"\n\t    complex_string = (\n\t        '  (   -0.037 ,     0.037 )  (-0.037,-0.037)(-6909,     9208)( -6909  ,-9208)  '\n\t        )\n\t    assert _count_complex(complex_string) == 4\n\t    parsed = _parse_list_of_complex_string(complex_string)\n\t    assert parsed == [('-0.037', '0.037'), ('-0.037', '-0.037'), ('-6909',\n\t        '9208'), ('-6909', '-9208')]\n\t    complex_string = '  (   -0.037 ,     0.037 )  (-0.037,-0.037'\n\t    with pytest.raises(ValueError):\n\t        _count_complex(complex_string)\n\t    with pytest.raises(ValueError):\n\t        _parse_list_of_complex_string(complex_string)\n\t\nTestSC3ML().test_parse_complex_list()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/seiscomp/tests/test_inventory.py"}], "method_code_mask": "import math\nimport re\nimport warnings\nfrom lxml import etree\nimport numpy as np\nfrom scipy.signal import tf2zpk\nimport obspy\nfrom obspy.core.util.obspy_types import ComplexWithUncertainties\nfrom obspy.core.util.obspy_types import FloatWithUncertaintiesAndUnit\nfrom obspy.core.inventory import Azimuth\nfrom obspy.core.inventory import ClockDrift\nfrom obspy.core.inventory import Dip\nfrom obspy.core.inventory import Distance\nfrom obspy.core.inventory import Frequency\nfrom obspy.core.inventory import Latitude\nfrom obspy.core.inventory import Longitude\nfrom obspy.core.inventory import SampleRate\nfrom obspy.core.inventory.response import CoefficientsTypeResponseStage\nfrom obspy.core.inventory.response import FilterCoefficient\nfrom obspy.core.inventory.response import FIRResponseStage\nfrom obspy.core.inventory.response import PolesZerosResponseStage\nfrom obspy.core.inventory.response import PolynomialResponseStage\nfrom obspy.core.inventory.response import ResponseListElement\nfrom obspy.core.inventory.response import ResponseListResponseStage\nfrom obspy.io.stationxml.core import _read_floattype\n\n\ndef _count_complex(complex_string): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "_is_rg16", "method_path": "../srcdata/Computation/obspy/obspy/io/rg16/core.py", "response": "from collections import namedtuple\nimport numpy as np\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core import Stats\nfrom obspy.core import UTCDateTime\nfrom obspy.io.rg16.util import _read\nfrom obspy.io.rg16.util import _open_file\nfrom obspy.io.rg16.util import _quick_merge\nimport doctest\n@_open_file\ndef _is_rg16(filename, **kwargs):\n    \"\"\"\n    Determine if a file is a rg16 file.\n\n    :param filename: a path to a file or a file object\n    :type filename: str or file-like object\n    :rtype: bool\n    :return: True if the file object is a rg16 file.\n    \"\"\"\n    try:\n        sample_format = _read(filename, 2, 2, 'bcd')\n        sample_format = _read(filename, 2, 2, 'bcd')\n        manufacturer_code = _read(filename, 16, 1, 'bcd')\n        version = _read(filename, 42, 2, 'binary')\n    except ValueError:\n        return False\n    con1 = version == 262 and sample_format == 8058\n    return con1 and manufacturer_code == 20", "test_code_list": [{"test_code": "import io\nimport numpy as np\nimport pytest\nimport obspy\nimport obspy.io.rg16.core as rc\nfrom obspy import read\nfrom obspy import UTCDateTime\n\nclass TestReadRG16():\n\tdef test_empty_buffer(self):\n\t    \"\"\"\n\t        Ensure an empty buffer returns false.\n\t        \"\"\"\n\t    buff = io.BytesIO()\n\t    assert not _is_rg16(buff)\n\t\nTestReadRG16().test_empty_buffer()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/io/rg16/tests/test_read_rg16.py"}], "method_code_mask": "from collections import namedtuple\nimport numpy as np\nfrom obspy.core import Stream\nfrom obspy.core import Trace\nfrom obspy.core import Stats\nfrom obspy.core import UTCDateTime\nfrom obspy.io.rg16.util import _read\nfrom obspy.io.rg16.util import _open_file\nfrom obspy.io.rg16.util import _quick_merge\nimport doctest\n\n\n@_open_file\ndef _is_rg16(filename, **kwargs): [MASK]\n"}
{"model_name": "std", "repository": "obspy", "full_method_name": "inside_geobounds", "method_path": "../srcdata/Computation/obspy/obspy/geodetics/base.py", "response": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\ndef inside_geobounds(obj, minlatitude=None, maxlatitude=None, minlongitude=\n    None, maxlongitude=None, latitude=None, longitude=None, minradius=None,\n    maxradius=None):\n    \"\"\"\n    Check whether an object is within a given latitude and/or longitude range,\n    or within a given distance range from a reference geographic point.\n\n    The object must have ``latitude`` and ``longitude`` attributes, expressed\n    in degrees.\n\n    :type obj: object\n    :param obj: An object with `latitude` and `longitude` attributes.\n    :type minlatitude: float\n    :param minlatitude: Minimum latitude in degrees.\n    :type maxlatitude: float\n    :param maxlatitude: Maximum latitude in degrees. If this value is smaller\n        than ``minlatitude``, then 360 degrees are added to this value (i.e.,\n        wrapping around latitude of +/- 180 degrees)\n    :type minlongitude: float\n    :param minlongitude: Minimum longitude in degrees.\n    :type maxlongitude: float\n    :param maxlongitude: Minimum longitude in degrees.\n    :type latitude: float\n    :param latitude: Latitude of the reference point, in degrees, for distance\n        range selection.\n    :type longitude: float\n    :param longitude: Longitude of the reference point, in degrees, for\n        distance range selection.\n    :type minradius: float\n    :param minradius: Minimum distance, in degrees, from the reference\n        geographic point defined by the latitude and longitude parameters.\n    :type maxradius: float\n    :param maxradius: Maximum distance, in degrees, from the reference\n        geographic point defined by the latitude and longitude parameters.\n    :return: ``True`` if the object is within the given range, ``False``\n        otherwise.\n\n    .. rubric:: Example\n\n    >>> from obspy.geodetics import inside_geobounds\n    >>> from obspy import read_events\n    >>> ev = read_events()[0]\n    >>> orig = ev.origins[0]\n    >>> inside_geobounds(orig, minlatitude=40, maxlatitude=42)\n    True\n    >>> inside_geobounds(orig, minlatitude=40, maxlatitude=42,\n    ...                  minlongitude=78, maxlongitude=79)\n    False\n    >>> inside_geobounds(orig, latitude=40, longitude=80,\n    ...                  minradius=1, maxradius=10)\n    True\n    \"\"\"\n    if not hasattr(obj, 'latitude') or not hasattr(obj, 'longitude'):\n        raise AttributeError(\n            'Object must have \"latitude\" and \"longitude\" attributes.')\n    olatitude = obj.latitude\n    _check_latitude(olatitude, 'obj.latitude')\n    _check_latitude(minlatitude, 'minlatitude')\n    _check_latitude(maxlatitude, 'maxlatitude')\n    _check_latitude(latitude, 'latitude')\n    olongitude = _normalize_longitude(obj.longitude)\n    minlongitude = _normalize_longitude(minlongitude)\n    maxlongitude = _normalize_longitude(maxlongitude)\n    longitude = _normalize_longitude(longitude)\n    if minlatitude is not None:\n        if olatitude is None or olatitude < minlatitude:\n            return False\n    if maxlatitude is not None:\n        if olatitude is None or olatitude > maxlatitude:\n            return False\n    if None not in [minlongitude, maxlongitude\n        ] and maxlongitude < minlongitude:\n        maxlongitude += 360\n        if olongitude is not None and olongitude < minlongitude:\n            olongitude += 360\n    if minlongitude is not None:\n        if olongitude is None or olongitude < minlongitude:\n            return False\n    if maxlongitude is not None:\n        if olongitude is None or olongitude > maxlongitude:\n            return False\n    if all([(coord is not None) for coord in (latitude, longitude,\n        olatitude, olongitude)]):\n        distance = locations2degrees(latitude, longitude, olatitude, olongitude\n            )\n        if minradius is not None and distance < minradius:\n            return False\n        if maxradius is not None and distance > maxradius:\n            return False\n    return True", "test_code_list": [{"test_code": "import math\nimport warnings\nimport numpy as np\nfrom obspy.geodetics import calc_vincenty_inverse\nfrom obspy.geodetics import degrees2kilometers\nfrom obspy.geodetics import gps2dist_azimuth\nfrom obspy.geodetics import inside_geobounds\nfrom obspy.geodetics import kilometer2degrees\nfrom obspy.geodetics import locations2degrees\nfrom obspy.geodetics.base import HAS_GEOGRAPHICLIB\nfrom obspy.core import AttribDict\nimport pytest\n\nclass TestUtilGeodetics():\n\tdef test_inside_geobounds(self):\n\t    obj = AttribDict()\n\t    obj.latitude = 48.8566\n\t    obj.longitude = 2.3522\n\t    ret = inside_geobounds(obj, minlatitude=48, maxlatitude=49,\n\t        minlongitude=2, maxlongitude=3)\n\t    assert ret\n\t    ret = inside_geobounds(obj, latitude=48, longitude=2, minradius=1,\n\t        maxradius=2)\n\t    assert not ret\n\t    obj.latitude = -41.2865\n\t    obj.longitude = 174.7762\n\t    ret = inside_geobounds(obj, minlongitude=170, maxlongitude=-170)\n\t    assert ret\n\t    obj.longitude = -175.0\n\t    ret = inside_geobounds(obj, minlongitude=170, maxlongitude=-170)\n\t    assert ret\n\t    ret = inside_geobounds(obj, minlongitude=170, maxlongitude=190)\n\t    assert ret\n\t\nTestUtilGeodetics().test_inside_geobounds()\n", "code_start": "", "test_path": "../srcdata/Computation/obspy/obspy/geodetics/tests/test_util_geodetics.py"}], "method_code_mask": "import math\nimport warnings\nimport numpy as np\nfrom obspy.core.util.misc import to_int_or_zero\nimport geographiclib\nfrom geographiclib.geodesic import Geodesic\nfrom scipy.stats import circmean\nimport doctest\n\n\ndef inside_geobounds(obj, minlatitude=None, maxlatitude=None, minlongitude=\n    None, maxlongitude=None, latitude=None, longitude=None, minradius=None,\n    maxradius=None): [MASK]\n"}
