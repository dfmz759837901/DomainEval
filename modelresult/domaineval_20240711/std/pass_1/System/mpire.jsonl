{"model_name": "std", "repository": "mpire", "full_method_name": "chunk_tasks", "method_path": "../srcdata/System/mpire/mpire/utils.py", "response": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\ndef chunk_tasks(iterable_of_args: Iterable, iterable_len: Optional[int]=\n    None, chunk_size: Optional[Union[int, float]]=None, n_splits: Optional[\n    int]=None) ->Generator[Collection, None, None]:\n    \"\"\"\n    Chunks tasks such that individual workers will receive chunks of tasks rather than individual ones, which can\n    speed up processing drastically.\n\n    :param iterable_of_args: A numpy array or an iterable containing tuples of arguments to pass to a worker, which\n        passes it to the function\n    :param iterable_len: Number of tasks available in ``iterable_of_args``. Only needed when ``iterable_of_args`` is a\n        generator\n    :param chunk_size: Number of simultaneous tasks to give to a worker. If ``None``, will use ``n_splits`` to determine\n        the chunk size\n    :param n_splits: Number of splits to use when ``chunk_size`` is ``None``\n    :return: Generator of chunked task arguments\n    \"\"\"\n    if chunk_size is None and n_splits is None:\n        raise ValueError('chunk_size and n_splits cannot both be None')\n    if chunk_size is None:\n        if iterable_len is not None:\n            n_tasks = iterable_len\n        elif hasattr(iterable_of_args, '__len__'):\n            n_tasks = len(iterable_of_args)\n        else:\n            raise ValueError(\n                'Either iterable_len or an iterable with a len() function should be provided when chunk_size and n_splits are None'\n                )\n        chunk_size = n_tasks / n_splits\n    args_iter = iter(iterable_of_args)\n    current_chunk_size = chunk_size\n    n_elements_returned = 0\n    while True:\n        if NUMPY_INSTALLED and isinstance(iterable_of_args, np.ndarray):\n            chunk = iterable_of_args[n_elements_returned:\n                n_elements_returned + max(1, math.ceil(current_chunk_size))]\n        else:\n            chunk = tuple(itertools.islice(args_iter, max(1, math.ceil(\n                current_chunk_size))))\n        if len(chunk) == 0:\n            return\n        if iterable_len is not None and n_elements_returned + len(chunk\n            ) > iterable_len:\n            chunk = chunk[:iterable_len - n_elements_returned]\n            if chunk:\n                yield chunk\n            return\n        yield chunk\n        current_chunk_size = current_chunk_size + chunk_size - math.ceil(\n            current_chunk_size)\n        n_elements_returned += len(chunk)", "test_code_list": [{"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_no_chunk_size_no_n_splits_provided(self):\n        \"\"\"\n            Test that a ValueError is raised when no chunk_size and n_splits are provided\n            \"\"\"\n        with self.assertRaises(ValueError):\n            next(chunk_tasks([]))\n    \nChunkTasksTest().test_no_chunk_size_no_n_splits_provided()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_generator_without_iterable_len(self):\n        \"\"\"\n            Test that a ValueError is raised when a generator is provided without iterable_len\n            \"\"\"\n        with self.assertRaises(ValueError):\n            next(chunk_tasks(iter([]), n_splits=1))\n    \nChunkTasksTest().test_generator_without_iterable_len()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}], "method_code_mask": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\n\n\ndef chunk_tasks(iterable_of_args: Iterable, iterable_len: Optional[int]=\n    None, chunk_size: Optional[Union[int, float]]=None, n_splits: Optional[\n    int]=None) ->Generator[Collection, None, None]: [MASK]\n"}
{"model_name": "std", "repository": "mpire", "full_method_name": "chunk_tasks", "method_path": "../srcdata/System/mpire/mpire/utils.py", "response": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\ntry:\n    import numpy as np\n    NUMPY_INSTALLED = True\nexcept ImportError:\n    np = None\n    NUMPY_INSTALLED = False\ndef chunk_tasks(iterable_of_args: Iterable, iterable_len: Optional[int]=\n    None, chunk_size: Optional[Union[int, float]]=None, n_splits: Optional[\n    int]=None) ->Generator[Collection, None, None]:\n    \"\"\"\n    Chunks tasks such that individual workers will receive chunks of tasks rather than individual ones, which can\n    speed up processing drastically.\n    :param iterable_of_args: A numpy array or an iterable containing tuples of arguments to pass to a worker, which\n        passes it to the function\n    :param iterable_len: Number of tasks available in ``iterable_of_args``. Only needed when ``iterable_of_args`` is a\n        generator\n    :param chunk_size: Number of simultaneous tasks to give to a worker. If ``None``, will use ``n_splits`` to determine\n        the chunk size\n    :param n_splits: Number of splits to use when ``chunk_size`` is ``None``\n    :return: Generator of chunked task arguments\n    \"\"\"\n    if chunk_size is None and n_splits is None:\n        raise ValueError('chunk_size and n_splits cannot both be None')\n    if chunk_size is None:\n        if iterable_len is not None:\n            n_tasks = iterable_len\n        elif hasattr(iterable_of_args, '__len__'):\n            n_tasks = len(iterable_of_args)\n        else:\n            raise ValueError(\n                'Either iterable_len or an iterable with a len() function should be provided when chunk_size and n_splits are None'\n                )\n        chunk_size = n_tasks / n_splits\n    args_iter = iter(iterable_of_args)\n    current_chunk_size = chunk_size\n    n_elements_returned = 0\n    while True:\n        if NUMPY_INSTALLED and isinstance(iterable_of_args, np.ndarray):\n            chunk = iterable_of_args[n_elements_returned:\n                n_elements_returned + max(1, math.ceil(current_chunk_size))]\n        else:\n            chunk = tuple(itertools.islice(args_iter, max(1, math.ceil(\n                current_chunk_size))))\n        if len(chunk) == 0:\n            return\n        if iterable_len is not None and n_elements_returned + len(chunk\n            ) > iterable_len:\n            chunk = chunk[:iterable_len - n_elements_returned]\n            if chunk:\n                yield chunk\n            return\n        yield chunk\n        current_chunk_size = current_chunk_size + chunk_size - math.ceil(\n            current_chunk_size)\n        n_elements_returned += len(chunk)", "test_code_list": [{"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_chunk_size_has_priority_over_n_splits(self):\n        \"\"\"\n            Test that chunk_size is prioritized over n_splits\n            \"\"\"\n        chunks = list(chunk_tasks(range(4), chunk_size=4, n_splits=4))\n        self.assertEqual(len(chunks), 1)\n        self.assertEqual(len(chunks[0]), 4)\n        self.assertEqual(list(range(4)), list(chain.from_iterable(chunks)))\n    \nChunkTasksTest().test_chunk_size_has_priority_over_n_splits()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_empty_input(self):\n        \"\"\"\n            Test that the chunker is an empty generator for an empty input iterable\n            \"\"\"\n        with self.subTest('list input'):\n            chunks = list(chunk_tasks([], n_splits=5))\n            self.assertEqual(len(chunks), 0)\n        with self.subTest('generator/iterator input'):\n            chunks = list(chunk_tasks(iter([]), iterable_len=0, n_splits=5))\n            self.assertEqual(len(chunks), 0)\n    \nChunkTasksTest().test_empty_input()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_iterable_len_doesnt_match_input_size(self):\n        \"\"\"\n            Test for cases where iterable_len does and does not match the number of arguments (it should work fine)\n            \"\"\"\n        num_args = 10\n        for iter_len in [5, 10, 20]:\n            expected_args_sum = min(iter_len, num_args)\n            with self.subTest(iter_len=iter_len, input='list'):\n                chunks = list(chunk_tasks(range(num_args), iterable_len=\n                    iter_len, n_splits=1))\n                total_args = sum(map(len, chunks))\n                self.assertEqual(total_args, expected_args_sum)\n                self.assertEqual(list(range(expected_args_sum)), list(chain.\n                    from_iterable(chunks)))\n            with self.subTest(iter_len=iter_len, input='generator/iterator'):\n                chunks = list(chunk_tasks(iter(range(num_args)), iterable_len=\n                    iter_len, n_splits=1))\n                total_args = sum(map(len, chunks))\n                self.assertEqual(total_args, expected_args_sum)\n                self.assertEqual(list(range(expected_args_sum)), list(chain.\n                    from_iterable(chunks)))\n    \nChunkTasksTest().test_iterable_len_doesnt_match_input_size()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_n_splits(self):\n        \"\"\"\n            Test different values of n_splits: len(args) {<, ==, >} n_splits\n            \"\"\"\n        n_splits = 5\n        for num_args in [n_splits - 1, n_splits, n_splits + 1]:\n            expected_n_chunks = min(n_splits, num_args)\n            with self.subTest(num_args=num_args, input='list'):\n                chunks = list(chunk_tasks(range(num_args), n_splits=n_splits))\n                self.assertEqual(len(chunks), expected_n_chunks)\n                self.assertEqual(list(range(num_args)), list(chain.\n                    from_iterable(chunks)))\n            with self.subTest(num_args=num_args, input='generator/iterator'):\n                chunks = list(chunk_tasks(iter(range(num_args)), iterable_len=\n                    num_args, n_splits=n_splits))\n                self.assertEqual(len(chunks), expected_n_chunks)\n                self.assertEqual(list(range(num_args)), list(chain.\n                    from_iterable(chunks)))\n    \nChunkTasksTest().test_n_splits()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass ChunkTasksTest(unittest.TestCase):\n    def test_chunk_size(self):\n        \"\"\"\n            Test that chunks are of the right size if chunk_size is provided\n            \"\"\"\n        chunk_size = 3\n        for num_args in [chunk_size - 1, chunk_size, chunk_size + 1]:\n            with self.subTest(num_args=num_args, input='list'):\n                chunks = list(chunk_tasks(range(num_args), chunk_size=chunk_size))\n                for chunk in chunks[:-1]:\n                    self.assertEqual(len(chunk), chunk_size)\n                self.assertLessEqual(len(chunks[-1]), chunk_size)\n                self.assertEqual(list(range(num_args)), list(chain.\n                    from_iterable(chunks)))\n            with self.subTest(num_args=num_args, input='generator/iterator'):\n                chunks = list(chunk_tasks(iter(range(num_args)), chunk_size=\n                    chunk_size))\n                for chunk in chunks[:-1]:\n                    self.assertEqual(len(chunk), chunk_size)\n                self.assertLessEqual(len(chunks[-1]), chunk_size)\n                self.assertEqual(list(range(num_args)), list(chain.\n                    from_iterable(chunks)))\n    \nChunkTasksTest().test_chunk_size()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}], "method_code_mask": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\ntry:\n    import numpy as np\n    NUMPY_INSTALLED = True\nexcept ImportError:\n    np = None\n    NUMPY_INSTALLED = False\n\n\ndef chunk_tasks(iterable_of_args: Iterable, iterable_len: Optional[int]=\n    None, chunk_size: Optional[Union[int, float]]=None, n_splits: Optional[\n    int]=None) ->Generator[Collection, None, None]: [MASK]\n"}
{"model_name": "std", "repository": "mpire", "full_method_name": "make_single_arguments", "method_path": "../srcdata/System/mpire/mpire/utils.py", "response": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\ndef make_single_arguments(iterable_of_args: Iterable, generator: bool=True\n    ) ->Union[List, Generator]:\n    \"\"\"\n    Converts an iterable of single arguments to an iterable of single argument tuples\n\n    :param iterable_of_args: A numpy array or an iterable containing tuples of arguments to pass to a worker, which\n        passes it to the function\n    :param generator: Whether or not to return a generator, otherwise a materialized list will be returned\n    :return: Iterable of single argument tuples\n    \"\"\"\n    gen = ((arg,) for arg in iterable_of_args)\n    return gen if generator else list(gen)", "test_code_list": [{"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass MakeSingleArgumentsTest(unittest.TestCase):\n    def test_make_single_arguments(self):\n        \"\"\"\n            Tests the make_single_arguments function for different inputs\n            \"\"\"\n        for (args_in, args_out), generator in product([(['a', 'c', 'b', 'd'], [\n            ('a',), ('c',), ('b',), ('d',)]), ([1, 2, 3, 4, 5], [(1,), (2,), (3\n            ,), (4,), (5,)]), ([(True,), (False,), (None,)], [((True,),), ((\n            False,),), ((None,),)])], [False, True]):\n            args_transformed = make_single_arguments((arg for arg in args_in) if\n                generator else args_in, generator=generator)\n            self.assertTrue(isinstance(args_transformed, types.GeneratorType if\n                generator else list))\n            self.assertEqual(list(args_transformed), args_out)\n    \nMakeSingleArgumentsTest().test_make_single_arguments()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}], "method_code_mask": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\n\n\ndef make_single_arguments(iterable_of_args: Iterable, generator: bool=True\n    ) ->Union[List, Generator]: [MASK]\n"}
{"model_name": "std", "repository": "mpire", "full_method_name": "format_seconds", "method_path": "../srcdata/System/mpire/mpire/utils.py", "response": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\ndef format_seconds(seconds: Optional[Union[int, float]], with_milliseconds:\n    bool) ->str:\n    \"\"\"\n    Format seconds to a string, optionally with or without milliseconds\n\n    :param seconds: Number of seconds\n    :param with_milliseconds: Whether to display milliseconds as well\n    :return: String formatted time\n    \"\"\"\n    if seconds is None:\n        return ''\n    duration = str(timedelta(seconds=seconds)).rsplit('.', 1)\n    if with_milliseconds and len(duration) > 1:\n        duration = f'{duration[0]}.{duration[1][:3]}'\n    else:\n        duration = duration[0]\n    return duration", "test_code_list": [{"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass FormatSecondsTest(unittest.TestCase):\n    def test_none_input(self):\n        \"\"\"\n            When the input is None it should return an empty string\n            \"\"\"\n        for with_milliseconds in [False, True]:\n            with self.subTest(with_milliseconds=with_milliseconds):\n                self.assertEqual(format_seconds(None, with_milliseconds=\n                    with_milliseconds), '')\n    \nFormatSecondsTest().test_none_input()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass FormatSecondsTest(unittest.TestCase):\n    def test_without_milliseconds(self):\n        \"\"\"\n            Test output without milliseconds\n            \"\"\"\n        for seconds, expected_output in [(0, '0:00:00'), (1, '0:00:01'), (1.337,\n            '0:00:01'), (2.9, '0:00:02'), (123456.78901234, '1 day, 10:17:36')]:\n            with self.subTest(seconds=seconds):\n                self.assertEqual(format_seconds(seconds, with_milliseconds=\n                    False), expected_output)\n    \nFormatSecondsTest().test_without_milliseconds()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}, {"test_code": "import types\nimport unittest\nfrom itertools import chain\nfrom itertools import product\nfrom multiprocessing import cpu_count\nfrom unittest.mock import patch\nimport numpy as np\n\nclass FormatSecondsTest(unittest.TestCase):\n    def test_with_milliseconds(self):\n        \"\"\"\n            Test output with milliseconds. Only shows them when they're actually needed.\n            \"\"\"\n        for seconds, expected_output in [(0, '0:00:00'), (1, '0:00:01'), (1.337,\n            '0:00:01.337'), (2.9, '0:00:02.900'), (123456.78901234,\n            '1 day, 10:17:36.789')]:\n            with self.subTest(seconds=seconds):\n                self.assertEqual(format_seconds(seconds, with_milliseconds=True\n                    ), expected_output)\n    \nFormatSecondsTest().test_with_milliseconds()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_utils.py"}], "method_code_mask": "import heapq\nimport itertools\nimport math\nimport os\nimport time\nfrom datetime import timedelta\nfrom multiprocessing import cpu_count\nfrom multiprocessing.managers import SyncManager\nfrom multiprocessing.sharedctypes import SynchronizedArray\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Generator\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom typing import Union\nimport numpy as np\n\n\ndef format_seconds(seconds: Optional[Union[int, float]], with_milliseconds:\n    bool) ->str: [MASK]\n"}
{"model_name": "std", "repository": "mpire", "full_method_name": "get_number_of_tasks", "method_path": "../srcdata/System/mpire/mpire/params.py", "response": "import itertools\nimport math\nimport multiprocessing as mp\nimport warnings\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Sized\nfrom typing import Tuple\nfrom typing import Type\nfrom typing import Union\nfrom tqdm import TqdmKeyError\ndef get_number_of_tasks(iterable_of_args: Union[Sized, Iterable],\n    iterable_len: Optional[int]) ->Optional[int]:\n    \"\"\"\n    Get the number of tasks to process. If iterable_len is provided, it will be used. Otherwise, if iterable_of_args\n    is a Sized object, len(iterable_of_args) will be used. Otherwise, None will be returned.\n\n    :param iterable_of_args: A numpy array or an iterable containing tuples of arguments to pass to a worker\n    :param iterable_len: Number of elements in the ``iterable_of_args``\n    :return: Number of tasks to process\n    \"\"\"\n    if iterable_len is not None:\n        return iterable_len\n    if hasattr(iterable_of_args, '__len__'):\n        return len(iterable_of_args)\n    return None", "test_code_list": [{"test_code": "import unittest\nimport warnings\nfrom functools import partial\nfrom itertools import product\nfrom unittest.mock import patch\nimport numpy as np\nimport pytest\nfrom tqdm import TqdmKeyError\n\nclass GetNumberOfTasksTest(unittest.TestCase):\n    def test_get_number_of_tasks(self):\n        \"\"\"\n            Test that the number of tasks is correctly derived\n            \"\"\"\n        with self.subTest('iterable_len is provided'):\n            self.assertEqual(get_number_of_tasks([], 100), 100)\n        with self.subTest('iterable_len is not provided, __len__ implemented'):\n            self.assertEqual(get_number_of_tasks([1, 2, 3], None), 3)\n        with self.subTest('iterable_len is not provided, __len__ not implemented'):\n            self.assertIsNone(get_number_of_tasks((x for x in []), None))\n    \nGetNumberOfTasksTest().test_get_number_of_tasks()\n", "code_start": "", "test_path": "../srcdata/System/mpire/tests/test_params.py"}], "method_code_mask": "import itertools\nimport math\nimport multiprocessing as mp\nimport warnings\nfrom dataclasses import dataclass\nfrom dataclasses import field\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import Sized\nfrom typing import Tuple\nfrom typing import Type\nfrom typing import Union\nfrom tqdm import TqdmKeyError\n\n\ndef get_number_of_tasks(iterable_of_args: Union[Sized, Iterable],\n    iterable_len: Optional[int]) ->Optional[int]: [MASK]\n"}
