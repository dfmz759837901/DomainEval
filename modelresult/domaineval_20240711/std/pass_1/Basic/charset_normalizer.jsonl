{"model_name": "std", "repository": "charset_normalizer", "full_method_name": "detect", "method_path": "../srcdata/Basic/charset_normalizer/charset_normalizer/legacy.py", "response": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Optional\nfrom warnings import warn\nfrom typing_extensions import TypedDict\ndef detect(byte_str: bytes, should_rename_legacy: bool=False, **kwargs: Any\n    ) ->ResultDict:\n    \"\"\"\n    chardet legacy method\n    Detect the encoding of the given byte string. It should be mostly backward-compatible.\n    Encoding name will match Chardet own writing whenever possible. (Not on encoding name unsupported by it)\n    This function is deprecated and should be used to migrate your project easily, consult the documentation for\n    further information. Not planned for removal.\n\n    :param byte_str:     The byte sequence to examine.\n    :param should_rename_legacy:  Should we rename legacy encodings\n                                  to their more modern equivalents?\n    \"\"\"\n    if len(kwargs):\n        warn(\n            f\"charset-normalizer disregard arguments '{','.join(list(kwargs.keys()))}' in legacy function detect()\"\n            )\n    if not isinstance(byte_str, (bytearray, bytes)):\n        raise TypeError('Expected object of type bytes or bytearray, got: {0}'\n            .format(type(byte_str)))\n    if isinstance(byte_str, bytearray):\n        byte_str = bytes(byte_str)\n    r = from_bytes(byte_str).best()\n    encoding = r.encoding if r is not None else None\n    language = r.language if r is not None and r.language != 'Unknown' else ''\n    confidence = 1.0 - r.chaos if r is not None else None\n    if r is not None and encoding == 'utf_8' and r.bom:\n        encoding += '_sig'\n    if should_rename_legacy is False and encoding in CHARDET_CORRESPONDENCE:\n        encoding = CHARDET_CORRESPONDENCE[encoding]\n    return {'encoding': encoding, 'language': language, 'confidence':\n        confidence}", "test_code_list": [{"test_code": "import unittest\nfrom charset_normalizer.legacy import detect\n\nclass TestDetectLegacy(unittest.TestCase):\n\tdef test_detect_dict_keys(self):\n\t    r = detect((u'\\ufeff' + '\u6211\u6ca1\u6709\u57cb\u6028\uff0c\u78cb\u7823\u7684\u53ea\u662f\u4e00\u4e9b\u65f6\u95f4\u3002').encode('gb18030'))\n\t    with self.subTest('encoding key present'):\n\t        self.assertIn('encoding', r.keys())\n\t    with self.subTest('language key present'):\n\t        self.assertIn('language', r.keys())\n\t    with self.subTest('confidence key present'):\n\t        self.assertIn('confidence', r.keys())\n\t\nTestDetectLegacy().test_detect_dict_keys()\n", "code_start": "", "test_path": "../srcdata/Basic/charset_normalizer/tests/test_detect_legacy.py"}, {"test_code": "import unittest\nfrom charset_normalizer.legacy import detect\n\nclass TestDetectLegacy(unittest.TestCase):\n\tdef test_detect_dict_value_type(self):\n\t    r = detect('\u6211\u6ca1\u6709\u57cb\u6028\uff0c\u78cb\u7823\u7684\u53ea\u662f\u4e00\u4e9b\u65f6\u95f4\u3002'.encode('utf_8'))\n\t    with self.subTest('encoding instance of str'):\n\t        self.assertIsInstance(r['encoding'], str)\n\t    with self.subTest('language instance of str'):\n\t        self.assertIsInstance(r['language'], str)\n\t    with self.subTest('confidence instance of float'):\n\t        self.assertIsInstance(r['confidence'], float)\n\t\nTestDetectLegacy().test_detect_dict_value_type()\n", "code_start": "", "test_path": "../srcdata/Basic/charset_normalizer/tests/test_detect_legacy.py"}, {"test_code": "import unittest\nfrom charset_normalizer.legacy import detect\n\nclass TestDetectLegacy(unittest.TestCase):\n\tdef test_detect_dict_value(self):\n\t    r = detect('\u6211\u6ca1\u6709\u57cb\u6028\uff0c\u78cb\u7823\u7684\u53ea\u662f\u4e00\u4e9b\u65f6\u95f4\u3002'.encode('utf_32'))\n\t    with self.subTest('encoding is equal to utf_32'):\n\t        self.assertEqual(r['encoding'], 'UTF-32')\n\t\nTestDetectLegacy().test_detect_dict_value()\n", "code_start": "", "test_path": "../srcdata/Basic/charset_normalizer/tests/test_detect_legacy.py"}, {"test_code": "import unittest\nfrom charset_normalizer.legacy import detect\n\nclass TestDetectLegacy(unittest.TestCase):\n\tdef test_utf8_sig_not_striped(self):\n\t    r = detect('Hello World'.encode('utf-8-sig'))\n\t    with self.subTest(\n\t        'Verify that UTF-8-SIG is returned when using legacy detect'):\n\t        self.assertEqual(r['encoding'], 'UTF-8-SIG')\n\t\nTestDetectLegacy().test_utf8_sig_not_striped()\n", "code_start": "", "test_path": "../srcdata/Basic/charset_normalizer/tests/test_detect_legacy.py"}], "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Optional\nfrom warnings import warn\nfrom typing_extensions import TypedDict\n\n\ndef detect(byte_str: bytes, should_rename_legacy: bool=False, **kwargs: Any\n    ) ->ResultDict: [MASK]\n"}
