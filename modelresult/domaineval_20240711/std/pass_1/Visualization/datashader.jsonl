{"model_name": "std", "repository": "datashader", "full_method_name": "rgb", "method_path": "../srcdata/Visualization/datashader/datashader/colors.py", "response": "from __future__ import annotations\ndef rgb(x):\n    \"\"\"Return a triple representing rgb color.\n\n    Can convert colors by name or hexcode. Passing in a valid rgb tuple is\n    idempotent.\n\n    Example\n    -------\n    >>> rgb('plum')\n    (221, 160, 221)\n    >>> rgb('#FFFFFF')\n    (255, 255, 255)\n    >>> rgb((255, 255, 255))\n    (255, 255, 255)\n    \"\"\"\n    if isinstance(x, str):\n        if x.startswith('#'):\n            return hex_to_rgb(x)\n        elif x in color_lookup:\n            return hex_to_rgb(color_lookup[x])\n        else:\n            raise ValueError(\"Unknown color: '{0}'\".format(x))\n    elif isinstance(x, tuple) and len(x) == 3:\n        if min(x) < 0 or max(x) > 255:\n            raise ValueError('Invalid RGB tuple')\n    else:\n        raise TypeError(\"Don't know how to convert {0} to RGB\".format(x))\n    return x", "test_code_list": [{"test_code": "from datashader.colors import rgb\nfrom datashader.colors import hex_to_rgb\nimport pytest\ndef test_rgb():\n    assert rgb(u'#FAFBFC') == (250, 251, 252)\n    assert rgb('#FAFBFC') == (250, 251, 252)\n    assert rgb('blue') == (0, 0, 255)\n    assert rgb(u'blue') == (0, 0, 255)\n    assert rgb((255, 255, 255)) == (255, 255, 255)\n    with pytest.raises(ValueError):\n        rgb((255, 256, 255))\n    with pytest.raises(ValueError):\n        rgb((-1, 255, 255))\n    with pytest.raises(ValueError):\n        rgb('foobar')\n\ntest_rgb()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_colors.py"}], "method_code_mask": "from __future__ import annotations\n\n\ndef rgb(x): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "isreal", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef isreal(dt):\n    \"\"\"Check if a datashape is numeric and real.\n\n    Example\n    -------\n    >>> isreal('int32')\n    True\n    >>> isreal('float64')\n    True\n    >>> isreal('string')\n    False\n    >>> isreal('complex64')\n    False\n    \"\"\"\n    dt = datashape.predicates.launder(dt)\n    return isinstance(dt, datashape.Unit) and dt in datashape.typesets.real", "test_code_list": [{"test_code": "import numpy as np\nfrom xarray import DataArray\nfrom datashader.datashape import dshape\nfrom datashader.utils import Dispatcher\nfrom datashader.utils import apply\nfrom datashader.utils import calc_res\nfrom datashader.utils import isreal\nfrom datashader.utils import orient_array\ndef test_isreal():\n    assert isreal('int32')\n    assert isreal(dshape('int32'))\n    assert isreal('?int32')\n    assert isreal('float64')\n    assert not isreal('complex64')\n    assert not isreal('{x: int64, y: float64}')\n\ntest_isreal()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_utils.py"}], "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef isreal(dt): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "apply", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef apply(func, args, kwargs=None):\n    if kwargs:\n        return func(*args, **kwargs)\n    else:\n        return func(*args)", "test_code_list": [{"test_code": "import numpy as np\nfrom xarray import DataArray\nfrom datashader.datashape import dshape\nfrom datashader.utils import Dispatcher\nfrom datashader.utils import apply\nfrom datashader.utils import calc_res\nfrom datashader.utils import isreal\nfrom datashader.utils import orient_array\ndef test_apply():\n\n    def f(a, b, c=1, d=2):\n        return a + b + c + d\n    assert apply(f, (1, 2)) == 6\n    assert apply(f, (1, 2), dict(c=3)) == 8\n\ntest_apply()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_utils.py"}], "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef apply(func, args, kwargs=None): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "calc_res", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef calc_res(raster):\n    \"\"\"Calculate the resolution of xarray.DataArray raster and return it as the\n    two-tuple (xres, yres). yres is positive if it is decreasing.\n    \"\"\"\n    h, w = raster.shape[-2:]\n    ydim, xdim = raster.dims[-2:]\n    xcoords = raster[xdim].values\n    ycoords = raster[ydim].values\n    xres = (xcoords[-1] - xcoords[0]) / (w - 1)\n    yres = (ycoords[0] - ycoords[-1]) / (h - 1)\n    return xres, yres", "test_code_list": [{"test_code": "import numpy as np\nfrom xarray import DataArray\nfrom datashader.datashape import dshape\nfrom datashader.utils import Dispatcher\nfrom datashader.utils import apply\nfrom datashader.utils import calc_res\nfrom datashader.utils import isreal\nfrom datashader.utils import orient_array\ndef test_calc_res():\n    x = [5, 7]\n    y = [0, 1]\n    z = [[0, 0], [0, 0]]\n    dims = 'y', 'x'\n    xarr = DataArray(z, coords=dict(x=x, y=y), dims=dims)\n    xres, yres = calc_res(xarr)\n    assert xres == 2\n    assert yres == -1\n    xarr = DataArray(z, coords=dict(x=x, y=y[::-1]), dims=dims)\n    xres, yres = calc_res(xarr)\n    assert xres == 2\n    assert yres == 1\n    xarr = DataArray(z, coords=dict(x=x[::-1], y=y), dims=dims)\n    xres, yres = calc_res(xarr)\n    assert xres == -2\n    assert yres == -1\n    xarr = DataArray(z, coords=dict(x=x[::-1], y=y[::-1]), dims=dims)\n    xres, yres = calc_res(xarr)\n    assert xres == -2\n    assert yres == 1\n\ntest_calc_res()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_utils.py"}], "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef calc_res(raster): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "orient_array", "method_path": "../srcdata/Visualization/datashader/datashader/utils.py", "response": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\ndef orient_array(raster, res=None, layer=None):\n    \"\"\"\n    Reorients the array to a canonical orientation depending on\n    whether the x and y-resolution values are positive or negative.\n\n    Parameters\n    ----------\n    raster : DataArray\n        xarray DataArray to be reoriented\n    res : tuple\n        Two-tuple (int, int) which includes x and y resolutions (aka \"grid/cell\n        sizes\"), respectively.\n    layer : int\n        Index of the raster layer to be reoriented (optional)\n\n    Returns\n    -------\n    array : numpy.ndarray\n        Reoriented 2d NumPy ndarray\n    \"\"\"\n    if res is None:\n        res = calc_res(raster)\n    array = raster.data\n    if layer is not None:\n        array = array[layer - 1]\n    r0zero = np.timedelta64(0, 'ns') if isinstance(res[0], np.timedelta64\n        ) else 0\n    r1zero = np.timedelta64(0, 'ns') if isinstance(res[1], np.timedelta64\n        ) else 0\n    xflip = res[0] < r0zero\n    yflip = res[1] > r1zero\n    array = _flip_array(array, xflip, yflip)\n    return array", "test_code_list": [{"test_code": "import numpy as np\nfrom xarray import DataArray\nfrom datashader.datashape import dshape\nfrom datashader.utils import Dispatcher\nfrom datashader.utils import apply\nfrom datashader.utils import calc_res\nfrom datashader.utils import isreal\nfrom datashader.utils import orient_array\ndef test_orient_array():\n    x = [5, 7]\n    y = [0, 1]\n    z = np.array([[0, 1], [2, 3]])\n    dims = 'y', 'x'\n    xarr = DataArray(z, coords=dict(x=x, y=y), dims=dims)\n    arr = orient_array(xarr)\n    assert np.array_equal(arr, z)\n    xarr = DataArray(z, coords=dict(x=x, y=y[::-1]), dims=dims)\n    arr = orient_array(xarr)\n    assert np.array_equal(arr, z[::-1])\n    xarr = DataArray(z, coords=dict(x=x[::-1], y=y), dims=dims)\n    arr = orient_array(xarr)\n    assert np.array_equal(arr, z[:, ::-1])\n    xarr = DataArray(z, coords=dict(x=x[::-1], y=y[::-1]), dims=dims)\n    arr = orient_array(xarr)\n    assert np.array_equal(arr, z[::-1, ::-1])\n\ntest_orient_array()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_utils.py"}], "method_code_mask": "from __future__ import annotations\nimport os\nimport re\nfrom inspect import getmro\nimport numba as nb\nimport numpy as np\nimport pandas as pd\nfrom toolz import memoize\nfrom xarray import DataArray\nimport dask.dataframe as dd\nimport datashader.datashape as datashape\nfrom datashader.datatypes import RaggedDtype\nfrom geopandas.array import GeometryDtype as gpd_GeometryDtype\nfrom datashader.transfer_functions import set_background\n\n\ndef orient_array(raster, res=None, layer=None): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "expand_varargs", "method_path": "../srcdata/Visualization/datashader/datashader/macros.py", "response": "import re\nimport copy\nimport inspect\nimport ast\nimport textwrap\nimport astor\ndef expand_varargs(expand_number):\n    \"\"\"\n    Decorator to expand the variable length (starred) argument in a function\n    signature with a fixed number of arguments.\n\n    Parameters\n    ----------\n    expand_number: int\n        The number of fixed arguments that should replace the variable length\n        argument\n\n    Returns\n    -------\n    function\n        Decorator Function\n    \"\"\"\n    if not isinstance(expand_number, int) or expand_number < 0:\n        raise ValueError('expand_number must be a non-negative integer')\n\n    def _expand_varargs(fn):\n        fn_ast = function_to_ast(fn)\n        fn_expanded_ast = expand_function_ast_varargs(fn_ast, expand_number)\n        return function_ast_to_function(fn_expanded_ast, stacklevel=2)\n    return _expand_varargs", "test_code_list": [{"test_code": "import warnings\nimport pytest\nfrom datashader.macros import expand_varargs\nimport inspect\nfrom numba import jit\ndef function_no_vararg(a, b):\n    return a + b\ndef test_invalid_expand_number():\n    with pytest.raises(ValueError) as e:\n        expand_varargs(function_no_vararg)\n    assert e.match('non\\\\-negative integer')\ntest_invalid_expand_number()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_macros.py"}], "method_code_mask": "import re\nimport copy\nimport inspect\nimport ast\nimport textwrap\nimport astor\n\n\ndef expand_varargs(expand_number): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "calculate_zoom_level_stats", "method_path": "../srcdata/Visualization/datashader/datashader/tiles.py", "response": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\ndef calculate_zoom_level_stats(super_tiles, load_data_func, rasterize_func,\n    color_ranging_strategy='fullscan'):\n    if color_ranging_strategy == 'fullscan':\n        stats = []\n        is_bool = False\n        for super_tile in super_tiles:\n            agg = _get_super_tile_min_max(super_tile, load_data_func,\n                rasterize_func)\n            super_tile['agg'] = agg\n            if agg.dtype.kind == 'b':\n                is_bool = True\n            else:\n                stats.append(np.nanmin(agg.data))\n                stats.append(np.nanmax(agg.data))\n        if is_bool:\n            span = 0, 1\n        else:\n            b = db.from_sequence(stats)\n            span = dask.compute(b.min(), b.max())\n        return super_tiles, span\n    else:\n        raise ValueError('Invalid color_ranging_strategy option')", "test_code_list": [{"test_code": "import datashader as ds\nimport datashader.transfer_functions as tf\nfrom datashader.colors import viridis\nfrom datashader.tiles import render_tiles\nfrom datashader.tiles import gen_super_tiles\nfrom datashader.tiles import _get_super_tile_min_max\nfrom datashader.tiles import calculate_zoom_level_stats\nfrom datashader.tiles import MercatorTileDefinition\nimport numpy as np\nimport pandas as pd\nfrom PIL import ImageDraw\ndef assert_is_numeric(value):\n    is_int_or_float = isinstance(value, (int, float))\n    type_name = type(value).__name__\n    is_numpy_int_or_float = 'int' in type_name or 'float' in type_name\n    assert any([is_int_or_float, is_numpy_int_or_float])\ndf = None\ndef mock_rasterize_func(df, x_range, y_range, height, width):\n    cvs = ds.Canvas(x_range=x_range, y_range=y_range, plot_height=height,\n        plot_width=width)\n    agg = cvs.points(df, 'x', 'y')\n    return agg\ndef mock_load_data_func(x_range, y_range):\n    global df\n    if df is None:\n        xs = np.random.normal(loc=0, scale=500000, size=10000000)\n        ys = np.random.normal(loc=0, scale=500000, size=10000000)\n        df = pd.DataFrame(dict(x=xs, y=ys))\n    return df.loc[df['x'].between(*x_range) & df['y'].between(*y_range)]\nMERCATOR_CONST = 20037508.34\ndef test_calculate_zoom_level_stats_with_fullscan_ranging_strategy():\n    full_extent = (-MERCATOR_CONST, -MERCATOR_CONST, MERCATOR_CONST,\n        MERCATOR_CONST)\n    level = 0\n    color_ranging_strategy = 'fullscan'\n    super_tiles, span = calculate_zoom_level_stats(list(gen_super_tiles(\n        full_extent, level)), mock_load_data_func, mock_rasterize_func,\n        color_ranging_strategy=color_ranging_strategy)\n    assert isinstance(span, (list, tuple))\n    assert len(span) == 2\n    assert_is_numeric(span[0])\n    assert_is_numeric(span[1])\ntest_calculate_zoom_level_stats_with_fullscan_ranging_strategy()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_tiles.py"}], "method_code_mask": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\n\n\ndef calculate_zoom_level_stats(super_tiles, load_data_func, rasterize_func,\n    color_ranging_strategy='fullscan'): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "gen_super_tiles", "method_path": "../srcdata/Visualization/datashader/datashader/tiles.py", "response": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\ndef gen_super_tiles(extent, zoom_level, span=None):\n    xmin, ymin, xmax, ymax = extent\n    super_tile_size = min(2 ** 4 * 256, 2 ** zoom_level * 256)\n    super_tile_def = MercatorTileDefinition(x_range=(xmin, xmax), y_range=(\n        ymin, ymax), tile_size=super_tile_size)\n    super_tiles = super_tile_def.get_tiles_by_extent(extent, zoom_level)\n    for s in super_tiles:\n        st_extent = s[3]\n        x_range = st_extent[0], st_extent[2]\n        y_range = st_extent[1], st_extent[3]\n        yield {'level': zoom_level, 'x_range': x_range, 'y_range': y_range,\n            'tile_size': super_tile_def.tile_size, 'span': span}", "test_code_list": [{"test_code": "import datashader as ds\nimport datashader.transfer_functions as tf\nfrom datashader.colors import viridis\nfrom datashader.tiles import render_tiles\nfrom datashader.tiles import gen_super_tiles\nfrom datashader.tiles import _get_super_tile_min_max\nfrom datashader.tiles import calculate_zoom_level_stats\nfrom datashader.tiles import MercatorTileDefinition\nimport numpy as np\nimport pandas as pd\nfrom PIL import ImageDraw\ndef assert_is_numeric(value):\n    is_int_or_float = isinstance(value, (int, float))\n    type_name = type(value).__name__\n    is_numpy_int_or_float = 'int' in type_name or 'float' in type_name\n    assert any([is_int_or_float, is_numpy_int_or_float])\ndf = None\ndef mock_rasterize_func(df, x_range, y_range, height, width):\n    cvs = ds.Canvas(x_range=x_range, y_range=y_range, plot_height=height,\n        plot_width=width)\n    agg = cvs.points(df, 'x', 'y')\n    return agg\ndef mock_load_data_func(x_range, y_range):\n    global df\n    if df is None:\n        xs = np.random.normal(loc=0, scale=500000, size=10000000)\n        ys = np.random.normal(loc=0, scale=500000, size=10000000)\n        df = pd.DataFrame(dict(x=xs, y=ys))\n    return df.loc[df['x'].between(*x_range) & df['y'].between(*y_range)]\nMERCATOR_CONST = 20037508.34\ndef test_calculate_zoom_level_stats_with_fullscan_ranging_strategy():\n    full_extent = (-MERCATOR_CONST, -MERCATOR_CONST, MERCATOR_CONST,\n        MERCATOR_CONST)\n    level = 0\n    color_ranging_strategy = 'fullscan'\n    super_tiles, span = calculate_zoom_level_stats(list(gen_super_tiles(\n        full_extent, level)), mock_load_data_func, mock_rasterize_func,\n        color_ranging_strategy=color_ranging_strategy)\n    assert isinstance(span, (list, tuple))\n    assert len(span) == 2\n    assert_is_numeric(span[0])\n    assert_is_numeric(span[1])\ntest_calculate_zoom_level_stats_with_fullscan_ranging_strategy()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_tiles.py"}], "method_code_mask": "from __future__ import annotations\nfrom io import BytesIO\nimport math\nimport os\nimport dask\nimport dask.bag as db\nimport numpy as np\nfrom PIL.Image import fromarray\nimport errno\nfrom bokeh.plotting import figure\nfrom bokeh.models.tiles import WMTSTileSource\nfrom bokeh.io import output_file\nfrom bokeh.io import save\nfrom os import path\nimport boto3\nfrom urllib.parse import urlparse\n\n\ndef gen_super_tiles(extent, zoom_level, span=None): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "draw_segment", "method_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py", "response": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n_draw_segment = _build_draw_segment(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols, 0, False)\ndef draw_segment(x0, y0, x1, y1, i, segment_start, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    buffer = np.empty(0)\n    _draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start,\n        False, x0, x1, y0, y1, 0.0, 0.0, buffer, agg)", "test_code_list": [{"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_line_same_point():\n    x0, y0 = 4, 4\n    x1, y1 = 4, 4\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n    x0, y0 = 4, 4\n    x1, y1 = 10, 10\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    assert agg.sum() == 0\n    assert agg[4, 4] == 0\ntest_draw_line_same_point()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_line_vertical_horizontal():\n    x0, y0 = 3, 3\n    x1, y1 = 3, 0\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    out = new_agg()\n    out[:4, 3] = 1\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_segment(y0, x0, y1, x1, 0, True, agg)\n    out = new_agg()\n    out[3, :4] = 1\n    np.testing.assert_equal(agg, out)\ntest_draw_line_vertical_horizontal()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}], "method_code_mask": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\n_draw_segment = _build_draw_segment(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols, 0, False)\n\n\ndef draw_segment(x0, y0, x1, y1, i, segment_start, agg): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "draw_trapezoid", "method_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py", "response": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n_draw_trapezoid = _build_draw_trapezoid_y(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols)\ndef draw_trapezoid(x0, x1, y0, y1, y2, y3, i, trapezoid_start, stacked, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    _draw_trapezoid(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, x0, x1, y0,\n        y1, y2, y3, trapezoid_start, stacked, agg)", "test_code_list": [{"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_acute_not_stacked():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 1, 3, 4, 0\n    out = np.array([[0, 0, 1, 1, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [1,\n        1, 1, 1, 0], [0, 0, 1, 1, 0]])\n    trapezoid_start = True\n    stacked = False\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_acute_not_stacked()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_right():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 1, 3, 4, 1\n    out = np.array([[0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0,\n        0, 1, 1, 0], [0, 0, 0, 0, 0]])\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_right()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_obtuse():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 0, 3, 5, 1\n    out = np.array([[1, 1, 0, 0, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0,\n        0, 1, 1, 0], [0, 0, 0, 0, 0]])\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_obtuse()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_intersecting():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 0, 5, 1, 4\n    out = np.array([[1, 0, 0, 0, 0], [1, 1, 0, 0, 0], [1, 1, 0, 1, 0], [1,\n        0, 1, 1, 0], [0, 0, 0, 1, 0]])\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_intersecting()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_vertical_line_start_and_not_clipped():\n    x0, x1 = 2, 2\n    y0, y1, y2, y3 = 1, 3, 4, 0\n    out = np.array([[0, 0, 1, 0, 0], [0, 0, 2, 0, 0], [0, 0, 2, 0, 0], [0,\n        0, 1, 0, 0], [0, 0, 0, 0, 0]])\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_vertical_line_start_and_not_clipped()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_vertical_line_not_start_and_not_clipped():\n    x0, x1 = 2, 2\n    y0, y1, y2, y3 = 1, 3, 4, 0\n    trapezoid_start = False\n    stacked = True\n    out = np.array([[0, 0, 1, 0, 0], [0, 0, 1, 0, 0], [0, 0, 1, 0, 0], [0,\n        0, 1, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    out = np.array([[0, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 1, 0, 0], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_vertical_line_not_start_and_not_clipped()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_clipped():\n    x0, x1 = 4, 6\n    y0, y1, y2, y3 = 1, 3, 5, 0\n    trapezoid_start = True\n    stacked = True\n    out = np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    out = np.array([[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0,\n        0, 0, 0, 1], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_clipped()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_vertical_line_not_start_and_clipped():\n    x0, x1 = 4, 6\n    y0, y1, y2, y3 = 1, 3, 4, 0\n    trapezoid_start = False\n    stacked = True\n    out = np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_vertical_line_not_start_and_clipped()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_horizontal_line():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 2, 2, 2, 2\n    trapezoid_start = True\n    stacked = False\n    out = np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg.sum(), 0)\ntest_draw_trapezoid_horizontal_line()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_diagonal_line():\n    x0, x1 = 0, 3\n    y0, y1, y2, y3 = 0, 0, 2, 2\n    trapezoid_start = True\n    stacked = False\n    out = np.array([[1, 0, 0, 0, 0], [0, 1, 1, 0, 0], [0, 0, 0, 1, 0], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg.sum(), 0)\ntest_draw_trapezoid_diagonal_line()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}, {"test_code": "import pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\ndef test_draw_trapezoid_point():\n    x0, x1 = 3, 3\n    y0, y1, y2, y3 = 2, 2, 2, 2\n    trapezoid_start = True\n    stacked = False\n    out = np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 2, 0], [0,\n        0, 0, 0, 0], [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    trapezoid_start = False\n    out[2, 3] = 1\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n    trapezoid_start = True\n    stacked = True\n    out[2, 3] = 0\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0, trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\ntest_draw_trapezoid_point()", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_glyphs.py"}], "method_code_mask": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point\nfrom datashader.glyphs import LinesAxis1\nfrom datashader.glyphs import Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import _build_map_onto_pixel_for_line\nfrom datashader.glyphs.line import _build_draw_segment\nfrom datashader.glyphs.line import _build_extend_line_axis0\nfrom datashader.glyphs.trimesh import _build_map_onto_pixel_for_triangle\nfrom datashader.glyphs.trimesh import _build_draw_triangle\nfrom datashader.glyphs.trimesh import _build_extend_triangles\nfrom datashader.utils import ngjit\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n\n_draw_trapezoid = _build_draw_trapezoid_y(append, map_onto_pixel_for_line,\n    expand_aggs_and_cols)\n\n\ndef draw_trapezoid(x0, x1, y0, y1, y2, y3, i, trapezoid_start, stacked, agg): [\n    MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "compute_chunksize", "method_path": "../srcdata/Visualization/datashader/datashader/resampling.py", "response": "from __future__ import annotations\nfrom itertools import groupby\nfrom math import floor\nfrom math import ceil\nimport dask.array as da\nimport numpy as np\nfrom dask.delayed import delayed\nfrom numba import prange\ndef compute_chunksize(src, w, h, chunksize=None, max_mem=None):\n    \"\"\"\n    Attempts to compute a chunksize for the resampling output array\n    that is as close as possible to the input array chunksize, while\n    also respecting the maximum memory constraint to avoid loading\n    to much data into memory at the same time.\n\n    Parameters\n    ----------\n    src : dask.array.Array\n        The source array to resample\n    w : int\n        New grid width\n    h : int\n        New grid height\n    chunksize : tuple(int, int) (optional)\n        Size of the output chunks. By default the chunk size is\n        inherited from the *src* array.\n    max_mem : int (optional)\n        The maximum number of bytes that should be loaded into memory\n        during the regridding operation.\n\n    Returns\n    -------\n    chunksize : tuple(int, int)\n        Size of the output chunks.\n    \"\"\"\n    start_chunksize = src.chunksize if chunksize is None else chunksize\n    if max_mem is None:\n        return start_chunksize\n    sh, sw = src.shape\n    height_fraction = float(sh) / h\n    width_fraction = float(sw) / w\n    ch, cw = start_chunksize\n    dim = True\n    nbytes = src.dtype.itemsize\n    while ch * height_fraction * (cw * width_fraction) * nbytes > max_mem:\n        if dim:\n            cw -= 1\n        else:\n            ch -= 1\n        dim = not dim\n    if ch == 0 or cw == 0:\n        min_mem = height_fraction * width_fraction * nbytes\n        raise ValueError(\n            'Given the memory constraints the resampling operation could not find a chunksize that avoids loading too much data into memory. Either relax the memory constraint to a minimum of %d bytes or resample to a larger grid size. Note: A future implementation could handle this condition by declaring temporary arrays.'\n             % min_mem)\n    return ch, cw", "test_code_list": [{"test_code": "import pytest\nfrom dask.context import config\nfrom os import path\nfrom itertools import product\nimport datashader as ds\nimport xarray as xr\nimport numpy as np\nimport dask.array as da\nimport pandas as pd\nfrom datashader.resampling import compute_chunksize\nimport datashader.transfer_functions as tf\nfrom packaging.version import Version\ndef test_resample_compute_chunksize():\n    \"\"\"\n    Ensure chunksize computation is correct.\n    \"\"\"\n    darr = da.from_array(np.zeros((100, 100)), (10, 10))\n    mem_limited_chunksize = compute_chunksize(darr, 10, 10, max_mem=2000)\n    assert mem_limited_chunksize == (2, 1)\n    explicit_chunksize = compute_chunksize(darr, 10, 10, chunksize=(5, 4))\n    assert explicit_chunksize == (5, 4)\n\ntest_resample_compute_chunksize()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Visualization/datashader/datashader/tests/test_raster.py"}], "method_code_mask": "from __future__ import annotations\nfrom itertools import groupby\nfrom math import floor\nfrom math import ceil\nimport dask.array as da\nimport numpy as np\nfrom dask.delayed import delayed\nfrom numba import prange\n\n\ndef compute_chunksize(src, w, h, chunksize=None, max_mem=None): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "lex", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/lexer.py", "response": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport re\nimport ast\nimport collections\nToken = collections.namedtuple('Token', 'id, name, span, val')\ndef _str_val(s):\n    return ast.parse('u' + s).body[0].value.value\n_tokens = [('BOOLEAN', 'True|False', ast.literal_eval), ('NAME_LOWER',\n    '[a-z][a-zA-Z0-9_]*', lambda x: x), ('NAME_UPPER', '[A-Z][a-zA-Z0-9_]*',\n    lambda x: x), ('NAME_OTHER', '_[a-zA-Z0-9_]*', lambda x: x), (\n    'ASTERISK', '\\\\*'), ('COMMA', ','), ('EQUAL', '='), ('COLON', ':'), (\n    'LBRACKET', '\\\\['), ('RBRACKET', '\\\\]'), ('LBRACE', '\\\\{'), ('RBRACE',\n    '\\\\}'), ('LPAREN', '\\\\('), ('RPAREN', '\\\\)'), ('ELLIPSIS', '\\\\.\\\\.\\\\.'),\n    ('RARROW', '->'), ('QUESTIONMARK', '\\\\?'), ('INTEGER',\n    '0(?![0-9])|-?[1-9][0-9]*', int), ('STRING',\n    '(?:\"(?:[^\"\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\[\"bfnrt]))*\")|' +\n    \"(?:'(?:[^'\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\['bfnrt]))*')\",\n    _str_val)]\n_tokens_re = re.compile('|'.join('(' + tok[1] + ')' for tok in _tokens), re\n    .MULTILINE)\n_whitespace = '(?:\\\\s|(?:#.*$))*'\n_whitespace_re = re.compile(_whitespace, re.MULTILINE)\ndef lex(ds_str):\n    \"\"\"A generator which lexes a datashape string into a\n    sequence of tokens.\n    Example\n    -------\n        import datashape\n        s = '   -> ... A... \"string\" 1234 Blah _eil(# comment'\n        print('lexing %r' % s)\n        for tok in datashape.lexer.lex(s):\n            print(tok.id, tok.name, tok.span, repr(tok.val))\n    \"\"\"\n    pos = 0\n    m = _whitespace_re.match(ds_str, pos)\n    if m:\n        pos = m.end()\n    while pos < len(ds_str):\n        m = _tokens_re.match(ds_str, pos)\n        if m:\n            id = m.lastindex\n            tokinfo = _tokens[id - 1]\n            name = tokinfo[0]\n            span = m.span()\n            if len(tokinfo) > 2:\n                val = tokinfo[2](ds_str[span[0]:span[1]])\n            else:\n                val = None\n            pos = m.end()\n            yield Token(id, name, span, val)\n        else:\n            raise error.DataShapeSyntaxError(pos, '<nofile>', ds_str,\n                'Invalid DataShape token')\n        m = _whitespace_re.match(ds_str, pos)\n        if m:\n            pos = m.end()", "test_code_list": [{"test_code": "import unittest\nfrom datashader import datashape\nfrom datashader.datashape import lexer\n\nclass TestDataShapeLexer(unittest.TestCase):\n    def test_whitespace(self):\n        expected_idval = [(lexer.COLON, None), (lexer.STRING, 'a'), (lexer.\n            INTEGER, 12345), (lexer.RARROW, None), (lexer.EQUAL, None), (lexer.\n            ASTERISK, None), (lexer.NAME_OTHER, '_b')]\n        toks = list(lex(':\"a\"12345->=*_b'))\n        self.assertEqual([(tok.id, tok.val) for tok in toks], expected_idval)\n        toks = list(lex(' : \"a\" 12345 -> = * _b '))\n        self.assertEqual([(tok.id, tok.val) for tok in toks], expected_idval)\n        toks = list(lex('\\t:\\t\"a\"\\t12345\\t->\\t=\\t*\\t_b\\t'))\n        self.assertEqual([(tok.id, tok.val) for tok in toks], expected_idval)\n        toks = list(lex('\\n:\\n\"a\"\\n12345\\n->\\n=\\n*\\n_b\\n'))\n        self.assertEqual([(tok.id, tok.val) for tok in toks], expected_idval)\n        toks = list(lex('# comment\\n' + ': # X\\n' + ' \"a\" # \"b\"\\t\\n' +\n            '\\t12345\\n\\n' + '->\\n' + '=\\n' + '*\\n' + '_b # comment\\n' +\n            ' \\t # end'))\n        self.assertEqual([(tok.id, tok.val) for tok in toks], expected_idval)\n    \nTestDataShapeLexer().test_whitespace()\n", "code_start": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_lexer.py"}], "method_code_mask": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport re\nimport ast\nimport collections\nToken = collections.namedtuple('Token', 'id, name, span, val')\n\n\ndef _str_val(s):\n    return ast.parse('u' + s).body[0].value.value\n\n\n_tokens = [('BOOLEAN', 'True|False', ast.literal_eval), ('NAME_LOWER',\n    '[a-z][a-zA-Z0-9_]*', lambda x: x), ('NAME_UPPER', '[A-Z][a-zA-Z0-9_]*',\n    lambda x: x), ('NAME_OTHER', '_[a-zA-Z0-9_]*', lambda x: x), (\n    'ASTERISK', '\\\\*'), ('COMMA', ','), ('EQUAL', '='), ('COLON', ':'), (\n    'LBRACKET', '\\\\['), ('RBRACKET', '\\\\]'), ('LBRACE', '\\\\{'), ('RBRACE',\n    '\\\\}'), ('LPAREN', '\\\\('), ('RPAREN', '\\\\)'), ('ELLIPSIS', '\\\\.\\\\.\\\\.'),\n    ('RARROW', '->'), ('QUESTIONMARK', '\\\\?'), ('INTEGER',\n    '0(?![0-9])|-?[1-9][0-9]*', int), ('STRING', \n    '(?:\"(?:[^\"\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\[\"bfnrt]))*\")|' +\n    \"(?:'(?:[^'\\\\n\\\\r\\\\\\\\]|(?:\\\\\\\\u[0-9a-fA-F]{4})|(?:\\\\\\\\['bfnrt]))*')\",\n    _str_val)]\n_tokens_re = re.compile('|'.join('(' + tok[1] + ')' for tok in _tokens), re\n    .MULTILINE)\n_whitespace = '(?:\\\\s|(?:#.*$))*'\n_whitespace_re = re.compile(_whitespace, re.MULTILINE)\n\n\ndef lex(ds_str): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "optionify", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/promote.py", "response": "from __future__ import absolute_import\nimport numpy as np\nfrom datashader import datashape\ndef optionify(lhs, rhs, dshape):\n    \"\"\"Check whether a binary operation's dshape came from\n    :class:`~datashape.coretypes.Option` typed operands and construct an\n    :class:`~datashape.coretypes.Option` type accordingly.\n\n    Examples\n    --------\n    >>> from datashader.datashape import int32, int64, Option\n    >>> x = Option(int32)\n    >>> x\n    Option(ty=ctype(\"int32\"))\n    >>> y = int64\n    >>> y\n    ctype(\"int64\")\n    >>> optionify(x, y, int64)\n    Option(ty=ctype(\"int64\"))\n    \"\"\"\n    if hasattr(dshape.measure, 'ty'):\n        return dshape\n    if hasattr(lhs, 'ty') or hasattr(rhs, 'ty'):\n        return datashape.Option(dshape)\n    return dshape", "test_code_list": [{"test_code": "import pytest\nfrom datashader.datashape import promote\nfrom datashader.datashape import Option\nfrom datashader.datashape import float64\nfrom datashader.datashape import int64\nfrom datashader.datashape import float32\nfrom datashader.datashape import optionify\nfrom datashader.datashape import string\nfrom datashader.datashape import datetime_ as datetime\nfrom datashader.datashape import dshape\ndef test_option_in_parent():\n    x = int64\n    y = Option(float32)\n    z = optionify(x, y, y)\n    assert z == y\n\ntest_option_in_parent()\n", "code_start": "", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_promote.py"}], "method_code_mask": "from __future__ import absolute_import\nimport numpy as np\nfrom datashader import datashape\n\n\ndef optionify(lhs, rhs, dshape): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "parse", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/parser.py", "response": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\ndef parse(ds_str, sym):\n    \"\"\"Parses a single datashape from a string.\n\n    Parameters\n    ----------\n    ds_str : string\n        The datashape string to parse.\n    sym : TypeSymbolTable\n        The symbol tables of dimensions, dtypes, and type constructors for each.\n\n    \"\"\"\n    dsp = DataShapeParser(ds_str, sym)\n    ds = dsp.parse_datashape()\n    if ds is None:\n        dsp.raise_error('Invalid datashape')\n    if dsp.pos != dsp.end_pos:\n        dsp.raise_error('Unexpected token in datashape')\n    return ds", "test_code_list": [{"test_code": "import unittest\nimport pytest\nfrom datashader import datashape\nfrom datashader.datashape.util.testing import assert_dshape_equal\nfrom datashader.datashape.parser import parse\nfrom datashader.datashape import coretypes as ct\nfrom datashader.datashape import DataShapeSyntaxError\n\nclass TestDataShapeParserDTypeConstr(unittest.TestCase):\n    def test_unary_dtype_constr(self):\n        sym = datashape.TypeSymbolTable(bare=True)\n        sym.dtype['int8'] = ct.int8\n        sym.dtype['uint16'] = ct.uint16\n        sym.dtype['float64'] = ct.float64\n        sym.dtype_constr['typevar'] = ct.TypeVar\n        expected_blah = [None]\n    \n        def _unary_type_constr(blah):\n            self.assertEqual(blah, expected_blah[0])\n            expected_blah[0] = None\n            return ct.float32\n        sym.dtype_constr['unary'] = _unary_type_constr\n    \n        def assertExpectedParse(ds_str, expected):\n            expected_blah[0] = expected\n            self.assertEqual(parse(ds_str, sym), ct.DataShape(ct.float32))\n            self.assertEqual(expected_blah[0], None,\n                'The test unary type constructor did not run')\n        assertExpectedParse('unary[0]', 0)\n        assertExpectedParse('unary[100000]', 100000)\n        assertExpectedParse('unary[\"test\"]', 'test')\n        assertExpectedParse(\"unary['test']\", 'test')\n        assertExpectedParse('unary[\"\\\\uc548\\\\ub155\"]', u'\uc548\ub155')\n        assertExpectedParse(u'unary[\"\uc548\ub155\"]', u'\uc548\ub155')\n        assertExpectedParse('unary[int8]', ct.DataShape(ct.int8))\n        assertExpectedParse('unary[X]', ct.DataShape(ct.TypeVar('X')))\n        assertExpectedParse('unary[[]]', [])\n        assertExpectedParse('unary[[0, 3, 12]]', [0, 3, 12])\n        assertExpectedParse('unary[[\"test\", \"one\", \"two\"]]', ['test', 'one', 'two']\n            )\n        assertExpectedParse('unary[[float64, int8, uint16]]', [ct.DataShape(ct.\n            float64), ct.DataShape(ct.int8), ct.DataShape(ct.uint16)])\n        assertExpectedParse('unary[blah=0]', 0)\n        assertExpectedParse('unary[blah=100000]', 100000)\n        assertExpectedParse('unary[blah=\"test\"]', 'test')\n        assertExpectedParse(\"unary[blah='test']\", 'test')\n        assertExpectedParse('unary[blah=\"\\\\uc548\\\\ub155\"]', u'\uc548\ub155')\n        assertExpectedParse(u'unary[blah=\"\uc548\ub155\"]', u'\uc548\ub155')\n        assertExpectedParse('unary[blah=int8]', ct.DataShape(ct.int8))\n        assertExpectedParse('unary[blah=X]', ct.DataShape(ct.TypeVar('X')))\n        assertExpectedParse('unary[blah=[]]', [])\n        assertExpectedParse('unary[blah=[0, 3, 12]]', [0, 3, 12])\n        assertExpectedParse('unary[blah=[\"test\", \"one\", \"two\"]]', ['test',\n            'one', 'two'])\n        assertExpectedParse('unary[blah=[float64, int8, uint16]]', [ct.\n            DataShape(ct.float64), ct.DataShape(ct.int8), ct.DataShape(ct.uint16)])\n    \nTestDataShapeParserDTypeConstr().test_unary_dtype_constr()\n", "code_start": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_parser.py"}, {"test_code": "import unittest\nimport pytest\nfrom datashader import datashape\nfrom datashader.datashape.util.testing import assert_dshape_equal\nfrom datashader.datashape.parser import parse\nfrom datashader.datashape import coretypes as ct\nfrom datashader.datashape import DataShapeSyntaxError\n\nclass TestDataShapeParserDTypeConstr(unittest.TestCase):\n    def test_binary_dtype_constr(self):\n        sym = datashape.TypeSymbolTable(bare=True)\n        sym.dtype['int8'] = ct.int8\n        sym.dtype['uint16'] = ct.uint16\n        sym.dtype['float64'] = ct.float64\n        sym.dtype_constr['typevar'] = ct.TypeVar\n        expected_arg = [None, None]\n    \n        def _binary_type_constr(a, b):\n            self.assertEqual(a, expected_arg[0])\n            self.assertEqual(b, expected_arg[1])\n            expected_arg[0] = None\n            expected_arg[1] = None\n            return ct.float32\n        sym.dtype_constr['binary'] = _binary_type_constr\n    \n        def assertExpectedParse(ds_str, expected_a, expected_b):\n            expected_arg[0] = expected_a\n            expected_arg[1] = expected_b\n            self.assertEqual(parse(ds_str, sym), ct.DataShape(ct.float32))\n            self.assertEqual(expected_arg, [None, None],\n                'The test binary type constructor did not run')\n        assertExpectedParse('binary[1, 0]', 1, 0)\n        assertExpectedParse('binary[0, \"test\"]', 0, 'test')\n        assertExpectedParse('binary[int8, \"test\"]', ct.DataShape(ct.int8), 'test')\n        assertExpectedParse('binary[[1,3,5], \"test\"]', [1, 3, 5], 'test')\n        assertExpectedParse('binary[0, b=1]', 0, 1)\n        assertExpectedParse('binary[\"test\", b=A]', 'test', ct.DataShape(ct.\n            TypeVar('A')))\n        assertExpectedParse('binary[[3, 6], b=int8]', [3, 6], ct.DataShape(ct.int8)\n            )\n        assertExpectedParse('binary[Arg, b=[\"x\", \"test\"]]', ct.DataShape(ct.\n            TypeVar('Arg')), ['x', 'test'])\n        assertExpectedParse('binary[a=1, b=0]', 1, 0)\n        assertExpectedParse('binary[a=[int8, A, uint16], b=\"x\"]', [ct.DataShape\n            (ct.int8), ct.DataShape(ct.TypeVar('A')), ct.DataShape(ct.uint16)], 'x'\n            )\n    \nTestDataShapeParserDTypeConstr().test_binary_dtype_constr()\n", "code_start": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_parser.py"}], "method_code_mask": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\ndef parse(ds_str, sym): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "isfixed", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/predicates.py", "response": "import numpy as np\ndef isfixed(ds):\n    \"\"\" Contains no variable dimensions\n\n    >>> isfixed('10 * int')\n    True\n    >>> isfixed('var * int')\n    False\n    >>> isfixed('10 * {name: string, amount: int}')\n    True\n    >>> isfixed('10 * {name: string, amounts: var * int}')\n    False\n    \"\"\"\n    ds = dshape(ds)\n    if isinstance(ds[0], TypeVar):\n        return None\n    if isinstance(ds[0], Var):\n        return False\n    if isinstance(ds[0], Record):\n        return all(map(isfixed, ds[0].types))\n    if len(ds) > 1:\n        return isfixed(ds.subarray(1))\n    return True", "test_code_list": [{"test_code": "from datashader.datashape.predicates import isfixed\nfrom datashader.datashape.predicates import _dimensions\nfrom datashader.datashape.predicates import isnumeric\nfrom datashader.datashape.predicates import isscalar\nfrom datashader.datashape.coretypes import TypeVar\nfrom datashader.datashape.coretypes import int32\nfrom datashader.datashape.coretypes import Categorical\ndef test_isfixed():\n    assert not isfixed(TypeVar('M') * int32)\n\ntest_isfixed()\n", "code_start": "", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_predicates.py"}], "method_code_mask": "import numpy as np\n\n\ndef isfixed(ds): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "isnumeric", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/predicates.py", "response": "import numpy as np\ndef isnumeric(ds):\n    \"\"\" Has a numeric measure\n\n    >>> isnumeric('int32')\n    True\n    >>> isnumeric('3 * ?real')\n    True\n    >>> isnumeric('string')\n    False\n    >>> isnumeric('var * {amount: ?int32}')\n    False\n    \"\"\"\n    ds = launder(ds)\n    try:\n        npdtype = to_numpy_dtype(ds)\n    except TypeError:\n        return False\n    else:\n        return isinstance(ds, Unit) and np.issubdtype(npdtype, np.number)", "test_code_list": [{"test_code": "from datashader.datashape.predicates import isfixed\nfrom datashader.datashape.predicates import _dimensions\nfrom datashader.datashape.predicates import isnumeric\nfrom datashader.datashape.predicates import isscalar\nfrom datashader.datashape.coretypes import TypeVar\nfrom datashader.datashape.coretypes import int32\nfrom datashader.datashape.coretypes import Categorical\ndef test_time():\n    assert not isnumeric('time')\n\ntest_time()\n", "code_start": "", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_predicates.py"}], "method_code_mask": "import numpy as np\n\n\ndef isnumeric(ds): [MASK]\n"}
{"model_name": "std", "repository": "datashader", "full_method_name": "unite_base", "method_path": "../srcdata/Visualization/datashader/datashader/datashape/discovery.py", "response": "from __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom datetime import date\nfrom datetime import time\nfrom datetime import timedelta\nfrom itertools import chain\nimport re\nfrom textwrap import dedent\nfrom types import MappingProxyType\nfrom warnings import warn\nfrom dateutil.parser import parse as dateparse\nimport numpy as np\nfrom unittest.mock import Mock\ndef unite_base(dshapes):\n    \"\"\" Performs lowest common dshape and also null aware\n\n    >>> unite_base([float64, float64, int64])\n    dshape(\"3 * float64\")\n\n    >>> unite_base([int32, int64, null])\n    dshape(\"3 * ?int64\")\n    \"\"\"\n    dshapes = [unpack(ds) for ds in dshapes]\n    bynull = groupby(isnull, dshapes)\n    try:\n        good_dshapes = bynull[False]\n    except KeyError:\n        return len(dshapes) * null\n    if all(isinstance(ds, Unit) for ds in good_dshapes):\n        base = lowest_common_dshape(good_dshapes)\n    elif (all(isinstance(ds, Record) for ds in good_dshapes) and ds.names ==\n        dshapes[0].names for ds in good_dshapes):\n        names = good_dshapes[0].names\n        base = Record([[name, unite_base([ds.dict.get(name, null) for ds in\n            good_dshapes]).subshape[0]] for name in names])\n    if base:\n        if bynull.get(True):\n            base = Option(base)\n        return len(dshapes) * base", "test_code_list": [{"test_code": "from collections import OrderedDict\nfrom itertools import starmap\nfrom types import MappingProxyType\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\nimport numpy as np\nimport pytest\nfrom datashader.datashape.discovery import discover\nfrom datashader.datashape.discovery import null\nfrom datashader.datashape.discovery import unite_identical\nfrom datashader.datashape.discovery import unite_base\nfrom datashader.datashape.discovery import unite_merge_dimensions\nfrom datashader.datashape.discovery import do_one\nfrom datashader.datashape.discovery import lowest_common_dshape\nfrom datashader.datashape.coretypes import int64\nfrom datashader.datashape.coretypes import float64\nfrom datashader.datashape.coretypes import complex128\nfrom datashader.datashape.coretypes import string\nfrom datashader.datashape.coretypes import bool_\nfrom datashader.datashape.coretypes import Tuple\nfrom datashader.datashape.coretypes import Record\nfrom datashader.datashape.coretypes import date_\nfrom datashader.datashape.coretypes import datetime_\nfrom datashader.datashape.coretypes import time_\nfrom datashader.datashape.coretypes import timedelta_\nfrom datashader.datashape.coretypes import int32\nfrom datashader.datashape.coretypes import var\nfrom datashader.datashape.coretypes import Option\nfrom datashader.datashape.coretypes import real\nfrom datashader.datashape.coretypes import Null\nfrom datashader.datashape.coretypes import TimeDelta\nfrom datashader.datashape.coretypes import String\nfrom datashader.datashape.coretypes import float32\nfrom datashader.datashape.coretypes import R\nfrom datashader.datashape.util.testing import assert_dshape_equal\nfrom datashader.datashape import dshape\nfrom datetime import date\nfrom datetime import time\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom unittest.mock import Mock\ndef test_unite_base():\n    assert unite_base([date_, datetime_]) == 2 * datetime_\n\ntest_unite_base()\n", "code_start": "", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_discovery.py"}, {"test_code": "from collections import OrderedDict\nfrom itertools import starmap\nfrom types import MappingProxyType\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\nimport numpy as np\nimport pytest\nfrom datashader.datashape.discovery import discover\nfrom datashader.datashape.discovery import null\nfrom datashader.datashape.discovery import unite_identical\nfrom datashader.datashape.discovery import unite_base\nfrom datashader.datashape.discovery import unite_merge_dimensions\nfrom datashader.datashape.discovery import do_one\nfrom datashader.datashape.discovery import lowest_common_dshape\nfrom datashader.datashape.coretypes import int64\nfrom datashader.datashape.coretypes import float64\nfrom datashader.datashape.coretypes import complex128\nfrom datashader.datashape.coretypes import string\nfrom datashader.datashape.coretypes import bool_\nfrom datashader.datashape.coretypes import Tuple\nfrom datashader.datashape.coretypes import Record\nfrom datashader.datashape.coretypes import date_\nfrom datashader.datashape.coretypes import datetime_\nfrom datashader.datashape.coretypes import time_\nfrom datashader.datashape.coretypes import timedelta_\nfrom datashader.datashape.coretypes import int32\nfrom datashader.datashape.coretypes import var\nfrom datashader.datashape.coretypes import Option\nfrom datashader.datashape.coretypes import real\nfrom datashader.datashape.coretypes import Null\nfrom datashader.datashape.coretypes import TimeDelta\nfrom datashader.datashape.coretypes import String\nfrom datashader.datashape.coretypes import float32\nfrom datashader.datashape.coretypes import R\nfrom datashader.datashape.util.testing import assert_dshape_equal\nfrom datashader.datashape import dshape\nfrom datetime import date\nfrom datetime import time\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom unittest.mock import Mock\ndef test_unite_base_on_records():\n    dshapes = [dshape('{name: string, amount: int32}'), dshape(\n        '{name: string, amount: int32}')]\n    assert unite_base(dshapes) == dshape('2 * {name: string, amount: int32}')\n    dshapes = [Null(), dshape('{name: string, amount: int32}')]\n    assert unite_base(dshapes) == dshape('2 * ?{name: string, amount: int32}')\n    dshapes = [dshape('{name: string, amount: int32}'), dshape(\n        '{name: string, amount: int64}')]\n    assert unite_base(dshapes) == dshape('2 * {name: string, amount: int64}')\n\ntest_unite_base_on_records()\n", "code_start": "", "test_path": "../srcdata/Visualization/datashader/datashader/datashape/tests/test_discovery.py"}], "method_code_mask": "from __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom datetime import date\nfrom datetime import time\nfrom datetime import timedelta\nfrom itertools import chain\nimport re\nfrom textwrap import dedent\nfrom types import MappingProxyType\nfrom warnings import warn\nfrom dateutil.parser import parse as dateparse\nimport numpy as np\nfrom unittest.mock import Mock\n\n\ndef unite_base(dshapes): [MASK]\n"}
