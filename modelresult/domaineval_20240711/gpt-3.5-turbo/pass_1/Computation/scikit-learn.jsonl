{"model_name": "gpt-3.5-turbo", "repository": "scikit-learn", "full_method_name": "clone", "method_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/base.py", "response": "def clone(estimator, *, safe=True):\n    if not safe:\n        warnings.warn(\"Cloning an estimator without checking it first via `estimator.check` is not recommended.\")\n    if isinstance(estimator, (list, tuple, set)):\n        return [clone(est) for est in estimator]\n    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n        if not safe:\n            return copy.deepcopy(estimator)\n        else:\n            raise TypeError(\"Cannot clone object '{0}' (type {1}): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\".format(estimator, type(estimator)))\n    else:\n        klass = estimator.__class__\n        new_object_params = estimator.get_params(deep=False)\n        for name, param in new_object_params.items():\n            new_object_params[name] = clone(param, safe=False)\n        new_object = klass(**new_object_params)\n        return new_object", "test_code_list": [{"test_code": "import re\nimport warnings\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom sklearn import datasets\nfrom sklearn.base import clone\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_regression\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble._gradient_boosting import predict_stages\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.svm import NuSVR\nfrom sklearn.utils import check_random_state\nfrom sklearn.utils._mocking import NoSampleWeightWrapper\nfrom sklearn.utils._param_validation import InvalidParameterError\nfrom sklearn.utils._testing import assert_array_almost_equal\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import skip_if_32bit\nimport pickle\nimport sys\nfrom io import StringIO\nfrom sklearn.tree._tree import TREE_LEAF\ndef test_gradient_boosting_validation_fraction():\n    X, y = make_classification(n_samples=1000, random_state=0)\n    gbc = GradientBoostingClassifier(n_estimators=100, n_iter_no_change=10,\n        validation_fraction=0.1, learning_rate=0.1, max_depth=3,\n        random_state=42)\n    gbc2 = clone(gbc).set_params(validation_fraction=0.3)\n    gbc3 = clone(gbc).set_params(n_iter_no_change=20)\n    gbr = GradientBoostingRegressor(n_estimators=100, n_iter_no_change=10,\n        learning_rate=0.1, max_depth=3, validation_fraction=0.1,\n        random_state=42)\n    gbr2 = clone(gbr).set_params(validation_fraction=0.3)\n    gbr3 = clone(gbr).set_params(n_iter_no_change=20)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    gbc.fit(X_train, y_train)\n    gbc2.fit(X_train, y_train)\n    assert gbc.n_estimators_ != gbc2.n_estimators_\n    gbr.fit(X_train, y_train)\n    gbr2.fit(X_train, y_train)\n    assert gbr.n_estimators_ != gbr2.n_estimators_\n    gbc3.fit(X_train, y_train)\n    gbr3.fit(X_train, y_train)\n    assert gbr.n_estimators_ < gbr3.n_estimators_\n    assert gbc.n_estimators_ < gbc3.n_estimators_\n\ntest_gradient_boosting_validation_fraction()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/ensemble/tests/test_gradient_boosting.py"}, {"test_code": "import re\nimport numpy as np\nimport pytest\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import clone\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble._weight_boosting import _samme_proba\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils import shuffle\nfrom sklearn.utils._mocking import NoSampleWeightWrapper\nfrom sklearn.utils._testing import assert_allclose\nfrom sklearn.utils._testing import assert_array_almost_equal\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_array_less\nimport pickle\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\ndef test_adaboostregressor_sample_weight():\n    rng = np.random.RandomState(42)\n    X = np.linspace(0, 100, num=1000)\n    y = 0.8 * X + 0.2 + rng.rand(X.shape[0]) * 0.0001\n    X = X.reshape(-1, 1)\n    X[-1] *= 10\n    y[-1] = 10000\n    regr_no_outlier = AdaBoostRegressor(estimator=LinearRegression(),\n        n_estimators=1, random_state=0)\n    regr_with_weight = clone(regr_no_outlier)\n    regr_with_outlier = clone(regr_no_outlier)\n    regr_with_outlier.fit(X, y)\n    regr_no_outlier.fit(X[:-1], y[:-1])\n    sample_weight = np.ones_like(y)\n    sample_weight[-1] = 0\n    regr_with_weight.fit(X, y, sample_weight=sample_weight)\n    score_with_outlier = regr_with_outlier.score(X[:-1], y[:-1])\n    score_no_outlier = regr_no_outlier.score(X[:-1], y[:-1])\n    score_with_weight = regr_with_weight.score(X[:-1], y[:-1])\n    assert score_with_outlier < score_no_outlier\n    assert score_with_outlier < score_with_weight\n    assert score_no_outlier == pytest.approx(score_with_weight)\n\ntest_adaboostregressor_sample_weight()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/ensemble/tests/test_weight_boosting.py"}, {"test_code": "import copyreg\nimport io\nimport pickle\nimport re\nimport warnings\nfrom unittest.mock import Mock\nimport joblib\nimport numpy as np\nimport pytest\nfrom joblib.numpy_pickle import NumpyPickler\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nimport sklearn\nfrom sklearn._loss.loss import AbsoluteError\nfrom sklearn._loss.loss import HalfBinomialLoss\nfrom sklearn._loss.loss import HalfSquaredError\nfrom sklearn._loss.loss import PinballLoss\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_regressor\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_low_rank_matrix\nfrom sklearn.datasets import make_regression\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.ensemble._hist_gradient_boosting.binning import _BinMapper\nfrom sklearn.ensemble._hist_gradient_boosting.common import G_H_DTYPE\nfrom sklearn.ensemble._hist_gradient_boosting.grower import TreeGrower\nfrom sklearn.ensemble._hist_gradient_boosting.predictor import TreePredictor\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.metrics import get_scorer\nfrom sklearn.metrics import mean_gamma_deviance\nfrom sklearn.metrics import mean_poisson_deviance\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils import shuffle\nfrom sklearn.utils._openmp_helpers import _openmp_effective_n_threads\nfrom sklearn.utils._testing import _convert_container\nimport pandas as pd\ndef test_missing_values_minmax_imputation():\n\n\n    class MinMaxImputer(TransformerMixin, BaseEstimator):\n\n        def fit(self, X, y=None):\n            mm = MinMaxScaler().fit(X)\n            self.data_min_ = mm.data_min_\n            self.data_max_ = mm.data_max_\n            return self\n\n        def transform(self, X):\n            X_min, X_max = X.copy(), X.copy()\n            for feature_idx in range(X.shape[1]):\n                nan_mask = np.isnan(X[:, feature_idx])\n                X_min[nan_mask, feature_idx] = self.data_min_[feature_idx] - 1\n                X_max[nan_mask, feature_idx] = self.data_max_[feature_idx] + 1\n            return np.concatenate([X_min, X_max], axis=1)\n\n    def make_missing_value_data(n_samples=int(10000.0), seed=0):\n        rng = np.random.RandomState(seed)\n        X, y = make_regression(n_samples=n_samples, n_features=4,\n            random_state=rng)\n        X = KBinsDiscretizer(n_bins=42, encode='ordinal').fit_transform(X)\n        rnd_mask = rng.rand(X.shape[0]) > 0.9\n        X[rnd_mask, 0] = np.nan\n        low_mask = X[:, 1] == 0\n        X[low_mask, 1] = np.nan\n        high_mask = X[:, 2] == X[:, 2].max()\n        X[high_mask, 2] = np.nan\n        y_max = np.percentile(y, 70)\n        y_max_mask = y >= y_max\n        y[y_max_mask] = y_max\n        X[y_max_mask, 3] = np.nan\n        for feature_idx in range(X.shape[1]):\n            assert any(np.isnan(X[:, feature_idx]))\n        return train_test_split(X, y, random_state=rng)\n    X_train, X_test, y_train, y_test = make_missing_value_data(n_samples=\n        int(10000.0), seed=0)\n    gbm1 = HistGradientBoostingRegressor(max_iter=100, max_leaf_nodes=5,\n        random_state=0)\n    gbm1.fit(X_train, y_train)\n    gbm2 = make_pipeline(MinMaxImputer(), clone(gbm1))\n    gbm2.fit(X_train, y_train)\n    assert gbm1.score(X_train, y_train) == pytest.approx(gbm2.score(X_train,\n        y_train))\n    assert gbm1.score(X_test, y_test) == pytest.approx(gbm2.score(X_test,\n        y_test))\n    assert_allclose(gbm1.predict(X_train), gbm2.predict(X_train))\n    assert_allclose(gbm1.predict(X_test), gbm2.predict(X_test))\n\ntest_missing_values_minmax_imputation()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py"}, {"test_code": "import copyreg\nimport io\nimport pickle\nimport re\nimport warnings\nfrom unittest.mock import Mock\nimport joblib\nimport numpy as np\nimport pytest\nfrom joblib.numpy_pickle import NumpyPickler\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nimport sklearn\nfrom sklearn._loss.loss import AbsoluteError\nfrom sklearn._loss.loss import HalfBinomialLoss\nfrom sklearn._loss.loss import HalfSquaredError\nfrom sklearn._loss.loss import PinballLoss\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_regressor\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_low_rank_matrix\nfrom sklearn.datasets import make_regression\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.ensemble._hist_gradient_boosting.binning import _BinMapper\nfrom sklearn.ensemble._hist_gradient_boosting.common import G_H_DTYPE\nfrom sklearn.ensemble._hist_gradient_boosting.grower import TreeGrower\nfrom sklearn.ensemble._hist_gradient_boosting.predictor import TreePredictor\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.metrics import get_scorer\nfrom sklearn.metrics import mean_gamma_deviance\nfrom sklearn.metrics import mean_poisson_deviance\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils import shuffle\nfrom sklearn.utils._openmp_helpers import _openmp_effective_n_threads\nfrom sklearn.utils._testing import _convert_container\nimport pandas as pd\ndef test_class_weights():\n    \"\"\"High level test to check class_weights.\"\"\"\n    n_samples = 255\n    n_features = 2\n    X, y = make_classification(n_samples=n_samples, n_features=n_features,\n        n_informative=n_features, n_redundant=0, n_clusters_per_class=1,\n        n_classes=2, random_state=0)\n    y_is_1 = y == 1\n    clf = HistGradientBoostingClassifier(min_samples_leaf=2, random_state=0,\n        max_depth=2)\n    sample_weight = np.ones(shape=n_samples)\n    sample_weight[y_is_1] = 3.0\n    clf.fit(X, y, sample_weight=sample_weight)\n    class_weight = {(0): 1.0, (1): 3.0}\n    clf_class_weighted = clone(clf).set_params(class_weight=class_weight)\n    clf_class_weighted.fit(X, y)\n    assert_allclose(clf.decision_function(X), clf_class_weighted.\n        decision_function(X))\n    clf.fit(X, y, sample_weight=sample_weight ** 2)\n    clf_class_weighted.fit(X, y, sample_weight=sample_weight)\n    assert_allclose(clf.decision_function(X), clf_class_weighted.\n        decision_function(X))\n    X_imb = np.concatenate((X[~y_is_1], X[y_is_1][:10]))\n    y_imb = np.concatenate((y[~y_is_1], y[y_is_1][:10]))\n    clf_balanced = clone(clf).set_params(class_weight='balanced')\n    clf_balanced.fit(X_imb, y_imb)\n    class_weight = y_imb.shape[0] / (2 * np.bincount(y_imb))\n    sample_weight = class_weight[y_imb]\n    clf_sample_weight = clone(clf).set_params(class_weight=None)\n    clf_sample_weight.fit(X_imb, y_imb, sample_weight=sample_weight)\n    assert_allclose(clf_balanced.decision_function(X_imb),\n        clf_sample_weight.decision_function(X_imb))\n\ntest_class_weights()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py"}, {"test_code": "import warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom sklearn import clone\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils._testing import assert_allclose\nfrom sklearn.utils._testing import assert_allclose_dense_sparse\nfrom sklearn.utils._testing import assert_array_almost_equal\nfrom sklearn.utils._testing import assert_array_equal\ndef test_kbinsdiscretizer_subsample_default():\n    X = np.array([-2, 1.5, -4, -1]).reshape(-1, 1)\n    kbd_default = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy=\n        'quantile')\n    kbd_default.fit(X)\n    kbd_without_subsampling = clone(kbd_default)\n    kbd_without_subsampling.set_params(subsample=None)\n    kbd_without_subsampling.fit(X)\n    for bin_kbd_default, bin_kbd_with_subsampling in zip(kbd_default.\n        bin_edges_[0], kbd_without_subsampling.bin_edges_[0]):\n        np.testing.assert_allclose(bin_kbd_default, bin_kbd_with_subsampling)\n    assert kbd_default.bin_edges_.shape == kbd_without_subsampling.bin_edges_.shape\n\ntest_kbinsdiscretizer_subsample_default()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/preprocessing/tests/test_discretization.py"}, {"test_code": "import numpy as np\nfrom sklearn.base import clone\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.cluster.tests.common import generate_clustered_data\nfrom sklearn.datasets import make_blobs\nfrom sklearn.manifold import TSNE\nfrom sklearn.manifold import Isomap\nfrom sklearn.manifold import SpectralEmbedding\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsTransformer\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.neighbors import RadiusNeighborsRegressor\nfrom sklearn.neighbors import RadiusNeighborsTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils._testing import assert_array_almost_equal\ndef test_kneighbors_regressor():\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(40, 5) - 1\n    X2 = 2 * rng.rand(40, 5) - 1\n    y = rng.rand(40, 1)\n    n_neighbors = 12\n    radius = 1.5\n    factor = 2\n    k_trans = KNeighborsTransformer(n_neighbors=n_neighbors, mode='distance')\n    k_trans_factor = KNeighborsTransformer(n_neighbors=int(n_neighbors *\n        factor), mode='distance')\n    r_trans = RadiusNeighborsTransformer(radius=radius, mode='distance')\n    r_trans_factor = RadiusNeighborsTransformer(radius=int(radius * factor),\n        mode='distance')\n    k_reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n    r_reg = RadiusNeighborsRegressor(radius=radius)\n    test_list = [(k_trans, k_reg), (k_trans_factor, r_reg), (r_trans, r_reg\n        ), (r_trans_factor, k_reg)]\n    for trans, reg in test_list:\n        reg_compact = clone(reg)\n        reg_precomp = clone(reg)\n        reg_precomp.set_params(metric='precomputed')\n        reg_chain = make_pipeline(clone(trans), reg_precomp)\n        y_pred_chain = reg_chain.fit(X, y).predict(X2)\n        y_pred_compact = reg_compact.fit(X, y).predict(X2)\n        assert_array_almost_equal(y_pred_chain, y_pred_compact)\n\ntest_kneighbors_regressor()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/neighbors/tests/test_neighbors_pipeline.py"}, {"test_code": "import re\nimport warnings\nfrom itertools import product\nimport joblib\nimport numpy as np\nimport pytest\nfrom scipy.sparse import issparse\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn import neighbors\nfrom sklearn.base import clone\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.exceptions import EfficiencyWarning\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.metrics._dist_metrics import DistanceMetric\nfrom sklearn.metrics.pairwise import PAIRWISE_BOOLEAN_FUNCTIONS\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.metrics.tests.test_dist_metrics import BOOL_METRICS\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import VALID_METRICS_SPARSE\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors._base import KNeighborsMixin\nfrom sklearn.neighbors._base import _check_precomputed\nfrom sklearn.neighbors._base import _is_sorted_by_data\nfrom sklearn.neighbors._base import sort_graph_by_row_values\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils._testing import assert_allclose\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.utils.fixes import parse_version\nfrom sklearn.utils.fixes import sp_version\nfrom sklearn.utils.validation import check_random_state\ndef test_pipeline_with_nearest_neighbors_transformer():\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(40, 5) - 1\n    X2 = 2 * rng.rand(40, 5) - 1\n    y = rng.rand(40, 1)\n    n_neighbors = 12\n    radius = 1.5\n    factor = 2\n    k_trans = neighbors.KNeighborsTransformer(n_neighbors=n_neighbors, mode\n        ='distance')\n    k_trans_factor = neighbors.KNeighborsTransformer(n_neighbors=int(\n        n_neighbors * factor), mode='distance')\n    r_trans = neighbors.RadiusNeighborsTransformer(radius=radius, mode=\n        'distance')\n    r_trans_factor = neighbors.RadiusNeighborsTransformer(radius=int(radius *\n        factor), mode='distance')\n    k_reg = neighbors.KNeighborsRegressor(n_neighbors=n_neighbors)\n    r_reg = neighbors.RadiusNeighborsRegressor(radius=radius)\n    test_list = [(k_trans, k_reg), (k_trans_factor, r_reg), (r_trans, r_reg\n        ), (r_trans_factor, k_reg)]\n    for trans, reg in test_list:\n        reg_compact = clone(reg)\n        reg_precomp = clone(reg)\n        reg_precomp.set_params(metric='precomputed')\n        reg_chain = make_pipeline(clone(trans), reg_precomp)\n        y_pred_chain = reg_chain.fit(X, y).predict(X2)\n        y_pred_compact = reg_compact.fit(X, y).predict(X2)\n        assert_allclose(y_pred_chain, y_pred_compact)\n\ntest_pipeline_with_nearest_neighbors_transformer()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/neighbors/tests/test_neighbors.py"}, {"test_code": "import pickle\nimport re\nimport warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom numpy.testing import assert_allclose\nimport sklearn\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import OutlierMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_classifier\nfrom sklearn.base import is_regressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.exceptions import InconsistentVersionWarning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils._mocking import MockDataFrame\nfrom sklearn.utils._set_output import _get_output_config\nfrom sklearn.utils._testing import _convert_container\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_no_warnings\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.feature_selection import SelectFpr\nfrom sklearn.feature_selection import f_classif\ndef test_clone():\n    from sklearn.feature_selection import SelectFpr, f_classif\n    selector = SelectFpr(f_classif, alpha=0.1)\n    new_selector = clone(selector)\n    assert selector is not new_selector\n    assert selector.get_params() == new_selector.get_params()\n    selector = SelectFpr(f_classif, alpha=np.zeros((10, 2)))\n    new_selector = clone(selector)\n    assert selector is not new_selector\n\ntest_clone()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/tests/test_base.py"}, {"test_code": "import pickle\nimport re\nimport warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom numpy.testing import assert_allclose\nimport sklearn\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import OutlierMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_classifier\nfrom sklearn.base import is_regressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.exceptions import InconsistentVersionWarning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils._mocking import MockDataFrame\nfrom sklearn.utils._set_output import _get_output_config\nfrom sklearn.utils._testing import _convert_container\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_no_warnings\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.feature_selection import SelectFpr\nfrom sklearn.feature_selection import f_classif\ndef test_clone_2():\n    from sklearn.feature_selection import SelectFpr, f_classif\n    selector = SelectFpr(f_classif, alpha=0.1)\n    selector.own_attribute = 'test'\n    new_selector = clone(selector)\n    assert not hasattr(new_selector, 'own_attribute')\n\ntest_clone_2()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/tests/test_base.py"}, {"test_code": "import pickle\nimport re\nimport warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom numpy.testing import assert_allclose\nimport sklearn\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import OutlierMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_classifier\nfrom sklearn.base import is_regressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.exceptions import InconsistentVersionWarning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils._mocking import MockDataFrame\nfrom sklearn.utils._set_output import _get_output_config\nfrom sklearn.utils._testing import _convert_container\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_no_warnings\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.feature_selection import SelectFpr\nfrom sklearn.feature_selection import f_classif\ndef test_clone_pandas_dataframe():\n\n\n    class DummyEstimator(TransformerMixin, BaseEstimator):\n        \"\"\"This is a dummy class for generating numerical features\n\n        This feature extractor extracts numerical features from pandas data\n        frame.\n\n        Parameters\n        ----------\n\n        df: pandas data frame\n            The pandas data frame parameter.\n\n        Notes\n        -----\n        \"\"\"\n\n        def __init__(self, df=None, scalar_param=1):\n            self.df = df\n            self.scalar_param = scalar_param\n\n        def fit(self, X, y=None):\n            pass\n\n        def transform(self, X):\n            pass\n    d = np.arange(10)\n    df = MockDataFrame(d)\n    e = DummyEstimator(df, scalar_param=1)\n    cloned_e = clone(e)\n    assert (e.df == cloned_e.df).values.all()\n    assert e.scalar_param == cloned_e.scalar_param\n\ntest_clone_pandas_dataframe()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/tests/test_base.py"}, {"test_code": "import pickle\nimport re\nimport warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom numpy.testing import assert_allclose\nimport sklearn\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import OutlierMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_classifier\nfrom sklearn.base import is_regressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.exceptions import InconsistentVersionWarning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils._mocking import MockDataFrame\nfrom sklearn.utils._set_output import _get_output_config\nfrom sklearn.utils._testing import _convert_container\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_no_warnings\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.feature_selection import SelectFpr\nfrom sklearn.feature_selection import f_classif\ndef test_clone_protocol():\n    \"\"\"Checks that clone works with `__sklearn_clone__` protocol.\"\"\"\n\n\n    class FrozenEstimator(BaseEstimator):\n\n        def __init__(self, fitted_estimator):\n            self.fitted_estimator = fitted_estimator\n\n        def __getattr__(self, name):\n            return getattr(self.fitted_estimator, name)\n\n        def __sklearn_clone__(self):\n            return self\n\n        def fit(self, *args, **kwargs):\n            return self\n\n        def fit_transform(self, *args, **kwargs):\n            return self.fitted_estimator.transform(*args, **kwargs)\n    X = np.array([[-1, -1], [-2, -1], [-3, -2]])\n    pca = PCA().fit(X)\n    components = pca.components_\n    frozen_pca = FrozenEstimator(pca)\n    assert_allclose(frozen_pca.components_, components)\n    assert_array_equal(frozen_pca.get_feature_names_out(), pca.\n        get_feature_names_out())\n    X_new = np.asarray([[-1, 2], [3, 4], [1, 2]])\n    frozen_pca.fit(X_new)\n    assert_allclose(frozen_pca.components_, components)\n    frozen_pca.fit_transform(X_new)\n    assert_allclose(frozen_pca.components_, components)\n    clone_frozen_pca = clone(frozen_pca)\n    assert clone_frozen_pca is frozen_pca\n    assert_allclose(clone_frozen_pca.components_, components)\n\ntest_clone_protocol()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/tests/test_base.py"}, {"test_code": "import pickle\nimport re\nimport warnings\nimport numpy as np\nimport pytest\nimport scipy.sparse as sp\nfrom numpy.testing import assert_allclose\nimport sklearn\nfrom sklearn import config_context\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import OutlierMixin\nfrom sklearn.base import TransformerMixin\nfrom sklearn.base import clone\nfrom sklearn.base import is_classifier\nfrom sklearn.base import is_regressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.exceptions import InconsistentVersionWarning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.utils._mocking import MockDataFrame\nfrom sklearn.utils._set_output import _get_output_config\nfrom sklearn.utils._testing import _convert_container\nfrom sklearn.utils._testing import assert_array_equal\nfrom sklearn.utils._testing import assert_no_warnings\nfrom sklearn.utils._testing import ignore_warnings\nfrom sklearn.feature_selection import SelectFpr\nfrom sklearn.feature_selection import f_classif\ndef test_clone_keeps_output_config():\n    \"\"\"Check that clone keeps the set_output config.\"\"\"\n    ss = StandardScaler().set_output(transform='pandas')\n    config = _get_output_config('transform', ss)\n    ss_clone = clone(ss)\n    config_clone = _get_output_config('transform', ss_clone)\n    assert config == config_clone\n\ntest_clone_keeps_output_config()\n", "code_start": "", "test_path": "/home/zhuqiming2022/workspace/srcdata/Computation/scikit-learn/sklearn/tests/test_base.py"}], "method_code_mask": "import copy\nimport functools\nimport inspect\nimport platform\nimport re\nimport warnings\nfrom collections import defaultdict\nimport numpy as np\n\n\ndef clone(estimator, *, safe=True): [MASK]\n"}
