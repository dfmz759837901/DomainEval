{"method_name": "load_pandas", "full_method_name": "load_pandas", "method_path": "../srcdata/Computation/statsmodels/statsmodels/datasets/longley/data.py", "method_code": "from statsmodels.datasets import utils as du\ndef load_pandas():\n    \"\"\"\n    Load the Longley data and return a Dataset class.\n\n    Returns\n    -------\n    Dataset\n        See DATASET_PROPOSAL.txt for more information.\n    \"\"\"\n    data = _get_data()\n    return du.process_pandas(data, endog_idx=0)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom io import StringIO\nimport warnings\nimport numpy as np\nimport numpy.testing as npt\nimport pandas as pd\nimport patsy\nimport pytest\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.datasets.longley import load_pandas\nfrom statsmodels.formula.api import ols\nfrom statsmodels.formula.formulatools import make_hypotheses_matrices\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tools.testing import assert_equal\nfrom pandas import read_csv\nfrom numpy import log\ndef test_tests():\n    formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n    dta = load_pandas().data\n    results = ols(formula, dta).fit()\n    test_formula = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n    LC = make_hypotheses_matrices(results, test_formula)\n    R = LC.coefs\n    Q = LC.constants\n    npt.assert_almost_equal(R, [[0, 1, -1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, \n        0], [0, 0, 0, 0, 0, 0, 1.0 / 1829]], 8)\n    npt.assert_array_equal(Q, [[0], [2], [1]])\n\ntest_tests()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/formula/tests/test_formula.py"}, {"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom io import StringIO\nimport warnings\nimport numpy as np\nimport numpy.testing as npt\nimport pandas as pd\nimport patsy\nimport pytest\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.datasets.longley import load_pandas\nfrom statsmodels.formula.api import ols\nfrom statsmodels.formula.formulatools import make_hypotheses_matrices\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tools.testing import assert_equal\nfrom pandas import read_csv\nfrom numpy import log\ndef test_formula_predict():\n    from numpy import log\n    formula = \"\"\"TOTEMP ~ log(GNPDEFL) + log(GNP) + UNEMP + ARMED +\n                    POP + YEAR\"\"\"\n    data = load_pandas()\n    dta = load_pandas().data\n    results = ols(formula, dta).fit()\n    npt.assert_almost_equal(results.fittedvalues.values, results.predict(\n        data.exog), 8)\n\ntest_formula_predict()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/formula/tests/test_formula.py"}], "instruction": "Functionality: The load_pandas function is responsible for loading the Longley dataset and returning it as a Dataset class, specifically formatted for pandas integration. This function is designed to facilitate data analysis and modeling for the Longley dataset, which is widely used in statistical learning.\n\nInputs: The function does not take any input arguments. It internally calls the _get_data() function to fetch the dataset.\n\nOutputs: The function returns a Dataset object. This object contains the dataset in a format that is compatible with pandas, which is a popular data manipulation library in Python. The endog_idx parameter in the process_pandas method indicates that the first column of the data is considered the endogenous (dependent) variable.", "method_code_mask": "from statsmodels.datasets import utils as du\n\n\ndef load_pandas(): [MASK]\n"}
{"method_name": "burg", "full_method_name": "burg", "method_path": "../srcdata/Computation/statsmodels/statsmodels/regression/linear_model.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nfrom typing import Literal\nfrom collections.abc import Sequence\nimport warnings\nimport numpy as np\nfrom scipy import optimize\nfrom scipy import stats\nfrom scipy.linalg import cholesky\nfrom scipy.linalg import toeplitz\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.base.model as base\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.emplike.elregress import _ELRegOpts\nfrom statsmodels.regression._prediction import PredictionResults\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.decorators import cache_writable\nfrom statsmodels.tools.sm_exceptions import InvalidTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import pinv_extended\nfrom statsmodels.tools.typing import Float64Array\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import string_like\nfrom scipy.stats.distributions import norm\nfrom statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.base.elastic_net import RegularizedResultsWrapper\nfrom statsmodels.base.elastic_net import fit_elasticnet\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import hqic\nfrom numpy.linalg import inv\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.base.covtype import descriptions\nfrom statsmodels.base.covtype import normalize_cov_type\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib import summary2\nfrom statsmodels.stats.outliers_influence import OLSInfluence\nfrom statsmodels.stats.outliers_influence import outlier_test\ndef burg(endog, order=1, demean=True):\n    \"\"\"\n    Compute Burg's AP(p) parameter estimator.\n\n    Parameters\n    ----------\n    endog : array_like\n        The endogenous variable.\n    order : int, optional\n        Order of the AR.  Default is 1.\n    demean : bool, optional\n        Flag indicating to subtract the mean from endog before estimation.\n\n    Returns\n    -------\n    rho : ndarray\n        The AR(p) coefficients computed using Burg's algorithm.\n    sigma2 : float\n        The estimate of the residual variance.\n\n    See Also\n    --------\n    yule_walker : Estimate AR parameters using the Yule-Walker method.\n\n    Notes\n    -----\n    AR model estimated includes a constant that is estimated using the sample\n    mean (see [1]_). This value is not reported.\n\n    References\n    ----------\n    .. [1] Brockwell, P.J. and Davis, R.A., 2016. Introduction to time series\n        and forecasting. Springer.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> from statsmodels.datasets.sunspots import load\n    >>> data = load()\n    >>> rho, sigma2 = sm.regression.linear_model.burg(data.endog, order=4)\n\n    >>> rho\n    array([ 1.30934186, -0.48086633, -0.20185982,  0.05501941])\n    >>> sigma2\n    271.2467306963966\n    \"\"\"\n    from statsmodels.tsa.stattools import levinson_durbin_pacf, pacf_burg\n    endog = np.squeeze(np.asarray(endog))\n    if endog.ndim != 1:\n        raise ValueError('endog must be 1-d or squeezable to 1-d.')\n    order = int(order)\n    if order < 1:\n        raise ValueError('order must be an integer larger than 1')\n    if demean:\n        endog = endog - endog.mean()\n    pacf, sigma = pacf_burg(endog, order, demean=demean)\n    ar, _ = levinson_durbin_pacf(pacf)\n    return ar, sigma[-1]", "test_code_list": [{"test_code": "from statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom scipy.linalg import toeplitz\nfrom scipy.stats import t as student_t\nfrom statsmodels.datasets import longley\nfrom statsmodels.regression.linear_model import GLS\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.regression.linear_model import burg\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.datasets.ccard import load\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.datasets.sunspots import load\nimport re\nimport os\nfrom patsy import PatsyError\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom scipy.stats.distributions import norm\nimport copy\ndef test_burg():\n    rnd = np.random.RandomState(12345)\n    e = rnd.randn(10001)\n    y = e[1:] + 0.5 * e[:-1]\n    expected = [[0.3909931], [0.4602607, -0.1771582], [0.47473245, -\n        0.21475602, 0.08168813], [0.4787017, -0.225191, 0.1047554, -0.04859\n        ], [0.47975462, -0.22746106, 0.10963527, -0.05896347, 0.02167001]]\n    for i in range(1, 6):\n        ar, _ = burg(y, i)\n        assert_allclose(ar, expected[i - 1], atol=1e-06)\n        as_nodemean, _ = burg(1 + y, i, False)\n        assert np.all(ar != as_nodemean)\n\ntest_burg()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_regression.py"}], "instruction": "Functionality: The burg function computes Burg's AP(p) parameter estimator for an autoregressive model of a given order. It estimates the coefficients of an autoregressive model using Burg's algorithm and provides an estimate of the residual variance.\n\nInputs: \n- endog: array_like\n    The endogenous variable, which is a 1-dimensional array representing the time series data.\n- order: int, optional (default=1)\n    The order of the autoregressive model to be estimated.\n- demean: bool, optional (default=True)\n    A flag indicating whether to subtract the mean from the endogenous variable before estimation.\n\nOutputs:\n- rho: ndarray\n    The AR(p) coefficients computed using Burg's algorithm, where p is the order of the model.\n- sigma2: float\n    The estimate of the residual variance after fitting the autoregressive model.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nfrom typing import Literal\nfrom collections.abc import Sequence\nimport warnings\nimport numpy as np\nfrom scipy import optimize\nfrom scipy import stats\nfrom scipy.linalg import cholesky\nfrom scipy.linalg import toeplitz\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.base.model as base\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.emplike.elregress import _ELRegOpts\nfrom statsmodels.regression._prediction import PredictionResults\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.decorators import cache_writable\nfrom statsmodels.tools.sm_exceptions import InvalidTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import pinv_extended\nfrom statsmodels.tools.typing import Float64Array\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import string_like\nfrom scipy.stats.distributions import norm\nfrom statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.base.elastic_net import RegularizedResultsWrapper\nfrom statsmodels.base.elastic_net import fit_elasticnet\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import hqic\nfrom numpy.linalg import inv\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.base.covtype import descriptions\nfrom statsmodels.base.covtype import normalize_cov_type\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib import summary2\nfrom statsmodels.stats.outliers_influence import OLSInfluence\nfrom statsmodels.stats.outliers_influence import outlier_test\n\n\ndef burg(endog, order=1, demean=True): [MASK]\n"}
{"method_name": "approx_fprime", "full_method_name": "approx_fprime", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/numdiff.py", "method_code": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\ndef approx_fprime(x, f, epsilon=None, args=(), kwargs={}, centered=False):\n    \"\"\"\n    Gradient of function, or Jacobian if function f returns 1d array\n\n    Parameters\n    ----------\n    x : ndarray\n        parameters at which the derivative is evaluated\n    f : function\n        `f(*((x,)+args), **kwargs)` returning either one value or 1d array\n    epsilon : float, optional\n        Stepsize, if None, optimal stepsize is used. This is EPS**(1/2)*x for\n        `centered` == False and EPS**(1/3)*x for `centered` == True.\n    args : tuple\n        Tuple of additional arguments for function `f`.\n    kwargs : dict\n        Dictionary of additional keyword arguments for function `f`.\n    centered : bool\n        Whether central difference should be returned. If not, does forward\n        differencing.\n\n    Returns\n    -------\n    grad : ndarray\n        gradient or Jacobian\n\n    Notes\n    -----\n    If f returns a 1d array, it returns a Jacobian. If a 2d array is returned\n    by f (e.g., with a value for each observation), it returns a 3d array\n    with the Jacobian of each observation with shape xk x nobs x xk. I.e.,\n    the Jacobian of the first observation would be [:, 0, :]\n    \"\"\"\n    n = len(x)\n    f0 = f(*((x,) + args), **kwargs)\n    dim = np.atleast_1d(f0).shape\n    grad = np.zeros((n,) + dim, np.promote_types(float, x.dtype))\n    ei = np.zeros((n,), float)\n    if not centered:\n        epsilon = _get_epsilon(x, 2, epsilon, n)\n        for k in range(n):\n            ei[k] = epsilon[k]\n            grad[k, :] = (f(*((x + ei,) + args), **kwargs) - f0) / epsilon[k]\n            ei[k] = 0.0\n    else:\n        epsilon = _get_epsilon(x, 3, epsilon, n) / 2.0\n        for k in range(n):\n            ei[k] = epsilon[k]\n            grad[k, :] = (f(*((x + ei,) + args), **kwargs) - f(*((x - ei,) +\n                args), **kwargs)) / (2 * epsilon[k])\n            ei[k] = 0.0\n    if n == 1:\n        return grad.T\n    else:\n        return grad.squeeze().T", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.dimred import SlicedInverseReg\nfrom statsmodels.regression.dimred import SAVE\nfrom statsmodels.regression.dimred import PHD\nfrom statsmodels.regression.dimred import CORE\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tools.numdiff import approx_fprime\ndef test_sir_regularized_numdiff():\n    np.random.seed(93482)\n    n = 1000\n    p = 10\n    xmat = np.random.normal(size=(n, p))\n    y1 = np.dot(xmat, np.linspace(-1, 1, p))\n    y2 = xmat.sum(1)\n    y = y2 / (1 + y1 ** 2) + np.random.normal(size=n)\n    model = SlicedInverseReg(y, xmat)\n    _ = model.fit()\n    fmat = np.zeros((p - 2, p))\n    for i in range(p - 2):\n        fmat[i, i:i + 3] = [1, -2, 1]\n    with pytest.warns(UserWarning, match='SIR.fit_regularized did not'):\n        _ = model.fit_regularized(2, 3 * fmat)\n    for _ in range(5):\n        pa = np.random.normal(size=(p, 2))\n        pa, _, _ = np.linalg.svd(pa, 0)\n        gn = approx_fprime(pa.ravel(), model._regularized_objective, 1e-07)\n        gr = model._regularized_grad(pa.ravel())\n        assert_allclose(gn, gr, atol=1e-05, rtol=0.0001)\n\ntest_sir_regularized_numdiff()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_dimred.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.dimred import SlicedInverseReg\nfrom statsmodels.regression.dimred import SAVE\nfrom statsmodels.regression.dimred import PHD\nfrom statsmodels.regression.dimred import CORE\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tools.numdiff import approx_fprime\ndef test_covreduce():\n    np.random.seed(34324)\n    p = 4\n    endog = []\n    exog = []\n    for k in range(3):\n        c = np.eye(p)\n        x = np.random.normal(size=(2, 2))\n        c[0:2, 0:2] = np.dot(x.T, x)\n        cr = np.linalg.cholesky(c)\n        m = 1000 * k + 50 * k\n        x = np.random.normal(size=(m, p))\n        x = np.dot(x, cr.T)\n        exog.append(x)\n        endog.append(k * np.ones(m))\n    endog = np.concatenate(endog)\n    exog = np.concatenate(exog, axis=0)\n    for dim in (1, 2, 3):\n        cr = CORE(endog, exog, dim)\n        pt = np.random.normal(size=(p, dim))\n        pt, _, _ = np.linalg.svd(pt, 0)\n        gn = approx_fprime(pt.ravel(), cr.loglike, 1e-07)\n        g = cr.score(pt.ravel())\n        assert_allclose(g, gn, 1e-05, 1e-05)\n        rslt = cr.fit()\n        proj = rslt.params\n        assert_equal(proj.shape[0], p)\n        assert_equal(proj.shape[1], dim)\n        assert_allclose(np.dot(proj.T, proj), np.eye(dim), 1e-08, 1e-08)\n        if dim == 2:\n            projt = np.zeros((p, 2))\n            projt[0:2, 0:2] = np.eye(2)\n            assert_allclose(np.trace(np.dot(proj.T, projt)), 2, rtol=0.001,\n                atol=0.001)\n\ntest_covreduce()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_dimred.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport statsmodels.api as sm\nfrom statsmodels.tools import numdiff\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.numdiff import _approx_fprime_scalar\nfrom statsmodels.tools.numdiff import _approx_fprime_cs_scalar\ndef test_dtypes():\n\n    def f(x):\n        return 2 * x\n    desired = np.array([[2, 0], [0, 2]])\n    assert_allclose(approx_fprime(np.array([1, 2]), f), desired)\n    assert_allclose(approx_fprime(np.array([1.0, 2.0]), f), desired)\n    assert_allclose(approx_fprime(np.array([1.0 + 0.0j, 2.0 + 0.0j]), f),\n        desired)\n\ntest_dtypes()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_numdiff.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_logit_1d():\n    y = np.r_[0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n    g = np.r_[0, 0, 0, 1, 1, 1, 2, 2, 2, 2]\n    x = np.r_[0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n    x = x[:, None]\n    model = ConditionalLogit(y, x, groups=g)\n    for x in (-1, 0, 1, 2):\n        params = np.r_[x,]\n        _, grad = model._denom_grad(0, params)\n        ngrad = approx_fprime(params, lambda x: model._denom(0, x)).squeeze()\n        assert_allclose(grad, ngrad)\n    for x in (-1, 0, 1, 2):\n        grad = approx_fprime(np.r_[x,], model.loglike).squeeze()\n        score = model.score(np.r_[x,])\n        assert_allclose(grad, score, rtol=0.0001)\n    result = model.fit()\n    assert_allclose(result.params, np.r_[0.9272407], rtol=1e-05)\n    assert_allclose(result.bse, np.r_[1.295155], rtol=1e-05)\n\ntest_logit_1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_logit_2d():\n    y = np.r_[0, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n    g = np.r_[0, 0, 0, 1, 1, 1, 2, 2, 2, 2]\n    x1 = np.r_[0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n    x2 = np.r_[0, 0, 1, 0, 0, 1, 0, 1, 1, 1]\n    x = np.empty((10, 2))\n    x[:, 0] = x1\n    x[:, 1] = x2\n    model = ConditionalLogit(y, x, groups=g)\n    for x in (-1, 0, 1, 2):\n        params = np.r_[x, -1.5 * x]\n        _, grad = model._denom_grad(0, params)\n        ngrad = approx_fprime(params, lambda x: model._denom(0, x))\n        assert_allclose(grad, ngrad, rtol=1e-05)\n    for x in (-1, 0, 1, 2):\n        params = np.r_[-0.5 * x, 0.5 * x]\n        grad = approx_fprime(params, model.loglike)\n        score = model.score(params)\n        assert_allclose(grad, score, rtol=0.0001)\n    result = model.fit()\n    assert_allclose(result.params, np.r_[1.011074, 1.236758], rtol=0.001)\n    assert_allclose(result.bse, np.r_[1.420784, 1.361738], rtol=1e-05)\n    result.summary()\n\ntest_logit_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_poisson_1d():\n    y = np.r_[3, 1, 1, 4, 5, 2, 0, 1, 6, 2]\n    g = np.r_[0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n    x = np.r_[0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n    x = x[:, None]\n    model = ConditionalPoisson(y, x, groups=g)\n    for x in (-1, 0, 1, 2):\n        grad = approx_fprime(np.r_[x,], model.loglike).squeeze()\n        score = model.score(np.r_[x,])\n        assert_allclose(grad, score, rtol=0.0001)\n    result = model.fit()\n    assert_allclose(result.params, np.r_[0.6466272], rtol=0.0001)\n    assert_allclose(result.bse, np.r_[0.4170918], rtol=1e-05)\n\ntest_poisson_1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_poisson_2d():\n    y = np.r_[3, 1, 4, 8, 2, 5, 4, 7, 2, 6]\n    g = np.r_[0, 0, 0, 1, 1, 1, 2, 2, 2, 2]\n    x1 = np.r_[0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n    x2 = np.r_[2, 1, 0, 0, 1, 2, 3, 2, 0, 1]\n    x = np.empty((10, 2))\n    x[:, 0] = x1\n    x[:, 1] = x2\n    model = ConditionalPoisson(y, x, groups=g)\n    for x in (-1, 0, 1, 2):\n        params = np.r_[-0.5 * x, 0.5 * x]\n        grad = approx_fprime(params, model.loglike)\n        score = model.score(params)\n        assert_allclose(grad, score, rtol=0.0001)\n    result = model.fit()\n    assert_allclose(result.params, np.r_[-0.9478957, -0.0134279], rtol=0.001)\n    assert_allclose(result.bse, np.r_[0.3874942, 0.1686712], rtol=1e-05)\n    result.summary()\n\ntest_poisson_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}], "instruction": "Functionality: The approx_fprime function estimates the gradient of a given function at a specified point using either forward or central differencing. It supports functions that return a single value or a 1D array, and it can handle additional positional and keyword arguments passed to the function.\n\nInputs:\n- x: An ndarray representing the parameters at which the derivative is evaluated.\n- f: A function that takes x as its first argument, potentially followed by additional arguments from args and kwargs, and returns either a single value or a 1D array.\n- epsilon: Optional float representing the step size for the derivative estimation. If None, an optimal step size is used, which is EPS**(1/2)*x for forward differencing and EPS**(1/3)*x for central differencing.\n- args: A tuple of additional positional arguments that are passed to function f.\n- kwargs: A dictionary of additional keyword arguments that are passed to function f.\n- centered: A boolean indicating whether to use central differencing (True) or forward differencing (False).\n\nOutputs:\n- grad: An ndarray representing the gradient of the function f at the point x. If f returns a 1D array, the output is a Jacobian. If f returns a 2D array, the output is a 3D array where each 2D slice represents the Jacobian for each observation.", "method_code_mask": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\n\n\ndef approx_fprime(x, f, epsilon=None, args=(), kwargs={}, centered=False): [M\n    ASK]\n"}
{"method_name": "summary_col", "full_method_name": "summary_col", "method_path": "../srcdata/Computation/statsmodels/statsmodels/iolib/summary2.py", "method_code": "from statsmodels.compat.python import lzip\nimport datetime\nfrom functools import reduce\nimport re\nimport textwrap\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\ndef summary_col(results, float_format='%.4f', model_names=(), stars=False,\n    info_dict=None, regressor_order=(), drop_omitted=False, include_r2=True,\n    fixed_effects=None, fe_present='Yes', fe_absent=''):\n    \"\"\"\n    Summarize multiple results instances side-by-side (coefs and SEs)\n\n    Parameters\n    ----------\n    results : statsmodels results instance or list of result instances\n    float_format : str, optional\n        float format for coefficients and standard errors\n        Default : '%.4f'\n    model_names : list[str], optional\n        Must have same length as the number of results. If the names are not\n        unique, a roman number will be appended to all model names\n    stars : bool\n        print significance stars\n    info_dict : dict, default None\n        dict of functions to be applied to results instances to retrieve\n        model info. To use specific information for different models, add a\n        (nested) info_dict with model name as the key.\n        Example: `info_dict = {\"N\":lambda x:(x.nobs), \"R2\": ..., \"OLS\":{\n        \"R2\":...}}` would only show `R2` for OLS regression models, but\n        additionally `N` for all other results.\n        Default : None (use the info_dict specified in\n        result.default_model_infos, if this property exists)\n    regressor_order : list[str], optional\n        list of names of the regressors in the desired order. All regressors\n        not specified will be appended to the end of the list.\n    drop_omitted : bool, optional\n        Includes regressors that are not specified in regressor_order. If\n        False, regressors not specified will be appended to end of the list.\n        If True, only regressors in regressor_order will be included.\n    include_r2 : bool, optional\n        Includes R2 and adjusted R2 in the summary table.\n    fixed_effects : list[str], optional\n        List of categorical variables for which to indicate presence of\n        fixed effects.\n    fe_present : str, optional\n        String to indicate the presence of fixed effects. Default is \"Yes\".\n    fe_absent : str, optional\n        String to indicate the absence of fixed effects. Default is empty\n        string.\n    \"\"\"\n    if not isinstance(results, list):\n        results = [results]\n    cols = [_col_params(x, stars=stars, float_format=float_format,\n        include_r2=include_r2) for x in results]\n    if model_names:\n        colnames = _make_unique(model_names)\n    else:\n        colnames = _make_unique([x.columns[0] for x in cols])\n    for i in range(len(cols)):\n        cols[i].columns = [colnames[i]]\n\n    def merg(x, y):\n        return x.merge(y, how='outer', right_index=True, left_index=True)\n    index = list(cols[0].index)\n    for col in cols[1:]:\n        for key in col.index:\n            if key not in index:\n                index.append(key)\n    for special in (('R-squared', ''), ('R-squared Adj.', '')):\n        if special in index:\n            index.remove(special)\n            index.insert(len(index), special)\n    summ = reduce(merg, cols)\n    summ = summ.reindex(index)\n    if regressor_order:\n        varnames = summ.index.get_level_values(0).tolist()\n        vc = pd.Series(varnames).value_counts()\n        varnames = vc.loc[vc == 2].index.tolist()\n        ordered = [x for x in regressor_order if x in varnames]\n        unordered = [x for x in varnames if x not in regressor_order]\n        new_order = ordered + unordered\n        other = [x for x in summ.index.get_level_values(0) if x not in\n            new_order]\n        new_order += other\n        if drop_omitted:\n            for uo in unordered:\n                new_order.remove(uo)\n        summ = summ.reindex(new_order, level=0)\n    idx = []\n    index = summ.index.get_level_values(0)\n    for i in range(0, index.shape[0], 2):\n        idx.append(index[i])\n        if i + 1 < index.shape[0] and index[i] == index[i + 1]:\n            idx.append('')\n        else:\n            idx.append(index[i + 1])\n    summ.index = idx\n    if fixed_effects:\n        if not info_dict:\n            info_dict = {}\n        for fe in fixed_effects:\n            info_dict[fe + ' FE'] = (lambda x, fe=fe, fe_present=fe_present,\n                fe_absent=fe_absent: fe_present if any(f'C({fe})' in param for\n                param in x.params.index) else fe_absent)\n    if info_dict:\n        cols = [_col_info(x, info_dict.get(x.model.__class__.__name__,\n            info_dict)) for x in results]\n    else:\n        cols = [_col_info(x, getattr(x, 'default_model_infos', None)) for x in\n            results]\n    for df, name in zip(cols, _make_unique([df.columns[0] for df in cols])):\n        df.columns = [name]\n    info = reduce(merg, cols)\n    dat = pd.DataFrame(np.vstack([summ, info]))\n    dat.columns = summ.columns\n    dat.index = pd.Index(summ.index.tolist() + info.index.tolist())\n    summ = dat\n    summ = summ.fillna('')\n    if fixed_effects:\n        index_series = pd.Series(summ.index, index=summ.index)\n        skip_flag = index_series.apply(lambda x: any(f'C({fe})' in x for fe in\n            fixed_effects))\n        skip_next_flag = skip_flag.shift(fill_value=False)\n        final_skip = skip_flag | skip_next_flag\n        summ = summ[~final_skip]\n        r_squared_rows = summ.index[summ.index.str.contains('R-squared')]\n        r_squared_section = summ.loc[r_squared_rows]\n        summ = summ.drop(index=r_squared_rows)\n        summ = pd.concat([summ, r_squared_section])\n    smry = Summary()\n    smry._merge_latex = True\n    smry.add_df(summ, header=True, align='l')\n    smry.add_text('Standard errors in parentheses.')\n    if stars:\n        smry.add_text('* p<.1, ** p<.05, ***p<.01')\n    return smry", "test_code_list": [{"test_code": "from statsmodels.compat.platform import PLATFORM_OSX\nimport os\nimport csv\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nimport pytest\nfrom statsmodels.regression.mixed_linear_model import MixedLM\nfrom statsmodels.regression.mixed_linear_model import MixedLMParams\nfrom statsmodels.regression.mixed_linear_model import _smw_solver\nfrom statsmodels.regression.mixed_linear_model import _smw_logdet\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_\nfrom statsmodels.base import _penalties as penalties\nimport statsmodels.tools.numdiff as nd\nfrom statsmodels.formula.api import mixedlm\nfrom statsmodels.iolib.summary2 import summary_col\nimport statsmodels\ndef test_summary_col():\n    from statsmodels.iolib.summary2 import summary_col\n    ids = [1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]\n    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n    y = np.array([1.727, -1.037, 2.904, 3.569, 4.629, 5.736, 6.747, 7.02, \n        5.624, 10.155, 10.4, 17.164, 17.276, 14.988, 14.453])\n    d = {'Y': y, 'X': x, 'IDS': ids}\n    d = pd.DataFrame(d)\n    sp1 = np.array([-1.26722599, 1.1617587, 0.19547518])\n    mod1 = MixedLM.from_formula('Y ~ X', d, groups=d['IDS'])\n    results1 = mod1.fit(start_params=sp1)\n    sp2 = np.array([3.48416861, 0.55287862, 1.38537901])\n    mod2 = MixedLM.from_formula('X ~ Y', d, groups=d['IDS'])\n    results2 = mod2.fit(start_params=sp2)\n    out = summary_col([results1, results2], stars=True, regressor_order=[\n        'Group Var', 'Intercept', 'X', 'Y'])\n    s = \"\"\"\n=============================\n              Y         X    \n-----------------------------\nGroup Var 0.1955    1.3854   \n          (0.6032)  (2.7377) \nIntercept -1.2672   3.4842*  \n          (1.6546)  (1.8882) \nX         1.1618***          \n          (0.1959)           \nY                   0.5529***\n                    (0.2080) \n=============================\nStandard errors in\nparentheses.\n* p<.1, ** p<.05, ***p<.01\"\"\"\n    assert_equal(str(out), s)\n\ntest_summary_col()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_lme.py"}, {"test_code": "import warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_equal\nfrom statsmodels.iolib.summary2 import summary_col\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.fair import load_pandas\n\nclass TestSummaryLatex():\n\tdef test_summarycol_drop_omitted(self):\n\t    x = [1, 5, 7, 3, 5]\n\t    x = add_constant(x)\n\t    x2 = np.concatenate([x, np.array([[3], [9], [-1], [4], [0]])], 1)\n\t    y1 = [6, 4, 2, 7, 4]\n\t    y2 = [8, 5, 0, 12, 4]\n\t    reg1 = OLS(y1, x).fit()\n\t    reg2 = OLS(y2, x2).fit()\n\t    actual = summary_col([reg1, reg2], regressor_order=['const', 'x1'],\n\t        drop_omitted=True)\n\t    assert 'x2' not in str(actual)\n\t    actual = summary_col([reg1, reg2], regressor_order=['x1'], drop_omitted\n\t        =False)\n\t    assert 'const' in str(actual)\n\t    assert 'x2' in str(actual)\n\t\nTestSummaryLatex().test_summarycol_drop_omitted()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/iolib/tests/test_summary2.py"}, {"test_code": "import warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_equal\nfrom statsmodels.iolib.summary2 import summary_col\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.fair import load_pandas\n\nclass TestSummaryLatex():\n\tdef test_summary_col_ordering_preserved(self):\n\t    x = [1, 5, 7, 3, 5]\n\t    x = add_constant(x)\n\t    x2 = np.concatenate([x, np.array([[3], [9], [-1], [4], [0]])], 1)\n\t    x2 = pd.DataFrame(x2, columns=['const', 'b', 'a'])\n\t    y1 = [6, 4, 2, 7, 4]\n\t    y2 = [8, 5, 0, 12, 4]\n\t    reg1 = OLS(y1, x2).fit()\n\t    reg2 = OLS(y2, x2).fit()\n\t    info_dict = {'R2': lambda x: f'{int(x.rsquared):.3f}', 'N': lambda x:\n\t        f'{int(x.nobs):d}'}\n\t    original = actual = summary_col([reg1, reg2], float_format='%0.4f')\n\t    actual = summary_col([reg1, reg2], regressor_order=['a', 'b'],\n\t        float_format='%0.4f', info_dict=info_dict)\n\t    variables = 'const', 'b', 'a'\n\t    for line in str(original).split('\\n'):\n\t        for variable in variables:\n\t            if line.startswith(variable):\n\t                assert line in str(actual)\n\t\nTestSummaryLatex().test_summary_col_ordering_preserved()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/iolib/tests/test_summary2.py"}], "instruction": "Functionality: The summary_col function is designed to summarize multiple statistical results instances side-by-side, displaying coefficients, standard errors, and other model information in a tabular format. It is particularly useful for comparing different regression models. The function supports customization of the output, including the formatting of floating-point numbers, the inclusion of significance stars, the order and selection of regressors, and the presence of fixed effects indicators.\n\nInputs:\n- results: A statsmodels results instance or a list of results instances to be summarized.\n- float_format: A string representing the format for floating-point numbers in the summary table. Default is '%.4f'.\n- model_names: A list of strings representing names for the models. If the names are not unique, a roman numeral will be appended to ensure uniqueness.\n- stars: A boolean indicating whether to include significance stars in the output.\n- info_dict: A dictionary of functions to be applied to results instances to retrieve model information. It can be used to show or hide specific information for different models.\n- regressor_order: A list of names of regressors in the desired order. By default, unspecified regressors will be appended to the end.\n- drop_omitted: A boolean indicating whether to drop regressors not specified in regressor_order from the summary.\n- include_r2: A boolean indicating whether to include R-squared and adjusted R-squared in the summary table.\n- fixed_effects: A list of strings indicating categorical variables for which the presence of fixed effects should be indicated.\n- fe_present: A string to indicate the presence of fixed effects.\n- fe_absent: A string to indicate the absence of fixed effects.\n\nOutputs:\n- A Summary object containing the tabular summary of the input results, formatted according to the parameters provided. The output includes coefficients, standard errors, and other model information, such as R-squared, in a LaTeX-compatible format, with optional significance stars and fixed effects indicators.", "method_code_mask": "from statsmodels.compat.python import lzip\nimport datetime\nfrom functools import reduce\nimport re\nimport textwrap\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\n\n\ndef summary_col(results, float_format='%.4f', model_names=(), stars=False,\n    info_dict=None, regressor_order=(), drop_omitted=False, include_r2=True,\n    fixed_effects=None, fe_present='Yes', fe_absent=''): [MASK]\n"}
{"method_name": "wls_prediction_std", "full_method_name": "wls_prediction_std", "method_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/regression/predstd.py", "method_code": "import numpy as np\nfrom scipy import stats\ndef wls_prediction_std(res, exog=None, weights=None, alpha=0.05):\n    \"\"\"calculate standard deviation and confidence interval for prediction\n\n    applies to WLS and OLS, not to general GLS,\n    that is independently but not identically distributed observations\n\n    Parameters\n    ----------\n    res : regression result instance\n        results of WLS or OLS regression required attributes see notes\n    exog : array_like (optional)\n        exogenous variables for points to predict\n    weights : scalar or array_like (optional)\n        weights as defined for WLS (inverse of variance of observation)\n    alpha : float (default: alpha = 0.05)\n        confidence level for two-sided hypothesis\n\n    Returns\n    -------\n    predstd : array_like, 1d\n        standard error of prediction\n        same length as rows of exog\n    interval_l, interval_u : array_like\n        lower und upper confidence bounds\n\n    Notes\n    -----\n    The result instance needs to have at least the following\n    res.model.predict() : predicted values or\n    res.fittedvalues : values used in estimation\n    res.cov_params() : covariance matrix of parameter estimates\n\n    If exog is 1d, then it is interpreted as one observation,\n    i.e. a row vector.\n\n    testing status: not compared with other packages\n\n    References\n    ----------\n\n    Greene p.111 for OLS, extended to WLS by analogy\n\n    \"\"\"\n    covb = res.cov_params()\n    if exog is None:\n        exog = res.model.exog\n        predicted = res.fittedvalues\n        if weights is None:\n            weights = res.model.weights\n    else:\n        exog = np.atleast_2d(exog)\n        if covb.shape[1] != exog.shape[1]:\n            raise ValueError('wrong shape of exog')\n        predicted = res.model.predict(res.params, exog)\n        if weights is None:\n            weights = 1.0\n        else:\n            weights = np.asarray(weights)\n            if weights.size > 1 and len(weights) != exog.shape[0]:\n                raise ValueError('weights and exog do not have matching shape')\n    predvar = res.mse_resid / weights + (exog * np.dot(covb, exog.T).T).sum(1)\n    predstd = np.sqrt(predvar)\n    tppf = stats.t.isf(alpha / 2.0, res.df_resid)\n    interval_u = predicted + tppf * predstd\n    interval_l = predicted - tppf * predstd\n    return predstd, interval_l, interval_u", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\nfrom statsmodels.regression._prediction import get_prediction\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.base._prediction_inference import params_transform_univariate\nfrom statsmodels.genmod.families import links\ndef test_predict_se():\n    nsample = 50\n    x1 = np.linspace(0, 20, nsample)\n    x = np.c_[x1, (x1 - 5) ** 2, np.ones(nsample)]\n    np.random.seed(0)\n    beta = [0.5, -0.01, 5.0]\n    y_true2 = np.dot(x, beta)\n    w = np.ones(nsample)\n    w[int(nsample * 6.0 / 10):] = 3\n    sig = 0.5\n    y2 = y_true2 + sig * w * np.random.normal(size=nsample)\n    x2 = x[:, [0, 2]]\n    res2 = OLS(y2, x2).fit()\n    covb = res2.cov_params()\n    predvar = res2.mse_resid + (x2 * np.dot(covb, x2.T).T).sum(1)\n    predstd = np.sqrt(predvar)\n    prstd, iv_l, iv_u = wls_prediction_std(res2)\n    np.testing.assert_almost_equal(prstd, predstd, 15)\n    q = 2.010634754696446\n    ci_half = q * predstd\n    np.testing.assert_allclose(iv_u, res2.fittedvalues + ci_half, rtol=1e-09)\n    np.testing.assert_allclose(iv_l, res2.fittedvalues - ci_half, rtol=1e-09)\n    prstd, iv_l, iv_u = wls_prediction_std(res2, x2[:3, :])\n    np.testing.assert_equal(prstd, prstd[:3])\n    np.testing.assert_allclose(iv_u, res2.fittedvalues[:3] + ci_half[:3],\n        rtol=1e-09)\n    np.testing.assert_allclose(iv_l, res2.fittedvalues[:3] - ci_half[:3],\n        rtol=1e-09)\n    res3 = WLS(y2, x2, 1.0 / w).fit()\n    covb = res3.cov_params()\n    predvar = res3.mse_resid * w + (x2 * np.dot(covb, x2.T).T).sum(1)\n    predstd = np.sqrt(predvar)\n    prstd, iv_l, iv_u = wls_prediction_std(res3)\n    np.testing.assert_almost_equal(prstd, predstd, 15)\n    q = 2.010634754696446\n    ci_half = q * predstd\n    np.testing.assert_allclose(iv_u, res3.fittedvalues + ci_half, rtol=1e-09)\n    np.testing.assert_allclose(iv_l, res3.fittedvalues - ci_half, rtol=1e-09)\n    prstd, iv_l, iv_u = wls_prediction_std(res3, x2[-1:, :], weights=3.0)\n    np.testing.assert_equal(prstd, prstd[-1])\n    prstd, iv_l, iv_u = wls_prediction_std(res3, x2[-1, :], weights=3.0)\n    np.testing.assert_equal(prstd, prstd[-1])\n    prstd, iv_l, iv_u = wls_prediction_std(res3, x2[-2:, :], weights=3.0)\n    np.testing.assert_equal(prstd, prstd[-2:])\n    prstd, iv_l, iv_u = wls_prediction_std(res3, x2[-2:, :], weights=[3, 3])\n    np.testing.assert_equal(prstd, prstd[-2:])\n    prstd, iv_l, iv_u = wls_prediction_std(res3, x2[:3, :])\n    np.testing.assert_equal(prstd, prstd[:3])\n    np.testing.assert_allclose(iv_u, res3.fittedvalues[:3] + ci_half[:3],\n        rtol=1e-09)\n    np.testing.assert_allclose(iv_l, res3.fittedvalues[:3] - ci_half[:3],\n        rtol=1e-09)\n    np.testing.assert_raises(ValueError, wls_prediction_std, res3, x2[-1, 0\n        ], weights=3.0)\n    sew1 = wls_prediction_std(res3, x2[-3:, :])[0] ** 2\n    for wv in np.linspace(0.5, 3, 5):\n        sew = wls_prediction_std(res3, x2[-3:, :], weights=1.0 / wv)[0] ** 2\n        np.testing.assert_allclose(sew, sew1 + res3.scale * (wv - 1))\n\ntest_predict_se()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_predict.py"}], "instruction": "Functionality: The wls_prediction_std function calculates the standard deviation and confidence interval for predictions made from a weighted least squares (WLS) or ordinary least squares (OLS) regression model. This function is designed to work with independently but not identically distributed observations, which are typical in WLS and OLS. It utilizes the covariance matrix of parameter estimates, the predicted values of the model, and potentially, exogenous variables for points to predict, along with weights.\n\nInputs:\n- res: An instance of the regression result, which is typically the output of a WLS or OLS regression analysis. The instance must contain attributes for the model prediction or fitted values, the covariance matrix of parameter estimates, and the weights of the model.\n- exog (optional): An array_like object representing the exogenous variables for points to predict. If not provided, the function uses the exogenous variables from the model.\n- weights (optional): A scalar or array_like object representing the weights as defined for WLS. If not provided, it assumes the model's weights or defaults to 1.0 if not available.\n- alpha (float, default: 0.05): Determines the confidence level for a two-sided hypothesis, typically set to 0.05, which corresponds to a 95% confidence interval.\n\nOutputs:\n- predstd: A 1D array representing the standard error of prediction, with a length equal to the number of rows in exog.\n- interval_l, interval_u: Lower and upper bounds of the confidence interval for the prediction, also 1D arrays.", "method_code_mask": "import numpy as np\nfrom scipy import stats\n\n\ndef wls_prediction_std(res, exog=None, weights=None, alpha=0.05): [MASK]\n"}
{"method_name": "load_pandas", "full_method_name": "load_pandas", "method_path": "../srcdata/Computation/statsmodels/statsmodels/datasets/macrodata/data.py", "method_code": "from statsmodels.datasets import utils as du\ndef load_pandas():\n    data = _get_data()\n    return du.Dataset(data=data, names=list(data.columns))", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nimport numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.base import data as sm_data\nfrom statsmodels.formula import handle_formula_data\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod import families\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.datasets.macrodata import load_pandas\nfrom statsmodels.datasets.longley import load_pandas\nfrom statsmodels.tools.sm_exceptions import MissingDataError\ndef test_alignment():\n    from statsmodels.datasets.macrodata import load_pandas\n    d = load_pandas().data\n    gs_l_realinv = 400 * np.log(d['realinv']).diff().dropna()\n    gs_l_realgdp = 400 * np.log(d['realgdp']).diff().dropna()\n    lint = d['realint'][:-1]\n    endog = gs_l_realinv\n    realgdp = gs_l_realgdp.reindex(lint.index, method='bfill')\n    data = dict(const=np.ones_like(lint), lrealgdp=realgdp, lint=lint)\n    exog = pd.DataFrame(data)\n    np.testing.assert_raises(ValueError, OLS, *(endog, exog))\n\ntest_alignment()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_data.py"}], "instruction": "Functionality: The load_pandas function is designed to load a dataset using pandas, a popular data manipulation library in Python. This function specifically utilizes the _get_data() method (not provided here) to fetch the data and then wraps this data into a statsmodels Dataset object for further statistical analysis and processing. It's essential for interviewees to demonstrate their ability to work with pandas data structures such as DataFrame, and to understand how to encapsulate data into a Dataset object for use in statsmodels.\n\nInputs: \n- The function does not take any input arguments. The data is internally fetched using the _get_data() method which candidates are expected to assume is correctly implemented and returns the necessary data.\n\nOutputs: \n- The function returns a statsmodels Dataset object. This object contains the data fetched by _get_data() method, which is structured as a pandas DataFrame and the column names of this DataFrame. The Dataset object is a useful construct for passing data to various statistical models in the statsmodels library.", "method_code_mask": "from statsmodels.datasets import utils as du\n\n\ndef load_pandas(): [MASK]\n"}
{"method_name": "reset_ramsey", "full_method_name": "reset_ramsey", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/outliers_influence.py", "method_code": "import warnings\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lzip\nfrom collections import defaultdict\nimport numpy as np\nfrom statsmodels.graphics._regressionplots_doc import _plot_influence_doc\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import maybe_unwrap_results\nfrom scipy import stats\nfrom pandas import DataFrame\nfrom statsmodels.graphics.regressionplots import _influence_plot\nfrom statsmodels.graphics import utils\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.sandbox.tools.cross_val import LeaveOneOut\nfrom copy import deepcopy\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.iolib.table import default_html_fmt\nfrom statsmodels.iolib.tableformatting import fmt_base\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\ndef reset_ramsey(res, degree=5):\n    \"\"\"Ramsey's RESET specification test for linear models\n\n    This is a general specification test, for additional non-linear effects\n    in a model.\n\n    Parameters\n    ----------\n    degree : int\n        Maximum power to include in the RESET test.  Powers 0 and 1 are\n        excluded, so that degree tests powers 2, ..., degree of the fitted\n        values.\n\n    Notes\n    -----\n    The test fits an auxiliary OLS regression where the design matrix, exog,\n    is augmented by powers 2 to degree of the fitted values. Then it performs\n    an F-test whether these additional terms are significant.\n\n    If the p-value of the f-test is below a threshold, e.g. 0.1, then this\n    indicates that there might be additional non-linear effects in the model\n    and that the linear model is mis-specified.\n\n    References\n    ----------\n    https://en.wikipedia.org/wiki/Ramsey_RESET_test\n    \"\"\"\n    order = degree + 1\n    k_vars = res.model.exog.shape[1]\n    norm_values = np.asarray(res.fittedvalues)\n    norm_values = norm_values / np.sqrt((norm_values ** 2).mean())\n    y_fitted_vander = np.vander(norm_values, order)[:, :-2]\n    exog = np.column_stack((res.model.exog, y_fitted_vander))\n    exog /= np.sqrt((exog ** 2).mean(0))\n    endog = res.model.endog / (res.model.endog ** 2).mean()\n    res_aux = OLS(endog, exog).fit()\n    r_matrix = np.eye(degree - 1, exog.shape[1], k_vars)\n    return res_aux.f_test(r_matrix)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom statsmodels.datasets import statecrime\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.outliers_influence import reset_ramsey\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools import add_constant\ndef test_reset_stata():\n    data = statecrime.load_pandas().data\n    mod = OLS(data.violent, add_constant(data[['murder', 'hs_grad']]))\n    res = mod.fit()\n    stat = reset_ramsey(res, degree=4)\n    assert_almost_equal(stat.fvalue, 1.52, decimal=2)\n    assert_almost_equal(stat.pvalue, 0.2221, decimal=4)\n    exog_idx = list(data.columns).index('urban')\n    data_arr = np.asarray(data)\n    vif = variance_inflation_factor(data_arr, exog_idx)\n    assert_almost_equal(vif, 16.4394, decimal=4)\n    exog_idx = list(data.columns).index('urban')\n    vif_df = variance_inflation_factor(data, exog_idx)\n    assert_almost_equal(vif_df, 16.4394, decimal=4)\n\ntest_reset_stata()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_outliers_influence.py"}], "instruction": "Functionality: The reset_ramsey function implements Ramsey's RESET (Regression Equation Specification Error Test) for linear models. It tests for specification errors by checking for additional non-linear effects in the model using the powers of the fitted values. The function fits an auxiliary OLS regression with the design matrix augmented by powers of the fitted values (excluding powers 0 and 1) and performs an F-test to determine if these additional terms are significant.\n\nInputs: \n- res: The result of a linear regression model, typically an instance of a statsmodels regression result.\n- degree: An integer representing the maximum power to include in the RESET test. Powers 0 and 1 are excluded, so degree tests powers 2, ..., degree of the fitted values.\n\nOutputs:\n- The function returns the result of an F-test. This can typically be interpreted as a tuple containing the F-statistic and the p-value. A small p-value (e.g., less than 0.1) indicates that there might be additional non-linear effects in the model, suggesting that the linear model might be mis-specified.", "method_code_mask": "import warnings\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lzip\nfrom collections import defaultdict\nimport numpy as np\nfrom statsmodels.graphics._regressionplots_doc import _plot_influence_doc\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import maybe_unwrap_results\nfrom scipy import stats\nfrom pandas import DataFrame\nfrom statsmodels.graphics.regressionplots import _influence_plot\nfrom statsmodels.graphics import utils\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.sandbox.tools.cross_val import LeaveOneOut\nfrom copy import deepcopy\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.iolib.table import default_html_fmt\nfrom statsmodels.iolib.tableformatting import fmt_base\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\n\n\ndef reset_ramsey(res, degree=5): [MASK]\n"}
{"method_name": "linear_lm", "full_method_name": "linear_lm", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/diagnostic.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nfrom collections.abc import Iterable\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.stats._adnorm import anderson_statistic\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats._lilliefors import kstest_exponential\nfrom statsmodels.stats._lilliefors import kstest_fit\nfrom statsmodels.stats._lilliefors import kstest_normal\nfrom statsmodels.stats._lilliefors import lilliefors\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.multivariate.pca import PCA\nfrom scipy.spatial.distance import cdist\ndef linear_lm(resid, exog, func=None):\n    \"\"\"\n    Lagrange multiplier test for linearity against functional alternative\n\n    # TODO: Remove the restriction\n    limitations: Assumes currently that the first column is integer.\n    Currently it does not check whether the transformed variables contain NaNs,\n    for example log of negative number.\n\n    Parameters\n    ----------\n    resid : ndarray\n        residuals of a regression\n    exog : ndarray\n        exogenous variables for which linearity is tested\n    func : callable, default None\n        If func is None, then squares are used. func needs to take an array\n        of exog and return an array of transformed variables.\n\n    Returns\n    -------\n    lm : float\n       Lagrange multiplier test statistic\n    lm_pval : float\n       p-value of Lagrange multiplier tes\n    ftest : ContrastResult instance\n       the results from the F test variant of this test\n\n    Notes\n    -----\n    Written to match Gretl's linearity test. The test runs an auxiliary\n    regression of the residuals on the combined original and transformed\n    regressors. The Null hypothesis is that the linear specification is\n    correct.\n    \"\"\"\n    if func is None:\n\n        def func(x):\n            return np.power(x, 2)\n    exog = np.asarray(exog)\n    exog_aux = np.column_stack((exog, func(exog[:, 1:])))\n    nobs, k_vars = exog.shape\n    ls = OLS(resid, exog_aux).fit()\n    ftest = ls.f_test(np.eye(k_vars - 1, k_vars * 2 - 1, k_vars))\n    lm = nobs * ls.rsquared\n    lm_pval = stats.chi2.sf(lm, k_vars - 1)\n    return lm, lm_pval, ftest", "test_code_list": [{"test_code": "import json\nimport os\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.diagnostic as smsdia\nimport statsmodels.stats.outliers_influence as oi\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom pandas import DataFrame\ndef test_linear_lm_direct():\n    endog = np.random.standard_normal(500)\n    exog = add_constant(np.random.standard_normal((500, 3)))\n    res = OLS(endog, exog).fit()\n    lm_res = linear_lm(res.resid, exog)\n    aug = np.hstack([exog, exog[:, 1:] ** 2])\n    res_aug = OLS(res.resid, aug).fit()\n    stat = res_aug.rsquared * aug.shape[0]\n    assert_allclose(lm_res[0], stat)\n\ntest_linear_lm_direct()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_diagnostic.py"}], "instruction": "Functionality: The linear_lm function is designed to perform a Lagrange multiplier test to evaluate the linearity of the relationship between the given residuals and exogenous variables. It tests the null hypothesis that the linear specification is correct against an alternative hypothesis that a functional transformation of the exogenous variables provides a better fit. This function can accommodate a user-defined transformation function or default to squaring the exogenous variables if no function is provided.\n\nInputs:\n- resid: An ndarray representing the residuals of a regression.\n- exog: An ndarray representing the exogenous variables for which linearity is being tested.\n- func: A callable function (default None) that takes an array of exog and returns an array of transformed variables. If None, the function defaults to squaring the exogenous variables.\n\nOutputs:\n- lm: A float, the Lagrange multiplier test statistic.\n- lm_pval: A float, the p-value of the Lagrange multiplier test.\n- ftest: A ContrastResult instance that contains the results from the F test variant of the linearity test, which includes the test statistic, degrees of freedom, and p-value.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nfrom collections.abc import Iterable\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.stats._adnorm import anderson_statistic\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats._lilliefors import kstest_exponential\nfrom statsmodels.stats._lilliefors import kstest_fit\nfrom statsmodels.stats._lilliefors import kstest_normal\nfrom statsmodels.stats._lilliefors import lilliefors\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.multivariate.pca import PCA\nfrom scipy.spatial.distance import cdist\n\n\ndef linear_lm(resid, exog, func=None): [MASK]\n"}
{"method_name": "variance_inflation_factor", "full_method_name": "variance_inflation_factor", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/outliers_influence.py", "method_code": "import warnings\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lzip\nfrom collections import defaultdict\nimport numpy as np\nfrom statsmodels.graphics._regressionplots_doc import _plot_influence_doc\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import maybe_unwrap_results\nfrom scipy import stats\nfrom pandas import DataFrame\nfrom statsmodels.graphics.regressionplots import _influence_plot\nfrom statsmodels.graphics import utils\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.sandbox.tools.cross_val import LeaveOneOut\nfrom copy import deepcopy\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.iolib.table import default_html_fmt\nfrom statsmodels.iolib.tableformatting import fmt_base\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\ndef variance_inflation_factor(exog, exog_idx):\n    \"\"\"\n    Variance inflation factor, VIF, for one exogenous variable\n\n    The variance inflation factor is a measure for the increase of the\n    variance of the parameter estimates if an additional variable, given by\n    exog_idx is added to the linear regression. It is a measure for\n    multicollinearity of the design matrix, exog.\n\n    One recommendation is that if VIF is greater than 5, then the explanatory\n    variable given by exog_idx is highly collinear with the other explanatory\n    variables, and the parameter estimates will have large standard errors\n    because of this.\n\n    Parameters\n    ----------\n    exog : {ndarray, DataFrame}\n        design matrix with all explanatory variables, as for example used in\n        regression\n    exog_idx : int\n        index of the exogenous variable in the columns of exog\n\n    Returns\n    -------\n    float\n        variance inflation factor\n\n    Notes\n    -----\n    This function does not save the auxiliary regression.\n\n    See Also\n    --------\n    xxx : class for regression diagnostics  TODO: does not exist yet\n\n    References\n    ----------\n    https://en.wikipedia.org/wiki/Variance_inflation_factor\n    \"\"\"\n    k_vars = exog.shape[1]\n    exog = np.asarray(exog)\n    x_i = exog[:, exog_idx]\n    mask = np.arange(k_vars) != exog_idx\n    x_noti = exog[:, mask]\n    r_squared_i = OLS(x_i, x_noti).fit().rsquared\n    vif = 1.0 / (1.0 - r_squared_i)\n    return vif", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom statsmodels.datasets import statecrime\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.outliers_influence import reset_ramsey\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools import add_constant\ndef test_reset_stata():\n    data = statecrime.load_pandas().data\n    mod = OLS(data.violent, add_constant(data[['murder', 'hs_grad']]))\n    res = mod.fit()\n    stat = reset_ramsey(res, degree=4)\n    assert_almost_equal(stat.fvalue, 1.52, decimal=2)\n    assert_almost_equal(stat.pvalue, 0.2221, decimal=4)\n    exog_idx = list(data.columns).index('urban')\n    data_arr = np.asarray(data)\n    vif = variance_inflation_factor(data_arr, exog_idx)\n    assert_almost_equal(vif, 16.4394, decimal=4)\n    exog_idx = list(data.columns).index('urban')\n    vif_df = variance_inflation_factor(data, exog_idx)\n    assert_almost_equal(vif_df, 16.4394, decimal=4)\n\ntest_reset_stata()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_outliers_influence.py"}], "instruction": "Functionality: Calculate the Variance Inflation Factor (VIF) for one exogenous variable in a design matrix.\nInputs: \n- exog: {ndarray, DataFrame} - design matrix with all explanatory variables, similar to those used in regression.\n- exog_idx: int - index of the exogenous variable in the columns of exog for which the VIF is to be calculated.\n\nOutputs:\n- float: variance inflation factor for the specified exogenous variable.\n\nNotes:\n- The VIF is a measure of multicollinearity in the design matrix. A VIF greater than 5 suggests the explanatory variable is highly collinear with other explanatory variables.\n- This function calculates the R-squared value from a regression of the exogenous variable (exog_idx) on all other variables in the design matrix, then computes the VIF from this R-squared value.\n- No auxiliary regression results are saved by this function.", "method_code_mask": "import warnings\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.python import lzip\nfrom collections import defaultdict\nimport numpy as np\nfrom statsmodels.graphics._regressionplots_doc import _plot_influence_doc\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import maybe_unwrap_results\nfrom scipy import stats\nfrom pandas import DataFrame\nfrom statsmodels.graphics.regressionplots import _influence_plot\nfrom statsmodels.graphics import utils\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.sandbox.tools.cross_val import LeaveOneOut\nfrom copy import deepcopy\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.iolib.table import default_html_fmt\nfrom statsmodels.iolib.tableformatting import fmt_base\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\n\n\ndef variance_inflation_factor(exog, exog_idx): [MASK]\n"}
{"method_name": "gen_data", "full_method_name": "gen_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_rolling.py", "method_code": "from io import BytesIO\nfrom itertools import product\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nfrom statsmodels import tools\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.regression.rolling import RollingWLS\nfrom statsmodels.regression.rolling import RollingOLS\nimport matplotlib.pyplot as plt\ndef gen_data(nobs, nvar, const, pandas=False, missing=0.0, weights=False):\n    rs = np.random.RandomState(987499302)\n    x = rs.standard_normal((nobs, nvar))\n    cols = [f'x{i}' for i in range(nvar)]\n    if const:\n        x = tools.add_constant(x)\n        cols = ['const'] + cols\n    if missing > 0.0:\n        mask = rs.random_sample(x.shape) < missing\n        x[mask] = np.nan\n    if x.shape[1] > 1:\n        y = x[:, :-1].sum(1) + rs.standard_normal(nobs)\n    else:\n        y = x.sum(1) + rs.standard_normal(nobs)\n    w = rs.chisquare(5, y.shape[0]) / 5\n    if pandas:\n        idx = pd.date_range('12-31-1999', periods=nobs)\n        x = pd.DataFrame(x, index=idx, columns=cols)\n        y = pd.Series(y, index=idx, name='y')\n        w = pd.Series(w, index=idx, name='weights')\n    if not weights:\n        w = None\n    return y, x, w", "test_code_list": [{"test_code": "from io import BytesIO\nfrom itertools import product\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nfrom statsmodels import tools\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.regression.rolling import RollingWLS\nfrom statsmodels.regression.rolling import RollingOLS\nimport matplotlib.pyplot as plt\ndef test_formula():\n    y, x, w = gen_data(250, 3, True, pandas=True)\n    fmla = 'y ~ 1 + x0 + x1 + x2'\n    data = pd.concat([y, x], axis=1)\n    mod = RollingWLS.from_formula(fmla, window=100, data=data, weights=w)\n    res = mod.fit()\n    alt = RollingWLS(y, x, window=100)\n    alt_res = alt.fit()\n    assert_allclose(res.params, alt_res.params)\n    ols_mod = RollingOLS.from_formula(fmla, window=100, data=data)\n    ols_mod.fit()\n\ntest_formula()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_rolling.py"}, {"test_code": "from io import BytesIO\nfrom itertools import product\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nfrom statsmodels import tools\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.regression.rolling import RollingWLS\nfrom statsmodels.regression.rolling import RollingOLS\nimport matplotlib.pyplot as plt\n@pytest.mark.matplotlib\ndef test_plot():\n    import matplotlib.pyplot as plt\n    y, x, w = gen_data(250, 3, True, pandas=True)\n    fmla = 'y ~ 1 + x0 + x1 + x2'\n    data = pd.concat([y, x], axis=1)\n    mod = RollingWLS.from_formula(fmla, window=100, data=data, weights=w)\n    res = mod.fit()\n    fig = res.plot_recursive_coefficient()\n    assert isinstance(fig, plt.Figure)\n    res.plot_recursive_coefficient(variables=2, alpha=None, figsize=(30, 7))\n    res.plot_recursive_coefficient(variables='x0', alpha=None, figsize=(30, 7))\n    res.plot_recursive_coefficient(variables=[0, 2], alpha=None, figsize=(\n        30, 7))\n    res.plot_recursive_coefficient(variables=['x0'], alpha=None, figsize=(\n        30, 7))\n    res.plot_recursive_coefficient(variables=['x0', 'x1', 'x2'], alpha=None,\n        figsize=(30, 7))\n    with pytest.raises(ValueError, match='variable x4 is not an integer'):\n        res.plot_recursive_coefficient(variables='x4')\n    fig = plt.Figure()\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        out = res.plot_recursive_coefficient(fig=fig)\n    assert out is fig\n    res.plot_recursive_coefficient(alpha=None, figsize=(30, 7))\n\ntest_plot()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/regression/tests/test_rolling.py"}], "instruction": "Functionality: The gen_data function is designed to generate synthetic data for regression analysis. It creates random data points for multiple variables, with an option to include a constant term, handle missing values, and generate weights for weighted regression. The data can also be formatted in a pandas DataFrame for compatibility with data analysis and regression models in pandas.\n\nInputs: \n    nobs: int\n        The number of observations to generate. This defines the size of the dataset along the rows.\n        \n    nvar: int\n        The number of predictor variables to include in the dataset. This defines the size of the dataset along the columns, excluding the constant term if present.\n        \n    const: bool\n        If True, adds a constant term to the data. This is typically used as an intercept in regression analysis.\n        \n    pandas: bool, default False\n        If True, returns the data in pandas DataFrame and Series format. If False, returns numpy arrays.\n        \n    missing: float, default 0.0\n        The fraction of values to make missing (NaN). Range should be between 0.0 and 1.0.\n        \n    weights: bool, default False\n        If True, generates weights for the data points. These can be used for weighted regression models.\n\nOutputs: \n    tuple of (y, x, w)\n        y: array-like (1-D)\n            The dependent variable or response data. It is a 1-D array or Series, depending on the 'pandas' parameter.\n            \n        x: array-like (2-D)\n            The independent variable(s) or regressor data. It is a 2-D array or DataFrame, depending on the 'pandas' parameter.\n            \n        w: array-like (1-D) or None\n            The weights for each data point. It is a 1-D array or Series, depending on the 'pandas' parameter, or None if 'weights' is False.", "method_code_mask": "from io import BytesIO\nfrom itertools import product\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nfrom statsmodels import tools\nfrom statsmodels.regression.linear_model import WLS\nfrom statsmodels.regression.rolling import RollingWLS\nfrom statsmodels.regression.rolling import RollingOLS\nimport matplotlib.pyplot as plt\n\n\ndef gen_data(nobs, nvar, const, pandas=False, missing=0.0, weights=False): [M\n    ASK]\n"}
{"method_name": "array_like", "full_method_name": "array_like", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/validation.py", "method_code": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\ndef array_like(obj, name, dtype=np.double, ndim=1, maxdim=None, shape=None,\n    order=None, contiguous=False, optional=False, writeable=True):\n    \"\"\"\n    Convert array-like to a ndarray and check conditions\n\n    Parameters\n    ----------\n    obj : array_like\n         An array, any object exposing the array interface, an object whose\n        __array__ method returns an array, or any (nested) sequence.\n    name : str\n        Name of the variable to use in exceptions\n    dtype : {None, numpy.dtype, str}\n        Required dtype. Default is double. If None, does not change the dtype\n        of obj (if present) or uses NumPy to automatically detect the dtype\n    ndim : {int, None}\n        Required number of dimensions of obj. If None, no check is performed.\n        If the number of dimensions of obj is less than ndim, additional axes\n        are inserted on the right. See examples.\n    maxdim : {int, None}\n        Maximum allowed dimension.  Use ``maxdim`` instead of ``ndim`` when\n        inputs are allowed to have ndim 1, 2, ..., or maxdim.\n    shape : {tuple[int], None}\n        Required shape obj.  If None, no check is performed. Partially\n        restricted shapes can be checked using None. See examples.\n    order : {'C', 'F', None}\n        Order of the array\n    contiguous : bool\n        Ensure that the array's data is contiguous with order ``order``\n    optional : bool\n        Flag indicating whether None is allowed\n    writeable : bool\n        Whether to ensure the returned array is writeable\n\n    Returns\n    -------\n    ndarray\n        The converted input.\n\n    Examples\n    --------\n    Convert a list or pandas series to an array\n    >>> import pandas as pd\n    >>> x = [0, 1, 2, 3]\n    >>> a = array_like(x, 'x', ndim=1)\n    >>> a.shape\n    (4,)\n\n    >>> a = array_like(pd.Series(x), 'x', ndim=1)\n    >>> a.shape\n    (4,)\n\n    >>> type(a.orig)\n    pandas.core.series.Series\n\n    Squeezes singleton dimensions when required\n    >>> x = np.array(x).reshape((4, 1))\n    >>> a = array_like(x, 'x', ndim=1)\n    >>> a.shape\n    (4,)\n\n    Right-appends when required size is larger than actual\n    >>> x = [0, 1, 2, 3]\n    >>> a = array_like(x, 'x', ndim=2)\n    >>> a.shape\n    (4, 1)\n\n    Check only the first and last dimension of the input\n    >>> x = np.arange(4*10*4).reshape((4, 10, 4))\n    >>> y = array_like(x, 'x', ndim=3, shape=(4, None, 4))\n\n    Check only the first two dimensions\n    >>> z = array_like(x, 'x', ndim=3, shape=(4, 10))\n\n    Raises ValueError if constraints are not satisfied\n    >>> z = array_like(x, 'x', ndim=2)\n    Traceback (most recent call last):\n     ...\n    ValueError: x is required to have ndim 2 but has ndim 3\n\n    >>> z = array_like(x, 'x', shape=(10, 4, 4))\n    Traceback (most recent call last):\n     ...\n    ValueError: x is required to have shape (10, 4, 4) but has shape (4, 10, 4)\n\n    >>> z = array_like(x, 'x', shape=(None, 4, 4))\n    Traceback (most recent call last):\n     ...\n    ValueError: x is required to have shape (*, 4, 4) but has shape (4, 10, 4)\n    \"\"\"\n    if optional and obj is None:\n        return None\n    reqs = ['W'] if writeable else []\n    if order == 'C' or contiguous:\n        reqs += ['C']\n    elif order == 'F':\n        reqs += ['F']\n    arr = np.require(obj, dtype=dtype, requirements=reqs)\n    if maxdim is not None:\n        if arr.ndim > maxdim:\n            msg = f'{name} must have ndim <= {maxdim}'\n            raise ValueError(msg)\n    elif ndim is not None:\n        if arr.ndim > ndim:\n            arr = _right_squeeze(arr, stop_dim=ndim)\n        elif arr.ndim < ndim:\n            arr = np.reshape(arr, arr.shape + (1,) * (ndim - arr.ndim))\n        if arr.ndim != ndim:\n            msg = '{0} is required to have ndim {1} but has ndim {2}'\n            raise ValueError(msg.format(name, ndim, arr.ndim))\n    if shape is not None:\n        for actual, req in zip(arr.shape, shape):\n            if req is not None and actual != req:\n                req_shape = str(shape).replace('None, ', '*, ')\n                msg = '{0} is required to have shape {1} but has shape {2}'\n                raise ValueError(msg.format(name, req_shape, arr.shape))\n    return arr", "test_code_list": [{"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\n\nclass TestArrayLike():\n\tdef test_right_squeeze_and_pad(self):\n\t    data = np.empty((2, 1, 2))\n\t    a = array_like(data, 'a', ndim=3)\n\t    assert a.shape == (2, 1, 2)\n\t    data = np.empty(2)\n\t    a = array_like(data, 'a', ndim=3)\n\t    assert a.shape == (2, 1, 1)\n\t    data = np.empty((2, 1))\n\t    a = array_like(data, 'a', ndim=3)\n\t    assert a.shape == (2, 1, 1)\n\t    data = np.empty((2, 1, 1, 1))\n\t    a = array_like(data, 'a', ndim=3)\n\t    assert a.shape == (2, 1, 1)\n\t    data = np.empty((2, 1, 1, 2, 1, 1))\n\t    with pytest.raises(ValueError):\n\t        array_like(data, 'a', ndim=3)\n\t\nTestArrayLike().test_right_squeeze_and_pad()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}, {"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\n\nclass TestArrayLike():\n\tdef test_contiguous(self):\n\t    x = np.arange(10)\n\t    y = x[::2]\n\t    a = array_like(y, 'a', contiguous=True)\n\t    assert not y.flags['C_CONTIGUOUS']\n\t    assert a.flags['C_CONTIGUOUS']\n\t\nTestArrayLike().test_contiguous()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}, {"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\n\nclass TestArrayLike():\n\tdef test_dtype(self):\n\t    x = np.arange(10)\n\t    a = array_like(x, 'a', dtype=np.float32)\n\t    assert a.dtype == np.float32\n\t    a = array_like(x, 'a', dtype=np.uint8)\n\t    assert a.dtype == np.uint8\n\t\nTestArrayLike().test_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}], "instruction": "Functionality: The 'array_like' function is designed to convert various array-like objects, including arrays, objects that expose the array interface, objects with __array__ methods, or nested sequences, into a NumPy ndarray. It ensures that the resulting array meets specific conditions such as dtype, ndim, maxdim, shape, order, and contiguity, as defined by the input parameters. If the 'optional' parameter is set to True and the input object is None, the function returns None.\n\nInputs: \n- obj: The array-like object to convert.\n- name: A string representing the name of the variable, used in exceptions.\n- dtype: The required dtype for the array. Defaults to numpy.double. If None, the dtype of 'obj' is used, or it's inferred by NumPy.\n- ndim: The required number of dimensions for the array. If None, no dimension check is performed.\n- maxdim: The maximum allowed dimensions for 'obj'. Used in place of 'ndim' when inputs can have any number of dimensions up to 'maxdim'.\n- shape: The required shape of 'obj'. If None, no shape check is performed.\n- order: The order of the array ('C' for C-style, 'F' for Fortran-style).\n- contiguous: Boolean flag indicating whether the array data should be contiguous with a specific order.\n- optional: Boolean flag indicating whether None is an acceptable input.\n- writeable: Boolean flag indicating whether the returned array should be writeable.\n\nOutputs:\n- ndarray: The converted input array which satisfies all the specified requirements.", "method_code_mask": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\n\n\ndef array_like(obj, name, dtype=np.double, ndim=1, maxdim=None, shape=None,\n    order=None, contiguous=False, optional=False, writeable=True): [MASK]\n"}
{"method_name": "confint_poisson_2indep", "full_method_name": "confint_poisson_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef confint_poisson_2indep(count1, exposure1, count2, exposure2, method=\n    'score', compare='ratio', alpha=0.05, method_mover='score'):\n    \"\"\"Confidence interval for ratio or difference of 2 indep poisson rates.\n\n    Parameters\n    ----------\n    count1 : int\n        Number of events in first sample.\n    exposure1 : float\n        Total exposure (time * subjects) in first sample.\n    count2 : int\n        Number of events in second sample.\n    exposure2 : float\n        Total exposure (time * subjects) in second sample.\n    method : string\n        Method for the test statistic and the p-value. Defaults to `'score'`.\n        see Notes.\n\n        ratio:\n\n        - 'wald': NOT YET, method W1A, wald test, variance based on observed\n          rates\n        - 'waldcc' :\n        - 'score': method W2A, score test, variance based on estimate under\n          the Null hypothesis\n        - 'wald-log': W3A, uses log-ratio, variance based on observed rates\n        - 'score-log' W4A, uses log-ratio, variance based on estimate under\n          the Null hypothesis\n        - 'sqrt': W5A, based on variance stabilizing square root transformation\n        - 'sqrtcc' :\n        - 'exact-cond': NOT YET, exact conditional test based on binomial\n          distribution\n          This uses ``binom_test`` which is minlike in the two-sided case.\n        - 'cond-midp': NOT YET, midpoint-pvalue of exact conditional test\n        - 'mover' :\n\n        diff:\n\n        - 'wald',\n        - 'waldccv'\n        - 'score'\n        - 'mover'\n\n    compare : {'diff', 'ratio'}\n        Default is \"ratio\".\n        If compare is `diff`, then the hypothesis test is for\n        diff = rate1 - rate2.\n        If compare is `ratio`, then the hypothesis test is for the\n        rate ratio defined by ratio = rate1 / rate2.\n    alternative : string\n        The alternative hypothesis, H1, has to be one of the following\n\n        - 'two-sided': H1: ratio of rates is not equal to ratio_null (default)\n        - 'larger' :   H1: ratio of rates is larger than ratio_null\n        - 'smaller' :  H1: ratio of rates is smaller than ratio_null\n\n    alpha : float in (0, 1)\n        Significance level, nominal coverage of the confidence interval is\n        1 - alpha.\n\n    Returns\n    -------\n    tuple (low, upp) : confidence limits.\n\n    \"\"\"\n    y1, n1, y2, n2 = map(np.asarray, [count1, exposure1, count2, exposure2])\n    rate1, rate2 = y1 / n1, y2 / n2\n    alpha = alpha / 2\n    if compare == 'ratio':\n        if method == 'score':\n            low, upp = _invert_test_confint_2indep(count1, exposure1,\n                count2, exposure2, alpha=alpha * 2, method='score', compare\n                ='ratio', method_start='waldcc')\n            ci = low, upp\n        elif method == 'wald-log':\n            crit = stats.norm.isf(alpha)\n            c = 0\n            center = (count1 + c) / (count2 + c) * n2 / n1\n            std = np.sqrt(1 / (count1 + c) + 1 / (count2 + c))\n            ci = center * np.exp(-crit * std), center * np.exp(crit * std)\n        elif method == 'score-log':\n            low, upp = _invert_test_confint_2indep(count1, exposure1,\n                count2, exposure2, alpha=alpha * 2, method='score-log',\n                compare='ratio', method_start='waldcc')\n            ci = low, upp\n        elif method == 'waldcc':\n            crit = stats.norm.isf(alpha)\n            center = (count1 + 0.5) / (count2 + 0.5) * n2 / n1\n            std = np.sqrt(1 / (count1 + 0.5) + 1 / (count2 + 0.5))\n            ci = center * np.exp(-crit * std), center * np.exp(crit * std)\n        elif method == 'sqrtcc':\n            crit = stats.norm.isf(alpha)\n            center = np.sqrt((count1 + 0.5) * (count2 + 0.5))\n            std = 0.5 * np.sqrt(count1 + 0.5 + count2 + 0.5 - 0.25 * crit)\n            denom = count2 + 0.5 - 0.25 * crit ** 2\n            low_sqrt = (center - crit * std) / denom\n            upp_sqrt = (center + crit * std) / denom\n            ci = low_sqrt ** 2, upp_sqrt ** 2\n        elif method == 'mover':\n            method_p = method_mover\n            ci1 = confint_poisson(y1, n1, method=method_p, alpha=2 * alpha)\n            ci2 = confint_poisson(y2, n2, method=method_p, alpha=2 * alpha)\n            ci = _mover_confint(rate1, rate2, ci1, ci2, contrast='ratio')\n        else:\n            raise ValueError(f'method \"{method}\" not recognized')\n        ci = np.maximum(ci[0], 0), ci[1]\n    elif compare == 'diff':\n        if method in ['wald']:\n            crit = stats.norm.isf(alpha)\n            center = rate1 - rate2\n            half = crit * np.sqrt(rate1 / n1 + rate2 / n2)\n            ci = center - half, center + half\n        elif method in ['waldccv']:\n            crit = stats.norm.isf(alpha)\n            center = rate1 - rate2\n            std = np.sqrt((count1 + 0.5) / n1 ** 2 + (count2 + 0.5) / n2 ** 2)\n            half = crit * std\n            ci = center - half, center + half\n        elif method == 'score':\n            low, upp = _invert_test_confint_2indep(count1, exposure1,\n                count2, exposure2, alpha=alpha * 2, method='score', compare\n                ='diff', method_start='waldccv')\n            ci = low, upp\n        elif method == 'mover':\n            method_p = method_mover\n            ci1 = confint_poisson(y1, n1, method=method_p, alpha=2 * alpha)\n            ci2 = confint_poisson(y2, n2, method=method_p, alpha=2 * alpha)\n            ci = _mover_confint(rate1, rate2, ci1, ci2, contrast='diff')\n        else:\n            raise ValueError(f'method \"{method}\" not recognized')\n    else:\n        raise NotImplementedError('\"compare\" needs to be ratio or diff')\n    return ci", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_confint_poisson_2indep():\n    count1, exposure1, count2, exposure2 = 60, 51477.5, 30, 54308.7\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='mover', compare='ratio', alpha=0.1, method_mover='jeff')\n    ci1 = 1.4667, 3.0608\n    assert_allclose(ci, ci1, atol=0.05)\n    ci1 = 1.466768, 3.058634\n    assert_allclose(ci, ci1, rtol=0.001)\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='mover', compare='ratio', alpha=0.1, method_mover='score')\n    ci1 = 1.4611, 3.0424\n    assert_allclose(ci, ci1, atol=0.05)\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='waldcc', compare='ratio', alpha=0.1)\n    ci1 = 1.4523, 3.0154\n    assert_allclose(ci, ci1, atol=0.0005)\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='score', compare='ratio', alpha=0.05)\n    ci1 = 1.365962, 3.259306\n    assert_allclose(ci, ci1, atol=5e-06)\n    exposure1 /= 1000\n    exposure2 /= 1000\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='mover', compare='diff', alpha=0.05, method_mover='jeff')\n    ci1 = 0.2629322, 0.9786493\n    assert_allclose(ci, ci1, atol=0.005)\n    ci = confint_poisson_2indep(count1, exposure1, count2, exposure2,\n        method='score', compare='diff', alpha=0.05)\n    ci1 = 0.265796, 0.989192\n    assert_allclose(ci, ci1, atol=5e-06)\n    ci = confint_poisson_2indep(count2, exposure2, count1, exposure1,\n        method='mover', compare='diff', alpha=0.1, method_mover='jeff')\n    ci1 = -0.9183272231752, -0.3188611692202\n    assert_allclose(ci, ci1, atol=0.005)\n    ci1 = -0.9195, -0.3193\n    assert_allclose(ci, ci1, atol=0.005)\n    ci = confint_poisson_2indep(count2, exposure2, count1, exposure1,\n        method='mover', compare='diff', alpha=0.1, method_mover='jeff')\n    ci1 = -0.9232, -0.3188\n    assert_allclose(ci, ci1, atol=0.006)\n\ntest_confint_poisson_2indep()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality:\nThis function calculates the confidence interval for the ratio or difference of two independent Poisson rates. It supports several statistical methods for constructing the confidence interval, depending on the comparison type (ratio or difference) and the chosen method.\n\nInputs:\n- count1: int\n  Number of events in the first sample.\n- exposure1: float\n  Total exposure (time * subjects) in the first sample.\n- count2: int\n  Number of events in the second sample.\n- exposure2: float\n  Total exposure (time * subjects) in the second sample.\n- method: string (default: 'score')\n  Method for the test statistic and the p-value. Options include 'score', 'wald-log', 'score-log', 'waldcc', 'sqrtcc', and 'mover' for the ratio, and 'wald', 'waldccv', 'score', and 'mover' for the difference.\n- compare: string (default: 'ratio')\n  Determines whether the comparison is for the difference ('diff') or the ratio ('ratio') of the rates.\n- alpha: float in (0, 1) (default: 0.05)\n  Significance level, indicating the nominal coverage of the confidence interval.\n\nOutputs:\n- tuple (low, upp): confidence limits\n  A tuple containing the lower and upper confidence limits for the comparison of the two Poisson rates.", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef confint_poisson_2indep(count1, exposure1, count2, exposure2, method=\n    'score', compare='ratio', alpha=0.05, method_mover='score'): [MASK]\n"}
{"method_name": "qsturng", "full_method_name": "qsturng", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/qsturng_.py", "method_code": "from statsmodels.compat.python import lrange\nimport math\nimport scipy.stats\nimport numpy as np\nfrom scipy.optimize import fminbound\ndef qsturng(p, r, v):\n    \"\"\"Approximates the quantile p for a studentized range\n       distribution having v degrees of freedom and r samples\n       for probability p.\n\n    Parameters\n    ----------\n    p : (scalar, array_like)\n        The cumulative probability value\n        p >= .1 and p <=.999\n        (values under .5 are not recommended)\n    r : (scalar, array_like)\n        The number of samples\n        r >= 2 and r <= 200\n        (values over 200 are permitted but not recommended)\n    v : (scalar, array_like)\n        The sample degrees of freedom\n        if p >= .9:\n            v >=1 and v >= inf\n        else:\n            v >=2 and v >= inf\n\n    Returns\n    -------\n    q : (scalar, array_like)\n        approximation of the Studentized Range\n    \"\"\"\n    if all(map(_isfloat, [p, r, v])):\n        return _qsturng(p, r, v)\n    return _vqsturng(p, r, v)", "test_code_list": [{"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestQsturng():\n\tdef test_scalar(self):\n\t    assert_almost_equal(4.43645545899562, qsturng(0.9, 5, 6), 5)\n\t\nTestQsturng().test_scalar()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestQsturng():\n\tdef test_vector(self):\n\t    assert_array_almost_equal(np.array([3.98832389, 4.56835318, 6.26400894]\n\t        ), qsturng([0.8932, 0.9345, 0.9827], [4, 4, 4], [6, 6, 6]), 5)\n\t\nTestQsturng().test_vector()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestQsturng():\n\tdef test_handful_to_tbl(self):\n\t    cases = [(0.75, 30.0, 12.0, 5.01973488482), (0.975, 15.0, 18.0, \n\t        6.00428263999), (0.1, 8.0, 11.0, 1.76248712658), (0.995, 6.0, 17.0,\n\t        6.13684839819), (0.85, 15.0, 18.0, 4.65007986215), (0.75, 17.0, \n\t        18.0, 4.33179650607), (0.75, 60.0, 16.0, 5.50520795792), (0.99, \n\t        100.0, 2.0, 50.3860723433), (0.9, 2.0, 40.0, 2.38132493732), (0.8, \n\t        12.0, 20.0, 4.15361239056), (0.675, 8.0, 14.0, 3.35011529943), (\n\t        0.75, 30.0, 24.0, 4.77976803574), (0.75, 2.0, 18.0, 1.68109190167),\n\t        (0.99, 7.0, 120.0, 5.00525918406), (0.8, 19.0, 15.0, 4.70694373713),\n\t        (0.8, 15.0, 8.0, 4.80392205906), (0.5, 12.0, 11.0, 3.31672775449),\n\t        (0.85, 30.0, 2.0, 10.2308503607), (0.675, 20.0, 18.0, 4.23706426096\n\t        ), (0.1, 60.0, 60.0, 3.69215469278)]\n\t    for p, r, v, q in cases:\n\t        assert_almost_equal(q, qsturng(p, r, v), 5)\n\t\nTestQsturng().test_handful_to_tbl()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestQsturng():\n\tdef test_handful_to_ch(self):\n\t    cases = [(0.8699908, 10.0, 465.4956, 3.997799075635331), (0.8559087, \n\t        43.0, 211.7474, 5.1348419692951675), (0.6019187, 11.0, 386.5556, \n\t        3.338310148769882), (0.658888, 51.0, 74.652, 4.810888048315373), (\n\t        0.6183604, 77.0, 479.8493, 4.986405932173287), (0.9238978, 77.0, \n\t        787.5278, 5.787105300302294), (0.8408322, 7.0, 227.3483, \n\t        3.555579831141358), (0.5930279, 60.0, 325.3461, 4.76580231238824),\n\t        (0.6236158, 61.0, 657.5285, 4.820781275598787), (0.9344575, 72.0, \n\t        846.4138, 5.801434132925911), (0.8761198, 56.0, 677.8171, \n\t        5.362460718311719), (0.7901517, 41.0, 131.525, 4.922283134195054),\n\t        (0.6396423, 44.0, 624.3828, 4.601512725008315), (0.8085966, 14.0, \n\t        251.4224, 4.079305842471975), (0.716179, 45.0, 136.7055, \n\t        4.805549808934009), (0.8204, 6.0, 290.9876, 3.3158771384085597), (\n\t        0.8705345, 83.0, 759.6216, 5.596933456448538), (0.8249085, 18.0, \n\t        661.9321, 4.3283725986180395), (0.9503, 2.0, 4.434, \n\t        3.7871158594867262), (0.7276132, 95.0, 91.43983, 5.410038486849989)]\n\t    for p, r, v, q in cases:\n\t        assert_almost_equal(q, qsturng(p, r, v), 5)\n\t\nTestQsturng().test_handful_to_ch()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\t@pytest.mark.slow\n\tdef test_100_random_values(self):\n\t    n = 100\n\t    random_state = np.random.RandomState(12345)\n\t    ps = random_state.random_sample(n) * (0.999 - 0.1) + 0.1\n\t    rs = random_state.randint(2, 101, n)\n\t    vs = random_state.random_sample(n) * 998.0 + 2.0\n\t    qs = qsturng(ps, rs, vs)\n\t    estimates = psturng(qs, rs, vs)\n\t    actuals = 1.0 - ps\n\t    errors = estimates - actuals\n\t    assert_equal(np.array([]), np.where(errors > 1e-05)[0])\n\t\nTestPsturng().test_100_random_values()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}], "instruction": "Functionality: The qsturng function approximates the quantile for a studentized range distribution. This distribution is characterized by having a specific number of degrees of freedom and a certain number of samples. The function is designed to provide the quantile value corresponding to a given cumulative probability level.\n\nInputs:\n- p (scalar or array_like): The cumulative probability value at which the quantile is sought. The value of p should be within the range of .1 to .999 (inclusive). Note that values under .5 are not recommended for use.\n- r (scalar or array_like): The number of samples in the distribution. This should be an integer value within the range of 2 to 200 (inclusive). Values over 200 are permitted but not recommended.\n- v (scalar or array_like): The degrees of freedom of the sample. If the cumulative probability value p is greater than or equal to .9, then v should be within the range of 1 to infinity. If p is less than .9, then v should be within the range of 2 to infinity.\n\nOutputs:\n- q (scalar or array_like): The function returns an approximation of the Studentized Range quantile corresponding to the input parameters. The output will match the type of the input (scalar or array_like).", "method_code_mask": "from statsmodels.compat.python import lrange\nimport math\nimport scipy.stats\nimport numpy as np\nfrom scipy.optimize import fminbound\n\n\ndef qsturng(p, r, v): [MASK]\n"}
{"method_name": "psturng", "full_method_name": "psturng", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/qsturng_.py", "method_code": "from statsmodels.compat.python import lrange\nimport math\nimport scipy.stats\nimport numpy as np\nfrom scipy.optimize import fminbound\ndef psturng(q, r, v):\n    \"\"\"Evaluates the probability from 0 to q for a studentized\n       range having v degrees of freedom and r samples.\n\n    Parameters\n    ----------\n    q : (scalar, array_like)\n        quantile value of Studentized Range\n        q >= 0.\n    r : (scalar, array_like)\n        The number of samples\n        r >= 2 and r <= 200\n        (values over 200 are permitted but not recommended)\n    v : (scalar, array_like)\n        The sample degrees of freedom\n        if p >= .9:\n            v >=1 and v >= inf\n        else:\n            v >=2 and v >= inf\n\n    Returns\n    -------\n    p : (scalar, array_like)\n        1. - area from zero to q under the Studentized Range\n        distribution. When v == 1, p is bound between .001\n        and .1, when v > 1, p is bound between .001 and .9.\n        Values between .5 and .9 are 1st order appoximations.\n    \"\"\"\n    if all(map(_isfloat, [q, r, v])):\n        return _psturng(q, r, v)\n    return _vpsturng(q, r, v)", "test_code_list": [{"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\tdef test_scalar(self):\n\t    \"\"\"scalar input -> scalar output\"\"\"\n\t    assert_almost_equal(0.1, psturng(4.43645545899562, 5, 6), 5)\n\t\nTestPsturng().test_scalar()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\tdef test_vector(self):\n\t    \"\"\"vector input -> vector output\"\"\"\n\t    assert_array_almost_equal(np.array([0.10679889, 0.06550009, 0.01730145]\n\t        ), psturng([3.98832389, 4.56835318, 6.26400894], [4, 4, 4], [6, 6, \n\t        6]), 5)\n\t\nTestPsturng().test_vector()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\tdef test_v_equal_one(self):\n\t    assert_almost_equal(0.1, psturng(0.2, 5, 1), 5)\n\t\nTestPsturng().test_v_equal_one()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\tdef test_handful_to_known_values(self):\n\t    cases = [(0.7149957872611143, 67, 956.7074248839239, 5.051765844307069),\n\t        (0.4297423485506767, 16, 723.5026173650232, 3.3303582093701354), (\n\t        0.9493642935954842, 2, 916.1867328010926, 2.7677975546417244), (\n\t        0.8535738177072504, 66, 65.67055060832368, 5.564743810827011), (\n\t        0.8737210802190093, 74, 626.4236947499363, 5.535554057070111), (\n\t        0.5389196056471373, 49, 862.6379943848578, 4.510864592337715), (\n\t        0.9881865955566457, 18, 36.269686711464274, 6.090664375088616), (\n\t        0.5303199489603763, 50, 265.29558652727917, 4.5179640079726795), (\n\t        0.7318857887397332, 59, 701.414975522512, 4.9980139875409915), (\n\t        0.653320193689827, 61, 591.0118366419591, 4.870658176670689), (\n\t        0.5540322165724856, 77, 907.3415672540519, 4.878613591798463), (\n\t        0.30783916857266, 83, 82.44692348798088, 4.439640124285829), (\n\t        0.2932172024241566, 16, 709.6438257555301, 3.030427754070273), (\n\t        0.27146478168880306, 31, 590.0059468357417, 3.5870031664477215), (\n\t        0.6734879695843378, 81, 608.0270611112766, 5.109619997443294), (\n\t        0.3277439394596894, 18, 17.70622439925084, 3.211903816376543), (\n\t        0.7081637474795982, 72, 443.10678914889695, 5.099003088941065), (\n\t        0.3335493927675786, 47, 544.0772192199048, 4.061335296419328), (\n\t        0.6041214394736305, 36, 895.8352693327155, 4.381717596850172), (\n\t        0.8873905230066598, 77, 426.0366551155826, 5.633392948034131)]\n\t    for p, r, v, q in cases:\n\t        assert_almost_equal(1.0 - p, psturng(q, r, v), 5)\n\t\nTestPsturng().test_handful_to_known_values()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}, {"test_code": "from statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lmap\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_raises\nimport numpy as np\nimport pytest\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport os\n\nclass TestPsturng():\n\t@pytest.mark.slow\n\tdef test_100_random_values(self):\n\t    n = 100\n\t    random_state = np.random.RandomState(12345)\n\t    ps = random_state.random_sample(n) * (0.999 - 0.1) + 0.1\n\t    rs = random_state.randint(2, 101, n)\n\t    vs = random_state.random_sample(n) * 998.0 + 2.0\n\t    qs = qsturng(ps, rs, vs)\n\t    estimates = psturng(qs, rs, vs)\n\t    actuals = 1.0 - ps\n\t    errors = estimates - actuals\n\t    assert_equal(np.array([]), np.where(errors > 1e-05)[0])\n\t\nTestPsturng().test_100_random_values()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/libqsturng/tests/test_qsturng.py"}], "instruction": "Functionality: The psturng function calculates the probability from 0 to q for a studentized range distribution, which is useful in statistical hypothesis testing, particularly for range tests. This function is applicable when dealing with the comparison of means from r samples, each having v degrees of freedom.\n\nInputs: \n- q : The quantile value of Studentized Range. This should be a scalar or array-like value, with the constraint that q >= 0.\n- r : The number of samples. This must also be a scalar or array-like value, and it should satisfy the condition r >= 2 and r <= 200. Note that values over 200 are technically allowed but not recommended.\n- v : The sample degrees of freedom. This is a scalar or array-like value and its range depends on the value of p (not a direct input but a calculated output), if p >= .9: v >=1 and v <= infinity; else: v >=2 and v <= infinity.\n\nOutputs:\n- p : This output is a scalar or array-like value representing 1. - the area from zero to q under the Studentized Range distribution. The value of p is bound between .001 and .1 when v == 1, and between .001 and .9 when v > 1. Values in the range between .5 and .9 are considered to be 1st order approximations.", "method_code_mask": "from statsmodels.compat.python import lrange\nimport math\nimport scipy.stats\nimport numpy as np\nfrom scipy.optimize import fminbound\n\n\ndef psturng(q, r, v): [MASK]\n"}
{"method_name": "fdrcorrection_twostage", "full_method_name": "fdrcorrection_twostage", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/multitest.py", "method_code": "import numpy as np\nfrom statsmodels.stats._knockoff import RegressionFDR\nimport gc\nimport warnings\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import families\nfrom statsmodels.regression.linear_model import OLS\nfrom scipy.stats.distributions import norm\nfrom scipy.optimize import minimize\ndef fdrcorrection_twostage(pvals, alpha=0.05, method='bky', maxiter=1, iter\n    =None, is_sorted=False):\n    \"\"\"(iterated) two stage linear step-up procedure with estimation of number of true\n    hypotheses\n\n    Benjamini, Krieger and Yekuteli, procedure in Definition 6\n\n    Parameters\n    ----------\n    pvals : array_like\n        set of p-values of the individual tests.\n    alpha : float\n        error rate\n    method : {'bky', 'bh')\n        see Notes for details\n\n        * 'bky' - implements the procedure in Definition 6 of Benjamini, Krieger\n           and Yekuteli 2006\n        * 'bh' - the two stage method of Benjamini and Hochberg\n\n    maxiter : int or bool\n        Maximum number of iterations.\n        maxiter=1 (default) corresponds to the two stage method.\n        maxiter=-1 corresponds to full iterations which is maxiter=len(pvals).\n        maxiter=0 uses only a single stage fdr correction using a 'bh' or 'bky'\n        prior fraction of assumed true hypotheses.\n        Boolean maxiter is allowed for backwards compatibility with the\n        deprecated ``iter`` keyword.\n        maxiter=False is two-stage fdr (maxiter=1)\n        maxiter=True is full iteration (maxiter=-1 or maxiter=len(pvals))\n\n        .. versionadded:: 0.14\n\n            Replacement for ``iter`` with additional features.\n\n    iter : bool\n        ``iter`` is deprecated use ``maxiter`` instead.\n        If iter is True, then only one iteration step is used, this is the\n        two-step method.\n        If iter is False, then iterations are stopped at convergence which\n        occurs in a finite number of steps (at most len(pvals) steps).\n\n        .. deprecated:: 0.14\n\n            Use ``maxiter`` instead of ``iter``.\n\n    Returns\n    -------\n    rejected : ndarray, bool\n        True if a hypothesis is rejected, False if not\n    pvalue-corrected : ndarray\n        pvalues adjusted for multiple hypotheses testing to limit FDR\n    m0 : int\n        ntest - rej, estimated number of true (not rejected) hypotheses\n    alpha_stages : list of floats\n        A list of alphas that have been used at each stage\n\n    Notes\n    -----\n    The returned corrected p-values are specific to the given alpha, they\n    cannot be used for a different alpha.\n\n    The returned corrected p-values are from the last stage of the fdr_bh\n    linear step-up procedure (fdrcorrection0 with method='indep') corrected\n    for the estimated fraction of true hypotheses.\n    This means that the rejection decision can be obtained with\n    ``pval_corrected <= alpha``, where ``alpha`` is the original significance\n    level.\n    (Note: This has changed from earlier versions (<0.5.0) of statsmodels.)\n\n    BKY described several other multi-stage methods, which would be easy to implement.\n    However, in their simulation the simple two-stage method (with iter=False) was the\n    most robust to the presence of positive correlation\n\n    TODO: What should be returned?\n\n    \"\"\"\n    pvals = np.asarray(pvals)\n    if iter is not None:\n        import warnings\n        msg = 'iter keyword is deprecated, use maxiter keyword instead.'\n        warnings.warn(msg, FutureWarning)\n    if iter is False:\n        maxiter = 1\n    elif iter is True or maxiter in [-1, None]:\n        maxiter = len(pvals)\n    if not is_sorted:\n        pvals_sortind = np.argsort(pvals)\n        pvals = np.take(pvals, pvals_sortind)\n    ntests = len(pvals)\n    if method == 'bky':\n        fact = 1.0 + alpha\n        alpha_prime = alpha / fact\n    elif method == 'bh':\n        fact = 1.0\n        alpha_prime = alpha\n    else:\n        raise ValueError(\"only 'bky' and 'bh' are available as method\")\n    alpha_stages = [alpha_prime]\n    rej, pvalscorr = fdrcorrection(pvals, alpha=alpha_prime, method='indep',\n        is_sorted=True)\n    r1 = rej.sum()\n    if r1 == 0 or r1 == ntests:\n        reject = rej\n        pvalscorr *= fact\n        ri = r1\n    else:\n        ri_old = ri = r1\n        ntests0 = ntests\n        for it in range(maxiter):\n            ntests0 = 1.0 * ntests - ri_old\n            alpha_star = alpha_prime * ntests / ntests0\n            alpha_stages.append(alpha_star)\n            rej, pvalscorr = fdrcorrection(pvals, alpha=alpha_star, method=\n                'indep', is_sorted=True)\n            ri = rej.sum()\n            if it >= maxiter - 1 or ri == ri_old:\n                break\n            elif ri < ri_old:\n                raise RuntimeError(' oops - should not be here')\n            ri_old = ri\n        pvalscorr *= ntests0 * 1.0 / ntests\n        if method == 'bky':\n            pvalscorr *= 1.0 + alpha\n    pvalscorr[pvalscorr > 1] = 1\n    if not is_sorted:\n        pvalscorr_ = np.empty_like(pvalscorr)\n        pvalscorr_[pvals_sortind] = pvalscorr\n        del pvalscorr\n        reject = np.empty_like(rej)\n        reject[pvals_sortind] = rej\n        return reject, pvalscorr_, ntests - ri, alpha_stages\n    else:\n        return rej, pvalscorr, ntests - ri, alpha_stages", "test_code_list": [{"test_code": "import pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.stats.multitest import fdrcorrection\nfrom statsmodels.stats.multitest import fdrcorrection_twostage\nfrom statsmodels.stats.multitest import NullDistribution\nfrom statsmodels.stats.multitest import local_fdr\nfrom statsmodels.stats.multitest import multitest_methods_names\nfrom statsmodels.stats.multicomp import tukeyhsd\nfrom scipy.stats.distributions import norm\nimport scipy\nfrom packaging import version\ndef test_fdr_bky():\n    pvals = [0.0001, 0.0004, 0.0019, 0.0095, 0.0201, 0.0278, 0.0298, 0.0344,\n        0.0459, 0.324, 0.4262, 0.5719, 0.6528, 0.759, 1.0]\n    with pytest.warns(FutureWarning, match='iter keyword'):\n        res_tst = fdrcorrection_twostage(pvals, alpha=0.05, iter=False)\n    assert_almost_equal([0.047619, 0.0649], res_tst[-1][:2], 3)\n    assert_equal(8, res_tst[0].sum())\n    res2 = np.array([0.0012, 0.0023, 0.0073, 0.0274, 0.0464, 0.0492, 0.0492,\n        0.0497, 0.0589, 0.3742, 0.4475, 0.5505, 0.58, 0.6262, 0.77])\n    assert_allclose(res_tst[1], res2, atol=6e-05)\n    pvals = np.array([0.2, 0.8, 0.3, 0.5, 1])\n    res1 = fdrcorrection_twostage(pvals, alpha=0.05, method='bky')\n    res2 = multipletests(pvals, alpha=0.05, method='fdr_tsbky')\n    assert_equal(res1[0], res2[0])\n    assert_allclose(res1[1], res2[1], atol=6e-05)\n    res_pv = np.array([0.7875, 1.0, 0.7875, 0.875, 1.0])\n    assert_allclose(res1[1], res_pv, atol=6e-05)\n\ntest_fdr_bky()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multi.py"}, {"test_code": "import pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.stats.multitest import fdrcorrection\nfrom statsmodels.stats.multitest import fdrcorrection_twostage\nfrom statsmodels.stats.multitest import NullDistribution\nfrom statsmodels.stats.multitest import local_fdr\nfrom statsmodels.stats.multitest import multitest_methods_names\nfrom statsmodels.stats.multicomp import tukeyhsd\nfrom scipy.stats.distributions import norm\nimport scipy\nfrom packaging import version\ndef test_fdr_twostage():\n    pvals = [0.0001, 0.0004, 0.0019, 0.0095, 0.0201, 0.0278, 0.0298, 0.0344,\n        0.0459, 0.324, 0.4262, 0.5719, 0.6528, 0.759, 1.0]\n    n = len(pvals)\n    k = 0\n    res0 = multipletests(pvals, alpha=0.05, method='fdr_bh')\n    res1 = fdrcorrection_twostage(pvals, alpha=0.05, method='bh', maxiter=k,\n        iter=None)\n    res2 = multipletests(pvals, alpha=0.05, method='fdr_tsbh', maxiter=k)\n    assert_allclose(res1[1], res0[1])\n    assert_allclose(res2[1], res1[1])\n    k = 1\n    res0 = multipletests(pvals, alpha=0.05, method='fdr_bh')\n    res1 = fdrcorrection_twostage(pvals, alpha=0.05, method='bh', maxiter=k,\n        iter=None)\n    res2 = multipletests(pvals, alpha=0.05, method='fdr_tsbh', maxiter=k)\n    res3 = multipletests(pvals, alpha=0.05, method='fdr_tsbh')\n    assert_allclose(res1[1], res0[1] * (1 - res0[0].sum() / n))\n    assert_allclose(res2[1], res1[1])\n    assert_allclose(res3[1], res1[1])\n    fact = 1 + 0.05\n    k = 0\n    res0 = multipletests(pvals, alpha=0.05, method='fdr_bh')\n    res1 = fdrcorrection_twostage(pvals, alpha=0.05, method='bky', maxiter=\n        k, iter=None)\n    res2 = multipletests(pvals, alpha=0.05, method='fdr_tsbky', maxiter=k)\n    assert_allclose(res1[1], np.clip(res0[1] * fact, 0, 1))\n    assert_allclose(res2[1], res1[1])\n    k = 1\n    res0 = multipletests(pvals, alpha=0.05, method='fdr_bh')\n    res1 = fdrcorrection_twostage(pvals, alpha=0.05, method='bky', maxiter=\n        k, iter=None)\n    res2 = multipletests(pvals, alpha=0.05, method='fdr_tsbky', maxiter=k)\n    res3 = multipletests(pvals, alpha=0.05, method='fdr_tsbky')\n    assert_allclose(res1[1], res0[1] * (1 - res0[0].sum() / n) * fact)\n    assert_allclose(res2[1], res1[1])\n    assert_allclose(res3[1], res1[1])\n\ntest_fdr_twostage()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multi.py"}], "instruction": "Functionality: The fdrcorrection_twostage function implements an iterated two-stage linear step-up procedure for controlling the False Discovery Rate (FDR) in multiple hypothesis testing. This function is particularly useful when dealing with a set of p-values from individual tests, aiming to identify which null hypotheses can be rejected while controlling the expected proportion of incorrectly rejected null hypotheses.\n\nInputs:\n- pvals: An array of p-values from the individual tests.\n- alpha: A float representing the desired error rate (default is 0.05).\n- method: A string specifying the method to use - 'bky' for the Benjamini, Krieger, and Yekuteli procedure, or 'bh' for the two-stage method of Benjamini and Hochberg (default is 'bky').\n- maxiter: An integer or boolean value determining the maximum number of iterations (default is 1 for two-stage method).\n- iter: A boolean argument that is deprecated and should be replaced by maxiter (default is None).\n- is_sorted: A boolean indicating whether the p-values are already sorted (default is False).\n\nOutputs:\n- rejected: A boolean array where True indicates a hypothesis is rejected, and False indicates it is not.\n- pvalue_corrected: An array of p-values adjusted to control FDR.\n- m0: An integer representing the estimated number of true (not rejected) hypotheses.\n- alpha_stages: A list of floats showing the alphas used at each stage of the procedure.", "method_code_mask": "import numpy as np\nfrom statsmodels.stats._knockoff import RegressionFDR\nimport gc\nimport warnings\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import families\nfrom statsmodels.regression.linear_model import OLS\nfrom scipy.stats.distributions import norm\nfrom scipy.optimize import minimize\n\n\ndef fdrcorrection_twostage(pvals, alpha=0.05, method='bky', maxiter=1, iter\n    =None, is_sorted=False): [MASK]\n"}
{"method_name": "local_fdr", "full_method_name": "local_fdr", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/multitest.py", "method_code": "import numpy as np\nfrom statsmodels.stats._knockoff import RegressionFDR\nimport gc\nimport warnings\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import families\nfrom statsmodels.regression.linear_model import OLS\nfrom scipy.stats.distributions import norm\nfrom scipy.optimize import minimize\ndef local_fdr(zscores, null_proportion=1.0, null_pdf=None, deg=7, nbins=30,\n    alpha=0):\n    \"\"\"\n    Calculate local FDR values for a list of Z-scores.\n\n    Parameters\n    ----------\n    zscores : array_like\n        A vector of Z-scores\n    null_proportion : float\n        The assumed proportion of true null hypotheses\n    null_pdf : function mapping reals to positive reals\n        The density of null Z-scores; if None, use standard normal\n    deg : int\n        The maximum exponent in the polynomial expansion of the\n        density of non-null Z-scores\n    nbins : int\n        The number of bins for estimating the marginal density\n        of Z-scores.\n    alpha : float\n        Use Poisson ridge regression with parameter alpha to estimate\n        the density of non-null Z-scores.\n\n    Returns\n    -------\n    fdr : array_like\n        A vector of FDR values\n\n    References\n    ----------\n    B Efron (2008).  Microarrays, Empirical Bayes, and the Two-Groups\n    Model.  Statistical Science 23:1, 1-22.\n\n    Examples\n    --------\n    Basic use (the null Z-scores are taken to be standard normal):\n\n    >>> from statsmodels.stats.multitest import local_fdr\n    >>> import numpy as np\n    >>> zscores = np.random.randn(30)\n    >>> fdr = local_fdr(zscores)\n\n    Use a Gaussian null distribution estimated from the data:\n\n    >>> null = EmpiricalNull(zscores)\n    >>> fdr = local_fdr(zscores, null_pdf=null.pdf)\n    \"\"\"\n    from statsmodels.genmod.generalized_linear_model import GLM\n    from statsmodels.genmod.generalized_linear_model import families\n    from statsmodels.regression.linear_model import OLS\n    minz = min(zscores)\n    maxz = max(zscores)\n    bins = np.linspace(minz, maxz, nbins)\n    zhist = np.histogram(zscores, bins)[0]\n    zbins = (bins[:-1] + bins[1:]) / 2\n    dmat = np.vander(zbins, deg + 1)\n    sd = dmat.std(0)\n    ii = sd > 1e-08\n    dmat[:, ii] /= sd[ii]\n    start = OLS(np.log(1 + zhist), dmat).fit().params\n    if alpha > 0:\n        md = GLM(zhist, dmat, family=families.Poisson()).fit_regularized(L1_wt\n            =0, alpha=alpha, start_params=start)\n    else:\n        md = GLM(zhist, dmat, family=families.Poisson()).fit(start_params=start\n            )\n    dmat_full = np.vander(zscores, deg + 1)\n    dmat_full[:, ii] /= sd[ii]\n    fz = md.predict(dmat_full) / (len(zscores) * (bins[1] - bins[0]))\n    if null_pdf is None:\n        f0 = np.exp(-0.5 * zscores ** 2) / np.sqrt(2 * np.pi)\n    else:\n        f0 = null_pdf(zscores)\n    fdr = null_proportion * f0 / fz\n    fdr = np.clip(fdr, 0, 1)\n    return fdr", "test_code_list": [{"test_code": "import pytest\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.stats.multitest import fdrcorrection\nfrom statsmodels.stats.multitest import fdrcorrection_twostage\nfrom statsmodels.stats.multitest import NullDistribution\nfrom statsmodels.stats.multitest import local_fdr\nfrom statsmodels.stats.multitest import multitest_methods_names\nfrom statsmodels.stats.multicomp import tukeyhsd\nfrom scipy.stats.distributions import norm\nimport scipy\nfrom packaging import version\ndef test_local_fdr():\n    grid = np.linspace(0.001, 0.999, 1000)\n    z0 = norm.ppf(grid)\n    z1 = np.linspace(3, 4, 20)\n    zs = np.concatenate((z0, z1))\n    f1 = np.exp(-z1 ** 2 / 2) / np.sqrt(2 * np.pi)\n    r = len(z1) / float(len(z0) + len(z1))\n    f1 /= (1 - r) * f1 + r\n    for alpha in (None, 0, 1e-08):\n        if alpha is None:\n            fdr = local_fdr(zs)\n        else:\n            fdr = local_fdr(zs, alpha=alpha)\n        fdr1 = fdr[len(z0):]\n        assert_allclose(f1, fdr1, rtol=0.05, atol=0.1)\n\ntest_local_fdr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multi.py"}], "instruction": "Functionality: Calculate local false discovery rate (FDR) values for a list of Z-scores using the two-groups model as described by B. Efron in 2008. This function estimates the proportion of true null hypotheses and the density of both null and non-null Z-scores to compute the local FDR.\n\nInputs:\n- zscores: An array-like object containing Z-scores.\n- null_proportion: A float representing the assumed proportion of true null hypotheses. Default is 1.0.\n- null_pdf: A function mapping reals to positive reals. It represents the density of null Z-scores. If None, standard normal distribution is used. Default is None.\n- deg: An integer specifying the maximum exponent in the polynomial expansion of the density of non-null Z-scores. Default is 7.\n- nbins: An integer indicating the number of bins for estimating the marginal density of Z-scores. Default is 30.\n- alpha: A float used for Poisson ridge regression with parameter alpha to estimate the density of non-null Z-scores. Default is 0.\n\nOutputs:\n- fdr: An array-like object containing FDR values corresponding to the input Z-scores.", "method_code_mask": "import numpy as np\nfrom statsmodels.stats._knockoff import RegressionFDR\nimport gc\nimport warnings\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import families\nfrom statsmodels.regression.linear_model import OLS\nfrom scipy.stats.distributions import norm\nfrom scipy.optimize import minimize\n\n\ndef local_fdr(zscores, null_proportion=1.0, null_pdf=None, deg=7, nbins=30,\n    alpha=0): [MASK]\n"}
{"method_name": "kernel_covariance", "full_method_name": "kernel_covariance", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef kernel_covariance(exog, loc, groups, kernel=None, bw=None):\n    \"\"\"\n    Use kernel averaging to estimate a multivariate covariance function.\n\n    The goal is to estimate a covariance function C(x, y) =\n    cov(Z(x), Z(y)) where x, y are vectors in R^p (e.g. representing\n    locations in time or space), and Z(.) represents a multivariate\n    process on R^p.\n\n    The data used for estimation can be observed at arbitrary values of the\n    position vector, and there can be multiple independent observations\n    from the process.\n\n    Parameters\n    ----------\n    exog : array_like\n        The rows of exog are realizations of the process obtained at\n        specified points.\n    loc : array_like\n        The rows of loc are the locations (e.g. in space or time) at\n        which the rows of exog are observed.\n    groups : array_like\n        The values of groups are labels for distinct independent copies\n        of the process.\n    kernel : MultivariateKernel instance, optional\n        An instance of MultivariateKernel, defaults to\n        GaussianMultivariateKernel.\n    bw : array_like or scalar\n        A bandwidth vector, or bandwidth multiplier.  If a 1d array, it\n        contains kernel bandwidths for each component of the process, and\n        must have length equal to the number of columns of exog.  If a scalar,\n        bw is a bandwidth multiplier used to adjust the default bandwidth; if\n        None, a default bandwidth is used.\n\n    Returns\n    -------\n    A real-valued function C(x, y) that returns an estimate of the covariance\n    between values of the process located at x and y.\n\n    References\n    ----------\n    .. [1] Genton M, W Kleiber (2015).  Cross covariance functions for\n        multivariate geostatics.  Statistical Science 30(2).\n        https://arxiv.org/pdf/1507.08017.pdf\n    \"\"\"\n    exog = np.asarray(exog)\n    loc = np.asarray(loc)\n    groups = np.asarray(groups)\n    if loc.ndim == 1:\n        loc = loc[:, None]\n    v = [exog.shape[0], loc.shape[0], len(groups)]\n    if min(v) != max(v):\n        msg = 'exog, loc, and groups must have the same number of rows'\n        raise ValueError(msg)\n    ix = {}\n    for i, g in enumerate(groups):\n        if g not in ix:\n            ix[g] = []\n        ix[g].append(i)\n    for g in ix.keys():\n        ix[g] = np.sort(ix[g])\n    if kernel is None:\n        kernel = GaussianMultivariateKernel()\n    if bw is None:\n        kernel.set_default_bw(loc)\n    elif np.isscalar(bw):\n        kernel.set_default_bw(loc, bwm=bw)\n    else:\n        kernel.set_bandwidth(bw)\n\n    def cov(x, y):\n        kx = kernel.call(x, loc)\n        ky = kernel.call(y, loc)\n        cm, cw = 0.0, 0.0\n        for g, ii in ix.items():\n            m = len(ii)\n            j1, j2 = np.indices((m, m))\n            j1 = ii[j1.flat]\n            j2 = ii[j2.flat]\n            w = kx[j1] * ky[j2]\n            cm += np.einsum('ij,ik,i->jk', exog[j1, :], exog[j2, :], w)\n            cw += w.sum()\n        if cw < 1e-10:\n            msg = ('Effective sample size is 0.  The bandwidth may be too ' +\n                'small, or you are outside the range of your data.')\n            warnings.warn(msg)\n            return np.nan * np.ones_like(cm)\n        return cm / cw\n    return cov", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.stats.correlation_tools import kernel_covariance\nfrom statsmodels.stats.correlation_tools import GaussianMultivariateKernel\nfrom numpy.testing import assert_allclose\ndef test_kernel_covariance():\n    np.random.seed(342)\n    ng = 1000\n    p = 3\n    r = 0.5\n    ii = np.arange(10)\n    qm = r ** np.abs(np.subtract.outer(ii, ii))\n    qm = np.linalg.cholesky(qm)\n    exog, groups, pos = [], [], []\n    for j in range(ng):\n        pos1 = np.arange(10)[:, None]\n        groups1 = j * np.ones(10)\n        ex1 = np.random.normal(size=(10, 3))\n        ex1 = np.dot(qm, ex1)\n        pos.append(pos1)\n        groups.append(groups1)\n        exog.append(ex1)\n    groups = np.concatenate(groups)\n    pos = np.concatenate(pos, axis=0)\n    exog = np.concatenate(exog, axis=0)\n    for j in range(4):\n        if j == 0:\n            kernel = None\n            bw = None\n        elif j == 1:\n            kernel = GaussianMultivariateKernel()\n            bw = None\n        elif j == 2:\n            kernel = GaussianMultivariateKernel()\n            bw = 1\n        elif j == 3:\n            kernel = GaussianMultivariateKernel()\n            bw = kernel.set_default_bw(pos)\n        cv = kernel_covariance(exog, pos, groups, kernel=kernel, bw=bw)\n        assert_allclose(cv(0, 0), np.eye(p), atol=0.1, rtol=0.01)\n        assert_allclose(cv(0, 1), 0.5 * np.eye(p), atol=0.1, rtol=0.01)\n        assert_allclose(cv(0, 2), 0.25 * np.eye(p), atol=0.1, rtol=0.01)\n        assert_allclose(cv(1, 2), 0.5 * np.eye(p), atol=0.1, rtol=0.01)\n\ntest_kernel_covariance()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_correlation.py"}], "instruction": "Functionality: Estimate a multivariate covariance function using kernel averaging. The function aims to estimate the covariance between values of a multivariate process located at different points in space or time, based on data observed at arbitrary locations.\n\nInputs:\n- exog: An array where each row is a realization of the process obtained at specified points.\n- loc: An array where each row represents the locations (in space or time) at which the rows of exog are observed.\n- groups: An array containing labels for distinct independent copies of the process.\n- kernel: (Optional) An instance of MultivariateKernel. Defaults to GaussianMultivariateKernel if not provided.\n- bw: (Optional) Either a 1D array containing kernel bandwidths for each component of the process, a scalar as a bandwidth multiplier, or None to use the default bandwidth.\n\nOutputs:\n- A function C(x, y) that estimates the covariance between values of the process located at x and y. The function takes two vectors (x and y) as input and returns an estimate of their covariance.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef kernel_covariance(exog, loc, groups, kernel=None, bw=None): [MASK]\n"}
{"method_name": "normal_power", "full_method_name": "normal_power", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/power.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import stats\nfrom scipy import optimize\nfrom scipy import special\nfrom statsmodels.tools.rootfinding import brentq_expanding\nfrom collections import defaultdict\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import convergence_doc\nfrom statsmodels.graphics import utils\nfrom statsmodels.graphics.plottools import rainbow\nimport matplotlib.pyplot as plt\nfrom statsmodels.stats.gof import chisquare_power\ndef normal_power(effect_size, nobs, alpha, alternative='two-sided', sigma=1.0):\n    \"\"\"Calculate power of a normal distributed test statistic\n\n    This is an generalization of `normal_power` when variance under Null and\n    Alternative differ.\n\n    Parameters\n    ----------\n    effect size : float\n        difference in the estimated means or statistics under the alternative\n        normalized by the standard deviation (without division by sqrt(nobs).\n    nobs : float or int\n        number of observations\n    alpha : float in interval (0,1)\n        significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        extra argument to choose whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    \"\"\"\n    d = effect_size\n    if alternative in ['two-sided', '2s']:\n        alpha_ = alpha / 2.0\n    elif alternative in ['smaller', 'larger']:\n        alpha_ = alpha\n    else:\n        raise ValueError(\"alternative has to be 'two-sided', 'larger' \" +\n            \"or 'smaller'\")\n    pow_ = 0\n    if alternative in ['two-sided', '2s', 'larger']:\n        crit = stats.norm.isf(alpha_)\n        pow_ = stats.norm.sf(crit - d * np.sqrt(nobs) / sigma)\n    if alternative in ['two-sided', '2s', 'smaller']:\n        crit = stats.norm.ppf(alpha_)\n        pow_ += stats.norm.cdf(crit - d * np.sqrt(nobs) / sigma)\n    return pow_", "test_code_list": [{"test_code": "import copy\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_array_equal\nimport pytest\nimport statsmodels.stats.power as smp\nfrom statsmodels.stats.tests.test_weightstats import Holder\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nimport matplotlib.pyplot as plt\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef test_normal_power_explicit():\n    sigma = 1\n    d = 0.3\n    nobs = 80\n    alpha = 0.05\n    res1 = normal_power(d, nobs / 2.0, 0.05)\n    res2 = smp.NormalIndPower().power(d, nobs, 0.05)\n    res3 = smp.NormalIndPower().solve_power(effect_size=0.3, nobs1=80,\n        alpha=0.05, power=None)\n    res_R = 0.475100870572638\n    assert_almost_equal(res1, res_R, decimal=13)\n    assert_almost_equal(res2, res_R, decimal=13)\n    assert_almost_equal(res3, res_R, decimal=13)\n    norm_pow = normal_power(-0.01, nobs / 2.0, 0.05)\n    norm_pow_R = 0.05045832927039234\n    assert_almost_equal(norm_pow, norm_pow_R, decimal=11)\n    norm_pow = smp.NormalIndPower().power(0.01, nobs, 0.05, alternative=\n        'larger')\n    norm_pow_R = 0.056869534873146124\n    assert_almost_equal(norm_pow, norm_pow_R, decimal=11)\n    norm_pow = smp.NormalIndPower().power(-0.01, nobs, 0.05, alternative=\n        'larger')\n    norm_pow_R = 0.0438089705093578\n    assert_almost_equal(norm_pow, norm_pow_R, decimal=11)\n\ntest_normal_power_explicit()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_power.py"}], "instruction": "Functionality: The function `normal_power` calculates the power of a test statistic that follows a normal distribution. This function generalizes the calculation of power when the variance under the null and alternative hypotheses may differ. It is designed to help determine the probability of correctly rejecting the null hypothesis when it is indeed false.\n\nInputs:\n- effect_size : float\n    The difference in the estimated means or statistics under the alternative hypothesis, normalized by the standard deviation, not considering the division by the square root of the number of observations.\n- nobs : float or int\n    The number of observations in the sample.\n- alpha : float in interval (0,1)\n    The significance level, which is the probability of a type I error, or incorrectly rejecting the null hypothesis when it is true. Common values are 0.05 or 0.01.\n- alternative : string, default 'two-sided'\n    Specifies the alternative hypothesis for the test. It can be 'two-sided', 'larger', or 'smaller'. 'Two-sided' tests whether the population parameter is different from the null hypothesis value in either direction, while 'larger' or 'smaller' tests whether the population parameter is greater than or less than the null hypothesis value, respectively.\n- sigma : float, default 1.0\n    The standard deviation of the distribution under the null hypothesis.\n\nOutputs:\n- pow_ : float\n    The calculated power of the test statistic. This is the probability of correctly rejecting the null hypothesis when the alternative hypothesis is true, given the specified effect size, sample size, and significance level.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import stats\nfrom scipy import optimize\nfrom scipy import special\nfrom statsmodels.tools.rootfinding import brentq_expanding\nfrom collections import defaultdict\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import convergence_doc\nfrom statsmodels.graphics import utils\nfrom statsmodels.graphics.plottools import rainbow\nimport matplotlib.pyplot as plt\nfrom statsmodels.stats.gof import chisquare_power\n\n\ndef normal_power(effect_size, nobs, alpha, alternative='two-sided', sigma=1.0\n    ): [MASK]\n"}
{"method_name": "normal_sample_size_one_tail", "full_method_name": "normal_sample_size_one_tail", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/power.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import stats\nfrom scipy import optimize\nfrom scipy import special\nfrom statsmodels.tools.rootfinding import brentq_expanding\nfrom collections import defaultdict\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import convergence_doc\nfrom statsmodels.graphics import utils\nfrom statsmodels.graphics.plottools import rainbow\nimport matplotlib.pyplot as plt\nfrom statsmodels.stats.gof import chisquare_power\ndef normal_sample_size_one_tail(diff, power, alpha, std_null=1.0,\n    std_alternative=None):\n    \"\"\"explicit sample size computation if only one tail is relevant\n\n    The sample size is based on the power in one tail assuming that the\n    alternative is in the tail where the test has power that increases\n    with sample size.\n    Use alpha/2 to compute the one tail approximation to the two-sided\n    test, i.e. consider only one tail of two-sided test.\n\n    Parameters\n    ----------\n    diff : float\n        difference in the estimated means or statistics under the alternative.\n    power : float in interval (0,1)\n        power of the test, e.g. 0.8, is one minus the probability of a type II\n        error. Power is the probability that the test correctly rejects the\n        Null Hypothesis if the Alternative Hypothesis is true.\n    alpha : float in interval (0,1)\n        significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n        Note: alpha is used for one tail. Use alpha/2 for two-sided\n        alternative.\n    std_null : float\n        standard deviation under the Null hypothesis without division by\n        sqrt(nobs)\n    std_alternative : float\n        standard deviation under the Alternative hypothesis without division\n        by sqrt(nobs). Defaults to None. If None, ``std_alternative`` is set\n        to the value of ``std_null``.\n\n    Returns\n    -------\n    nobs : float\n        Sample size to achieve (at least) the desired power.\n        If the minimum power is satisfied for all positive sample sizes, then\n        ``nobs`` will be zero. This will be the case when power <= alpha if\n        std_alternative is equal to std_null.\n\n    \"\"\"\n    if std_alternative is None:\n        std_alternative = std_null\n    crit_power = stats.norm.isf(power)\n    crit = stats.norm.isf(alpha)\n    n1 = (np.maximum(crit * std_null - crit_power * std_alternative, 0) / diff\n        ) ** 2\n    return n1", "test_code_list": [{"test_code": "import copy\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_array_equal\nimport pytest\nimport statsmodels.stats.power as smp\nfrom statsmodels.stats.tests.test_weightstats import Holder\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nimport matplotlib.pyplot as plt\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef test_normal_sample_size_one_tail():\n    normal_sample_size_one_tail(5, 0.8, 0.05, 2, std_alternative=None)\n    alphas = np.asarray([0.01, 0.05, 0.1, 0.5, 0.8])\n    powers = np.asarray([0.99, 0.95, 0.9, 0.5, 0.2])\n    nobs_with_zeros = normal_sample_size_one_tail(5, powers, alphas, 2, 2)\n    assert_array_equal(nobs_with_zeros[powers <= alphas], 0)\n\ntest_normal_sample_size_one_tail()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_power.py"}, {"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_power_2indep():\n    pow_ = power_proportions_2indep(-0.25, 0.75, 76.70692)\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.25, 0.75, 0.9, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 76.70692, atol=1e-05)\n    power_proportions_2indep(-0.25, 0.75, 62.33551, alternative='smaller')\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative='smaller')\n    assert_array_less(pow_.power, 0.05)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative=\n        'larger', return_results=False)\n    assert_allclose(pow_, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(-0.15, 0.65, 83.4373, return_results=False)\n    assert_allclose(pow_, 0.5, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.15, 0.65, 0.5, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 83.4373, atol=0.05)\n    from statsmodels.stats.power import normal_sample_size_one_tail\n    res = power_proportions_2indep(-0.014, 0.015, 550, ratio=1.0)\n    assert_allclose(res.power, 0.74156, atol=1e-07)\n    n = normal_sample_size_one_tail(-0.014, 0.74156, 0.05 / 2, std_null=res\n        .std_null, std_alternative=res.std_alt)\n    assert_allclose(n, 550, atol=0.05)\n    n2 = samplesize_proportions_2indep_onetail(-0.014, 0.015, 0.74156,\n        ratio=1, alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n2, n, rtol=1e-13)\n    pwr_st = 0.7995659211532175\n    n = 154\n    res = power_proportions_2indep(-0.1, 0.2, n, ratio=2.0)\n    assert_allclose(res.power, pwr_st, atol=1e-07)\n    n2 = samplesize_proportions_2indep_onetail(-0.1, 0.2, pwr_st, ratio=2)\n    assert_allclose(n2, n, rtol=0.0001)\n\ntest_power_2indep()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: Computes the explicit sample size required for a one-tailed test assuming the alternative hypothesis is in the tail where test power increases with sample size. This function is based on the difference in estimated means, the desired power of the test, the significance level, and standard deviations under the null and alternative hypotheses.\n\nInputs:\n- diff: A float representing the difference in estimated means or statistics under the alternative hypothesis.\n- power: A float in the interval (0,1) representing the power of the test. This is one minus the probability of a type II error.\n- alpha: A float in the interval (0,1) representing the significance level, which is the probability of a type I error.\n- std_null: A float representing the standard deviation under the null hypothesis, not divided by sqrt(nobs). Default is 1.0.\n- std_alternative: A float representing the standard deviation under the alternative hypothesis, not divided by sqrt(nobs). If None, it defaults to the value of std_null.\n\nOutputs:\n- nobs: A float representing the sample size required to achieve the desired power. If the minimum power is satisfied for all positive sample sizes, nobs will be zero. This occurs when power <= alpha and std_alternative equals std_null.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import stats\nfrom scipy import optimize\nfrom scipy import special\nfrom statsmodels.tools.rootfinding import brentq_expanding\nfrom collections import defaultdict\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import convergence_doc\nfrom statsmodels.graphics import utils\nfrom statsmodels.graphics.plottools import rainbow\nimport matplotlib.pyplot as plt\nfrom statsmodels.stats.gof import chisquare_power\n\n\ndef normal_sample_size_one_tail(diff, power, alpha, std_null=1.0,\n    std_alternative=None): [MASK]\n"}
{"method_name": "_design_knockoff_equi", "full_method_name": "_design_knockoff_equi", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/_knockoff.py", "method_code": "import numpy as np\nimport pandas as pd\nfrom statsmodels.iolib import summary2\ndef _design_knockoff_equi(exog):\n    \"\"\"\n    Construct an equivariant design matrix for knockoff analysis.\n\n    Follows the 'equi-correlated knockoff approach of equation 2.4 in\n    Barber and Candes.\n\n    Constructs a pair of design matrices exogs, exogn such that exogs\n    is a scaled/centered version of the input matrix exog, exogn is\n    another matrix of the same shape with cov(exogn) = cov(exogs), and\n    the covariances between corresponding columns of exogn and exogs\n    are as small as possible.\n    \"\"\"\n    nobs, nvar = exog.shape\n    if nobs < 2 * nvar:\n        msg = 'The equivariant knockoff can ony be used when n >= 2*p'\n        raise ValueError(msg)\n    xnm = np.sum(exog ** 2, 0)\n    xnm = np.sqrt(xnm)\n    exog = exog / xnm\n    xcov = np.dot(exog.T, exog)\n    ev, _ = np.linalg.eig(xcov)\n    evmin = np.min(ev)\n    sl = min(2 * evmin, 1)\n    sl = sl * np.ones(nvar)\n    exogn = _get_knmat(exog, xcov, sl)\n    return exog, exogn, sl", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nimport pytest\nimport statsmodels.api as sm\nfrom statsmodels.stats import knockoff_regeffects as kr\nfrom statsmodels.stats._knockoff import RegressionFDR\nfrom statsmodels.stats._knockoff import _design_knockoff_equi\nfrom statsmodels.stats._knockoff import _design_knockoff_sdp\ndef test_equi():\n    np.random.seed(2342)\n    exog = np.random.normal(size=(10, 4))\n    exog1, exog2, sl = _design_knockoff_equi(exog)\n    exoga = np.concatenate((exog1, exog2), axis=1)\n    gmat = np.dot(exoga.T, exoga)\n    cm1 = gmat[0:4, 0:4]\n    cm2 = gmat[4:, 4:]\n    cm3 = gmat[0:4, 4:]\n    assert_allclose(cm1, cm2, rtol=0.0001, atol=0.0001)\n    assert_allclose(cm1 - cm3, np.diag(sl * np.ones(4)), rtol=0.0001, atol=\n        0.0001)\n\ntest_equi()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_knockoff.py"}], "instruction": "Functionality: Construct an equivariant design matrix for knockoff analysis. The function implements the 'equi-correlated knockoff approach' described in equation 2.4 of Barber and Candes. It creates two design matrices: one that is a scaled and centered version of the input matrix, and another that has the same shape and covariance as the first, with minimized covariances between corresponding columns of the two matrices.\n\nInputs: \n- exog: A numpy array representing the original design matrix. This matrix is expected to have dimensions (nobs, nvar), where nobs is the number of observations and nvar is the number of variables.\n\nOutputs:\n- exog: The scaled and centered version of the input matrix 'exog'.\n- exogn: The knockoff matrix designed to have the same shape and covariance as 'exog', with minimized covariances between corresponding columns of 'exog' and 'exogn'.\n- sl: A numpy array containing the scaling factors used in the construction of the knockoff matrix 'exogn'.", "method_code_mask": "import numpy as np\nimport pandas as pd\nfrom statsmodels.iolib import summary2\n\n\ndef _design_knockoff_equi(exog): [MASK]\n"}
{"method_name": "corr_nearest", "full_method_name": "corr_nearest", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef corr_nearest(corr, threshold=1e-15, n_fact=100):\n    \"\"\"\n    Find the nearest correlation matrix that is positive semi-definite.\n\n    The function iteratively adjust the correlation matrix by clipping the\n    eigenvalues of a difference matrix. The diagonal elements are set to one.\n\n    Parameters\n    ----------\n    corr : ndarray, (k, k)\n        initial correlation matrix\n    threshold : float\n        clipping threshold for smallest eigenvalue, see Notes\n    n_fact : int or float\n        factor to determine the maximum number of iterations. The maximum\n        number of iterations is the integer part of the number of columns in\n        the correlation matrix times n_fact.\n\n    Returns\n    -------\n    corr_new : ndarray, (optional)\n        corrected correlation matrix\n\n    Notes\n    -----\n    The smallest eigenvalue of the corrected correlation matrix is\n    approximately equal to the ``threshold``.\n    If the threshold=0, then the smallest eigenvalue of the correlation matrix\n    might be negative, but zero within a numerical error, for example in the\n    range of -1e-16.\n\n    Assumes input correlation matrix is symmetric.\n\n    Stops after the first step if correlation matrix is already positive\n    semi-definite or positive definite, so that smallest eigenvalue is above\n    threshold. In this case, the returned array is not the original, but\n    is equal to it within numerical precision.\n\n    See Also\n    --------\n    corr_clipped\n    cov_nearest\n\n    \"\"\"\n    k_vars = corr.shape[0]\n    if k_vars != corr.shape[1]:\n        raise ValueError('matrix is not square')\n    diff = np.zeros(corr.shape)\n    x_new = corr.copy()\n    diag_idx = np.arange(k_vars)\n    for ii in range(int(len(corr) * n_fact)):\n        x_adj = x_new - diff\n        x_psd, clipped = clip_evals(x_adj, value=threshold)\n        if not clipped:\n            x_new = x_psd\n            break\n        diff = x_psd - x_adj\n        x_new = x_psd.copy()\n        x_new[diag_idx, diag_idx] = 1\n    else:\n        warnings.warn(iteration_limit_doc, IterationLimitWarning)\n    return x_new", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\ndef test_corr_psd():\n    x = np.array([[1, -0.2, -0.9], [-0.2, 1, -0.2], [-0.9, -0.2, 1]])\n    y = corr_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    y = corr_clipped(x)\n    assert_almost_equal(x, y, decimal=14)\n    y = cov_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    x2 = x + 0.001 * np.eye(3)\n    y = cov_nearest(x2, n_fact=100)\n    assert_almost_equal(x2, y, decimal=14)\n\ntest_corr_psd()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The corr_nearest function is designed to find the nearest correlation matrix that is positive semi-definite. It does this by iteratively adjusting the input correlation matrix through clipping the eigenvalues of a difference matrix and ensuring the diagonal elements remain at one.\n\nInputs:\n- corr: An ndarray of shape (k, k) representing the initial correlation matrix. This matrix must be square and symmetric.\n- threshold: A float that serves as the clipping threshold for the smallest eigenvalue. It determines how close the smallest eigenvalue of the corrected correlation matrix should be to zero (default is 1e-15).\n- n_fact: An int or float that represents a factor used to determine the maximum number of iterations. The exact number of iterations is calculated by multiplying the number of columns in the correlation matrix by n_fact (default is 100).\n\nOutputs:\n- corr_new: An ndarray. This is the corrected correlation matrix that is positive semi-definite. The diagonal elements of this matrix are set to one.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef corr_nearest(corr, threshold=1e-15, n_fact=100): [MASK]\n"}
{"method_name": "corr_clipped", "full_method_name": "corr_clipped", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef corr_clipped(corr, threshold=1e-15):\n    \"\"\"\n    Find a near correlation matrix that is positive semi-definite\n\n    This function clips the eigenvalues, replacing eigenvalues smaller than\n    the threshold by the threshold. The new matrix is normalized, so that the\n    diagonal elements are one.\n    Compared to corr_nearest, the distance between the original correlation\n    matrix and the positive definite correlation matrix is larger, however,\n    it is much faster since it only computes eigenvalues once.\n\n    Parameters\n    ----------\n    corr : ndarray, (k, k)\n        initial correlation matrix\n    threshold : float\n        clipping threshold for smallest eigenvalue, see Notes\n\n    Returns\n    -------\n    corr_new : ndarray, (optional)\n        corrected correlation matrix\n\n\n    Notes\n    -----\n    The smallest eigenvalue of the corrected correlation matrix is\n    approximately equal to the ``threshold``. In examples, the\n    smallest eigenvalue can be by a factor of 10 smaller than the threshold,\n    e.g. threshold 1e-8 can result in smallest eigenvalue in the range\n    between 1e-9 and 1e-8.\n    If the threshold=0, then the smallest eigenvalue of the correlation matrix\n    might be negative, but zero within a numerical error, for example in the\n    range of -1e-16.\n\n    Assumes input correlation matrix is symmetric. The diagonal elements of\n    returned correlation matrix is set to ones.\n\n    If the correlation matrix is already positive semi-definite given the\n    threshold, then the original correlation matrix is returned.\n\n    ``cov_clipped`` is 40 or more times faster than ``cov_nearest`` in simple\n    example, but has a slightly larger approximation error.\n\n    See Also\n    --------\n    corr_nearest\n    cov_nearest\n\n    \"\"\"\n    x_new, clipped = clip_evals(corr, value=threshold)\n    if not clipped:\n        return corr\n    x_std = np.sqrt(np.diag(x_new))\n    x_new = x_new / x_std / x_std[:, None]\n    return x_new", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\ndef test_corr_psd():\n    x = np.array([[1, -0.2, -0.9], [-0.2, 1, -0.2], [-0.9, -0.2, 1]])\n    y = corr_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    y = corr_clipped(x)\n    assert_almost_equal(x, y, decimal=14)\n    y = cov_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    x2 = x + 0.001 * np.eye(3)\n    y = cov_nearest(x2, n_fact=100)\n    assert_almost_equal(x2, y, decimal=14)\n\ntest_corr_psd()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The corr_clipped function is designed to adjust a given correlation matrix to ensure it is positive semi-definite. This is achieved by clipping the eigenvalues of the matrix such that any value below a specified threshold is replaced by the threshold. The modified matrix is then normalized to maintain diagonal elements at unity. This process is faster than alternative methods like corr_nearest but may result in a slightly larger distance between the original and the modified matrix.\n\nInputs: \n1. corr: An ndarray of shape (k, k) representing the initial correlation matrix that is to be checked and adjusted for positive semi-definiteness.\n2. threshold: An optional float parameter (default is 1e-15) that defines the minimum eigenvalue. Any eigenvalue smaller than this threshold will be replaced by the threshold value.\n\nOutputs: \n1. corr_new: An ndarray of the same shape as the input corr, representing the adjusted correlation matrix that is positive semi-definite. The diagonal elements of this matrix are set to one.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef corr_clipped(corr, threshold=1e-15): [MASK]\n"}
{"method_name": "cov_nearest", "full_method_name": "cov_nearest", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef cov_nearest(cov, method='clipped', threshold=1e-15, n_fact=100,\n    return_all=False):\n    \"\"\"\n    Find the nearest covariance matrix that is positive (semi-) definite\n\n    This leaves the diagonal, i.e. the variance, unchanged\n\n    Parameters\n    ----------\n    cov : ndarray, (k,k)\n        initial covariance matrix\n    method : str\n        if \"clipped\", then the faster but less accurate ``corr_clipped`` is\n        used.if \"nearest\", then ``corr_nearest`` is used\n    threshold : float\n        clipping threshold for smallest eigen value, see Notes\n    n_fact : int or float\n        factor to determine the maximum number of iterations in\n        ``corr_nearest``. See its doc string\n    return_all : bool\n        if False (default), then only the covariance matrix is returned.\n        If True, then correlation matrix and standard deviation are\n        additionally returned.\n\n    Returns\n    -------\n    cov_ : ndarray\n        corrected covariance matrix\n    corr_ : ndarray, (optional)\n        corrected correlation matrix\n    std_ : ndarray, (optional)\n        standard deviation\n\n\n    Notes\n    -----\n    This converts the covariance matrix to a correlation matrix. Then, finds\n    the nearest correlation matrix that is positive semidefinite and converts\n    it back to a covariance matrix using the initial standard deviation.\n\n    The smallest eigenvalue of the intermediate correlation matrix is\n    approximately equal to the ``threshold``.\n    If the threshold=0, then the smallest eigenvalue of the correlation matrix\n    might be negative, but zero within a numerical error, for example in the\n    range of -1e-16.\n\n    Assumes input covariance matrix is symmetric.\n\n    See Also\n    --------\n    corr_nearest\n    corr_clipped\n    \"\"\"\n    from statsmodels.stats.moment_helpers import cov2corr, corr2cov\n    cov_, std_ = cov2corr(cov, return_std=True)\n    if method == 'clipped':\n        corr_ = corr_clipped(cov_, threshold=threshold)\n    else:\n        corr_ = corr_nearest(cov_, threshold=threshold, n_fact=n_fact)\n    cov_ = corr2cov(corr_, std_)\n    if return_all:\n        return cov_, corr_, std_\n    else:\n        return cov_", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\ndef test_corr_psd():\n    x = np.array([[1, -0.2, -0.9], [-0.2, 1, -0.2], [-0.9, -0.2, 1]])\n    y = corr_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    y = corr_clipped(x)\n    assert_almost_equal(x, y, decimal=14)\n    y = cov_nearest(x, n_fact=100)\n    assert_almost_equal(x, y, decimal=14)\n    x2 = x + 0.001 * np.eye(3)\n    y = cov_nearest(x2, n_fact=100)\n    assert_almost_equal(x2, y, decimal=14)\n\ntest_corr_psd()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The cov_nearest function adjusts a given covariance matrix to ensure it is positive semi-definite, which is a crucial property for covariance matrices in statistical and econometric models. It first converts the covariance matrix to a correlation matrix, adjusts this correlation matrix to be positive semi-definite, and then converts it back to a covariance matrix using the original standard deviations.\n\nInputs:\n- cov: A numpy array representing the covariance matrix to be adjusted. It should be a square matrix of size (k,k).\n- method: A string indicating the method to use for adjusting the covariance matrix. It can take one of two values: 'clipped' for a faster but less accurate method, or 'nearest' for a more accurate but slower method.\n- threshold: A float specifying the threshold for the smallest eigenvalue in the adjustment process. This value is used to clip the eigenvalues to ensure positive semi-definiteness.\n- n_fact: An integer or float used to determine the maximum number of iterations if the 'nearest' method is chosen.\n- return_all: A boolean indicating whether to return additional information. If False (default), only the adjusted covariance matrix is returned. If True, the adjusted correlation matrix and standard deviations are also returned.\n\nOutputs:\nIf return_all is False (default):\n- cov_: A numpy array representing the adjusted covariance matrix.\n\nIf return_all is True:\n- cov_: A numpy array representing the adjusted covariance matrix.\n- corr_: A numpy array representing the adjusted correlation matrix.\n- std_: A numpy array representing the standard deviations associated with the adjusted covariance matrix.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef cov_nearest(cov, method='clipped', threshold=1e-15, n_fact=100,\n    return_all=False): [MASK]\n"}
{"method_name": "_project_correlation_factors", "full_method_name": "_project_correlation_factors", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef _project_correlation_factors(X):\n    \"\"\"\n    Project a matrix into the domain of matrices whose row-wise sums\n    of squares are less than or equal to 1.\n\n    The input matrix is modified in-place.\n    \"\"\"\n    nm = np.sqrt((X * X).sum(1))\n    ii = np.flatnonzero(nm > 1)\n    if len(ii) > 0:\n        X[ii, :] /= nm[ii][:, None]", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\n\nclass Test_Factor():\n\tdef test_corr_nearest_factor_arrpack(self):\n\t    u2 = np.array([[6.39407581e-19, 0.00915225947, 0.0182631698, \n\t        0.0272917181, 0.0361975557, 0.0449413101, 0.0534848732, \n\t        0.0617916613, 0.0698268388, 0.0775575058, 0.0849528448, \n\t        0.0919842264, 0.0986252769, 0.104851906, 0.110642305, 0.115976906, \n\t        0.120838331, 0.125211306, 0.12908257, 0.132440778, 0.135276397, \n\t        0.137581605, 0.139350201, 0.140577526, 0.141260396, 0.141397057, \n\t        0.14098716, 0.140031756, 0.138533306, 0.136495727, 0.133924439, \n\t        0.130826443, 0.127210404, 0.12308675, 0.118467769, 0.113367717, \n\t        0.107802909, 0.101791811, 0.0953551023, 0.088515732, 0.0812989329, \n\t        0.0737322125, 0.0658453049, 0.0576700847, 0.0492404406, \n\t        0.0405921079, 0.0317624629, 0.0227902803, 0.0137154584, \n\t        0.00457871801, -0.00457871801, -0.0137154584, -0.0227902803, -\n\t        0.0317624629, -0.0405921079, -0.0492404406, -0.0576700847, -\n\t        0.0658453049, -0.0737322125, -0.0812989329, -0.088515732, -\n\t        0.0953551023, -0.101791811, -0.107802909, -0.113367717, -\n\t        0.118467769, -0.12308675, -0.127210404, -0.130826443, -0.133924439,\n\t        -0.136495727, -0.138533306, -0.140031756, -0.14098716, -0.141397057,\n\t        -0.141260396, -0.140577526, -0.139350201, -0.137581605, -\n\t        0.135276397, -0.132440778, -0.12908257, -0.125211306, -0.120838331,\n\t        -0.115976906, -0.110642305, -0.104851906, -0.0986252769, -\n\t        0.0919842264, -0.0849528448, -0.0775575058, -0.0698268388, -\n\t        0.0617916613, -0.0534848732, -0.0449413101, -0.0361975557, -\n\t        0.0272917181, -0.0182631698, -0.00915225947, -3.51829569e-17]]).T\n\t    s2 = np.array([24.88812183])\n\t    d = 100\n\t    dm = 1\n\t    X = np.zeros((d, dm), dtype=np.float64)\n\t    x = np.linspace(0, 2 * np.pi, d)\n\t    for j in range(dm):\n\t        X[:, j] = np.sin(x * (j + 1))\n\t    _project_correlation_factors(X)\n\t    X *= 0.7\n\t    mat = np.dot(X, X.T)\n\t    np.fill_diagonal(mat, 1.0)\n\t    from scipy.sparse.linalg import svds\n\t    u, s, vt = svds(mat, dm)\n\t    dsign = np.sign(u[1]) * np.sign(u2[1])\n\t    assert_allclose(u, dsign * u2, rtol=1e-06, atol=1e-14)\n\t    assert_allclose(s, s2, rtol=1e-06)\n\t\nTest_Factor().test_corr_nearest_factor_arrpack()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The _project_correlation_factors function projects a given matrix into the domain of matrices whose row-wise sums of squares are less than or equal to 1. This function modifies the input matrix in-place, ensuring that each row of the matrix, when squared and summed, does not exceed 1. This is particularly useful in statistics and data analysis when dealing with correlation matrices or when normalizing data.\n\nInputs: \n- X: A 2D numpy array representing the matrix to be projected. The matrix should be of shape (n, m), where n is the number of rows and m is the number of columns.\n\nOutputs: \n- The function modifies the input matrix X in-place, adjusting the elements so that the sum of squares of each row is less than or equal to 1. No explicit output is returned; the changes are made directly to the input matrix.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef _project_correlation_factors(X): [MASK]\n"}
{"method_name": "_spg_optim", "full_method_name": "_spg_optim", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef _spg_optim(func, grad, start, project, maxiter=10000.0, M=10, ctol=\n    0.001, maxiter_nmls=200, lam_min=1e-30, lam_max=1e+30, sig1=0.1, sig2=\n    0.9, gam=0.0001):\n    \"\"\"\n    Implements the spectral projected gradient method for minimizing a\n    differentiable function on a convex domain.\n\n    Parameters\n    ----------\n    func : real valued function\n        The objective function to be minimized.\n    grad : real array-valued function\n        The gradient of the objective function\n    start : array_like\n        The starting point\n    project : function\n        In-place projection of the argument to the domain\n        of func.\n    ... See notes regarding additional arguments\n\n    Returns\n    -------\n    rslt : Bunch\n        rslt.params is the final iterate, other fields describe\n        convergence status.\n\n    Notes\n    -----\n    This can be an effective heuristic algorithm for problems where no\n    guaranteed algorithm for computing a global minimizer is known.\n\n    There are a number of tuning parameters, but these generally\n    should not be changed except for `maxiter` (positive integer) and\n    `ctol` (small positive real).  See the Birgin et al reference for\n    more information about the tuning parameters.\n\n    Reference\n    ---------\n    E. Birgin, J.M. Martinez, and M. Raydan. Spectral projected\n    gradient methods: Review and perspectives. Journal of Statistical\n    Software (preprint).  Available at:\n    http://www.ime.usp.br/~egbirgin/publications/bmr5.pdf\n    \"\"\"\n    lam = min(10 * lam_min, lam_max)\n    params = start.copy()\n    gval = grad(params)\n    obj_hist = [func(params)]\n    for itr in range(int(maxiter)):\n        df = params - gval\n        project(df)\n        df -= params\n        if np.max(np.abs(df)) < ctol:\n            return Bunch(**{'Converged': True, 'params': params,\n                'objective_values': obj_hist, 'Message':\n                'Converged successfully'})\n        d = params - lam * gval\n        project(d)\n        d -= params\n        alpha, params1, fval, gval1 = _nmono_linesearch(func, grad, params,\n            d, obj_hist, M=M, sig1=sig1, sig2=sig2, gam=gam, maxiter=\n            maxiter_nmls)\n        if alpha is None:\n            return Bunch(**{'Converged': False, 'params': params,\n                'objective_values': obj_hist, 'Message':\n                'Failed in nmono_linesearch'})\n        obj_hist.append(fval)\n        s = params1 - params\n        y = gval1 - gval\n        sy = (s * y).sum()\n        if sy <= 0:\n            lam = lam_max\n        else:\n            ss = (s * s).sum()\n            lam = max(lam_min, min(ss / sy, lam_max))\n        params = params1\n        gval = gval1\n    return Bunch(**{'Converged': False, 'params': params,\n        'objective_values': obj_hist, 'Message': 'spg_optim did not converge'})", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\n\nclass Test_Factor():\n\tdef test_spg_optim(self):\n\t    dm = 100\n\t    ind = np.arange(dm)\n\t    indmat = np.abs(ind[:, None] - ind[None, :])\n\t    M = 0.8 ** indmat\n\t\n\t    def obj(x):\n\t        return np.dot(x, np.dot(M, x))\n\t\n\t    def grad(x):\n\t        return 2 * np.dot(M, x)\n\t\n\t    def project(x):\n\t        return x\n\t    x = np.random.normal(size=dm)\n\t    rslt = _spg_optim(obj, grad, x, project)\n\t    xnew = rslt.params\n\t    assert rslt.Converged is True\n\t    assert_almost_equal(obj(xnew), 0, decimal=3)\n\t\nTest_Factor().test_spg_optim()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The _spg_optim function implements the spectral projected gradient method for minimizing a differentiable function on a convex domain. It serves as an effective heuristic algorithm for problems where no guaranteed algorithm for computing a global minimizer is known. The function iterates to find the minimum of the given objective function by adjusting parameters within the defined domain.\n\nInputs: \n- func: A real-valued function representing the objective function to be minimized.\n- grad: A real array-valued function providing the gradient of the objective function.\n- start: An array_like object representing the starting point for the optimization process.\n- project: A function used for in-place projection of the argument to the domain of func, ensuring that each update of the parameters stays within the feasible region.\n- maxiter: A positive integer defining the maximum number of iterations for the optimization.\n- M: An integer specifying the maximum number of previous gradients used in the optimization.\n- ctol: A small positive real number for the convergence tolerance; the iteration will stop if the maximum absolute value of the difference in the parameters is less than this.\n- lam_min, lam_max: The minimum and maximum values for the spectral coefficient used in the optimization.\n- sig1, sig2, gam: Constants used in the line search procedure to ensure a sufficient decrease in the objective function value.\n\nOutputs: \n- A Bunch object containing the results of the optimization:\n  - Converged: A boolean value indicating whether the optimization converged.\n  - params: The final iterate (the parameters at convergence).\n  - objective_values: A list of objective function values at each iteration.\n  - Message: A string containing a message about the convergence status.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef _spg_optim(func, grad, start, project, maxiter=10000.0, M=10, ctol=\n    0.001, maxiter_nmls=200, lam_min=1e-30, lam_max=1e+30, sig1=0.1, sig2=\n    0.9, gam=0.0001): [MASK]\n"}
{"method_name": "corr_thresholded", "full_method_name": "corr_thresholded", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/correlation_tools.py", "method_code": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\ndef corr_thresholded(data, minabs=None, max_elt=10000000.0):\n    \"\"\"\n    Construct a sparse matrix containing the thresholded row-wise\n    correlation matrix from a data array.\n\n    Parameters\n    ----------\n    data : array_like\n        The data from which the row-wise thresholded correlation\n        matrix is to be computed.\n    minabs : non-negative real\n        The threshold value; correlation coefficients smaller in\n        magnitude than minabs are set to zero.  If None, defaults\n        to 1 / sqrt(n), see Notes for more information.\n\n    Returns\n    -------\n    cormat : sparse.coo_matrix\n        The thresholded correlation matrix, in COO format.\n\n    Notes\n    -----\n    This is an alternative to C = np.corrcoef(data); C \\\\*= (np.abs(C)\n    >= absmin), suitable for very tall data matrices.\n\n    If the data are jointly Gaussian, the marginal sampling\n    distributions of the elements of the sample correlation matrix are\n    approximately Gaussian with standard deviation 1 / sqrt(n).  The\n    default value of ``minabs`` is thus equal to 1 standard error, which\n    will set to zero approximately 68% of the estimated correlation\n    coefficients for which the population value is zero.\n\n    No intermediate matrix with more than ``max_elt`` values will be\n    constructed.  However memory use could still be high if a large\n    number of correlation values exceed `minabs` in magnitude.\n\n    The thresholded matrix is returned in COO format, which can easily\n    be converted to other sparse formats.\n\n    Examples\n    --------\n    Here X is a tall data matrix (e.g. with 100,000 rows and 50\n    columns).  The row-wise correlation matrix of X is calculated\n    and stored in sparse form, with all entries smaller than 0.3\n    treated as 0.\n\n    >>> import numpy as np\n    >>> np.random.seed(1234)\n    >>> b = 1.5 - np.random.rand(10, 1)\n    >>> x = np.random.randn(100,1).dot(b.T) + np.random.randn(100,10)\n    >>> cmat = corr_thresholded(x, 0.3)\n    \"\"\"\n    nrow, ncol = data.shape\n    if minabs is None:\n        minabs = 1.0 / float(ncol)\n    data = data.copy()\n    data -= data.mean(1)[:, None]\n    sd = data.std(1, ddof=1)\n    ii = np.flatnonzero(sd > 1e-05)\n    data[ii, :] /= sd[ii][:, None]\n    ii = np.flatnonzero(sd <= 1e-05)\n    data[ii, :] = 0\n    bs = int(np.floor(max_elt / nrow))\n    ipos_all, jpos_all, cor_values = [], [], []\n    ir = 0\n    while ir < nrow:\n        ir2 = min(data.shape[0], ir + bs)\n        cm = np.dot(data[ir:ir2, :], data.T) / (ncol - 1)\n        cma = np.abs(cm)\n        ipos, jpos = np.nonzero(cma >= minabs)\n        ipos_all.append(ipos + ir)\n        jpos_all.append(jpos)\n        cor_values.append(cm[ipos, jpos])\n        ir += bs\n    ipos = np.concatenate(ipos_all)\n    jpos = np.concatenate(jpos_all)\n    cor_values = np.concatenate(cor_values)\n    cmat = sparse.coo_matrix((cor_values, (ipos, jpos)), (nrow, nrow))\n    return cmat", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_allclose\nimport scipy.sparse as sparse\nimport pytest\nfrom statsmodels.stats.correlation_tools import corr_nearest\nfrom statsmodels.stats.correlation_tools import corr_clipped\nfrom statsmodels.stats.correlation_tools import cov_nearest\nfrom statsmodels.stats.correlation_tools import _project_correlation_factors\nfrom statsmodels.stats.correlation_tools import corr_nearest_factor\nfrom statsmodels.stats.correlation_tools import _spg_optim\nfrom statsmodels.stats.correlation_tools import corr_thresholded\nfrom statsmodels.stats.correlation_tools import cov_nearest_factor_homog\nfrom statsmodels.stats.correlation_tools import FactoredPSDMatrix\nfrom statsmodels.tools.testing import Holder\nfrom scipy.sparse.linalg import svds\nimport datetime\n\nclass Test_Factor():\n\tdef test_corr_thresholded(self):\n\t    import datetime\n\t    t1 = datetime.datetime.now()\n\t    X = np.random.normal(size=(2000, 10))\n\t    tcor = corr_thresholded(X, 0.2, max_elt=4000000.0)\n\t    t2 = datetime.datetime.now()\n\t    ss = (t2 - t1).seconds\n\t    fcor = np.corrcoef(X)\n\t    fcor *= np.abs(fcor) >= 0.2\n\t    assert_allclose(tcor.todense(), fcor, rtol=0.25, atol=0.001)\n\t\nTest_Factor().test_corr_thresholded()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_corrpsd.py"}], "instruction": "Functionality: The corr_thresholded function constructs a sparse matrix that represents a thresholded row-wise correlation matrix from a given data array. This is particularly useful for handling large datasets where the full correlation matrix would be too memory-intensive to compute and store. By setting correlation coefficients smaller in magnitude than a specified threshold to zero, the function provides a more manageable and memory-efficient representation of the correlation structure.\n\nInputs: \n1. data: array_like\n   - The data array from which the row-wise thresholded correlation matrix is to be computed.\n2. minabs: non-negative real (optional)\n   - The threshold value; correlation coefficients smaller in magnitude than minabs are set to zero. If None, it defaults to 1 / sqrt(n), where n is the number of columns in the data array.\n3. max_elt: non-negative real (optional, default: 10000000.0)\n   - The maximum number of elements allowed in any intermediate matrix during computation. This parameter ensures that the function does not construct matrices that are too large, potentially causing memory issues.\n\nOutputs:\n1. cormat: sparse.coo_matrix\n   - The thresholded correlation matrix, represented in Coordinate format (COO). This is a sparse matrix format that is efficient for storing and working with sparse data.", "method_code_mask": "import numpy as np\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import svds\nfrom scipy.optimize import fminbound\nimport warnings\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import IterationLimitWarning\nfrom statsmodels.tools.sm_exceptions import iteration_limit_doc\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import corr2cov\n\n\ndef corr_thresholded(data, minabs=None, max_elt=10000000.0): [MASK]\n"}
{"method_name": "durbin_watson", "full_method_name": "durbin_watson", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/stattools.py", "method_code": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\ndef durbin_watson(resids, axis=0):\n    \"\"\"\n    Calculates the Durbin-Watson statistic.\n\n    Parameters\n    ----------\n    resids : array_like\n        Data for which to compute the Durbin-Watson statistic. Usually\n        regression model residuals.\n    axis : int, optional\n        Axis to use if data has more than 1 dimension. Default is 0.\n\n    Returns\n    -------\n    dw : float, array_like\n        The Durbin-Watson statistic.\n\n    Notes\n    -----\n    The null hypothesis of the test is that there is no serial correlation\n    in the residuals.\n    The Durbin-Watson test statistic is defined as:\n\n    .. math::\n\n       \\\\sum_{t=2}^T((e_t - e_{t-1})^2)/\\\\sum_{t=1}^Te_t^2\n\n    The test statistic is approximately equal to 2*(1-r) where ``r`` is the\n    sample autocorrelation of the residuals. Thus, for r == 0, indicating no\n    serial correlation, the test statistic equals 2. This statistic will\n    always be between 0 and 4. The closer to 0 the statistic, the more\n    evidence for positive serial correlation. The closer to 4, the more\n    evidence for negative serial correlation.\n    \"\"\"\n    resids = np.asarray(resids)\n    diff_resids = np.diff(resids, 1, axis=axis)\n    dw = np.sum(diff_resids ** 2, axis=axis) / np.sum(resids ** 2, axis=axis)\n    return dw", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\ndef test_durbin_watson_pandas():\n    x = np.random.randn(50)\n    x_series = pd.Series(x)\n    assert_almost_equal(durbin_watson(x), durbin_watson(x_series), decimal=13)\n\ntest_durbin_watson_pandas()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_durbin_watson(self):\n\t    x = np.random.standard_normal(100)\n\t    dw = sum(np.diff(x) ** 2.0) / np.dot(x, x)\n\t    assert_almost_equal(dw, durbin_watson(x))\n\t\nTestStattools().test_durbin_watson()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_durbin_watson_2d(self):\n\t    shape = 1, 10\n\t    x = np.random.standard_normal(100)\n\t    dw = sum(np.diff(x) ** 2.0) / np.dot(x, x)\n\t    x = np.tile(x[:, None], shape)\n\t    assert_almost_equal(np.squeeze(dw * np.ones(shape)), durbin_watson(x))\n\t\nTestStattools().test_durbin_watson_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_durbin_watson_3d(self):\n\t    shape = 10, 1, 10\n\t    x = np.random.standard_normal(100)\n\t    dw = sum(np.diff(x) ** 2.0) / np.dot(x, x)\n\t    x = np.tile(x[None, :, None], shape)\n\t    assert_almost_equal(np.squeeze(dw * np.ones(shape)), durbin_watson(x,\n\t        axis=1))\n\t\nTestStattools().test_durbin_watson_3d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}], "instruction": "Functionality: The Durbin-Watson statistic is calculated to test for the presence of serial correlation in the residuals from a regression analysis. This function computes the statistic using the residuals provided by the user.\n\nInputs: \n1. resids: array_like - Data for which the Durbin-Watson statistic is to be calculated. This is typically the residuals from a regression model.\n2. axis: int, optional - The axis to use if the data has more than one dimension. The default value is 0.\n\nOutputs: \n1. dw: float, array_like - The Durbin-Watson statistic generated from the input data. This statistic provides insight into the presence of serial correlation in the data. A value close to 2 suggests no serial correlation, while values below 2 indicate positive serial correlation, and values above 2 suggest negative serial correlation.", "method_code_mask": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\n\n\ndef durbin_watson(resids, axis=0): [MASK]\n"}
{"method_name": "medcouple", "full_method_name": "medcouple", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/stattools.py", "method_code": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\ndef medcouple(y, axis=0):\n    \"\"\"\n    Calculate the medcouple robust measure of skew.\n\n    Parameters\n    ----------\n    y : array_like\n        Data to compute use in the estimator.\n    axis : {int, None}\n        Axis along which the medcouple statistic is computed.  If `None`, the\n        entire array is used.\n\n    Returns\n    -------\n    mc : ndarray\n        The medcouple statistic with the same shape as `y`, with the specified\n        axis removed.\n\n    Notes\n    -----\n    The current algorithm requires a O(N**2) memory allocations, and so may\n    not work for very large arrays (N>10000).\n\n    .. [*] M. Hubert and E. Vandervieren, \"An adjusted boxplot for skewed\n       distributions\" Computational Statistics & Data Analysis, vol. 52, pp.\n       5186-5201, August 2008.\n    \"\"\"\n    y = np.asarray(y, dtype=np.double)\n    if axis is None:\n        return _medcouple_1d(y.ravel())\n    return np.apply_along_axis(_medcouple_1d, axis, y)", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_no_axis(self):\n\t    x = np.reshape(np.arange(100.0), (50, 2))\n\t    mc = medcouple(x, axis=None)\n\t    assert_almost_equal(mc, medcouple(x.ravel()))\n\t\nTestStattools().test_medcouple_no_axis()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_symmetric(self):\n\t    mc = medcouple(np.arange(5.0))\n\t    assert_almost_equal(mc, 0)\n\t\nTestStattools().test_medcouple_symmetric()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_nonzero(self):\n\t    mc = medcouple(np.array([1, 2, 7, 9, 10.0]))\n\t    assert_almost_equal(mc, -0.3333333)\n\t\nTestStattools().test_medcouple_nonzero()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_int(self):\n\t    mc1 = medcouple(np.array([1, 2, 7, 9, 10]))\n\t    mc2 = medcouple(np.array([1, 2, 7, 9, 10.0]))\n\t    assert_equal(mc1, mc2)\n\t\nTestStattools().test_medcouple_int()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_symmetry(self):\n\t    x = np.random.standard_normal(100)\n\t    mcp = medcouple(x)\n\t    mcn = medcouple(-x)\n\t    assert_almost_equal(mcp + mcn, 0)\n\t\nTestStattools().test_medcouple_symmetry()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_medcouple_ties(self):\n\t    x = np.array([1, 2, 2, 3, 4])\n\t    mc = medcouple(x)\n\t    assert_almost_equal(mc, 1.0 / 6.0)\n\t\nTestStattools().test_medcouple_ties()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}], "instruction": "Functionality: The medcouple function calculates the medcouple robust measure of skew, which is a statistic used to describe the asymmetry of a distribution. It's particularly useful for skewed distributions, offering a more robust alternative to the traditional skewness measure.\n\nInputs: \n- y: An array-like data structure containing the data points for which the medcouple statistic is to be computed. The data points should be convertible to a NumPy array of double precision floating-point numbers.\n- axis: An integer or None, specifying the axis along which the medcouple statistic should be computed. If set to None, the statistic is computed for the flattened array.\n\nOutputs: \n- mc: A NumPy array containing the medcouple statistic for the input data. The shape of the output matches that of the input array, with the specified axis removed. If the input data is one-dimensional and axis is None, the output will be a scalar value representing the medcouple statistic.\n\nPlease implement the medcouple function according to the provided specifications. Your implementation should accurately calculate the medcouple statistic for the given input data along the specified axis. Note that for large datasets (N>10000), the current algorithm may require significant memory allocation due to its O(N**2) complexity.", "method_code_mask": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\n\n\ndef medcouple(y, axis=0): [MASK]\n"}
{"method_name": "robust_skewness", "full_method_name": "robust_skewness", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/stattools.py", "method_code": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\ndef robust_skewness(y, axis=0):\n    \"\"\"\n    Calculates the four skewness measures in Kim & White\n\n    Parameters\n    ----------\n    y : array_like\n        Data to compute use in the estimator.\n    axis : int or None, optional\n        Axis along which the skewness measures are computed.  If `None`, the\n        entire array is used.\n\n    Returns\n    -------\n    sk1 : ndarray\n          The standard skewness estimator.\n    sk2 : ndarray\n          Skewness estimator based on quartiles.\n    sk3 : ndarray\n          Skewness estimator based on mean-median difference, standardized by\n          absolute deviation.\n    sk4 : ndarray\n          Skewness estimator based on mean-median difference, standardized by\n          standard deviation.\n\n    Notes\n    -----\n    The robust skewness measures are defined\n\n    .. math::\n\n        SK_{2}=\\\\frac{\\\\left(q_{.75}-q_{.5}\\\\right)\n        -\\\\left(q_{.5}-q_{.25}\\\\right)}{q_{.75}-q_{.25}}\n\n    .. math::\n\n        SK_{3}=\\\\frac{\\\\mu-\\\\hat{q}_{0.5}}\n        {\\\\hat{E}\\\\left[\\\\left|y-\\\\hat{\\\\mu}\\\\right|\\\\right]}\n\n    .. math::\n\n        SK_{4}=\\\\frac{\\\\mu-\\\\hat{q}_{0.5}}{\\\\hat{\\\\sigma}}\n\n    .. [*] Tae-Hwan Kim and Halbert White, \"On more robust estimation of\n       skewness and kurtosis,\" Finance Research Letters, vol. 1, pp. 56-73,\n       March 2004.\n    \"\"\"\n    if axis is None:\n        y = y.ravel()\n        axis = 0\n    y = np.sort(y, axis)\n    q1, q2, q3 = np.percentile(y, [25.0, 50.0, 75.0], axis=axis)\n    mu = y.mean(axis)\n    shape = y.size,\n    if axis is not None:\n        shape = list(mu.shape)\n        shape.insert(axis, 1)\n        shape = tuple(shape)\n    mu_b = np.reshape(mu, shape)\n    q2_b = np.reshape(q2, shape)\n    sigma = np.sqrt(np.mean((y - mu_b) ** 2, axis))\n    sk1 = stats.skew(y, axis=axis)\n    sk2 = (q1 + q3 - 2.0 * q2) / (q3 - q1)\n    sk3 = (mu - q2) / np.mean(abs(y - q2_b), axis=axis)\n    sk4 = (mu - q2) / sigma\n    return sk1, sk2, sk3, sk4", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_robust_skewness_1d(self):\n\t    x = np.arange(21.0)\n\t    sk = robust_skewness(x)\n\t    assert_almost_equal(np.array(sk), np.zeros(4))\n\t\nTestStattools().test_robust_skewness_1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_robust_skewness_1d_2d(self):\n\t    x = np.random.randn(21)\n\t    y = x[:, None]\n\t    sk_x = robust_skewness(x)\n\t    sk_y = robust_skewness(y, axis=None)\n\t    assert_almost_equal(np.array(sk_x), np.array(sk_y))\n\t\nTestStattools().test_robust_skewness_1d_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_robust_skewness_symmetric(self):\n\t    x = np.random.standard_normal(100)\n\t    x = np.hstack([x, np.zeros(1), -x])\n\t    sk = robust_skewness(x)\n\t    assert_almost_equal(np.array(sk), np.zeros(4))\n\t\nTestStattools().test_robust_skewness_symmetric()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_robust_skewness_3d(self):\n\t    x = np.random.standard_normal(100)\n\t    x = np.hstack([x, np.zeros(1), -x])\n\t    x = np.tile(x, (10, 10, 1))\n\t    sk_3d = robust_skewness(x, axis=2)\n\t    result = np.zeros((10, 10))\n\t    for sk in sk_3d:\n\t        assert_almost_equal(sk, result)\n\t\nTestStattools().test_robust_skewness_3d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats._adnorm import normal_ad\nfrom statsmodels.stats.stattools import omni_normtest\nfrom statsmodels.stats.stattools import jarque_bera\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.stats.stattools import _medcouple_1d\nfrom statsmodels.stats.stattools import medcouple\nfrom statsmodels.stats.stattools import robust_kurtosis\nfrom statsmodels.stats.stattools import robust_skewness\nfrom scipy import stats\nfrom scipy.stats import shapiro\n\nclass TestStattools():\n\tdef test_robust_skewness_4(self):\n\t    x = np.random.standard_normal(1000)\n\t    x[x > 0] *= 3\n\t    m = np.median(x)\n\t    s = x.std(ddof=0)\n\t    expected = (x.mean() - m) / s\n\t    _, _, _, sk4 = robust_skewness(x)\n\t    assert_allclose(expected, sk4)\n\t\nTestStattools().test_robust_skewness_4()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_statstools.py"}], "instruction": "Functionality: The robust_skewness function calculates four different measures of skewness for a given dataset as proposed by Kim & White. These measures include the standard skewness estimator, a skewness estimator based on quartiles, a skewness estimator based on the mean-median difference standardized by the absolute deviation, and a skewness estimator based on the mean-median difference standardized by the standard deviation.\n\nInputs: \n- y : array_like\n  Data to compute the skewness measures from.\n- axis : int or None, optional (default is 0)\n  Axis along which the skewness measures are computed. If `None`, the entire array is used.\n\nOutputs: \n- sk1 : ndarray\n  The standard skewness estimator.\n- sk2 : ndarray\n  Skewness estimator based on quartiles.\n- sk3 : ndarray\n  Skewness estimator based on mean-median difference, standardized by absolute deviation.\n- sk4 : ndarray\n  Skewness estimator based on mean-median difference, standardized by standard deviation.", "method_code_mask": "from scipy import stats\nimport numpy as np\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom warnings import warn\n\n\ndef robust_skewness(y, axis=0): [MASK]\n"}
{"method_name": "chisquare", "full_method_name": "chisquare", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/gof.py", "method_code": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom scipy import stats\ndef chisquare(f_obs, f_exp=None, value=0, ddof=0, return_basic=True):\n    \"\"\"chisquare goodness-of-fit test\n\n    The null hypothesis is that the distance between the expected distribution\n    and the observed frequencies is ``value``. The alternative hypothesis is\n    that the distance is larger than ``value``. ``value`` is normalized in\n    terms of effect size.\n\n    The standard chisquare test has the null hypothesis that ``value=0``, that\n    is the distributions are the same.\n\n\n    Notes\n    -----\n    The case with value greater than zero is similar to an equivalence test,\n    that the exact null hypothesis is replaced by an approximate hypothesis.\n    However, TOST \"reverses\" null and alternative hypothesis, while here the\n    alternative hypothesis is that the distance (divergence) is larger than a\n    threshold.\n\n    References\n    ----------\n    McLaren, ...\n    Drost,...\n\n    See Also\n    --------\n    powerdiscrepancy\n    scipy.stats.chisquare\n\n    \"\"\"\n    f_obs = np.asarray(f_obs)\n    n_bins = len(f_obs)\n    nobs = f_obs.sum(0)\n    if f_exp is None:\n        f_exp = np.empty(n_bins, float)\n        f_exp.fill(nobs / float(n_bins))\n    f_exp = np.asarray(f_exp, float)\n    chisq = ((f_obs - f_exp) ** 2 / f_exp).sum(0)\n    if value == 0:\n        pvalue = stats.chi2.sf(chisq, n_bins - 1 - ddof)\n    else:\n        pvalue = stats.ncx2.sf(chisq, n_bins - 1 - ddof, value ** 2 * nobs)\n    if return_basic:\n        return chisq, pvalue\n    else:\n        return chisq, pvalue", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats.gof import chisquare\nfrom statsmodels.stats.gof import chisquare_power\nfrom statsmodels.stats.gof import chisquare_effectsize\nfrom statsmodels.tools.testing import Holder\ndef test_chisquare():\n    res1 = Holder()\n    res2 = Holder()\n    res1.statistic = 2.084086388178453\n    res1.parameter = 4\n    res1.p_value = 0.72029651761105\n    res1.method = 'Chi-squared test for given probabilities'\n    res1.data_name = 'freq'\n    res1.observed = np.array([1048, 660, 510, 420, 362])\n    res1.expected = np.array([1020, 690, 510, 420, 360])\n    res1.residuals = np.array([0.876714007519206, -1.142080481440321, -\n        2.517068894406109e-15, -2.773674830645328e-15, 0.105409255338946])\n    res2.statistic = 0.01492063492063492\n    res2.parameter = 4\n    res2.p_value = 0.999972309849908\n    res2.method = 'Chi-squared test for given probabilities'\n    res2.data_name = 'freq'\n    res2.observed = np.array([1048, 660, 510, 420, 362])\n    res2.expected = np.array([1050, 660, 510, 420, 360])\n    res2.residuals = np.array([-0.06172133998483677, 0, -\n        2.517068894406109e-15, -2.773674830645328e-15, 0.105409255338946])\n    freq = np.array([1048, 660, 510, 420, 362])\n    pr1 = np.array([1020, 690, 510, 420, 360])\n    pr2 = np.array([1050, 660, 510, 420, 360])\n    for pr, res in zip([pr1, pr2], [res1, res2]):\n        stat, pval = chisquare(freq, pr)\n        assert_almost_equal(stat, res.statistic, decimal=12)\n        assert_almost_equal(pval, res.p_value, decimal=13)\n\ntest_chisquare()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_gof.py"}], "instruction": "Functionality: The chisquare function performs a goodness-of-fit test using the chi-square statistic. It compares observed frequencies in categorical data with expected frequencies under a null hypothesis. This function can test if the observed distribution is significantly different from the expected distribution, with an option to specify a non-zero distance value for the null hypothesis, allowing for equivalence testing.\n\nInputs:\n- f_obs: A 1D array of observed frequencies.\n- f_exp: (Optional) A 1D array of expected frequencies. If not provided, the expected frequencies are assumed to be uniform.\n- value: (Optional) A scalar representing the normalized effect size or distance value for the null hypothesis. Default is 0.\n- ddof: (Optional) An integer indicating the number of degrees of freedom to be deducted from the observed frequencies. Default is 0.\n- return_basic: (Optional) A boolean indicating whether to return only the chi-square statistic and p-value (True) or additional values (False). Default is True.\n\nOutputs:\n- If return_basic is True:\n  - chisq: The chi-square statistic.\n  - pvalue: The p-value of the chi-square test.\n- If return_basic is False:\n  - chisq: The chi-square statistic.\n  - pvalue: The p-value of the chi-square test.\n  - Additional values: (Not specified as per the provided code snippet)", "method_code_mask": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom scipy import stats\n\n\ndef chisquare(f_obs, f_exp=None, value=0, ddof=0, return_basic=True): [MASK]\n"}
{"method_name": "chisquare_effectsize", "full_method_name": "chisquare_effectsize", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/gof.py", "method_code": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom scipy import stats\ndef chisquare_effectsize(probs0, probs1, correction=None, cohen=True, axis=0):\n    \"\"\"effect size for a chisquare goodness-of-fit test\n\n    Parameters\n    ----------\n    probs0 : array_like\n        probabilities or cell frequencies under the Null hypothesis\n    probs1 : array_like\n        probabilities or cell frequencies under the Alternative hypothesis\n        probs0 and probs1 need to have the same length in the ``axis`` dimension.\n        and broadcast in the other dimensions\n        Both probs0 and probs1 are normalized to add to one (in the ``axis``\n        dimension).\n    correction : None or tuple\n        If None, then the effect size is the chisquare statistic divide by\n        the number of observations.\n        If the correction is a tuple (nobs, df), then the effectsize is\n        corrected to have less bias and a smaller variance. However, the\n        correction can make the effectsize negative. In that case, the\n        effectsize is set to zero.\n        Pederson and Johnson (1990) as referenced in McLaren et all. (1994)\n    cohen : bool\n        If True, then the square root is returned as in the definition of the\n        effect size by Cohen (1977), If False, then the original effect size\n        is returned.\n    axis : int\n        If the probability arrays broadcast to more than 1 dimension, then\n        this is the axis over which the sums are taken.\n\n    Returns\n    -------\n    effectsize : float\n        effect size of chisquare test\n\n    \"\"\"\n    probs0 = np.asarray(probs0, float)\n    probs1 = np.asarray(probs1, float)\n    probs0 = probs0 / probs0.sum(axis)\n    probs1 = probs1 / probs1.sum(axis)\n    d2 = ((probs1 - probs0) ** 2 / probs0).sum(axis)\n    if correction is not None:\n        nobs, df = correction\n        diff = ((probs1 - probs0) / probs0).sum(axis)\n        d2 = np.maximum((d2 * nobs - diff - df) / (nobs - 1.0), 0)\n    if cohen:\n        return np.sqrt(d2)\n    else:\n        return d2", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats.gof import chisquare\nfrom statsmodels.stats.gof import chisquare_power\nfrom statsmodels.stats.gof import chisquare_effectsize\nfrom statsmodels.tools.testing import Holder\ndef test_chisquare_effectsize():\n    pr1 = np.array([1020, 690, 510, 420, 360])\n    pr2 = np.array([1050, 660, 510, 420, 360])\n    es_r = 0.02699815282115563\n    es1 = chisquare_effectsize(pr1, pr2)\n    es2 = chisquare_effectsize(pr1, pr2, cohen=False)\n    assert_almost_equal(es1, es_r, decimal=14)\n    assert_almost_equal(es2, es_r ** 2, decimal=14)\n    res1 = chisquare_effectsize(pr1, pr2, cohen=False, correction=(3000, \n        len(pr1) - 1))\n    res0 = 0\n    assert_equal(res1, res0)\n    pr3 = pr2 + [0, 0, 0, 50, 50]\n    res1 = chisquare_effectsize(pr1, pr3, cohen=False, correction=(3000, \n        len(pr1) - 1))\n    res0 = 0.0023106468846296755\n    assert_almost_equal(res1, res0, decimal=14)\n\ntest_chisquare_effectsize()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_gof.py"}], "instruction": "Functionality: The chisquare_effectsize function computes the effect size for a chi-square goodness-of-fit test, comparing two sets of probabilities or cell frequencies. This effect size indicates the strength of the association between the observed and expected frequencies.\n\nInputs:\n- probs0: An array representing probabilities or cell frequencies under the Null hypothesis.\n- probs1: An array representing probabilities or cell frequencies under the Alternative hypothesis. probs0 and probs1 must have the same length in the axis dimension and can broadcast in other dimensions.\n- correction: An optional parameter. If None, the effect size is the chi-square statistic divided by the number of observations. If a tuple (nobs, df), the effect size is corrected for bias and variance, setting to zero if negative.\n- cohen: A boolean indicating whether to return the square root of the effect size (Cohen's definition) or the original effect size.\n- axis: An integer determining the axis over which the sums are taken when probability arrays broadcast to more than one dimension.\n\nOutputs:\n- effectsize: A float representing the effect size of the chi-square test.", "method_code_mask": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom scipy import stats\n\n\ndef chisquare_effectsize(probs0, probs1, correction=None, cohen=True, axis=0\n    ): [MASK]\n"}
{"method_name": "mcnemar", "full_method_name": "mcnemar", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/contingency_tables.py", "method_code": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom statsmodels import iolib\nfrom statsmodels.tools import sm_exceptions\nfrom statsmodels.tools.decorators import cache_readonly\ndef mcnemar(table, exact=True, correction=True):\n    \"\"\"\n    McNemar test of homogeneity.\n\n    Parameters\n    ----------\n    table : array_like\n        A square contingency table.\n    exact : bool\n        If exact is true, then the binomial distribution will be used.\n        If exact is false, then the chisquare distribution will be\n        used, which is the approximation to the distribution of the\n        test statistic for large sample sizes.\n    correction : bool\n        If true, then a continuity correction is used for the chisquare\n        distribution (if exact is false.)\n\n    Returns\n    -------\n    A bunch with attributes:\n\n    statistic : float or int, array\n        The test statistic is the chisquare statistic if exact is\n        false. If the exact binomial distribution is used, then this\n        contains the min(n1, n2), where n1, n2 are cases that are zero\n        in one sample but one in the other sample.\n    pvalue : float or array\n        p-value of the null hypothesis of equal marginal distributions.\n\n    Notes\n    -----\n    This is a special case of Cochran's Q test, and of the homogeneity\n    test. The results when the chisquare distribution is used are\n    identical, except for continuity correction.\n    \"\"\"\n    table = _make_df_square(table)\n    table = np.asarray(table, dtype=np.float64)\n    n1, n2 = table[0, 1], table[1, 0]\n    if exact:\n        statistic = np.minimum(n1, n2)\n        int_sum = int(n1 + n2)\n        if int_sum != n1 + n2:\n            raise ValueError(\n                'exact can only be used with tables containing integers.')\n        pvalue = stats.binom.cdf(statistic, int_sum, 0.5) * 2\n        pvalue = np.minimum(pvalue, 1)\n    else:\n        corr = int(correction)\n        statistic = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pvalue = stats.chi2.sf(statistic, df)\n    b = _Bunch()\n    b.statistic = statistic\n    b.pvalue = pvalue\n    return b", "test_code_list": [{"test_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_approx_equal\nfrom numpy.testing import assert_\nfrom scipy import stats\nimport pytest\nfrom statsmodels.stats.contingency_tables import mcnemar\nfrom statsmodels.stats.contingency_tables import cochrans_q\nfrom statsmodels.stats.contingency_tables import SquareTable\nfrom statsmodels.sandbox.stats.runs import Runs\nfrom statsmodels.sandbox.stats.runs import runstest_1samp\nfrom statsmodels.sandbox.stats.runs import runstest_2samp\nfrom statsmodels.sandbox.stats.runs import mcnemar as sbmcnemar\nfrom statsmodels.stats.nonparametric import rank_compare_2indep\nfrom statsmodels.stats.nonparametric import rank_compare_2ordinal\nfrom statsmodels.stats.nonparametric import prob_larger_continuous\nfrom statsmodels.stats.nonparametric import cohensd2problarger\nfrom statsmodels.tools.testing import Holder\ndef test_mcnemar_exact():\n    f_obs1 = np.array([[101, 121], [59, 33]])\n    f_obs2 = np.array([[101, 70], [59, 33]])\n    f_obs3 = np.array([[101, 80], [59, 33]])\n    f_obs4 = np.array([[101, 30], [60, 33]])\n    f_obs5 = np.array([[101, 10], [30, 33]])\n    f_obs6 = np.array([[101, 10], [10, 33]])\n    res1 = 4e-06\n    res2 = 0.378688\n    res3 = 0.089452\n    res4 = 0.00206\n    res5 = 0.002221\n    res6 = 1.0\n    stat = mcnemar(f_obs1, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [59, res1], decimal=6)\n    stat = mcnemar(f_obs2, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [59, res2], decimal=6)\n    stat = mcnemar(f_obs3, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [59, res3], decimal=6)\n    stat = mcnemar(f_obs4, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [30, res4], decimal=6)\n    stat = mcnemar(f_obs5, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [10, res5], decimal=6)\n    stat = mcnemar(f_obs6, exact=True)\n    assert_almost_equal([stat.statistic, stat.pvalue], [10, res6], decimal=6)\n\ntest_mcnemar_exact()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_nonparametric.py"}, {"test_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_approx_equal\nfrom numpy.testing import assert_\nfrom scipy import stats\nimport pytest\nfrom statsmodels.stats.contingency_tables import mcnemar\nfrom statsmodels.stats.contingency_tables import cochrans_q\nfrom statsmodels.stats.contingency_tables import SquareTable\nfrom statsmodels.sandbox.stats.runs import Runs\nfrom statsmodels.sandbox.stats.runs import runstest_1samp\nfrom statsmodels.sandbox.stats.runs import runstest_2samp\nfrom statsmodels.sandbox.stats.runs import mcnemar as sbmcnemar\nfrom statsmodels.stats.nonparametric import rank_compare_2indep\nfrom statsmodels.stats.nonparametric import rank_compare_2ordinal\nfrom statsmodels.stats.nonparametric import prob_larger_continuous\nfrom statsmodels.stats.nonparametric import cohensd2problarger\nfrom statsmodels.tools.testing import Holder\ndef test_mcnemar_chisquare():\n    f_obs1 = np.array([[101, 121], [59, 33]])\n    f_obs2 = np.array([[101, 70], [59, 33]])\n    f_obs3 = np.array([[101, 80], [59, 33]])\n    res1 = [20.67222, 5.450095e-06]\n    res2 = [0.7751938, 0.3786151]\n    res3 = [2.87769784, 0.08981434]\n    stat = mcnemar(f_obs1, exact=False)\n    assert_allclose([stat.statistic, stat.pvalue], res1, rtol=1e-06)\n    stat = mcnemar(f_obs2, exact=False)\n    assert_allclose([stat.statistic, stat.pvalue], res2, rtol=1e-06)\n    stat = mcnemar(f_obs3, exact=False)\n    assert_allclose([stat.statistic, stat.pvalue], res3, rtol=1e-06)\n    res1 = [21.35556, 3.815136e-06]\n    res2 = [0.9379845, 0.3327967]\n    res3 = [3.17266187, 0.07488031]\n    res = mcnemar(f_obs1, exact=False, correction=False)\n    assert_allclose([res.statistic, res.pvalue], res1, rtol=1e-06)\n    res = mcnemar(f_obs2, exact=False, correction=False)\n    assert_allclose([res.statistic, res.pvalue], res2, rtol=1e-06)\n    res = mcnemar(f_obs3, exact=False, correction=False)\n    assert_allclose([res.statistic, res.pvalue], res3, rtol=1e-06)\n\ntest_mcnemar_chisquare()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_nonparametric.py"}], "instruction": "Functionality: The mcnemar function performs the McNemar test of homogeneity, which is used to compare the marginal frequencies of a square contingency table before and after an intervention or between two matched pairs. This test is particularly useful when the data is dichotomous (binary) and paired.\n\nInputs:\n- table: An array-like input representing a square contingency table. The table should be of shape (2, 2) for a basic McNemar's test, where the values represent the number of cases that are positive in one sample but not the other and vice versa.\n- exact (optional): A boolean value indicating whether the test should use the exact binomial distribution (True) or the approximate chi-square distribution (False). The default is True.\n- correction (optional): A boolean value indicating whether to apply a continuity correction when using the chi-square distribution (if exact is False). The default is True.\n\nOutputs:\n- A bunch object containing the following attributes:\n    - statistic: The test statistic, which is either the minimum count of discordant pairs when using the exact distribution or the chi-square statistic when using the chi-square distribution.\n    - pvalue: The p-value of the test, which is the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming the null hypothesis of equal marginal distributions.", "method_code_mask": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom statsmodels import iolib\nfrom statsmodels.tools import sm_exceptions\nfrom statsmodels.tools.decorators import cache_readonly\n\n\ndef mcnemar(table, exact=True, correction=True): [MASK]\n"}
{"method_name": "zconfint", "full_method_name": "zconfint", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/weightstats.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.decorators import cache_readonly\nimport pandas as pd\nfrom statsmodels.iolib.summary import summary_params\ndef zconfint(x1, x2=None, value=0, alpha=0.05, alternative='two-sided',\n    usevar='pooled', ddof=1.0):\n    \"\"\"confidence interval based on normal distribution z-test\n\n    Parameters\n    ----------\n    x1 : array_like, 1-D or 2-D\n        first of the two independent samples, see notes for 2-D case\n    x2 : array_like, 1-D or 2-D\n        second of the two independent samples, see notes for 2-D case\n    value : float\n        In the one sample case, value is the mean of x1 under the Null\n        hypothesis.\n        In the two sample case, value is the difference between mean of x1 and\n        mean of x2 under the Null hypothesis. The test statistic is\n        `x1_mean - x2_mean - value`.\n    usevar : str, 'pooled'\n        Currently, only 'pooled' is implemented.\n        If ``pooled``, then the standard deviation of the samples is assumed to be\n        the same. see CompareMeans.ztest_ind for different options.\n    ddof : int\n        Degrees of freedom use in the calculation of the variance of the mean\n        estimate. In the case of comparing means this is one, however it can\n        be adjusted for testing other statistics (proportion, correlation)\n\n    Notes\n    -----\n    checked only for 1 sample case\n\n    usevar not implemented, is always pooled in two sample case\n\n    ``value`` shifts the confidence interval so it is centered at\n    `x1_mean - x2_mean - value`\n\n    See Also\n    --------\n    ztest\n    CompareMeans\n\n    \"\"\"\n    if usevar != 'pooled':\n        raise NotImplementedError('only usevar=\"pooled\" is implemented')\n    x1 = np.asarray(x1)\n    nobs1 = x1.shape[0]\n    x1_mean = x1.mean(0)\n    x1_var = x1.var(0)\n    if x2 is not None:\n        x2 = np.asarray(x2)\n        nobs2 = x2.shape[0]\n        x2_mean = x2.mean(0)\n        x2_var = x2.var(0)\n        var_pooled = nobs1 * x1_var + nobs2 * x2_var\n        var_pooled /= nobs1 + nobs2 - 2 * ddof\n        var_pooled *= 1.0 / nobs1 + 1.0 / nobs2\n    else:\n        var_pooled = x1_var / (nobs1 - ddof)\n        x2_mean = 0\n    std_diff = np.sqrt(var_pooled)\n    ci = _zconfint_generic(x1_mean - x2_mean - value, std_diff, alpha,\n        alternative)\n    return ci", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_ztost():\n    xfair = np.repeat([1, 0], [228, 762 - 228])\n    from statsmodels.stats.weightstats import zconfint, ztost\n    ci01 = zconfint(xfair, alpha=0.1, ddof=0)\n    assert_almost_equal(ci01, [0.2719, 0.3265], 4)\n    res = ztost(xfair, 0.18, 0.38, ddof=0)\n    assert_almost_equal(res[1][0], 7.1865, 4)\n    assert_almost_equal(res[2][0], -4.8701, 4)\n    assert_array_less(res[0], 0.0001)\n\ntest_ztost()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: \nThe zconfint function calculates the confidence interval based on the normal distribution z-test for either one or two independent samples. It can handle 1-D or 2-D array-like inputs for the samples. The function supports pooled variance for the two-sample case and allows for a shift in the confidence interval center by specifying a 'value' parameter. The 'usevar' parameter is currently only implemented for 'pooled' variance.\n\nInputs: \n- x1: An array-like object representing the first sample. Can be 1-D or 2-D.\n- x2: An optional array-like object representing the second sample. Can be 1-D or 2-D.\n- value: A float value. In the one-sample case, it is the mean of x1 under the null hypothesis. In the two-sample case, it is the difference between the means of x1 and x2 under the null hypothesis. Default is 0.\n- alpha: A float representing the significance level for the confidence interval. Default is 0.05.\n- alternative: A string indicating the alternative hypothesis. Options include 'two-sided', 'less', or 'greater'. Default is 'two-sided'.\n- usevar: A string indicating the variance to use. Currently, only 'pooled' is implemented, assuming equal variance between samples. Default is 'pooled'.\n- ddof: An integer representing degrees of freedom used in calculating the variance of the mean estimate. Default is 1.\n\nOutputs: \n- ci: A tuple representing the lower and upper bounds of the confidence interval based on the z-test. The interval is centered on the difference between the means of x1 and x2, adjusted by the 'value' parameter if provided.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.decorators import cache_readonly\nimport pandas as pd\nfrom statsmodels.iolib.summary import summary_params\n\n\ndef zconfint(x1, x2=None, value=0, alpha=0.05, alternative='two-sided',\n    usevar='pooled', ddof=1.0): [MASK]\n"}
{"method_name": "ksstat", "full_method_name": "ksstat", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/_lilliefors.py", "method_code": "from functools import partial\nimport numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.validation import string_like\ndef ksstat(x, cdf, alternative='two_sided', args=()):\n    \"\"\"\n    Calculate statistic for the Kolmogorov-Smirnov test for goodness of fit\n\n    This calculates the test statistic for a test of the distribution G(x) of\n    an observed variable against a given distribution F(x). Under the null\n    hypothesis the two distributions are identical, G(x)=F(x). The\n    alternative hypothesis can be either 'two_sided' (default), 'less'\n    or 'greater'. The KS test is only valid for continuous distributions.\n\n    Parameters\n    ----------\n    x : array_like, 1d\n        array of observations\n    cdf : str or callable\n        string: name of a distribution in scipy.stats\n        callable: function to evaluate cdf\n    alternative : 'two_sided' (default), 'less' or 'greater'\n        defines the alternative hypothesis (see explanation)\n    args : tuple, sequence\n        distribution parameters for call to cdf\n\n\n    Returns\n    -------\n    D : float\n        KS test statistic, either D, D+ or D-\n\n    See Also\n    --------\n    scipy.stats.kstest\n\n    Notes\n    -----\n\n    In the one-sided test, the alternative is that the empirical\n    cumulative distribution function of the random variable is \"less\"\n    or \"greater\" than the cumulative distribution function F(x) of the\n    hypothesis, G(x)<=F(x), resp. G(x)>=F(x).\n\n    In contrast to scipy.stats.kstest, this function only calculates the\n    statistic which can be used either as distance measure or to implement\n    case specific p-values.\n    \"\"\"\n    nobs = float(len(x))\n    if isinstance(cdf, str):\n        cdf = getattr(stats.distributions, cdf).cdf\n    elif hasattr(cdf, 'cdf'):\n        cdf = getattr(cdf, 'cdf')\n    x = np.sort(x)\n    cdfvals = cdf(x, *args)\n    d_plus = (np.arange(1.0, nobs + 1) / nobs - cdfvals).max()\n    d_min = (cdfvals - np.arange(0.0, nobs) / nobs).max()\n    if alternative == 'greater':\n        return d_plus\n    elif alternative == 'less':\n        return d_min\n    return np.max([d_plus, d_min])", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom numpy.testing import assert_almost_equal\nfrom scipy import stats\nfrom statsmodels.stats._lilliefors import lilliefors\nfrom statsmodels.stats._lilliefors import get_lilliefors_table\nfrom statsmodels.stats._lilliefors import kstest_fit\nfrom statsmodels.stats._lilliefors import ksstat\ndef test_ksstat():\n    x = np.random.uniform(0, 1, 100)\n    two_sided = ksstat(x, 'uniform', alternative='two_sided')\n    greater = ksstat(x, 'uniform', alternative='greater')\n    lower = ksstat(x, stats.uniform, alternative='lower')\n    print(two_sided, greater, lower)\n    assert lower <= two_sided\n    assert greater <= two_sided\n\ntest_ksstat()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_lilliefors.py"}], "instruction": "Functionality: The ksstat function is designed to calculate the test statistic for the Kolmogorov-Smirnov (KS) test, which is used for assessing the goodness of fit of an observed distribution against a given distribution.\n\nInputs:\n- x: A 1D array of observations. This is the data for which the distribution is being tested.\n- cdf: A string or a callable function that describes the cumulative distribution function (CDF) to be tested against. If a string is provided, it must be the name of a distribution in scipy.stats. If a callable is provided, it should be a function that evaluates the CDF.\n- alternative: A string indicating the type of alternative hypothesis to be tested. It can be 'two_sided' (default), 'less', or 'greater'.\n- args: A tuple or sequence providing the distribution parameters necessary for calling the cdf function.\n\nOutputs:\n- D: A float representing the KS test statistic. This is either D (for 'two_sided'), D+ (for 'greater'), or D- (for 'less'). This statistic can be used as a distance measure or in implementing case-specific p-values.\n\nNotes: The function is designed to work with continuous distributions and can handle either a string name or a callable for the cdf input. The function sorts the input data and calculates the KS test statistic based on the specified alternative hypothesis.", "method_code_mask": "from functools import partial\nimport numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.validation import string_like\n\n\ndef ksstat(x, cdf, alternative='two_sided', args=()): [MASK]\n"}
{"method_name": "cov2corr", "full_method_name": "cov2corr", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/moment_helpers.py", "method_code": "import numpy as np\nfrom scipy.special import comb\ndef cov2corr(cov, return_std=False):\n    \"\"\"\n    convert covariance matrix to correlation matrix\n\n    Parameters\n    ----------\n    cov : array_like, 2d\n        covariance matrix, see Notes\n\n    Returns\n    -------\n    corr : ndarray (subclass)\n        correlation matrix\n    return_std : bool\n        If this is true then the standard deviation is also returned.\n        By default only the correlation matrix is returned.\n\n    Notes\n    -----\n    This function does not convert subclasses of ndarrays. This requires that\n    division is defined elementwise. np.ma.array and np.matrix are allowed.\n    \"\"\"\n    cov = np.asanyarray(cov)\n    std_ = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_, std_)\n    if return_std:\n        return corr, std_\n    else:\n        return corr", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats import moment_helpers\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.moment_helpers import mvsk2mc\nfrom statsmodels.stats.moment_helpers import mc2mvsk\nfrom statsmodels.stats.moment_helpers import mnc2mc\nfrom statsmodels.stats.moment_helpers import mc2mnc\nfrom statsmodels.stats.moment_helpers import cum2mc\nfrom statsmodels.stats.moment_helpers import mc2cum\nfrom statsmodels.stats.moment_helpers import mnc2cum\ndef test_cov2corr():\n    cov_a = np.ones((3, 3)) + np.diag(np.arange(1, 4) ** 2 - 1)\n    corr_a = np.array([[1, 1 / 2.0, 1 / 3.0], [1 / 2.0, 1, 1 / 2.0 / 3.0],\n        [1 / 3.0, 1 / 2.0 / 3.0, 1]])\n    corr = cov2corr(cov_a)\n    assert_almost_equal(corr, corr_a, decimal=15)\n    cov_mat = cov_a\n    corr_mat = cov2corr(cov_mat)\n    assert_(isinstance(corr_mat, np.ndarray))\n    assert_equal(corr_mat, corr)\n    cov_ma = np.ma.array(cov_a)\n    corr_ma = cov2corr(cov_ma)\n    assert_equal(corr_mat, corr)\n    assert_(isinstance(corr_ma, np.ma.core.MaskedArray))\n    cov_ma2 = np.ma.array(cov_a, mask=[[False, True, False], [True, False, \n        False], [False, False, False]])\n    corr_ma2 = cov2corr(cov_ma2)\n    assert_(np.ma.allclose(corr_ma, corr, atol=1e-15))\n    assert_equal(corr_ma2.mask, cov_ma2.mask)\n\ntest_cov2corr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_moment_helpers.py"}], "instruction": "Functionality: The function 'cov2corr' is designed to convert a given covariance matrix into a correlation matrix. It can also optionally return the standard deviation of the elements if specified.\n\nInputs: \n1. cov : array_like, 2d - This is the covariance matrix that needs to be converted into a correlation matrix. It should be a 2-dimensional array.\n2. return_std : bool - A boolean parameter that indicates whether the function should return the standard deviation along with the correlation matrix. By default, it is set to False.\n\nOutputs:\n1. corr : ndarray (subclass) - The correlation matrix derived from the input covariance matrix.\n2. std_ : ndarray (optional) - Only returned if 'return_std' is set to True. It represents the standard deviation of the elements in the covariance matrix.", "method_code_mask": "import numpy as np\nfrom scipy.special import comb\n\n\ndef cov2corr(cov, return_std=False): [MASK]\n"}
{"method_name": "power_equivalence_poisson_2indep", "full_method_name": "power_equivalence_poisson_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef power_equivalence_poisson_2indep(rate1, rate2, nobs1, low, upp,\n    nobs_ratio=1, exposure=1, alpha=0.05, dispersion=1, method_var='alt',\n    return_results=False):\n    \"\"\"Power of equivalence test of ratio of 2 independent poisson rates.\n\n    Parameters\n    ----------\n    rate1 : float\n        Poisson rate for the first sample, treatment group, under the\n        alternative hypothesis.\n    rate2 : float\n        Poisson rate for the second sample, reference group, under the\n        alternative hypothesis.\n    nobs1 : float or int\n        Number of observations in sample 1.\n    low : float\n        Lower equivalence margin for the rate ratio, rate1 / rate2.\n    upp : float\n        Upper equivalence margin for the rate ratio, rate1 / rate2.\n    nobs_ratio : float\n        Sample size ratio, nobs2 = nobs_ratio * nobs1.\n    exposure : float\n        Exposure for each observation. Total exposure is nobs1 * exposure\n        and nobs2 * exposure.\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    value : float\n        Difference between rates 1 and 2 under the null hypothesis.\n    method_var : {\"score\", \"alt\"}\n        The variance of the test statistic for the null hypothesis given the\n        rates uder the alternative, can be either equal to the rates under the\n        alternative ``method_var=\"alt\"``, or estimated under the constrained\n        of the null hypothesis, ``method_var=\"score\"``.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is False, then only the power is returned.\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n\n    References\n    ----------\n    .. [1] Zhu, Haiyuan. 2017. \u201cSample Size Calculation for Comparing Two\n       Poisson or Negative Binomial Rates in Noninferiority or Equivalence\n       Trials.\u201d Statistics in Biopharmaceutical Research, March.\n       https://doi.org/10.1080/19466315.2016.1225594\n    .. [2] Zhu, Haiyuan, and Hassan Lakkis. 2014. \u201cSample Size Calculation for\n       Comparing Two Negative Binomial Rates.\u201d Statistics in Medicine 33 (3):\n       376\u201387. https://doi.org/10.1002/sim.5947.\n    .. [3] PASS documentation\n    \"\"\"\n    rate1, rate2, nobs1 = map(np.asarray, [rate1, rate2, nobs1])\n    nobs2 = nobs_ratio * nobs1\n    v1 = dispersion / exposure * (1 / rate1 + 1 / (nobs_ratio * rate2))\n    if method_var == 'alt':\n        v0_low = v0_upp = v1\n    elif method_var == 'score':\n        v0_low = dispersion / exposure * (1 + low * nobs_ratio) ** 2\n        v0_low /= low * nobs_ratio * (rate1 + nobs_ratio * rate2)\n        v0_upp = dispersion / exposure * (1 + upp * nobs_ratio) ** 2\n        v0_upp /= upp * nobs_ratio * (rate1 + nobs_ratio * rate2)\n    else:\n        raise NotImplementedError(f'method_var {method_var} not recognized')\n    es_low = np.log(rate1 / rate2) - np.log(low)\n    es_upp = np.log(rate1 / rate2) - np.log(upp)\n    std_null_low = np.sqrt(v0_low)\n    std_null_upp = np.sqrt(v0_upp)\n    std_alternative = np.sqrt(v1)\n    pow_ = _power_equivalence_het(es_low, es_upp, nobs2, alpha=alpha,\n        std_null_low=std_null_low, std_null_upp=std_null_upp,\n        std_alternative=std_alternative)\n    if return_results:\n        res = HolderTuple(power=pow_[0], power_margins=pow[1:],\n            std_null_low=std_null_low, std_null_upp=std_null_upp, std_alt=\n            std_alternative, nobs1=nobs1, nobs2=nobs2, nobs_ratio=\n            nobs_ratio, alpha=alpha, tuple_=('power',))\n        return res\n    else:\n        return pow_[0]", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_poisson_power_2ratio():\n    rate1, rate2 = 2.2, 2.2\n    nobs1, nobs2 = 95, 95\n    alpha = 0.025\n    exposure = 2.5\n    low, upp = 0.8, 1.25\n    dispersion = 1\n    cases = [(1.9, 704, 704, 0.90012), (2.0, 246, 246, 0.90057), (2.2, 95, \n        95, 0.90039), (2.5, 396, 396, 0.90045)]\n    for case in cases:\n        rate1, nobs1, nobs2, p = case\n        pow_ = power_equivalence_poisson_2indep(rate1, rate2, nobs1, low,\n            upp, nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n            dispersion=dispersion)\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_equivalence_poisson_2indep(rate1, rate2, nobs1, low,\n            upp, nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n            method_var='score', dispersion=dispersion)\n        assert_allclose(pow_2, p, rtol=0.005)\n    cases = [(1.8, 29, 29, 0.90056), (1.9, 39, 39, 0.90649), (2.2, 115, 115,\n        0.90014), (2.4, 404, 404, 0.90064)]\n    low = 1.2\n    for case in cases:\n        rate1, nobs1, nobs2, p = case\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            dispersion=1, alternative='smaller')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            dispersion=1, alternative='two-sided')\n        assert_allclose(pow_, p, atol=5e-05)\n    pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=nobs2 /\n        nobs1, exposure=exposure, value=rate1 / rate2, alpha=0.05,\n        dispersion=1, alternative='two-sided')\n    assert_allclose(pow_, 0.05, atol=5e-05)\n    cases = [(1.8, 29, 29, 0.90056), (1.9, 39, 39, 0.90649), (2.2, 115, 115,\n        0.90014), (2.4, 404, 404, 0.90064)]\n    rate1 = 2.2\n    low = 1 / 1.2\n    for case in cases:\n        rate2, nobs1, nobs2, p = case\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            dispersion=1, alternative='larger')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            method_var='score', dispersion=1, alternative='larger')\n        assert_allclose(pow_2, p, rtol=0.005)\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            dispersion=1, alternative='two-sided')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            method_var='score', dispersion=1, alternative='two-sided')\n        assert_allclose(pow_2, p, rtol=0.005)\n\ntest_poisson_power_2ratio()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality: Computes the power of an equivalence test for the ratio of two independent Poisson rates.\n\nInputs:\n- rate1: float - Poisson rate for the first sample (treatment group) under the alternative hypothesis.\n- rate2: float - Poisson rate for the second sample (reference group) under the alternative hypothesis.\n- nobs1: float or int - Number of observations in the first sample.\n- low: float - Lower equivalence margin for the rate ratio (rate1 / rate2).\n- upp: float - Upper equivalence margin for the rate ratio (rate1 / rate2).\n- nobs_ratio: float (default=1) - Sample size ratio, where nobs2 = nobs_ratio * nobs1.\n- exposure: float (default=1) - Exposure for each observation.\n- alpha: float in interval (0,1) (default=0.05) - Significance level for the probability of a type I error.\n- dispersion: float (default=1) - Dispersion parameter to account for overdispersion.\n- method_var: string (\"score\", \"alt\") (default=\"alt\") - Method for estimating the variance of the test statistic.\n- return_results: bool (default=False) - Flag to indicate if a results instance should be returned.\n\nOutputs:\n- results: results instance or float - If return_results is False, only the computed power is returned; if True, a results instance is returned containing the power and additional information such as standard error under the null and alternative hypotheses.", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef power_equivalence_poisson_2indep(rate1, rate2, nobs1, low, upp,\n    nobs_ratio=1, exposure=1, alpha=0.05, dispersion=1, method_var='alt',\n    return_results=False): [MASK]\n"}
{"method_name": "power_poisson_ratio_2indep", "full_method_name": "power_poisson_ratio_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=1, exposure=\n    1, value=0, alpha=0.05, dispersion=1, alternative='smaller', method_var\n    ='alt', return_results=True):\n    \"\"\"Power of test of ratio of 2 independent poisson rates.\n\n    This is based on Zhu and Zhu and Lakkis. It does not directly correspond\n    to `test_poisson_2indep`.\n\n    Parameters\n    ----------\n    rate1 : float\n        Poisson rate for the first sample, treatment group, under the\n        alternative hypothesis.\n    rate2 : float\n        Poisson rate for the second sample, reference group, under the\n        alternative hypothesis.\n    nobs1 : float or int\n        Number of observations in sample 1.\n    nobs_ratio : float\n        Sample size ratio, nobs2 = nobs_ratio * nobs1.\n    exposure : float\n        Exposure for each observation. Total exposure is nobs1 * exposure\n        and nobs2 * exposure.\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    value : float\n        Rate ratio, rate1 / rate2, under the null hypothesis.\n    dispersion : float\n        Dispersion coefficient for quasi-Poisson. Dispersion different from\n        one can capture over or under dispersion relative to Poisson\n        distribution.\n    method_var : {\"score\", \"alt\"}\n        The variance of the test statistic for the null hypothesis given the\n        rates under the alternative can be either equal to the rates under the\n        alternative ``method_var=\"alt\"``, or estimated under the constrained\n        of the null hypothesis, ``method_var=\"score\"``.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is False, then only the power is returned.\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n\n    References\n    ----------\n    .. [1] Zhu, Haiyuan. 2017. \u201cSample Size Calculation for Comparing Two\n       Poisson or Negative Binomial Rates in Noninferiority or Equivalence\n       Trials.\u201d Statistics in Biopharmaceutical Research, March.\n       https://doi.org/10.1080/19466315.2016.1225594\n    .. [2] Zhu, Haiyuan, and Hassan Lakkis. 2014. \u201cSample Size Calculation for\n       Comparing Two Negative Binomial Rates.\u201d Statistics in Medicine 33 (3):\n       376\u201387. https://doi.org/10.1002/sim.5947.\n    .. [3] PASS documentation\n    \"\"\"\n    from statsmodels.stats.power import normal_power_het\n    rate1, rate2, nobs1 = map(np.asarray, [rate1, rate2, nobs1])\n    nobs2 = nobs_ratio * nobs1\n    v1 = dispersion / exposure * (1 / rate1 + 1 / (nobs_ratio * rate2))\n    if method_var == 'alt':\n        v0 = v1\n    elif method_var == 'score':\n        v0 = dispersion / exposure * (1 + value / nobs_ratio) ** 2\n        v0 /= value / nobs_ratio * (rate1 + nobs_ratio * rate2)\n    else:\n        raise NotImplementedError(f'method_var {method_var} not recognized')\n    std_null = np.sqrt(v0)\n    std_alt = np.sqrt(v1)\n    es = np.log(rate1 / rate2) - np.log(value)\n    pow_ = normal_power_het(es, nobs1, alpha, std_null=std_null,\n        std_alternative=std_alt, alternative=alternative)\n    p_pooled = None\n    if return_results:\n        res = HolderTuple(power=pow_, p_pooled=p_pooled, std_null=std_null,\n            std_alt=std_alt, nobs1=nobs1, nobs2=nobs2, nobs_ratio=\n            nobs_ratio, alpha=alpha, tuple_=('power',))\n        return res\n    return pow_", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_poisson_power_2ratio():\n    rate1, rate2 = 2.2, 2.2\n    nobs1, nobs2 = 95, 95\n    alpha = 0.025\n    exposure = 2.5\n    low, upp = 0.8, 1.25\n    dispersion = 1\n    cases = [(1.9, 704, 704, 0.90012), (2.0, 246, 246, 0.90057), (2.2, 95, \n        95, 0.90039), (2.5, 396, 396, 0.90045)]\n    for case in cases:\n        rate1, nobs1, nobs2, p = case\n        pow_ = power_equivalence_poisson_2indep(rate1, rate2, nobs1, low,\n            upp, nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n            dispersion=dispersion)\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_equivalence_poisson_2indep(rate1, rate2, nobs1, low,\n            upp, nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n            method_var='score', dispersion=dispersion)\n        assert_allclose(pow_2, p, rtol=0.005)\n    cases = [(1.8, 29, 29, 0.90056), (1.9, 39, 39, 0.90649), (2.2, 115, 115,\n        0.90014), (2.4, 404, 404, 0.90064)]\n    low = 1.2\n    for case in cases:\n        rate1, nobs1, nobs2, p = case\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            dispersion=1, alternative='smaller')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            dispersion=1, alternative='two-sided')\n        assert_allclose(pow_, p, atol=5e-05)\n    pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=nobs2 /\n        nobs1, exposure=exposure, value=rate1 / rate2, alpha=0.05,\n        dispersion=1, alternative='two-sided')\n    assert_allclose(pow_, 0.05, atol=5e-05)\n    cases = [(1.8, 29, 29, 0.90056), (1.9, 39, 39, 0.90649), (2.2, 115, 115,\n        0.90014), (2.4, 404, 404, 0.90064)]\n    rate1 = 2.2\n    low = 1 / 1.2\n    for case in cases:\n        rate2, nobs1, nobs2, p = case\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            dispersion=1, alternative='larger')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.025,\n            method_var='score', dispersion=1, alternative='larger')\n        assert_allclose(pow_2, p, rtol=0.005)\n        pow_ = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            dispersion=1, alternative='two-sided')\n        assert_allclose(pow_, p, atol=5e-05)\n        pow_2 = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n            nobs2 / nobs1, exposure=exposure, value=low, alpha=0.05,\n            method_var='score', dispersion=1, alternative='two-sided')\n        assert_allclose(pow_2, p, rtol=0.005)\n\ntest_poisson_power_2ratio()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}, {"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_power_negbin():\n    rate1, rate2 = 2.5, 2.5\n    nobs1, nobs2 = 965, 965\n    alpha = 0.05\n    exposure = 0.9\n    low, upp = 0.875, 1 / 0.875\n    dispersion = 0.35\n    pow1 = 0.90022\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='alt')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    nobs1, nobs2 = 966, 966\n    pow1 = 0.90015\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='ftotal')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    pow1 = 0.90034\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='score')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    rate2, nobs2, rate1, nobs1, exposure = 0.3, 50, 0.5, 100, 2\n    pow1 = 0.6207448\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.5825763\n    nobs1, nobs2 = nobs2, nobs1\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.7248956\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='two-sided', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow1 = 0.823889\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='smaller', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='smaller', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow_ = power_negbin_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=nobs2 /\n        nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='larger', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n        nobs2 / nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='larger', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n\ntest_power_negbin()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality: The power_poisson_ratio_2indep function calculates the power of a test for the ratio of two independent Poisson rates. This function is essential for determining the sample size needed to detect a specific difference between two Poisson rates with a given level of confidence.\n\nInputs: \n- rate1: float - The Poisson rate for the first sample (treatment group) under the alternative hypothesis.\n- rate2: float - The Poisson rate for the second sample (reference group) under the alternative hypothesis.\n- nobs1: float or int - The number of observations in sample 1.\n- nobs_ratio: float (default=1) - The ratio of the sample sizes, nobs2 = nobs_ratio * nobs1.\n- exposure: float (default=1) - The exposure for each observation. Total exposure for each sample is calculated as nobs1 * exposure and nobs2 * exposure.\n- value: float (default=0) - The hypothesized rate ratio, rate1 / rate2, under the null hypothesis.\n- alpha: float in interval (0,1) (default=0.05) - The significance level of the test.\n- dispersion: float (default=1) - Dispersion coefficient for quasi-Poisson, to capture over or under dispersion.\n- alternative: string ('two-sided', 'larger', 'smaller') (default='smaller') - The alternative hypothesis for the test.\n- method_var: string ('score', 'alt') (default='alt') - Method to calculate the variance for the test statistic.\n- return_results: bool (default=True) - If True, a results instance with extra information is returned; otherwise, only the power is returned.\n\nOutputs:\n- If return_results is False, the function returns the power of the test.\n- If return_results is True, a results instance is returned with the following attributes:\n  - power: float - The power of the test, which is one minus the probability of a type II error.\n  - std_null: standard error under the null hypothesis (without sqrt(nobs1)).\n  - std_alt: standard error under the alternative hypothesis (without sqrt(nobs1)).\n  - Additional information related to the test (e.g., sample sizes, significance level).", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=1, exposure=\n    1, value=0, alpha=0.05, dispersion=1, alternative='smaller', method_var\n    ='alt', return_results=True): [MASK]\n"}
{"method_name": "power_poisson_diff_2indep", "full_method_name": "power_poisson_diff_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef power_poisson_diff_2indep(rate1, rate2, nobs1, nobs_ratio=1, alpha=0.05,\n    value=0, method_var='score', alternative='two-sided', return_results=True):\n    \"\"\"Power of ztest for the difference between two independent poisson rates.\n\n    Parameters\n    ----------\n    rate1 : float\n        Poisson rate for the first sample, treatment group, under the\n        alternative hypothesis.\n    rate2 : float\n        Poisson rate for the second sample, reference group, under the\n        alternative hypothesis.\n    nobs1 : float or int\n        Number of observations in sample 1.\n    nobs_ratio : float\n        Sample size ratio, nobs2 = nobs_ratio * nobs1.\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    value : float\n        Difference between rates 1 and 2 under the null hypothesis.\n    method_var : {\"score\", \"alt\"}\n        The variance of the test statistic for the null hypothesis given the\n        rates uder the alternative, can be either equal to the rates under the\n        alternative ``method_var=\"alt\"``, or estimated under the constrained\n        of the null hypothesis, ``method_var=\"score\"``.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is False, then only the power is returned.\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n\n    References\n    ----------\n    .. [1] Stucke, Kathrin, and Meinhard Kieser. 2013. \u201cSample Size\n       Calculations for Noninferiority Trials with Poisson Distributed Count\n       Data.\u201d Biometrical Journal 55 (2): 203\u201316.\n       https://doi.org/10.1002/bimj.201200142.\n    .. [2] PASS manual chapter 436\n\n    \"\"\"\n    from statsmodels.stats.power import normal_power_het\n    rate1, rate2, nobs1 = map(np.asarray, [rate1, rate2, nobs1])\n    diff = rate1 - rate2\n    _, std_null, std_alt = _std_2poisson_power(rate1, rate2, nobs_ratio=\n        nobs_ratio, alpha=alpha, value=value, method_var=method_var)\n    pow_ = normal_power_het(diff - value, nobs1, alpha, std_null=std_null,\n        std_alternative=std_alt, alternative=alternative)\n    if return_results:\n        res = HolderTuple(power=pow_, rates_alt=(rate2 + diff, rate2),\n            std_null=std_null, std_alt=std_alt, nobs1=nobs1, nobs2=\n            nobs_ratio * nobs1, nobs_ratio=nobs_ratio, alpha=alpha, tuple_=\n            ('power',))\n        return res\n    else:\n        return pow_", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_power_poisson_equal():\n    nobs1, nobs2 = 6, 8\n    nobs_ratio = nobs2 / nobs1\n    rate1, rate2 = 15, 10\n    pow_ = power_poisson_diff_2indep(rate1, rate2, nobs1, nobs_ratio=\n        nobs_ratio, alpha=0.05, value=0, method_var='alt', alternative=\n        'larger', return_results=True)\n    assert_allclose(pow_.power, 0.82566, atol=5e-05)\n    pow_ = power_poisson_diff_2indep(0.6, 0.6, 97, 3 / 2, value=0.3, alpha=\n        0.025, alternative='smaller', method_var='score', return_results=True)\n    assert_allclose(pow_.power, 0.802596, atol=5e-05)\n    pow_ = power_poisson_diff_2indep(0.6, 0.6, 128, 2 / 3, value=0.3, alpha\n        =0.025, alternative='smaller', method_var='score', return_results=True)\n    assert_allclose(pow_.power, 0.80194, atol=5e-05)\n\ntest_power_poisson_equal()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality: The power_poisson_diff_2indep function calculates the power of a z-test for the difference between two independent Poisson rates. It is designed to estimate the probability of correctly rejecting the null hypothesis when the alternative hypothesis is true, given the sample sizes and the hypothesized rates under both the null and alternative hypotheses.\n\nInputs:\n- rate1: A positive float representing the Poisson rate for the first sample (treatment group) under the alternative hypothesis.\n- rate2: A positive float representing the Poisson rate for the second sample (reference group) under the alternative hypothesis.\n- nobs1: A positive float or int representing the number of observations in sample 1 (treatment group).\n- nobs_ratio: An optional positive float (default is 1) representing the sample size ratio, i.e., nobs2 = nobs_ratio * nobs1.\n- alpha: A float in the interval (0, 1) (default is 0.05) representing the significance level, which is the probability of a type I error.\n- value: A float (default is 0) representing the difference between rates 1 and 2 under the null hypothesis.\n- method_var: A string specifying the method for calculating the variance of the test statistic (\"score\" or \"alt\", default is \"score\").\n- alternative: A string specifying the alternative hypothesis (\"two-sided\", \"larger\", or \"smaller\", default is \"two-sided\").\n- return_results: A boolean (default is True) indicating whether to return a results instance with extra information or just the computed power.\n\nOutputs:\nIf return_results is False:\n- A float representing the power of the test, which is one minus the probability of a type II error.\n\nIf return_results is True:\n- A results instance containing:\n  - power: A float representing the power of the test.\n  - rates_alt: A tuple containing the Poisson rates under the alternative hypothesis (rate1, rate2).\n  - std_null: A float representing the standard error of the difference under the null hypothesis (without sqrt(nobs1)).\n  - std_alt: A float representing the standard error of the difference under the alternative hypothesis (without sqrt(nobs1)).\n  - nobs1: The number of observations in sample 1.\n  - nobs2: The number of observations in sample 2, calculated based on nobs1 and nobs_ratio.\n  - nobs_ratio: The sample size ratio used.\n  - alpha: The significance level used.", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef power_poisson_diff_2indep(rate1, rate2, nobs1, nobs_ratio=1, alpha=0.05,\n    value=0, method_var='score', alternative='two-sided', return_results=True\n    ): [MASK]\n"}
{"method_name": "power_negbin_ratio_2indep", "full_method_name": "power_negbin_ratio_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef power_negbin_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=1, exposure=1,\n    value=1, alpha=0.05, dispersion=0.01, alternative='two-sided',\n    method_var='alt', return_results=True):\n    \"\"\"\n    Power of test of ratio of 2 independent negative binomial rates.\n\n    Parameters\n    ----------\n    rate1 : float\n        Poisson rate for the first sample, treatment group, under the\n        alternative hypothesis.\n    rate2 : float\n        Poisson rate for the second sample, reference group, under the\n        alternative hypothesis.\n    nobs1 : float or int\n        Number of observations in sample 1.\n    low : float\n        Lower equivalence margin for the rate ratio, rate1 / rate2.\n    upp : float\n        Upper equivalence margin for the rate ratio, rate1 / rate2.\n    nobs_ratio : float\n        Sample size ratio, nobs2 = nobs_ratio * nobs1.\n    exposure : float\n        Exposure for each observation. Total exposure is nobs1 * exposure\n        and nobs2 * exposure.\n    value : float\n        Rate ratio, rate1 / rate2, under the null hypothesis.\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    dispersion : float >= 0.\n        Dispersion parameter for Negative Binomial distribution.\n        The Poisson limiting case corresponds to ``dispersion=0``.\n    method_var : {\"score\", \"alt\"}\n        The variance of the test statistic for the null hypothesis given the\n        rates under the alternative, can be either equal to the rates under the\n        alternative ``method_var=\"alt\"``, or estimated under the constrained\n        of the null hypothesis, ``method_var=\"score\"``, or based on a moment\n        constrained estimate, ``method_var=\"ftotal\"``. see references.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is False, then only the power is returned.\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n\n    References\n    ----------\n    .. [1] Zhu, Haiyuan. 2017. \u201cSample Size Calculation for Comparing Two\n       Poisson or Negative Binomial Rates in Noninferiority or Equivalence\n       Trials.\u201d Statistics in Biopharmaceutical Research, March.\n       https://doi.org/10.1080/19466315.2016.1225594\n    .. [2] Zhu, Haiyuan, and Hassan Lakkis. 2014. \u201cSample Size Calculation for\n       Comparing Two Negative Binomial Rates.\u201d Statistics in Medicine 33 (3):\n       376\u201387. https://doi.org/10.1002/sim.5947.\n    .. [3] PASS documentation\n    \"\"\"\n    from statsmodels.stats.power import normal_power_het\n    rate1, rate2, nobs1 = map(np.asarray, [rate1, rate2, nobs1])\n    nobs2 = nobs_ratio * nobs1\n    v1 = (1 / rate1 + 1 / (nobs_ratio * rate2)) / exposure + (1 + nobs_ratio\n        ) / nobs_ratio * dispersion\n    if method_var == 'alt':\n        v0 = v1\n    elif method_var == 'ftotal':\n        v0 = (1 + value * nobs_ratio) ** 2 / (exposure * nobs_ratio * value *\n            (rate1 + nobs_ratio * rate2))\n        v0 += (1 + nobs_ratio) / nobs_ratio * dispersion\n    elif method_var == 'score':\n        v0 = _var_cmle_negbin(rate1, rate2, nobs_ratio, exposure=exposure,\n            value=value, dispersion=dispersion)[0]\n    else:\n        raise NotImplementedError(f'method_var {method_var} not recognized')\n    std_null = np.sqrt(v0)\n    std_alt = np.sqrt(v1)\n    es = np.log(rate1 / rate2) - np.log(value)\n    pow_ = normal_power_het(es, nobs1, alpha, std_null=std_null,\n        std_alternative=std_alt, alternative=alternative)\n    if return_results:\n        res = HolderTuple(power=pow_, std_null=std_null, std_alt=std_alt,\n            nobs1=nobs1, nobs2=nobs2, nobs_ratio=nobs_ratio, alpha=alpha,\n            tuple_=('power',))\n        return res\n    return pow_", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_power_negbin():\n    rate1, rate2 = 2.5, 2.5\n    nobs1, nobs2 = 965, 965\n    alpha = 0.05\n    exposure = 0.9\n    low, upp = 0.875, 1 / 0.875\n    dispersion = 0.35\n    pow1 = 0.90022\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='alt')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    nobs1, nobs2 = 966, 966\n    pow1 = 0.90015\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='ftotal')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    pow1 = 0.90034\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='score')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    rate2, nobs2, rate1, nobs1, exposure = 0.3, 50, 0.5, 100, 2\n    pow1 = 0.6207448\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.5825763\n    nobs1, nobs2 = nobs2, nobs1\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.7248956\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='two-sided', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow1 = 0.823889\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='smaller', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='smaller', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow_ = power_negbin_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=nobs2 /\n        nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='larger', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n        nobs2 / nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='larger', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n\ntest_power_negbin()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality: The power_negbin_ratio_2indep function calculates the power of a test for comparing two independent negative binomial rates. This is useful for determining the probability of correctly rejecting the null hypothesis when the alternative hypothesis is true, given specific parameters such as sample sizes, rates, and dispersion.\n\nInputs:\n- rate1: float - Poisson rate for the first sample (treatment group) under the alternative hypothesis.\n- rate2: float - Poisson rate for the second sample (reference group) under the alternative hypothesis.\n- nobs1: float or int - Number of observations in sample 1.\n- nobs_ratio: float (default=1) - Sample size ratio, where nobs2 = nobs_ratio * nobs1.\n- exposure: float (default=1) - Exposure for each observation.\n- value: float (default=1) - Rate ratio, rate1 / rate2, under the null hypothesis.\n- alpha: float in interval (0,1) (default=0.05) - Significance level for the test.\n- dispersion: float >= 0. (default=0.01) - Dispersion parameter for Negative Binomial distribution.\n- alternative: string (default='two-sided') - Type of alternative hypothesis ('two-sided', 'larger', 'smaller').\n- method_var: string (default='alt') - Method for calculating the variance of the test statistic.\n- return_results: bool (default=True) - Whether to return a results instance with extra information.\n\nOutputs:\n- If return_results is False:\n  - power: float - Power of the test, probability of correctly rejecting the null hypothesis.\n- If return_results is True:\n  - results: results instance\n    - power: float - Power of the test.\n    - std_null: float - Standard error under the null hypothesis.\n    - std_alt: float - Standard error under the alternative hypothesis.\n    - Other attributes include nobs1, nobs2, nobs_ratio, and alpha.", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef power_negbin_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=1, exposure=1,\n    value=1, alpha=0.05, dispersion=0.01, alternative='two-sided',\n    method_var='alt', return_results=True): [MASK]\n"}
{"method_name": "power_equivalence_neginb_2indep", "full_method_name": "power_equivalence_neginb_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/rates.py", "method_code": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\ndef power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n    nobs_ratio=1, exposure=1, alpha=0.05, dispersion=0, method_var='alt',\n    return_results=False):\n    \"\"\"\n    Power of equivalence test of ratio of 2 indep. negative binomial rates.\n\n    Parameters\n    ----------\n    rate1 : float\n        Poisson rate for the first sample, treatment group, under the\n        alternative hypothesis.\n    rate2 : float\n        Poisson rate for the second sample, reference group, under the\n        alternative hypothesis.\n    nobs1 : float or int\n        Number of observations in sample 1.\n    low : float\n        Lower equivalence margin for the rate ratio, rate1 / rate2.\n    upp : float\n        Upper equivalence margin for the rate ratio, rate1 / rate2.\n    nobs_ratio : float\n        Sample size ratio, nobs2 = nobs_ratio * nobs1.\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    dispersion : float >= 0.\n        Dispersion parameter for Negative Binomial distribution.\n        The Poisson limiting case corresponds to ``dispersion=0``.\n    method_var : {\"score\", \"alt\"}\n        The variance of the test statistic for the null hypothesis given the\n        rates under the alternative, can be either equal to the rates under the\n        alternative ``method_var=\"alt\"``, or estimated under the constrained\n        of the null hypothesis, ``method_var=\"score\"``, or based on a moment\n        constrained estimate, ``method_var=\"ftotal\"``. see references.\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is False, then only the power is returned.\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n\n\n    References\n    ----------\n    .. [1] Zhu, Haiyuan. 2017. \u201cSample Size Calculation for Comparing Two\n       Poisson or Negative Binomial Rates in Noninferiority or Equivalence\n       Trials.\u201d Statistics in Biopharmaceutical Research, March.\n       https://doi.org/10.1080/19466315.2016.1225594\n    .. [2] Zhu, Haiyuan, and Hassan Lakkis. 2014. \u201cSample Size Calculation for\n       Comparing Two Negative Binomial Rates.\u201d Statistics in Medicine 33 (3):\n       376\u201387. https://doi.org/10.1002/sim.5947.\n    .. [3] PASS documentation\n    \"\"\"\n    rate1, rate2, nobs1 = map(np.asarray, [rate1, rate2, nobs1])\n    nobs2 = nobs_ratio * nobs1\n    v1 = (1 / rate2 + 1 / (nobs_ratio * rate1)) / exposure + (1 + nobs_ratio\n        ) / nobs_ratio * dispersion\n    if method_var == 'alt':\n        v0_low = v0_upp = v1\n    elif method_var == 'ftotal':\n        v0_low = (1 + low * nobs_ratio) ** 2 / (exposure * nobs_ratio * low *\n            (rate1 + nobs_ratio * rate2))\n        v0_low += (1 + nobs_ratio) / nobs_ratio * dispersion\n        v0_upp = (1 + upp * nobs_ratio) ** 2 / (exposure * nobs_ratio * upp *\n            (rate1 + nobs_ratio * rate2))\n        v0_upp += (1 + nobs_ratio) / nobs_ratio * dispersion\n    elif method_var == 'score':\n        v0_low = _var_cmle_negbin(rate1, rate2, nobs_ratio, exposure=\n            exposure, value=low, dispersion=dispersion)[0]\n        v0_upp = _var_cmle_negbin(rate1, rate2, nobs_ratio, exposure=\n            exposure, value=upp, dispersion=dispersion)[0]\n    else:\n        raise NotImplementedError(f'method_var {method_var} not recognized')\n    es_low = np.log(rate1 / rate2) - np.log(low)\n    es_upp = np.log(rate1 / rate2) - np.log(upp)\n    std_null_low = np.sqrt(v0_low)\n    std_null_upp = np.sqrt(v0_upp)\n    std_alternative = np.sqrt(v1)\n    pow_ = _power_equivalence_het(es_low, es_upp, nobs1, alpha=alpha,\n        std_null_low=std_null_low, std_null_upp=std_null_upp,\n        std_alternative=std_alternative)\n    if return_results:\n        res = HolderTuple(power=pow_[0], power_margins=pow[1:],\n            std_null_low=std_null_low, std_null_upp=std_null_upp, std_alt=\n            std_alternative, nobs1=nobs1, nobs2=nobs2, nobs_ratio=\n            nobs_ratio, alpha=alpha, tuple_=('power',))\n        return res\n    else:\n        return pow_[0]", "test_code_list": [{"test_code": "import pytest\nimport warnings\nimport numpy as np\nfrom numpy import arange\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.stats.rates as smr\nfrom statsmodels.stats.rates import confint_poisson\nfrom statsmodels.stats.rates import tolerance_int_poisson\nfrom statsmodels.stats.rates import confint_quantile_poisson\nfrom statsmodels.stats.rates import etest_poisson_2indep\nfrom statsmodels.stats.rates import confint_poisson_2indep\nfrom statsmodels.stats.rates import nonequivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_ratio_2indep\nfrom statsmodels.stats.rates import power_equivalence_poisson_2indep\nfrom statsmodels.stats.rates import power_poisson_diff_2indep\nfrom statsmodels.stats.rates import power_equivalence_neginb_2indep\nfrom statsmodels.stats.rates import power_negbin_ratio_2indep\nfrom statsmodels.stats.rates import method_names_poisson_1samp\nfrom statsmodels.stats.rates import method_names_poisson_2indep\ndef test_power_negbin():\n    rate1, rate2 = 2.5, 2.5\n    nobs1, nobs2 = 965, 965\n    alpha = 0.05\n    exposure = 0.9\n    low, upp = 0.875, 1 / 0.875\n    dispersion = 0.35\n    pow1 = 0.90022\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='alt')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    nobs1, nobs2 = 966, 966\n    pow1 = 0.90015\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='ftotal')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    pow1 = 0.90034\n    pow_ = power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n        nobs_ratio=nobs2 / nobs1, exposure=exposure, alpha=alpha,\n        dispersion=dispersion, method_var='score')\n    assert_allclose(pow_, pow1, atol=5e-05)\n    rate2, nobs2, rate1, nobs1, exposure = 0.3, 50, 0.5, 100, 2\n    pow1 = 0.6207448\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.5825763\n    nobs1, nobs2 = nobs2, nobs1\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0.5,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow1 = 0.7248956\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='two-sided', method_var='score', return_results=False)\n    assert_allclose(pow_, pow1, atol=0.05)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='two-sided', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow1 = 0.823889\n    pow_ = power_negbin_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=nobs1 /\n        nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='smaller', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate2, rate1, nobs2, nobs_ratio=\n        nobs1 / nobs2, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='smaller', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n    pow_ = power_negbin_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=nobs2 /\n        nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=0,\n        alternative='larger', method_var='score', return_results=False)\n    pow_p = power_poisson_ratio_2indep(rate1, rate2, nobs1, nobs_ratio=\n        nobs2 / nobs1, exposure=exposure, value=1, alpha=alpha, dispersion=\n        1, alternative='larger', method_var='score', return_results=True)\n    assert_allclose(pow_p, pow1, atol=0.05)\n    assert_allclose(pow_p, pow_, rtol=1e-13)\n\ntest_power_negbin()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_rates_poisson.py"}], "instruction": "Functionality: The power_equivalence_neginb_2indep function calculates the power of an equivalence test for the ratio of two independent negative binomial rates. It is particularly useful in scenarios where the interest is in determining if two groups, such as treatment and reference, have rates that are equivalent within a certain margin, rather than simply being different. The function takes into account the sample sizes, rates, equivalence margins, and the dispersion parameter of the negative binomial distribution.\n\nInputs:\n- rate1: A floating-point number representing the rate for the first sample (treatment group) under the alternative hypothesis.\n- rate2: A floating-point number representing the rate for the second sample (reference group) under the alternative hypothesis.\n- nobs1: An integer or floating-point number indicating the number of observations in sample 1.\n- low: A floating-point number specifying the lower equivalence margin for the rate ratio (rate1 / rate2).\n- upp: A floating-point number specifying the upper equivalence margin for the rate ratio (rate1 / rate2).\n- nobs_ratio: A floating-point number (default is 1) indicating the sample size ratio (nobs2 = nobs_ratio * nobs1).\n- exposure: A floating-point number (default is 1) which accounts for the exposure or observation time that may affect the rate calculations.\n- alpha: A floating-point number in the interval (0,1) representing the significance level for type I error.\n- dispersion: A floating-point number greater than or equal to 0, representing the dispersion parameter for the negative binomial distribution. A value of 0 corresponds to the Poisson limiting case.\n- method_var: A string, either \"score\", \"alt\", or \"ftotal\", specifying the method for calculating the variance of the test statistic.\n- return_results: A boolean (default is False) indicating whether to return a results instance with extra information or just the computed power.\n\nOutputs:\n- results: Depending on the value of return_results, the function either returns a single floating-point number representing the power of the test or a results instance containing additional information such as the standard errors under the null and alternative hypotheses, along with other details.", "method_code_mask": "import numpy as np\nimport warnings\nfrom scipy import stats\nfrom scipy import optimize\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.stats._inference_tools import _mover_confint\nfrom statsmodels.stats import proportion\nfrom statsmodels.stats.power import normal_power_het\n\n\ndef power_equivalence_neginb_2indep(rate1, rate2, nobs1, low, upp,\n    nobs_ratio=1, exposure=1, alpha=0.05, dispersion=0, method_var='alt',\n    return_results=False): [MASK]\n"}
{"method_name": "mcnemar", "full_method_name": "mcnemar", "method_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/stats/runs.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import comb\nimport warnings\nfrom statsmodels.tools.validation import array_like\ndef mcnemar(x, y=None, exact=True, correction=True):\n    \"\"\"McNemar test\n\n    Parameters\n    ----------\n    x, y : array_like\n        two paired data samples. If y is None, then x can be a 2 by 2\n        contingency table. x and y can have more than one dimension, then\n        the results are calculated under the assumption that axis zero\n        contains the observation for the samples.\n    exact : bool\n        If exact is true, then the binomial distribution will be used.\n        If exact is false, then the chisquare distribution will be used, which\n        is the approximation to the distribution of the test statistic for\n        large sample sizes.\n    correction : bool\n        If true, then a continuity correction is used for the chisquare\n        distribution (if exact is false.)\n\n    Returns\n    -------\n    stat : float or int, array\n        The test statistic is the chisquare statistic if exact is false. If the\n        exact binomial distribution is used, then this contains the min(n1, n2),\n        where n1, n2 are cases that are zero in one sample but one in the other\n        sample.\n\n    pvalue : float or array\n        p-value of the null hypothesis of equal effects.\n\n    Notes\n    -----\n    This is a special case of Cochran's Q test. The results when the chisquare\n    distribution is used are identical, except for continuity correction.\n\n    \"\"\"\n    warnings.warn('Deprecated, use stats.TableSymmetry instead', FutureWarning)\n    x = np.asarray(x)\n    if y is None and x.shape[0] == x.shape[1]:\n        if x.shape[0] != 2:\n            raise ValueError('table needs to be 2 by 2')\n        n1, n2 = x[1, 0], x[0, 1]\n    else:\n        n1 = np.sum(x < y, 0)\n        n2 = np.sum(x > y, 0)\n    if exact:\n        stat = np.minimum(n1, n2)\n        pval = stats.binom.cdf(stat, n1 + n2, 0.5) * 2\n        pval = np.minimum(pval, 1)\n    else:\n        corr = int(correction)\n        stat = (np.abs(n1 - n2) - corr) ** 2 / (1.0 * (n1 + n2))\n        df = 1\n        pval = stats.chi2.sf(stat, df)\n    return stat, pval", "test_code_list": [{"test_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_approx_equal\nfrom numpy.testing import assert_\nfrom scipy import stats\nimport pytest\nfrom statsmodels.stats.contingency_tables import mcnemar\nfrom statsmodels.stats.contingency_tables import cochrans_q\nfrom statsmodels.stats.contingency_tables import SquareTable\nfrom statsmodels.sandbox.stats.runs import Runs\nfrom statsmodels.sandbox.stats.runs import runstest_1samp\nfrom statsmodels.sandbox.stats.runs import runstest_2samp\nfrom statsmodels.sandbox.stats.runs import mcnemar as mcnemar\nfrom statsmodels.stats.nonparametric import rank_compare_2indep\nfrom statsmodels.stats.nonparametric import rank_compare_2ordinal\nfrom statsmodels.stats.nonparametric import prob_larger_continuous\nfrom statsmodels.stats.nonparametric import cohensd2problarger\nfrom statsmodels.tools.testing import Holder\ndef test_mcnemar_vectorized():\n    ttk = np.random.randint(5, 15, size=(2, 2, 3))\n    with pytest.warns(FutureWarning):\n        res = mcnemar(ttk, exact=False)\n    with pytest.warns(FutureWarning):\n        res1 = lzip(*[mcnemar(ttk[:, :, i], exact=False) for i in range(3)])\n    assert_allclose(res, res1, rtol=1e-13)\n    with pytest.warns(FutureWarning):\n        res = mcnemar(ttk, exact=False, correction=False)\n    with pytest.warns(FutureWarning):\n        res1 = lzip(*[mcnemar(ttk[:, :, i], exact=False, correction=False\n            ) for i in range(3)])\n    assert_allclose(res, res1, rtol=1e-13)\n    with pytest.warns(FutureWarning):\n        res = mcnemar(ttk, exact=True)\n    with pytest.warns(FutureWarning):\n        res1 = lzip(*[mcnemar(ttk[:, :, i], exact=True) for i in range(3)])\n    assert_allclose(res, res1, rtol=1e-13)\n\ntest_mcnemar_vectorized()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_nonparametric.py"}, {"test_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_approx_equal\nfrom numpy.testing import assert_\nfrom scipy import stats\nimport pytest\nfrom statsmodels.stats.contingency_tables import mcnemar\nfrom statsmodels.stats.contingency_tables import cochrans_q\nfrom statsmodels.stats.contingency_tables import SquareTable\nfrom statsmodels.sandbox.stats.runs import Runs\nfrom statsmodels.sandbox.stats.runs import runstest_1samp\nfrom statsmodels.sandbox.stats.runs import runstest_2samp\nfrom statsmodels.sandbox.stats.runs import mcnemar as mcnemar\nfrom statsmodels.stats.nonparametric import rank_compare_2indep\nfrom statsmodels.stats.nonparametric import rank_compare_2ordinal\nfrom statsmodels.stats.nonparametric import prob_larger_continuous\nfrom statsmodels.stats.nonparametric import cohensd2problarger\nfrom statsmodels.tools.testing import Holder\ndef test_cochransq():\n    x = np.array([[1, 1, 1], [1, 1, 1], [0, 1, 0], [1, 1, 0], [0, 0, 0], [1,\n        1, 1], [1, 1, 1], [1, 1, 0], [0, 0, 1], [0, 1, 0], [1, 1, 1], [1, 1,\n        1]])\n    res_qstat = 2.8\n    res_pvalue = 0.246597\n    res = cochrans_q(x)\n    assert_almost_equal([res.statistic, res.pvalue], [res_qstat, res_pvalue])\n    a, b = x[:, :2].T\n    res = cochrans_q(x[:, :2])\n    with pytest.warns(FutureWarning):\n        assert_almost_equal(mcnemar(a, b, exact=False, correction=False),\n            [res.statistic, res.pvalue])\n\ntest_cochransq()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_nonparametric.py"}], "instruction": "Functionality: The McNemar test is a statistical test used to determine whether there is a significant change in the proportions of a dichotomous trait in matched pairs or related samples. The mcnemar function calculates the test statistic and p-value for this test, which can be achieved either by using the binomial distribution for exact calculations or the chi-square distribution for large sample approximations.\n\nInputs:\n- x, y : array_like\n    Two paired data samples. If y is None, x can be a 2 by 2 contingency table. x and y can have more than one dimension, under the assumption that axis zero contains the observations for the samples.\n- exact : bool\n    Determines the method of calculation. If True, uses the binomial distribution. If False, uses the chi-square distribution for large samples.\n- correction : bool\n    If True, applies a continuity correction to the chi-square distribution when exact is False.\n\nOutputs:\n- stat : float or int, array\n    The test statistic, which is the chi-square statistic if exact is False. If the exact binomial distribution is used, it contains the minimum of n1 and n2, where n1, n2 are cases that are zero in one sample but one in the other sample.\n- pvalue : float or array\n    The p-value of the null hypothesis of equal effects, indicating whether there is a significant change in the proportions of the dichotomous trait between the paired samples.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import comb\nimport warnings\nfrom statsmodels.tools.validation import array_like\n\n\ndef mcnemar(x, y=None, exact=True, correction=True): [MASK]\n"}
{"method_name": "_calc_nodewise_row", "full_method_name": "_calc_nodewise_row", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/regularized_covariance.py", "method_code": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\ndef _calc_nodewise_row(exog, idx, alpha):\n    \"\"\"calculates the nodewise_row values for the idxth variable, used to\n    estimate approx_inv_cov.\n\n    Parameters\n    ----------\n    exog : array_like\n        The weighted design matrix for the current partition.\n    idx : scalar\n        Index of the current variable.\n    alpha : scalar or array_like\n        The penalty weight.  If a scalar, the same penalty weight\n        applies to all variables in the model.  If a vector, it\n        must have the same length as `params`, and contains a\n        penalty weight for each coefficient.\n\n    Returns\n    -------\n    An array-like object of length p-1\n\n    Notes\n    -----\n\n    nodewise_row_i = arg min 1/(2n) ||exog_i - exog_-i gamma||_2^2\n                             + alpha ||gamma||_1\n    \"\"\"\n    p = exog.shape[1]\n    ind = list(range(p))\n    ind.pop(idx)\n    if not np.isscalar(alpha):\n        alpha = alpha[ind]\n    tmod = OLS(exog[:, idx], exog[:, ind])\n    nodewise_row = tmod.fit_regularized(alpha=alpha).params\n    return nodewise_row", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.stats.regularized_covariance import RegularizedInvCovariance\ndef test_calc_nodewise_row():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    ghat = _calc_nodewise_row(X, 0, 0.01)\n    assert_equal(ghat.shape, (2,))\n\ntest_calc_nodewise_row()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_regularized_covariance.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.stats.regularized_covariance import RegularizedInvCovariance\ndef test_calc_approx_inv_cov():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    ghat_l = []\n    that_l = []\n    for i in range(3):\n        ghat = _calc_nodewise_row(X, i, 0.01)\n        that = _calc_nodewise_weight(X, ghat, i, 0.01)\n        ghat_l.append(ghat)\n        that_l.append(that)\n    theta_hat = _calc_approx_inv_cov(np.array(ghat_l), np.array(that_l))\n    assert_equal(theta_hat.shape, (3, 3))\n\ntest_calc_approx_inv_cov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_regularized_covariance.py"}], "instruction": "Functionality: This function calculates the nodewise row values for a specified variable index, which is used in estimating the approximate inverse covariance matrix. The nodewise row is determined by minimizing the regularized least squares objective function for the given variable.\n\nInputs:\n- exog: An array-like object representing the weighted design matrix for the current data partition.\n- idx: A scalar integer representing the index of the current variable for which the nodewise row is to be calculated.\n- alpha: A scalar or an array-like object representing the penalty weight. If a scalar, it applies the same weight to all variables. If an array, it must have the same length as the number of parameters and contains a weight for each coefficient.\n\nOutputs:\n- An array-like object of length (p-1) where p is the number of columns in the design matrix. This output represents the estimated nodewise row for the variable at the specified index.\n\nThe function uses the Ordinary Least Squares (OLS) model from statsmodels for fitting the regularized regression and calculates the nodewise row by minimizing the weighted least squares objective plus the L1-norm penalty on the coefficients, with the penalty weight given by alpha.", "method_code_mask": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\n\n\ndef _calc_nodewise_row(exog, idx, alpha): [MASK]\n"}
{"method_name": "_calc_nodewise_weight", "full_method_name": "_calc_nodewise_weight", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/regularized_covariance.py", "method_code": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\ndef _calc_nodewise_weight(exog, nodewise_row, idx, alpha):\n    \"\"\"calculates the nodewise_weightvalue for the idxth variable, used to\n    estimate approx_inv_cov.\n\n    Parameters\n    ----------\n    exog : array_like\n        The weighted design matrix for the current partition.\n    nodewise_row : array_like\n        The nodewise_row values for the current variable.\n    idx : scalar\n        Index of the current variable\n    alpha : scalar or array_like\n        The penalty weight.  If a scalar, the same penalty weight\n        applies to all variables in the model.  If a vector, it\n        must have the same length as `params`, and contains a\n        penalty weight for each coefficient.\n\n    Returns\n    -------\n    A scalar\n\n    Notes\n    -----\n\n    nodewise_weight_i = sqrt(1/n ||exog,i - exog_-i nodewise_row||_2^2\n                             + alpha ||nodewise_row||_1)\n    \"\"\"\n    n, p = exog.shape\n    ind = list(range(p))\n    ind.pop(idx)\n    if not np.isscalar(alpha):\n        alpha = alpha[ind]\n    d = np.linalg.norm(exog[:, idx] - exog[:, ind].dot(nodewise_row)) ** 2\n    d = np.sqrt(d / n + alpha * np.linalg.norm(nodewise_row, 1))\n    return d", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.stats.regularized_covariance import RegularizedInvCovariance\ndef test_calc_nodewise_weight():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    ghat = np.random.normal(size=2)\n    that = _calc_nodewise_weight(X, ghat, 0, 0.01)\n    assert_(isinstance(that, float))\n\ntest_calc_nodewise_weight()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_regularized_covariance.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.stats.regularized_covariance import RegularizedInvCovariance\ndef test_calc_approx_inv_cov():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    ghat_l = []\n    that_l = []\n    for i in range(3):\n        ghat = _calc_nodewise_row(X, i, 0.01)\n        that = _calc_nodewise_weight(X, ghat, i, 0.01)\n        ghat_l.append(ghat)\n        that_l.append(that)\n    theta_hat = _calc_approx_inv_cov(np.array(ghat_l), np.array(that_l))\n    assert_equal(theta_hat.shape, (3, 3))\n\ntest_calc_approx_inv_cov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_regularized_covariance.py"}], "instruction": "Functionality: The _calc_nodewise_weight function is designed to calculate the nodewise weight value for a specific variable indexed by 'idx'. This value is crucial for estimating the approximate inverse covariance matrix in the context of regression analysis, particularly when dealing with high-dimensional data. The function implements a formula that incorporates the weighted design matrix, nodewise_row values, and a penalty weight (alpha) to compute the nodewise weight.\n\nInputs:\n- exog: An array-like object representing the weighted design matrix for the current partition. This matrix is typically used in regression analysis, where each column corresponds to a feature or variable.\n- nodewise_row: An array-like object containing the nodewise_row values for the current variable. These values are derived from previous computations and are used in the formula to calculate the nodewise weight.\n- idx: A scalar that represents the index of the current variable. This index is used to identify the column of the design matrix corresponding to the variable of interest.\n- alpha: A scalar or array-like object representing the penalty weight. This parameter can be a single value applicable to all variables or a vector of weights, each corresponding to a coefficient in the model.\n\nOutputs:\n- A scalar value representing the nodewise weight for the specified variable. This value is computed based on the formula detailed in the function's docstring, which combines the L2 norm of the difference between the 'idx'th column of the design matrix and the product of the remaining columns with the nodewise_row vector, normalized by the number of observations, and the L1 norm of the nodewise_row vector, penalized by alpha.", "method_code_mask": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\n\n\ndef _calc_nodewise_weight(exog, nodewise_row, idx, alpha): [MASK]\n"}
{"method_name": "_calc_approx_inv_cov", "full_method_name": "_calc_approx_inv_cov", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/regularized_covariance.py", "method_code": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\ndef _calc_approx_inv_cov(nodewise_row_l, nodewise_weight_l):\n    \"\"\"calculates the approximate inverse covariance matrix\n\n    Parameters\n    ----------\n    nodewise_row_l : list\n        A list of array-like object where each object corresponds to\n        the nodewise_row values for the corresponding variable, should\n        be length p.\n    nodewise_weight_l : list\n        A list of scalars where each scalar corresponds to the nodewise_weight\n        value for the corresponding variable, should be length p.\n\n    Returns\n    ------\n    An array-like object, p x p matrix\n\n    Notes\n    -----\n\n    nwr = nodewise_row\n    nww = nodewise_weight\n\n    approx_inv_cov_j = - 1 / nww_j [nwr_j,1,...,1,...nwr_j,p]\n    \"\"\"\n    p = len(nodewise_weight_l)\n    approx_inv_cov = -np.eye(p)\n    for idx in range(p):\n        ind = list(range(p))\n        ind.pop(idx)\n        approx_inv_cov[idx, ind] = nodewise_row_l[idx]\n    approx_inv_cov *= -1 / nodewise_weight_l[:, None] ** 2\n    return approx_inv_cov", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.stats.regularized_covariance import RegularizedInvCovariance\ndef test_calc_approx_inv_cov():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    ghat_l = []\n    that_l = []\n    for i in range(3):\n        ghat = _calc_nodewise_row(X, i, 0.01)\n        that = _calc_nodewise_weight(X, ghat, i, 0.01)\n        ghat_l.append(ghat)\n        that_l.append(that)\n    theta_hat = _calc_approx_inv_cov(np.array(ghat_l), np.array(that_l))\n    assert_equal(theta_hat.shape, (3, 3))\n\ntest_calc_approx_inv_cov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_regularized_covariance.py"}], "instruction": "Functionality: This function calculates the approximate inverse covariance matrix using nodewise regression coefficients and nodewise weights. It is particularly useful in graphical model estimation and high-dimensional data analysis.\n\nInputs:\n- nodewise_row_l: A list containing array-like objects. Each object represents the nodewise regression coefficients for a specific variable. The list's length corresponds to the number of variables (p).\n- nodewise_weight_l: A list of scalars, each corresponding to the nodewise weight value for a specific variable. The list's length should also equal p.\n\nOutputs:\n- An array-like object representing the p x p approximate inverse covariance matrix, where p is the number of variables. This matrix is computed based on the input nodewise regression coefficients and weights.", "method_code_mask": "from statsmodels.regression.linear_model import OLS\nimport numpy as np\n\n\ndef _calc_approx_inv_cov(nodewise_row_l, nodewise_weight_l): [MASK]\n"}
{"method_name": "confint_mvmean", "full_method_name": "confint_mvmean", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/multivariate.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.tools.validation import array_like\ndef confint_mvmean(data, lin_transf=None, alpha=0.5, simult=False):\n    \"\"\"Confidence interval for linear transformation of a multivariate mean\n\n    Either pointwise or simultaneous confidence intervals are returned.\n\n    Parameters\n    ----------\n    data : array_like\n        data with observations in rows and variables in columns\n    lin_transf : array_like or None\n        The linear transformation or contrast matrix for transforming the\n        vector of means. If this is None, then the identity matrix is used\n        which specifies the means themselves.\n    alpha : float in (0, 1)\n        confidence level for the confidence interval, commonly used is\n        alpha=0.05.\n    simult : bool\n        If ``simult`` is False (default), then the pointwise confidence\n        interval is returned.\n        Otherwise, a simultaneous confidence interval is returned.\n        Warning: additional simultaneous confidence intervals might be added\n        and the default for those might change.\n\n    Returns\n    -------\n    low : ndarray\n        lower confidence bound on the linear transformed\n    upp : ndarray\n        upper confidence bound on the linear transformed\n    values : ndarray\n        mean or their linear transformation, center of the confidence region\n\n    Notes\n    -----\n    Pointwise confidence interval is based on Johnson and Wichern\n    equation (5-21) page 224.\n\n    Simultaneous confidence interval is based on Johnson and Wichern\n    Result 5.3 page 225.\n    This looks like Sheffe simultaneous confidence intervals.\n\n    Bonferroni corrected simultaneous confidence interval might be added in\n    future\n\n    References\n    ----------\n    Johnson, Richard A., and Dean W. Wichern. 2007. Applied Multivariate\n    Statistical Analysis. 6th ed. Upper Saddle River, N.J: Pearson Prentice\n    Hall.\n    \"\"\"\n    x = np.asarray(data)\n    nobs, k_vars = x.shape\n    if lin_transf is None:\n        lin_transf = np.eye(k_vars)\n    mean = x.mean(0)\n    cov = np.cov(x, rowvar=False, ddof=0)\n    ci = confint_mvmean_fromstats(mean, cov, nobs, lin_transf=lin_transf,\n        alpha=alpha, simult=simult)\n    return ci", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats import weightstats\nimport statsmodels.stats.multivariate as smmv\nfrom statsmodels.stats.multivariate import confint_mvmean_fromstats\nfrom statsmodels.tools.testing import Holder\ndef test_mv_mean():\n    x = np.asarray([[1.0, 24.0, 23.5, 1.0], [2.0, 25.0, 24.5, 1.0], [3.0, \n        21.0, 20.5, 1.0], [4.0, 22.0, 20.5, 1.0], [5.0, 23.0, 22.5, 1.0], [\n        6.0, 18.0, 16.5, 1.0], [7.0, 17.0, 16.5, 1.0], [8.0, 28.0, 27.5, \n        1.0], [9.0, 24.0, 23.5, 1.0], [10.0, 27.0, 25.5, 1.0], [11.0, 21.0,\n        20.5, 1.0], [12.0, 23.0, 22.5, 1.0], [1.0, 20.0, 19.0, 0.0], [2.0, \n        23.0, 22.0, 0.0], [3.0, 21.0, 20.0, 0.0], [4.0, 25.0, 24.0, 0.0], [\n        5.0, 18.0, 17.0, 0.0], [6.0, 17.0, 16.0, 0.0], [7.0, 18.0, 17.0, \n        0.0], [8.0, 24.0, 23.0, 0.0], [9.0, 20.0, 19.0, 0.0], [10.0, 24.0, \n        22.0, 0.0], [11.0, 23.0, 22.0, 0.0], [12.0, 19.0, 18.0, 0.0]])\n    res = smmv.test_mvmean(x[:, 1:3], [21, 21])\n    res_stata = Holder(p_F=1.25062334808e-09, df_r=22, df_m=2, F=\n        59.91609589041116, T2=125.2791095890415)\n    assert_allclose(res.statistic, res_stata.F, rtol=1e-10)\n    assert_allclose(res.pvalue, res_stata.p_F, rtol=1e-10)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-10)\n    assert_equal(res.df, [res_stata.df_m, res_stata.df_r])\n    mask = x[:, -1] == 1\n    x1 = x[mask, 1:3]\n    x0 = x[~mask, 1:3]\n    res_p = smmv.test_mvmean(x1 - x0, [0, 0])\n    res_stata = Holder(T2=9.698067632850247, df=10, k=2, N=12, F=4.4082126,\n        p_F=0.0424)\n    res = res_p\n    assert_allclose(res.statistic, res_stata.F, atol=5e-07)\n    assert_allclose(res.pvalue, res_stata.p_F, atol=0.0005)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-10)\n    assert_equal(res.df, [res_stata.k, res_stata.df])\n    res_stata = Holder(p_F=0.0423949782937231, df_r=10, df_m=2, F=\n        4.408212560386478, T2=9.69806763285025)\n    assert_allclose(res.statistic, res_stata.F, rtol=1e-12)\n    assert_allclose(res.pvalue, res_stata.p_F, rtol=1e-12)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-12)\n    assert_equal(res.df, [res_stata.df_m, res_stata.df_r])\n    dw = weightstats.DescrStatsW(x)\n    ci0 = dw.tconfint_mean(alpha=0.05)\n    nobs = len(x[:, 1:])\n    ci1 = confint_mvmean_fromstats(dw.mean, np.diag(dw.var), nobs,\n        lin_transf=np.eye(4), alpha=0.05)\n    ci2 = confint_mvmean_fromstats(dw.mean, dw.cov, nobs, lin_transf=np.eye\n        (4), alpha=0.05)\n    assert_allclose(ci1[:2], ci0, rtol=1e-13)\n    assert_allclose(ci2[:2], ci0, rtol=1e-13)\n    res = confint_mvmean(x, lin_transf=np.eye(4), alpha=0.05)\n    assert_allclose(res, ci2, rtol=1e-13)\n\ntest_mv_mean()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multivariate.py"}], "instruction": "Functionality: The confint_mvmean function calculates confidence intervals for linear transformations of a multivariate mean. It can calculate either pointwise or simultaneous confidence intervals based on input parameters. The function is designed to work with multivariate data, providing a lower confidence bound, an upper confidence bound, and the mean or the linear transformation of the mean as the center of the confidence region.\n\nInputs:\n- data : array_like\n    A 2D array where observations are in rows and variables are in columns. This is the multivariate data for which the confidence interval of the mean is calculated.\n- lin_transf : array_like or None (default: None)\n    A matrix that specifies the linear transformation or contrasts applied to the variables. If None, the identity matrix is used, indicating the means of the variables themselves.\n- alpha : float in (0, 1) (default: 0.05)\n    The desired confidence level for the confidence interval. Commonly used value is 0.05.\n- simult : bool (default: False)\n    A boolean indicating whether to return pointwise (False) or simultaneous (True) confidence intervals.\n\nOutputs:\n- low : ndarray\n    The lower confidence bound on the linearly transformed mean.\n- upp : ndarray\n    The upper confidence bound on the linearly transformed mean.\n- values : ndarray\n    The mean or the linear transformation of the mean, which is the center of the confidence region.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.tools.validation import array_like\n\n\ndef confint_mvmean(data, lin_transf=None, alpha=0.5, simult=False): [MASK]\n"}
{"method_name": "confint_mvmean_fromstats", "full_method_name": "confint_mvmean_fromstats", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/multivariate.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.tools.validation import array_like\ndef confint_mvmean_fromstats(mean, cov, nobs, lin_transf=None, alpha=0.05,\n    simult=False):\n    \"\"\"Confidence interval for linear transformation of a multivariate mean\n\n    Either pointwise or simultaneous confidence intervals are returned.\n    Data is provided in the form of summary statistics, mean, cov, nobs.\n\n    Parameters\n    ----------\n    mean : ndarray\n    cov : ndarray\n    nobs : int\n    lin_transf : array_like or None\n        The linear transformation or contrast matrix for transforming the\n        vector of means. If this is None, then the identity matrix is used\n        which specifies the means themselves.\n    alpha : float in (0, 1)\n        confidence level for the confidence interval, commonly used is\n        alpha=0.05.\n    simult : bool\n        If simult is False (default), then pointwise confidence interval is\n        returned.\n        Otherwise, a simultaneous confidence interval is returned.\n        Warning: additional simultaneous confidence intervals might be added\n        and the default for those might change.\n\n    Notes\n    -----\n    Pointwise confidence interval is based on Johnson and Wichern\n    equation (5-21) page 224.\n\n    Simultaneous confidence interval is based on Johnson and Wichern\n    Result 5.3 page 225.\n    This looks like Sheffe simultaneous confidence intervals.\n\n    Bonferroni corrected simultaneous confidence interval might be added in\n    future\n\n    References\n    ----------\n    Johnson, Richard A., and Dean W. Wichern. 2007. Applied Multivariate\n    Statistical Analysis. 6th ed. Upper Saddle River, N.J: Pearson Prentice\n    Hall.\n\n    \"\"\"\n    mean = np.asarray(mean)\n    cov = np.asarray(cov)\n    c = np.atleast_2d(lin_transf)\n    k_vars = len(mean)\n    if simult is False:\n        values = c.dot(mean)\n        quad_form = (c * cov.dot(c.T).T).sum(1)\n        df = nobs - 1\n        t_critval = stats.t.isf(alpha / 2, df)\n        ci_diff = np.sqrt(quad_form / df) * t_critval\n        low = values - ci_diff\n        upp = values + ci_diff\n    else:\n        values = c.dot(mean)\n        quad_form = (c * cov.dot(c.T).T).sum(1)\n        factor = (nobs - 1) * k_vars / (nobs - k_vars) / nobs\n        df = k_vars, nobs - k_vars\n        f_critval = stats.f.isf(alpha, df[0], df[1])\n        ci_diff = np.sqrt(factor * quad_form * f_critval)\n        low = values - ci_diff\n        upp = values + ci_diff\n    return low, upp, values", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats import weightstats\nimport statsmodels.stats.multivariate as smmv\nfrom statsmodels.stats.multivariate import confint_mvmean_fromstats\nfrom statsmodels.tools.testing import Holder\ndef test_mv_mean():\n    x = np.asarray([[1.0, 24.0, 23.5, 1.0], [2.0, 25.0, 24.5, 1.0], [3.0, \n        21.0, 20.5, 1.0], [4.0, 22.0, 20.5, 1.0], [5.0, 23.0, 22.5, 1.0], [\n        6.0, 18.0, 16.5, 1.0], [7.0, 17.0, 16.5, 1.0], [8.0, 28.0, 27.5, \n        1.0], [9.0, 24.0, 23.5, 1.0], [10.0, 27.0, 25.5, 1.0], [11.0, 21.0,\n        20.5, 1.0], [12.0, 23.0, 22.5, 1.0], [1.0, 20.0, 19.0, 0.0], [2.0, \n        23.0, 22.0, 0.0], [3.0, 21.0, 20.0, 0.0], [4.0, 25.0, 24.0, 0.0], [\n        5.0, 18.0, 17.0, 0.0], [6.0, 17.0, 16.0, 0.0], [7.0, 18.0, 17.0, \n        0.0], [8.0, 24.0, 23.0, 0.0], [9.0, 20.0, 19.0, 0.0], [10.0, 24.0, \n        22.0, 0.0], [11.0, 23.0, 22.0, 0.0], [12.0, 19.0, 18.0, 0.0]])\n    res = smmv.test_mvmean(x[:, 1:3], [21, 21])\n    res_stata = Holder(p_F=1.25062334808e-09, df_r=22, df_m=2, F=\n        59.91609589041116, T2=125.2791095890415)\n    assert_allclose(res.statistic, res_stata.F, rtol=1e-10)\n    assert_allclose(res.pvalue, res_stata.p_F, rtol=1e-10)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-10)\n    assert_equal(res.df, [res_stata.df_m, res_stata.df_r])\n    mask = x[:, -1] == 1\n    x1 = x[mask, 1:3]\n    x0 = x[~mask, 1:3]\n    res_p = smmv.test_mvmean(x1 - x0, [0, 0])\n    res_stata = Holder(T2=9.698067632850247, df=10, k=2, N=12, F=4.4082126,\n        p_F=0.0424)\n    res = res_p\n    assert_allclose(res.statistic, res_stata.F, atol=5e-07)\n    assert_allclose(res.pvalue, res_stata.p_F, atol=0.0005)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-10)\n    assert_equal(res.df, [res_stata.k, res_stata.df])\n    res_stata = Holder(p_F=0.0423949782937231, df_r=10, df_m=2, F=\n        4.408212560386478, T2=9.69806763285025)\n    assert_allclose(res.statistic, res_stata.F, rtol=1e-12)\n    assert_allclose(res.pvalue, res_stata.p_F, rtol=1e-12)\n    assert_allclose(res.t2, res_stata.T2, rtol=1e-12)\n    assert_equal(res.df, [res_stata.df_m, res_stata.df_r])\n    dw = weightstats.DescrStatsW(x)\n    ci0 = dw.tconfint_mean(alpha=0.05)\n    nobs = len(x[:, 1:])\n    ci1 = confint_mvmean_fromstats(dw.mean, np.diag(dw.var), nobs,\n        lin_transf=np.eye(4), alpha=0.05)\n    ci2 = confint_mvmean_fromstats(dw.mean, dw.cov, nobs, lin_transf=np.eye\n        (4), alpha=0.05)\n    assert_allclose(ci1[:2], ci0, rtol=1e-13)\n    assert_allclose(ci2[:2], ci0, rtol=1e-13)\n    res = smmv.confint_mvmean(x, lin_transf=np.eye(4), alpha=0.05)\n    assert_allclose(res, ci2, rtol=1e-13)\n\ntest_mv_mean()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multivariate.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats import weightstats\nimport statsmodels.stats.multivariate as smmv\nfrom statsmodels.stats.multivariate import confint_mvmean_fromstats\nfrom statsmodels.tools.testing import Holder\ndef test_confint_simult():\n    m = [526.29, 54.69, 25.13]\n    cov = [[5808.06, 597.84, 222.03], [597.84, 126.05, 23.39], [222.03, \n        23.39, 23.11]]\n    nobs = 87\n    res_ci = confint_mvmean_fromstats(m, cov, nobs, lin_transf=np.eye(3),\n        simult=True)\n    cii = [confint_mvmean_fromstats(m, cov, nobs, lin_transf=np.eye(3)[i],\n        simult=True)[:2] for i in range(3)]\n    cii = np.array(cii).squeeze()\n    res_ci_book = np.array([[503.06, 550.12], [51.22, 58.16], [23.65, 26.61]])\n    assert_allclose(res_ci[0], res_ci_book[:, 0], rtol=0.001)\n    assert_allclose(res_ci[0], res_ci_book[:, 0], rtol=0.001)\n    assert_allclose(res_ci[0], cii[:, 0], rtol=1e-13)\n    assert_allclose(res_ci[1], cii[:, 1], rtol=1e-13)\n    res_constr = confint_mvmean_fromstats(m, cov, nobs, lin_transf=[0, 1, -\n        1], simult=True)\n    assert_allclose(res_constr[0], 29.56 - 3.12, rtol=0.001)\n    assert_allclose(res_constr[1], 29.56 + 3.12, rtol=0.001)\n    lt = [[0, 1, -1], [0, -1, 1], [0, 2, -2]]\n    res_constr2 = confint_mvmean_fromstats(m, cov, nobs, lin_transf=lt,\n        simult=True)\n    lows = res_constr[0], -res_constr[1], 2 * res_constr[0]\n    upps = res_constr[1], -res_constr[0], 2 * res_constr[1]\n    lows = np.asarray(lows).squeeze()\n    upps = np.asarray(upps).squeeze()\n    assert_allclose(res_constr2[0], lows, rtol=1e-13)\n    assert_allclose(res_constr2[1], upps, rtol=1e-13)\n\ntest_confint_simult()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_multivariate.py"}], "instruction": "Functionality: The confint_mvmean_fromstats function calculates either pointwise or simultaneous confidence intervals for linear transformations of a multivariate mean. It takes statistical summaries (mean, covariance, sample size) as inputs and computes confidence intervals based on the data's linear transformation or the means themselves.\n\nInputs:\n- mean: An ndarray representing the mean vector of the multivariate distribution.\n- cov: An ndarray representing the covariance matrix of the multivariate distribution.\n- nobs: An integer representing the number of observations.\n- lin_transf: An array-like object or None, representing the linear transformation matrix for the multivariate mean. If None, the identity matrix is used, indicating the means themselves are of interest.\n- alpha: A float in the range (0, 1) indicating the desired confidence level for the interval, commonly set to 0.05.\n- simult: A boolean value. If False, pointwise confidence intervals are calculated. If True, simultaneous confidence intervals are returned.\n\nOutputs:\n- low: An array representing the lower bounds of the confidence intervals for the linearly transformed means.\n- upp: An array representing the upper bounds of the confidence intervals for the linearly transformed means.\n- values: An array representing the linearly transformed means themselves.\n\nThe function supports both pointwise and simultaneous confidence interval calculations, with the choice being determined by the simult parameter. Pointwise intervals are based on the t-distribution, while simultaneous intervals utilize the F-distribution, following the methodology detailed in Johnson and Wichern's Applied Multivariate Statistical Analysis.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.stats.moment_helpers import cov2corr\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.tools.validation import array_like\n\n\ndef confint_mvmean_fromstats(mean, cov, nobs, lin_transf=None, alpha=0.05,\n    simult=False): [MASK]\n"}
{"method_name": "_contrast_pairs", "full_method_name": "_contrast_pairs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/contrast.py", "method_code": "import numpy as np\nfrom scipy.stats import f as fdist\nfrom scipy.stats import t as student_t\nfrom scipy import stats\nfrom statsmodels.tools.tools import clean0\nfrom statsmodels.tools.tools import fullrank\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import summary_params_frame\nimport statsmodels.sandbox.stats.multicomp as mc\ndef _contrast_pairs(k_params, k_level, idx_start):\n    \"\"\"create pairwise contrast for reference coding\n\n    currently not used,\n    using encoding contrast matrix is more general, but requires requires\n    factor information from patsy design_info.\n\n\n    Parameters\n    ----------\n    k_params : int\n        number of parameters\n    k_level : int\n        number of levels or categories (including reference case)\n    idx_start : int\n        Index of the first parameter of this factor. The restrictions on the\n        factor are inserted as a block in the full restriction matrix starting\n        at column with index `idx_start`.\n\n    Returns\n    -------\n    contrasts : ndarray\n        restriction matrix with k_params columns and number of rows equal to\n        the number of restrictions.\n    \"\"\"\n    k_level_m1 = k_level - 1\n    idx_pairs = np.triu_indices(k_level_m1, 1)\n    k = len(idx_pairs[0])\n    c_pairs = np.zeros((k, k_level_m1))\n    c_pairs[np.arange(k), idx_pairs[0]] = -1\n    c_pairs[np.arange(k), idx_pairs[1]] = 1\n    c_reference = np.eye(k_level_m1)\n    c = np.concatenate((c_reference, c_pairs), axis=0)\n    k_all = c.shape[0]\n    contrasts = np.zeros((k_all, k_params))\n    contrasts[:, idx_start:idx_start + k_level_m1] = c\n    return contrasts", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.random\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom statsmodels.stats.contrast import Contrast\nimport statsmodels.stats.contrast as smc\ndef test_constraints():\n    cm_ = np.eye(4, 3, k=-1)\n    cpairs = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [\n        -1.0, 1.0, 0.0], [-1.0, 0.0, 1.0], [0.0, -1.0, 1.0]])\n    c0 = smc._constraints_factor(cm_)\n    assert_equal(c0, cpairs)\n    c1 = _contrast_pairs(3, 4, 0)\n    assert_equal(c1, cpairs)\n    cpairs2 = np.array([[0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0,\n        0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, -1.0, 1.0, 0.0, \n        0.0, 0.0], [0.0, -1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, -1.0, 1.0, \n        0.0, 0.0]])\n    c0 = smc._constraints_factor(cm_, k_params=6, idx_start=1)\n    assert_equal(c0, cpairs2)\n    c1 = _contrast_pairs(6, 4, 1)\n    assert_equal(c1, cpairs2)\n\ntest_constraints()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_contrast.py"}], "instruction": "Functionality: The _contrast_pairs function is designed to create a pairwise contrast matrix for reference coding in statistical models. This is particularly useful in analyzing categorical variables where comparisons between different levels of a factor are of interest. The function generates restrictions or contrasts between levels, including the reference level, and returns a matrix representing these contrasts.\n\nInputs: \n- k_params: An integer representing the number of parameters in the statistical model.\n- k_level: An integer indicating the number of levels or categories for the factor, including the reference level.\n- idx_start: An integer specifying the index of the first parameter associated with this factor. This is used to correctly position the contrast matrix within the larger model matrix.\n\nOutputs: \n- contrasts: A 2D ndarray serving as the restriction matrix. This matrix has `k_params` columns, and its number of rows equals the number of restrictions imposed by the pairwise contrasts. Each row represents a specific contrast or comparison between factor levels.", "method_code_mask": "import numpy as np\nfrom scipy.stats import f as fdist\nfrom scipy.stats import t as student_t\nfrom scipy import stats\nfrom statsmodels.tools.tools import clean0\nfrom statsmodels.tools.tools import fullrank\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import summary_params_frame\nimport statsmodels.sandbox.stats.multicomp as mc\n\n\ndef _contrast_pairs(k_params, k_level, idx_start): [MASK]\n"}
{"method_name": "trimboth", "full_method_name": "trimboth", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/robust_compare.py", "method_code": "import numbers\nimport numpy as np\nimport statsmodels.stats.weightstats as smws\ndef trimboth(a, proportiontocut, axis=0):\n    \"\"\"\n    Slices off a proportion of items from both ends of an array.\n\n    Slices off the passed proportion of items from both ends of the passed\n    array (i.e., with `proportiontocut` = 0.1, slices leftmost 10% **and**\n    rightmost 10% of scores).  You must pre-sort the array if you want\n    'proper' trimming.  Slices off less if proportion results in a\n    non-integer slice index (i.e., conservatively slices off\n    `proportiontocut`).\n\n    Parameters\n    ----------\n    a : array_like\n        Data to trim.\n    proportiontocut : float or int\n        Proportion of data to trim at each end.\n    axis : int or None\n        Axis along which the observations are trimmed. The default is to trim\n        along axis=0. If axis is None then the array will be flattened before\n        trimming.\n\n    Returns\n    -------\n    out : array-like\n        Trimmed version of array `a`.\n\n    Examples\n    --------\n    >>> from scipy import stats\n    >>> a = np.arange(20)\n    >>> b = stats.trimboth(a, 0.1)\n    >>> b.shape\n    (16,)\n\n    \"\"\"\n    a = np.asarray(a)\n    if axis is None:\n        a = a.ravel()\n        axis = 0\n    nobs = a.shape[axis]\n    lowercut = int(proportiontocut * nobs)\n    uppercut = nobs - lowercut\n    if lowercut >= uppercut:\n        raise ValueError('Proportion too big.')\n    sl = [slice(None)] * a.ndim\n    sl[axis] = slice(lowercut, uppercut)\n    return a[tuple(sl)]", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pytest\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import trim_mean\nfrom statsmodels.stats.robust_compare import trimboth\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.tools.testing import Holder\nfrom scipy.stats import trim1\n\nclass Test_Trim():\n\tdef test_trimboth(self):\n\t    a = np.arange(11)\n\t    a2 = np.arange(24).reshape(6, 4)\n\t    a3 = np.arange(24).reshape(6, 4, order='F')\n\t    assert_equal(trimboth(a, 3 / 11.0), np.arange(3, 8))\n\t    assert_equal(trimboth(a, 0.2), np.array([2, 3, 4, 5, 6, 7, 8]))\n\t    assert_equal(trimboth(a2, 0.2), np.arange(4, 20).reshape(4, 4))\n\t    assert_equal(trimboth(a3, 2 / 6.0), np.array([[2, 8, 14, 20], [3, 9, 15,\n\t        21]]))\n\t    assert_raises(ValueError, trimboth, np.arange(24).reshape(4, 6).T, 4 / 6.0)\n\t\nTest_Trim().test_trimboth()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_robust_compare.py"}], "instruction": "Functionality: The trimboth function is designed to slice off a specified proportion of items from both ends of an array. This is particularly useful for data trimming, where outliers or unwanted data points at the extremes of the distribution are to be removed. The function allows for trimming along a specified axis, or it can flatten the array before trimming if no axis is specified.\n\nInputs: \n1. a: An array-like object representing the data from which elements will be trimmed.\n2. proportiontocut: A float or integer that indicates the proportion of data to trim from each end of the array. This value should range between 0 and 1, where 0 indicates no trimming and 1 indicates that all elements would be trimmed (an invalid scenario).\n3. axis: An integer representing the axis along which the data will be trimmed. By default, trimming occurs along axis=0. If axis is set to None, the array will be flattened before trimming.\n\nOutputs: \n1. out: An array-like object that represents the trimmed version of the input array `a`. The shape of the output will reflect the removal of the elements corresponding to `proportiontocut` from both ends of the array, along the specified axis or across the flattened array.\n\nNote: The input array must be sorted if the user wants 'proper' trimming, meaning the elements are removed from the correct ends of the array. The function conservatively removes fewer elements if the proportion results in a non-integer slice index.\n\nExamples of usage are not to be revealed in this instruction.", "method_code_mask": "import numbers\nimport numpy as np\nimport statsmodels.stats.weightstats as smws\n\n\ndef trimboth(a, proportiontocut, axis=0): [MASK]\n"}
{"method_name": "trim_mean", "full_method_name": "trim_mean", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/robust_compare.py", "method_code": "import numbers\nimport numpy as np\nimport statsmodels.stats.weightstats as smws\ndef trim_mean(a, proportiontocut, axis=0):\n    \"\"\"\n    Return mean of array after trimming observations from both tails.\n\n    If `proportiontocut` = 0.1, slices off 'leftmost' and 'rightmost' 10% of\n    scores. Slices off LESS if proportion results in a non-integer slice\n    index (i.e., conservatively slices off `proportiontocut` ).\n\n    Parameters\n    ----------\n    a : array_like\n        Input array\n    proportiontocut : float\n        Fraction to cut off at each tail of the sorted observations.\n    axis : int or None\n        Axis along which the trimmed means are computed. The default is axis=0.\n        If axis is None then the trimmed mean will be computed for the\n        flattened array.\n\n    Returns\n    -------\n    trim_mean : ndarray\n        Mean of trimmed array.\n\n    \"\"\"\n    newa = trimboth(np.sort(a, axis), proportiontocut, axis=axis)\n    return np.mean(newa, axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pytest\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import trim_mean\nfrom statsmodels.stats.robust_compare import trimboth\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.tools.testing import Holder\nfrom scipy.stats import trim1\n\nclass Test_Trim():\n\tdef test_trim_mean(self):\n\t    idx = np.array([3, 5, 0, 1, 2, 4])\n\t    a2 = np.arange(24).reshape(6, 4)[idx, :]\n\t    a3 = np.arange(24).reshape(6, 4, order='F')[idx, :]\n\t    assert_equal(trim_mean(a3, 2 / 6.0), np.array([2.5, 8.5, 14.5, 20.5]))\n\t    assert_equal(trim_mean(a2, 2 / 6.0), np.array([10.0, 11.0, 12.0, 13.0]))\n\t    idx4 = np.array([1, 0, 3, 2])\n\t    a4 = np.arange(24).reshape(4, 6)[idx4, :]\n\t    assert_equal(trim_mean(a4, 2 / 6.0), np.array([9.0, 10.0, 11.0, 12.0, \n\t        13.0, 14.0]))\n\t    a = np.array([7, 11, 12, 21, 16, 6, 22, 1, 5, 0, 18, 10, 17, 9, 19, 15,\n\t        23, 20, 2, 14, 4, 13, 8, 3])\n\t    assert_equal(trim_mean(a, 2 / 6.0), 11.5)\n\t    assert_equal(trim_mean([5, 4, 3, 1, 2, 0], 2 / 6.0), 2.5)\n\t    np.random.seed(1234)\n\t    a = np.random.randint(20, size=(5, 6, 4, 7))\n\t    for axis in [0, 1, 2, 3, -1]:\n\t        res1 = trim_mean(a, 2 / 6.0, axis=axis)\n\t        res2 = trim_mean(np.rollaxis(a, axis), 2 / 6.0)\n\t        assert_equal(res1, res2)\n\t    res1 = trim_mean(a, 2 / 6.0, axis=None)\n\t    res2 = trim_mean(a.ravel(), 2 / 6.0)\n\t    assert_equal(res1, res2)\n\t\nTest_Trim().test_trim_mean()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_robust_compare.py"}], "instruction": "Functionality: The trim_mean function computes the mean of an array after trimming a specified proportion of observations from both tails of the sorted array. This function is useful for calculating the mean while mitigating the effects of outliers.\n\nInputs: \n    a : array_like\n        The input array from which the trimmed mean will be calculated.\n    proportiontocut : float\n        The fraction of observations to cut off at each tail of the sorted array. The total proportion of observations trimmed is twice this value.\n    axis : int or None (default: 0)\n        The axis along which the trimmed means are computed. If axis is 0 (the default), the calculation is done column-wise. If axis is None, the array is flattened before the calculation.\n\nOutputs:\n    trim_mean : ndarray\n        The mean of the trimmed array. If the input array is 1D or axis=None, the output will be a scalar. Otherwise, it will be an ndarray with one dimension less than the input array.", "method_code_mask": "import numbers\nimport numpy as np\nimport statsmodels.stats.weightstats as smws\n\n\ndef trim_mean(a, proportiontocut, axis=0): [MASK]\n"}
{"method_name": "confint_effectsize_oneway", "full_method_name": "confint_effectsize_oneway", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef confint_effectsize_oneway(f_stat, df, alpha=0.05, nobs=None):\n    \"\"\"\n    Confidence interval for effect size in oneway anova for F distribution\n\n    This does not yet handle non-negativity constraint on nc.\n    Currently only two-sided alternative is supported.\n\n    Parameters\n    ----------\n    f_stat : float\n    df : tuple\n        degrees of freedom ``df = (df1, df2)`` where\n\n        - df1 : numerator degrees of freedom, number of constraints\n        - df2 : denominator degrees of freedom, df_resid\n\n    alpha : float, default 0.05\n    nobs : int, default None\n\n    Returns\n    -------\n    Holder\n        Class with effect size and confidence attributes\n\n    Notes\n    -----\n    The confidence interval for the noncentrality parameter is obtained by\n    inverting the cdf of the noncentral F distribution. Confidence intervals\n    for other effect sizes are computed by endpoint transformation.\n\n\n    R package ``effectsize`` does not compute the confidence intervals in the\n    same way. Their confidence intervals can be replicated with\n\n    >>> ci_nc = confint_noncentrality(f_stat, df1, df2, alpha=0.1)\n    >>> ci_es = smo._fstat2effectsize(ci_nc / df1, df1, df2)\n\n    See Also\n    --------\n    confint_noncentrality\n    \"\"\"\n    df1, df2 = df\n    if nobs is None:\n        nobs = df1 + df2 + 1\n    ci_nc = confint_noncentrality(f_stat, df, alpha=alpha)\n    ci_f2 = ci_nc / nobs\n    ci_res = convert_effectsize_fsqu(f2=ci_f2)\n    ci_res.ci_omega2 = (ci_f2 - df1 / df2) / (ci_f2 + 1 + 1 / df2)\n    ci_res.ci_nc = ci_nc\n    ci_res.ci_f = np.sqrt(ci_res.f2)\n    ci_res.ci_eta = np.sqrt(ci_res.eta2)\n    ci_res.ci_f_corrected = np.sqrt(ci_res.f2 * (df1 + 1) / df1)\n    return ci_res", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_oneway_effectsize():\n    F = 5\n    df1 = 3\n    df2 = 76\n    nobs = 80\n    ci = confint_noncentrality(F, (df1, df2), alpha=0.05, alternative=\n        'two-sided')\n    ci_es = confint_effectsize_oneway(F, (df1, df2), alpha=0.05)\n    ci_steiger = ci_es.ci_f * np.sqrt(4 / 3)\n    res_ci_steiger = [0.1764, 0.7367]\n    res_ci_nc = np.asarray([1.8666, 32.563])\n    assert_allclose(ci, res_ci_nc, atol=0.0001)\n    assert_allclose(ci_es.ci_f_corrected, res_ci_steiger, atol=6e-05)\n    assert_allclose(ci_steiger, res_ci_steiger, atol=6e-05)\n    assert_allclose(ci_es.ci_f ** 2, res_ci_nc / nobs, atol=6e-05)\n    assert_allclose(ci_es.ci_nc, res_ci_nc, atol=0.0001)\n\ntest_oneway_effectsize()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_effectsize_fstat_stata():\n    eta2 = 0.2720398648288652\n    lb_eta2 = 0.0742092468714613\n    ub_eta2 = 0.4156116886974804\n    omega2 = 0.2356418580703085\n    lb_omega2 = 0.0279197092150344\n    ub_omega2 = 0.3863922731323545\n    f_stat, df1, df2 = 7.47403193349075, 2, 40\n    fes = smo._fstat2effectsize(f_stat, (df1, df2))\n    assert_allclose(fes.eta2, eta2, rtol=1e-13)\n    assert_allclose(fes.omega2, omega2, rtol=0.02)\n    ci_es = confint_effectsize_oneway(f_stat, (df1, df2), alpha=0.1)\n    assert_allclose(ci_es.eta2, (lb_eta2, ub_eta2), rtol=0.0001)\n    assert_allclose(ci_es.ci_omega2, (lb_omega2, ub_omega2), rtol=0.025)\n\ntest_effectsize_fstat_stata()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: The confint_effectsize_oneway function computes the confidence interval for various effect sizes in a one-way ANOVA given the F-statistic and degrees of freedom. This function inverts the CDF of the noncentral F distribution to obtain the confidence interval for the noncentrality parameter, and then transforms these endpoints into confidence intervals for other effect sizes.\n\nInputs:\n- f_stat : float - The F-statistic from the ANOVA test.\n- df : tuple - A tuple of degrees of freedom (df1, df2), where df1 is the numerator degrees of freedom (number of constraints), and df2 is the denominator degrees of freedom (df_resid).\n- alpha : float, default 0.05 - The significance level for the confidence interval.\n- nobs : int, default None - The number of observations. If None, it is calculated as df1 + df2 + 1.\n\nOutputs:\n- Holder - A class instance containing attributes for various effect sizes and their confidence intervals:\n    - effect_size : The estimated effect size.\n    - ci_f : Confidence interval for the f effect size.\n    - ci_f2 : Confidence interval for the f^2 effect size.\n    - ci_eta : Confidence interval for the eta-squared effect size.\n    - ci_omega2 : Confidence interval for the omega-squared effect size.\n    - ci_nc : Confidence interval for the noncentrality parameter.\n    - ci_f_corrected : Confidence interval for the corrected f effect size.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef confint_effectsize_oneway(f_stat, df, alpha=0.05, nobs=None): [MASK]\n"}
{"method_name": "confint_noncentrality", "full_method_name": "confint_noncentrality", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef confint_noncentrality(f_stat, df, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Confidence interval for noncentrality parameter in F-test\n\n    This does not yet handle non-negativity constraint on nc.\n    Currently only two-sided alternative is supported.\n\n    Parameters\n    ----------\n    f_stat : float\n    df : tuple\n        degrees of freedom ``df = (df1, df2)`` where\n\n        - df1 : numerator degrees of freedom, number of constraints\n        - df2 : denominator degrees of freedom, df_resid\n\n    alpha : float, default 0.05\n    alternative : {\"two-sided\"}\n        Other alternatives have not been implements.\n\n    Returns\n    -------\n    float\n        The end point of the confidence interval.\n\n    Notes\n    -----\n    The algorithm inverts the cdf of the noncentral F distribution with\n    respect to the noncentrality parameters.\n    See Steiger 2004 and references cited in it.\n\n    References\n    ----------\n    .. [1] Steiger, James H. 2004. \u201cBeyond the F Test: Effect Size Confidence\n       Intervals and Tests of Close Fit in the Analysis of Variance and\n       Contrast Analysis.\u201d Psychological Methods 9 (2): 164\u201382.\n       https://doi.org/10.1037/1082-989X.9.2.164.\n\n    See Also\n    --------\n    confint_effectsize_oneway\n    \"\"\"\n    df1, df2 = df\n    if alternative in ['two-sided', '2s', 'ts']:\n        alpha1s = alpha / 2\n        ci = ncfdtrinc(df1, df2, [1 - alpha1s, alpha1s], f_stat)\n    else:\n        raise NotImplementedError\n    return ci", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_oneway_effectsize():\n    F = 5\n    df1 = 3\n    df2 = 76\n    nobs = 80\n    ci = confint_noncentrality(F, (df1, df2), alpha=0.05, alternative=\n        'two-sided')\n    ci_es = confint_effectsize_oneway(F, (df1, df2), alpha=0.05)\n    ci_steiger = ci_es.ci_f * np.sqrt(4 / 3)\n    res_ci_steiger = [0.1764, 0.7367]\n    res_ci_nc = np.asarray([1.8666, 32.563])\n    assert_allclose(ci, res_ci_nc, atol=0.0001)\n    assert_allclose(ci_es.ci_f_corrected, res_ci_steiger, atol=6e-05)\n    assert_allclose(ci_steiger, res_ci_steiger, atol=6e-05)\n    assert_allclose(ci_es.ci_f ** 2, res_ci_nc / nobs, atol=6e-05)\n    assert_allclose(ci_es.ci_nc, res_ci_nc, atol=0.0001)\n\ntest_oneway_effectsize()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_effectsize_fstat():\n    Eta_Sq_partial = 0.796983758700696\n    CI_eta2 = 0.685670133284926, 0.855981325777856\n    Epsilon_Sq_partial = 0.779582366589327\n    CI_eps2 = 0.658727573280777, 0.843636867987386\n    Omega_Sq_partial = 0.775086505190311\n    CI_omega2 = 0.65286429480169, 0.840179680453464\n    Cohens_f_partial = 1.98134153686695\n    CI_f = 1.47694659580859, 2.43793847155554\n    f_stat, df1, df2 = 45.8, 3, 35\n    fes = smo._fstat2effectsize(f_stat, (df1, df2))\n    assert_allclose(np.sqrt(fes.f2), Cohens_f_partial, rtol=1e-13)\n    assert_allclose(fes.eta2, Eta_Sq_partial, rtol=1e-13)\n    assert_allclose(fes.eps2, Epsilon_Sq_partial, rtol=1e-13)\n    assert_allclose(fes.omega2, Omega_Sq_partial, rtol=1e-13)\n    ci_nc = confint_noncentrality(f_stat, (df1, df2), alpha=0.1)\n    ci_es = smo._fstat2effectsize(ci_nc / df1, (df1, df2))\n    assert_allclose(ci_es.eta2, CI_eta2, rtol=0.0002)\n    assert_allclose(ci_es.eps2, CI_eps2, rtol=0.0002)\n    assert_allclose(ci_es.omega2, CI_omega2, rtol=0.0002)\n    assert_allclose(np.sqrt(ci_es.f2), CI_f, rtol=0.0002)\n\ntest_effectsize_fstat()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: The confint_noncentrality function calculates the confidence interval for the noncentrality parameter in an F-test. It inverts the cdf of the noncentral F distribution with respect to the noncentrality parameters, providing an interval estimate for the noncentrality parameter which is closely related to the effect size in analysis of variance (ANOVA) and contrast analysis.\n\nInputs: \n    f_stat : float\n        The F-statistic from the F-test.\n    df : tuple\n        A tuple containing the numerator degrees of freedom (number of constraints) and the denominator degrees of freedom (df_resid).\n    alpha : float, default 0.05\n        The significance level for calculating the confidence interval.\n    alternative : {\"two-sided\"}\n        Specifies the alternative hypothesis. Currently, only 'two-sided' is supported.\n\nOutputs: \n    float\n        A tuple containing the lower and upper bounds of the confidence interval for the noncentrality parameter.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef confint_noncentrality(f_stat, df, alpha=0.05, alternative='two-sided'): [M\n    ASK]\n"}
{"method_name": "_fstat2effectsize", "full_method_name": "_fstat2effectsize", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef _fstat2effectsize(f_stat, df):\n    \"\"\"Compute anova effect size from F-statistic\n\n    This might be combined with convert_effectsize_fsqu\n\n    Parameters\n    ----------\n    f_stat : array_like\n        Test statistic of an F-test\n    df : tuple\n        degrees of freedom ``df = (df1, df2)`` where\n         - df1 : numerator degrees of freedom, number of constraints\n         - df2 : denominator degrees of freedom, df_resid\n\n    Returns\n    -------\n    res : Holder instance\n        This instance contains effect size measures f2, eta2, omega2 and eps2\n        as attributes.\n\n    Notes\n    -----\n    This uses the following definitions:\n\n    - f2 = f_stat * df1 / df2\n    - eta2 = f2 / (f2 + 1)\n    - omega2 = (f2 - df1 / df2) / (f2 + 2)\n    - eps2 = (f2 - df1 / df2) / (f2 + 1)\n\n    This differs from effect size measures in other function which define\n    ``f2 = f_stat * df1 / nobs``\n    or an equivalent expression for power computation. The noncentrality\n    index for the hypothesis test is in those cases given by\n    ``nc = f_stat * df1``.\n\n    Currently omega2 and eps2 are computed in two different ways. Those\n    values agree for regular cases but can show different behavior in corner\n    cases (e.g. zero division).\n\n    \"\"\"\n    df1, df2 = df\n    f2 = f_stat * df1 / df2\n    eta2 = f2 / (f2 + 1)\n    omega2_ = (f_stat - 1) / (f_stat + (df2 + 1) / df1)\n    omega2 = (f2 - df1 / df2) / (f2 + 1 + 1 / df2)\n    eps2_ = (f_stat - 1) / (f_stat + df2 / df1)\n    eps2 = (f2 - df1 / df2) / (f2 + 1)\n    return Holder(f2=f2, eta2=eta2, omega2=omega2, eps2=eps2, eps2_=eps2_,\n        omega2_=omega2_)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_effectsize_fstat():\n    Eta_Sq_partial = 0.796983758700696\n    CI_eta2 = 0.685670133284926, 0.855981325777856\n    Epsilon_Sq_partial = 0.779582366589327\n    CI_eps2 = 0.658727573280777, 0.843636867987386\n    Omega_Sq_partial = 0.775086505190311\n    CI_omega2 = 0.65286429480169, 0.840179680453464\n    Cohens_f_partial = 1.98134153686695\n    CI_f = 1.47694659580859, 2.43793847155554\n    f_stat, df1, df2 = 45.8, 3, 35\n    fes = _fstat2effectsize(f_stat, (df1, df2))\n    assert_allclose(np.sqrt(fes.f2), Cohens_f_partial, rtol=1e-13)\n    assert_allclose(fes.eta2, Eta_Sq_partial, rtol=1e-13)\n    assert_allclose(fes.eps2, Epsilon_Sq_partial, rtol=1e-13)\n    assert_allclose(fes.omega2, Omega_Sq_partial, rtol=1e-13)\n    ci_nc = confint_noncentrality(f_stat, (df1, df2), alpha=0.1)\n    ci_es = _fstat2effectsize(ci_nc / df1, (df1, df2))\n    assert_allclose(ci_es.eta2, CI_eta2, rtol=0.0002)\n    assert_allclose(ci_es.eps2, CI_eps2, rtol=0.0002)\n    assert_allclose(ci_es.omega2, CI_omega2, rtol=0.0002)\n    assert_allclose(np.sqrt(ci_es.f2), CI_f, rtol=0.0002)\n\ntest_effectsize_fstat()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_effectsize_fstat_stata():\n    eta2 = 0.2720398648288652\n    lb_eta2 = 0.0742092468714613\n    ub_eta2 = 0.4156116886974804\n    omega2 = 0.2356418580703085\n    lb_omega2 = 0.0279197092150344\n    ub_omega2 = 0.3863922731323545\n    f_stat, df1, df2 = 7.47403193349075, 2, 40\n    fes = _fstat2effectsize(f_stat, (df1, df2))\n    assert_allclose(fes.eta2, eta2, rtol=1e-13)\n    assert_allclose(fes.omega2, omega2, rtol=0.02)\n    ci_es = smo.confint_effectsize_oneway(f_stat, (df1, df2), alpha=0.1)\n    assert_allclose(ci_es.eta2, (lb_eta2, ub_eta2), rtol=0.0001)\n    assert_allclose(ci_es.ci_omega2, (lb_omega2, ub_omega2), rtol=0.025)\n\ntest_effectsize_fstat_stata()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: The _fstat2effectsize function computes various effect size measures (f2, eta2, omega2, and eps2) from a given F-statistic and degrees of freedom. This is useful for understanding the magnitude of an effect in the context of an F-test, commonly used in ANOVA (Analysis of Variance) scenarios.\n\nInputs: \n1. f_stat: An array-like object representing the F-statistic of the F-test.\n2. df: A tuple containing the degrees of freedom. The tuple is structured as (df1, df2), where df1 denotes the numerator degrees of freedom (number of constraints), and df2 denotes the denominator degrees of freedom (degrees of freedom of the residual, df_resid).\n\nOutputs:\nThe function returns a Holder instance containing the following attributes:\n- f2: Represents the effect size in terms of f-squared.\n- eta2: Represents eta-squared, a measure of effect size.\n- omega2: Represents omega-squared, a more conservative estimate of effect size than eta-squared.\n- eps2: Represents epsilon-squared, another measure of effect size that adjusts for bias.\n- omega2_: An alternative computation of omega-squared.\n- eps2_: An alternative computation of epsilon-squared.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef _fstat2effectsize(f_stat, df): [MASK]\n"}
{"method_name": "wellek_to_f2", "full_method_name": "wellek_to_f2", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef wellek_to_f2(eps, n_groups):\n    \"\"\"Convert Wellek's effect size (sqrt) to Cohen's f-squared\n\n    This computes the following effect size :\n\n       f2 = 1 / n_groups * eps**2\n\n    Parameters\n    ----------\n    eps : float or ndarray\n        Wellek's effect size used in anova equivalence test\n    n_groups : int\n        Number of groups in oneway comparison\n\n    Returns\n    -------\n    f2 : effect size Cohen's f-squared\n\n    \"\"\"\n    f2 = 1 / n_groups * eps ** 2\n    return f2", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_simulate_equivalence():\n    k_groups = 4\n    k_repl = 10\n    nobs = np.array([10, 12, 13, 15]) * k_repl\n    means = np.array([-1, 0, 0, 1]) * 0.12\n    vars_ = np.array([1, 2, 3, 4])\n    nobs_t = nobs.sum()\n    eps = 0.0191 * 10\n    opt_var = ['unequal', 'equal', 'bf']\n    k_mc = 100\n    np.random.seed(987126)\n    res_mc = smo.simulate_power_equivalence_oneway(means, nobs, eps, vars_=\n        vars_, k_mc=k_mc, trim_frac=0.1, options_var=opt_var, margin_type=\n        'wellek')\n    frac_reject = (res_mc.pvalue <= 0.05).sum(0) / k_mc\n    assert_allclose(frac_reject, [0.17, 0.18, 0.14], atol=0.001)\n    es_alt_li = []\n    for uv in opt_var:\n        es = effectsize_oneway(means, vars_, nobs, use_var=uv)\n        es_alt_li.append(es)\n    margin = wellek_to_f2(eps, k_groups)\n    pow_ = [power_equivalence_oneway(es_, margin, nobs_t, n_groups=k_groups,\n        df=None, alpha=0.05, margin_type='f2') for es_ in es_alt_li]\n    assert_allclose(pow_, [0.147749, 0.173358, 0.177412], atol=0.007)\n\ntest_simulate_equivalence()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: Convert Wellek's effect size (sqrt) to Cohen's f-squared for an analysis of variance (ANOVA) equivalence test.\n\nInputs:\n- eps: float or ndarray\n    Wellek's effect size used in an ANOVA equivalence test. This can be a single float value or an array of values.\n- n_groups: int\n    The number of groups or conditions being compared in the oneway analysis. This is an integer value specifying the total number of groups.\n\nOutputs:\n- f2: float or ndarray\n    Cohen's f-squared effect size. This is the calculated effect size based on the input Wellek's effect size (eps) and the number of groups (n_groups). The output will be a single float if the input is a single value, or an array of floats if the input is an array.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef wellek_to_f2(eps, n_groups): [MASK]\n"}
{"method_name": "simulate_power_equivalence_oneway", "full_method_name": "simulate_power_equivalence_oneway", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef simulate_power_equivalence_oneway(means, nobs, equiv_margin, vars_=None,\n    k_mc=1000, trim_frac=0, options_var=None, margin_type='f2'):\n    \"\"\"Simulate Power for oneway equivalence test (Wellek's Anova)\n\n    This function is experimental and written to evaluate asymptotic power\n    function. This function will change without backwards compatibility\n    constraints. The only part that is stable is `pvalue` attribute in results.\n\n    Effect size for equivalence margin\n\n    \"\"\"\n    if options_var is None:\n        options_var = ['unequal', 'equal', 'bf']\n    if vars_ is not None:\n        stds = np.sqrt(vars_)\n    else:\n        stds = np.ones(len(means))\n    nobs_mean = nobs.mean()\n    n_groups = len(nobs)\n    res_mc = []\n    f_mc = []\n    reject_mc = []\n    other_mc = []\n    for _ in range(k_mc):\n        y0, y1, y2, y3 = (m + std * np.random.randn(n) for n, m, std in zip\n            (nobs, means, stds))\n        res_i = []\n        f_i = []\n        reject_i = []\n        other_i = []\n        for uv in options_var:\n            res0 = anova_oneway([y0, y1, y2, y3], use_var=uv, trim_frac=\n                trim_frac)\n            f_stat = res0.statistic\n            res1 = equivalence_oneway_generic(f_stat, n_groups, nobs.sum(),\n                equiv_margin, res0.df, alpha=0.05, margin_type=margin_type)\n            res_i.append(res1.pvalue)\n            es_wellek = f_stat * (n_groups - 1) / nobs_mean\n            f_i.append(es_wellek)\n            reject_i.append(res1.reject)\n            other_i.extend([res1.crit_f, res1.crit_es, res1.power_zero])\n        res_mc.append(res_i)\n        f_mc.append(f_i)\n        reject_mc.append(reject_i)\n        other_mc.append(other_i)\n    f_mc = np.asarray(f_mc)\n    other_mc = np.asarray(other_mc)\n    res_mc = np.asarray(res_mc)\n    reject_mc = np.asarray(reject_mc)\n    res = Holder(f_stat=f_mc, other=other_mc, pvalue=res_mc, reject=reject_mc)\n    return res", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_simulate_equivalence():\n    k_groups = 4\n    k_repl = 10\n    nobs = np.array([10, 12, 13, 15]) * k_repl\n    means = np.array([-1, 0, 0, 1]) * 0.12\n    vars_ = np.array([1, 2, 3, 4])\n    nobs_t = nobs.sum()\n    eps = 0.0191 * 10\n    opt_var = ['unequal', 'equal', 'bf']\n    k_mc = 100\n    np.random.seed(987126)\n    res_mc = simulate_power_equivalence_oneway(means, nobs, eps, vars_=\n        vars_, k_mc=k_mc, trim_frac=0.1, options_var=opt_var, margin_type=\n        'wellek')\n    frac_reject = (res_mc.pvalue <= 0.05).sum(0) / k_mc\n    assert_allclose(frac_reject, [0.17, 0.18, 0.14], atol=0.001)\n    es_alt_li = []\n    for uv in opt_var:\n        es = effectsize_oneway(means, vars_, nobs, use_var=uv)\n        es_alt_li.append(es)\n    margin = wellek_to_f2(eps, k_groups)\n    pow_ = [power_equivalence_oneway(es_, margin, nobs_t, n_groups=k_groups,\n        df=None, alpha=0.05, margin_type='f2') for es_ in es_alt_li]\n    assert_allclose(pow_, [0.147749, 0.173358, 0.177412], atol=0.007)\n\ntest_simulate_equivalence()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: \nThis function simulates power for oneway equivalence tests (Wellek's Anova). It is designed to evaluate the asymptotic power function in a statistical context, focusing on the effect size for equivalence margin. The function generates simulated data based on input parameters and calculates statistical measures such as F-statistics, effect sizes, p-values, and rejection decisions for various variance options.\n\nInputs:\n- means: A list or array of group means.\n- nobs: A list or array of sample sizes for each group.\n- equiv_margin: The equivalence margin used in the equivalence test.\n- vars_: Optional; A list or array of variances for each group. If not provided, variances are assumed to be equal to 1.\n- k_mc: Optional; The number of Monte Carlo simulations to run (default is 1000).\n- trim_frac: Optional; The fraction of observations to trim for trimmed mean calculations (default is 0).\n- options_var: Optional; A list specifying the variance options to consider ('unequal', 'equal', 'bf') for the ANOVA test. If not provided, defaults to all three options.\n- margin_type: Optional; The type of margin used in the effect size calculation ('f2' by default).\n\nOutputs:\nThe function returns an object containing the following attributes:\n- f_stat: An array of F-statistic values computed for each simulation.\n- other: An array of auxiliary statistics including critical F-values, critical effect sizes, and power at zero effect.\n- pvalue: An array of p-values for the equivalence test computed for each simulation.\n- reject: An array of boolean values indicating whether the equivalence null hypothesis was rejected in each simulation.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef simulate_power_equivalence_oneway(means, nobs, equiv_margin, vars_=None,\n    k_mc=1000, trim_frac=0, options_var=None, margin_type='f2'): [MASK]\n"}
{"method_name": "power_equivalence_oneway", "full_method_name": "power_equivalence_oneway", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/oneway.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\ndef power_equivalence_oneway(f2_alt, equiv_margin, nobs_t, n_groups=None,\n    df=None, alpha=0.05, margin_type='f2'):\n    \"\"\"\n    Power of  oneway equivalence test\n\n    Parameters\n    ----------\n    f2_alt : float\n        Effect size, squared Cohen's f, under the alternative.\n    equiv_margin : float\n        Equivalence margin in terms of effect size. Effect size can be chosen\n        with `margin_type`. default is squared Cohen's f.\n    nobs_t : ndarray\n        Total number of observations summed over all groups.\n    n_groups : int\n        Number of groups in oneway comparison. If margin_type is \"wellek\",\n        then either ``n_groups`` or ``df`` has to be given.\n    df : tuple\n        Degrees of freedom for F distribution,\n        ``df = (n_groups - 1, nobs_t - n_groups)``\n    alpha : float in (0, 1)\n        Significance level for the hypothesis test.\n    margin_type : \"f2\" or \"wellek\"\n        Type of effect size used for equivalence margin, either squared\n        Cohen's f or Wellek's psi. Default is \"f2\".\n\n    Returns\n    -------\n    pow_alt : float\n        Power of the equivalence test at given equivalence effect size under\n        the alternative.\n    \"\"\"\n    if df is None:\n        if n_groups is None:\n            raise ValueError('either df or n_groups has to be provided')\n        df = n_groups - 1, nobs_t - n_groups\n    if f2_alt == 0:\n        f2_alt = 1e-13\n    if margin_type in ['f2', 'fsqu', 'fsquared']:\n        f2_null = equiv_margin\n    elif margin_type == 'wellek':\n        if n_groups is None:\n            raise ValueError(\n                'If margin_type is wellek, then n_groups has to be provided')\n        nobs_mean = nobs_t / n_groups\n        f2_null = nobs_mean * equiv_margin ** 2 / nobs_t\n        f2_alt = nobs_mean * f2_alt ** 2 / nobs_t\n    else:\n        raise ValueError('`margin_type` should be \"f2\" or \"wellek\"')\n    crit_f_margin = ncf_ppf(alpha, df[0], df[1], nobs_t * f2_null)\n    pwr_alt = ncf_cdf(crit_f_margin, df[0], df[1], nobs_t * f2_alt)\n    return pwr_alt", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.power as smpwr\nimport statsmodels.stats.oneway as smo\nfrom statsmodels.stats.oneway import confint_effectsize_oneway\nfrom statsmodels.stats.oneway import confint_noncentrality\nfrom statsmodels.stats.oneway import effectsize_oneway\nfrom statsmodels.stats.oneway import anova_oneway\nfrom statsmodels.stats.oneway import anova_generic\nfrom statsmodels.stats.oneway import equivalence_oneway\nfrom statsmodels.stats.oneway import equivalence_oneway_generic\nfrom statsmodels.stats.oneway import power_equivalence_oneway\nfrom statsmodels.stats.oneway import _power_equivalence_oneway_emp\nfrom statsmodels.stats.oneway import f2_to_wellek\nfrom statsmodels.stats.oneway import fstat_to_wellek\nfrom statsmodels.stats.oneway import wellek_to_f2\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.stats.contrast import wald_test_noncent_generic\nfrom statsmodels.stats.contrast import wald_test_noncent\nfrom statsmodels.stats.contrast import _offset_constraint\nfrom statsmodels.stats.power import FTestAnovaPower\nfrom scipy import stats\ndef test_simulate_equivalence():\n    k_groups = 4\n    k_repl = 10\n    nobs = np.array([10, 12, 13, 15]) * k_repl\n    means = np.array([-1, 0, 0, 1]) * 0.12\n    vars_ = np.array([1, 2, 3, 4])\n    nobs_t = nobs.sum()\n    eps = 0.0191 * 10\n    opt_var = ['unequal', 'equal', 'bf']\n    k_mc = 100\n    np.random.seed(987126)\n    res_mc = smo.simulate_power_equivalence_oneway(means, nobs, eps, vars_=\n        vars_, k_mc=k_mc, trim_frac=0.1, options_var=opt_var, margin_type=\n        'wellek')\n    frac_reject = (res_mc.pvalue <= 0.05).sum(0) / k_mc\n    assert_allclose(frac_reject, [0.17, 0.18, 0.14], atol=0.001)\n    es_alt_li = []\n    for uv in opt_var:\n        es = effectsize_oneway(means, vars_, nobs, use_var=uv)\n        es_alt_li.append(es)\n    margin = wellek_to_f2(eps, k_groups)\n    pow_ = [power_equivalence_oneway(es_, margin, nobs_t, n_groups=k_groups,\n        df=None, alpha=0.05, margin_type='f2') for es_ in es_alt_li]\n    assert_allclose(pow_, [0.147749, 0.173358, 0.177412], atol=0.007)\n\ntest_simulate_equivalence()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_oneway.py"}], "instruction": "Functionality: The power_equivalence_oneway function calculates the power of a one-way equivalence test. This test is used to determine whether the observed effect size falls within a specified equivalence margin around zero, indicating that the effect size is practically negligible or equivalent to zero.\n\nInputs:\n- f2_alt: A float representing the effect size under the alternative hypothesis, measured as the squared Cohen's f.\n- equiv_margin: A float indicating the equivalence margin in terms of effect size. The type of effect size is determined by the `margin_type` parameter.\n- nobs_t: An array-like object containing the total number of observations summed over all groups.\n- n_groups: An optional integer specifying the number of groups in the one-way comparison. Required if margin_type is \"wellek\" or df is not provided.\n- df: An optional tuple containing the degrees of freedom for the F distribution, where the first element is n_groups - 1 and the second is nobs_t - n_groups.\n- alpha: A float in (0, 1) representing the significance level for the hypothesis test. Default is 0.05.\n- margin_type: A string indicating the type of effect size used for the equivalence margin. Choices are \"f2\" (squared Cohen's f) or \"wellek\" (Wellek's psi). Default is \"f2\".\n\nOutputs:\n- pow_alt: A float representing the power of the equivalence test at the given equivalence effect size under the alternative hypothesis.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.special import ncfdtrinc\nfrom statsmodels.stats.power import ncf_cdf\nfrom statsmodels.stats.power import ncf_ppf\nfrom statsmodels.stats.robust_compare import TrimmedMean\nfrom statsmodels.stats.robust_compare import scale_transform\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.base import HolderTuple\n\n\ndef power_equivalence_oneway(f2_alt, equiv_margin, nobs_t, n_groups=None,\n    df=None, alpha=0.05, margin_type='f2'): [MASK]\n"}
{"method_name": "samplesize_confint_proportion", "full_method_name": "samplesize_confint_proportion", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef samplesize_confint_proportion(proportion, half_length, alpha=0.05,\n    method='normal'):\n    \"\"\"\n    Find sample size to get desired confidence interval length\n\n    Parameters\n    ----------\n    proportion : float in (0, 1)\n        proportion or quantile\n    half_length : float in (0, 1)\n        desired half length of the confidence interval\n    alpha : float in (0, 1)\n        significance level, default 0.05,\n        coverage of the two-sided interval is (approximately) ``1 - alpha``\n    method : str in ['normal']\n        method to use for confidence interval,\n        currently only normal approximation\n\n    Returns\n    -------\n    n : float\n        sample size to get the desired half length of the confidence interval\n\n    Notes\n    -----\n    this is mainly to store the formula.\n    possible application: number of replications in bootstrap samples\n\n    \"\"\"\n    q_ = proportion\n    if method == 'normal':\n        n = q_ * (1 - q_) / (half_length / stats.norm.isf(alpha / 2.0)) ** 2\n    else:\n        raise NotImplementedError('only \"normal\" is available')\n    return n", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_samplesize_confidenceinterval_prop():\n    nobs = 20\n    ci = smprop.proportion_confint(12, nobs, alpha=0.05, method='normal')\n    res = samplesize_confint_proportion(12.0 / nobs, (ci[1] - ci[0]) / 2\n        )\n    assert_almost_equal(res, nobs, decimal=13)\n\ntest_samplesize_confidenceinterval_prop()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The function samplesize_confint_proportion calculates the required sample size to achieve a desired confidence interval length for a given proportion using the normal approximation method.\n\nInputs:\n- proportion: A float in the range (0, 1) representing the proportion or quantile of interest.\n- half_length: A float in the range (0, 1) indicating the desired half length of the confidence interval.\n- alpha: An optional float in (0, 1) specifying the significance level; the default is 0.05. The coverage of the two-sided interval is approximately \"1 - alpha\".\n- method: An optional string argument that specifies the method to use for calculating the confidence interval. Currently, only the 'normal' method is supported.\n\nOutputs:\n- n: A float representing the sample size required to achieve the desired half length of the confidence interval.\n\nNotes: This function is primarily designed to store the formula for calculating sample size based on the desired half-length of a confidence interval for a given proportion. It can be applied to determine the number of replications needed in bootstrap samples or similar scenarios.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef samplesize_confint_proportion(proportion, half_length, alpha=0.05,\n    method='normal'): [MASK]\n"}
{"method_name": "proportion_effectsize", "full_method_name": "proportion_effectsize", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef proportion_effectsize(prop1, prop2, method='normal'):\n    \"\"\"\n    Effect size for a test comparing two proportions\n\n    for use in power function\n\n    Parameters\n    ----------\n    prop1, prop2 : float or array_like\n        The proportion value(s).\n\n    Returns\n    -------\n    es : float or ndarray\n        effect size for (transformed) prop1 - prop2\n\n    Notes\n    -----\n    only method='normal' is implemented to match pwr.p2.test\n    see http://www.statmethods.net/stats/power.html\n\n    Effect size for `normal` is defined as ::\n\n        2 * (arcsin(sqrt(prop1)) - arcsin(sqrt(prop2)))\n\n    I think other conversions to normality can be used, but I need to check.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> sm.stats.proportion_effectsize(0.5, 0.4)\n    0.20135792079033088\n    >>> sm.stats.proportion_effectsize([0.3, 0.4, 0.5], 0.4)\n    array([-0.21015893,  0.        ,  0.20135792])\n\n    \"\"\"\n    if method != 'normal':\n        raise ValueError('only \"normal\" is implemented')\n    es = 2 * (np.arcsin(np.sqrt(prop1)) - np.arcsin(np.sqrt(prop2)))\n    return es", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_proportion_effect_size():\n    es = proportion_effectsize(0.5, 0.4)\n    assert_almost_equal(es, 0.2013579207903309, decimal=13)\n\ntest_proportion_effect_size()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The proportion_effectsize function calculates the effect size for a test comparing two proportions, which is crucial for power analysis in statistical hypothesis testing. This function specifically implements the method 'normal', converting proportions to a normal distribution through an arcsine transformation to facilitate the calculation of the effect size.\n\nInputs: \n- prop1: A float or array-like object representing the first proportion value(s) to be compared.\n- prop2: A float or array-like object representing the second proportion value(s) to be compared.\n- method: A string specifying the method for calculating the effect size. Currently, only 'normal' is implemented.\n\nOutputs: \n- es: A float or ndarray representing the effect size for the (transformed) difference between prop1 and prop2. This output can be a single value or an array, depending on the input types of prop1 and prop2.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef proportion_effectsize(prop1, prop2, method='normal'): [MASK]\n"}
{"method_name": "binom_tost_reject_interval", "full_method_name": "binom_tost_reject_interval", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef binom_tost_reject_interval(low, upp, nobs, alpha=0.05):\n    \"\"\"\n    Rejection region for binomial TOST\n\n    The interval includes the end points,\n    `reject` if and only if `r_low <= x <= r_upp`.\n\n    The interval might be empty with `r_upp < r_low`.\n\n    Parameters\n    ----------\n    low, upp : floats\n        lower and upper limit of equivalence region\n    nobs : int\n        the number of trials or observations.\n\n    Returns\n    -------\n    x_low, x_upp : float\n        lower and upper bound of rejection region\n\n    \"\"\"\n    x_low = stats.binom.isf(alpha, nobs, low) + 1\n    x_upp = stats.binom.ppf(alpha, nobs, upp) - 1\n    return x_low, x_upp", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_power_binom_tost():\n    p_alt = 0.6 + np.linspace(0, 0.09, 10)\n    power = smprop.power_binom_tost(0.5, 0.7, 500, p_alt=p_alt, alpha=0.05)\n    res_power = np.array([0.9965, 0.994, 0.9815, 0.9482, 0.8783, 0.7583, \n        0.5914, 0.4041, 0.2352, 0.1139])\n    assert_almost_equal(power, res_power, decimal=4)\n    rej_int = binom_tost_reject_interval(0.5, 0.7, 500)\n    res_rej_int = 269, 332\n    assert_equal(rej_int, res_rej_int)\n    nobs = np.arange(20, 210, 20)\n    power = smprop.power_binom_tost(0.4, 0.6, nobs, p_alt=0.5, alpha=0.05)\n    res_power = np.array([0.0, 0.0, 0.0, 0.0889, 0.2356, 0.3517, 0.4457, \n        0.6154, 0.6674, 0.7708])\n    assert_almost_equal(np.maximum(power, 0), res_power, decimal=4)\n\ntest_power_binom_tost()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The binom_tost_reject_interval function calculates the rejection interval for a two-one-sided tests (TOST) procedure on a binomial distribution. This interval is used to determine if the observed number of successes in n trials falls outside the equivalence bounds, indicating statistical significance.\n\nInputs:\n- low: A float representing the lower limit of the equivalence region.\n- upp: A float representing the upper limit of the equivalence region.\n- nobs: An integer representing the number of trials or observations.\n- alpha: A float, optional (default is 0.05), representing the significance level of the test.\n\nOutputs:\n- x_low: A float representing the lower bound of the rejection region.\n- x_upp: A float representing the upper bound of the rejection region. The function returns these values as a tuple (x_low, x_upp).", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef binom_tost_reject_interval(low, upp, nobs, alpha=0.05): [MASK]\n"}
{"method_name": "ztost", "full_method_name": "ztost", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/weightstats.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.decorators import cache_readonly\nimport pandas as pd\nfrom statsmodels.iolib.summary import summary_params\ndef ztost(x1, low, upp, x2=None, usevar='pooled', ddof=1.0):\n    \"\"\"Equivalence test based on normal distribution\n\n    Parameters\n    ----------\n    x1 : array_like\n        one sample or first sample for 2 independent samples\n    low, upp : float\n        equivalence interval low < m1 - m2 < upp\n    x1 : array_like or None\n        second sample for 2 independent samples test. If None, then a\n        one-sample test is performed.\n    usevar : str, 'pooled'\n        If `pooled`, then the standard deviation of the samples is assumed to be\n        the same. Only `pooled` is currently implemented.\n\n    Returns\n    -------\n    pvalue : float\n        pvalue of the non-equivalence test\n    t1, pv1 : tuple of floats\n        test statistic and pvalue for lower threshold test\n    t2, pv2 : tuple of floats\n        test statistic and pvalue for upper threshold test\n\n    Notes\n    -----\n    checked only for 1 sample case\n\n    \"\"\"\n    tt1 = ztest(x1, x2, alternative='larger', usevar=usevar, value=low,\n        ddof=ddof)\n    tt2 = ztest(x1, x2, alternative='smaller', usevar=usevar, value=upp,\n        ddof=ddof)\n    return np.maximum(tt1[1], tt2[1]), tt1, tt2", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_ztost():\n    xfair = np.repeat([1, 0], [228, 762 - 228])\n    from statsmodels.stats.weightstats import zconfint, ztost\n    ci01 = zconfint(xfair, alpha=0.1, ddof=0)\n    assert_almost_equal(ci01, [0.2719, 0.3265], 4)\n    res = ztost(xfair, 0.18, 0.38, ddof=0)\n    assert_almost_equal(res[1][0], 7.1865, 4)\n    assert_almost_equal(res[2][0], -4.8701, 4)\n    assert_array_less(res[0], 0.0001)\n\ntest_ztost()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The ztost function performs an equivalence test based on the normal distribution to determine if the difference between two sample means falls within a specified equivalence interval. This can be applied to either a one-sample test or a two-independent-samples test.\n\nInputs: \n- x1: an array-like object representing one sample or the first sample for a two-independent-samples test.\n- low: a float representing the lower bound of the equivalence interval.\n- upp: a float representing the upper bound of the equivalence interval.\n- x2: an optional array-like object representing the second sample for a two-independent-samples test. If not provided (None), a one-sample test is performed.\n- usevar: a string that specifies whether the standard deviation of the samples is assumed to be the same ('pooled'). Currently, only 'pooled' is implemented.\n- ddof: a float representing the delta degrees of freedom used in the calculation of standard deviation. Default is 1.0.\n\nOutputs:\n- pvalue: a float representing the p-value of the non-equivalence test.\n- t1, pv1: a tuple of floats representing the test statistic and p-value for the lower threshold test.\n- t2, pv2: a tuple of floats representing the test statistic and p-value for the upper threshold test.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom statsmodels.tools.decorators import cache_readonly\nimport pandas as pd\nfrom statsmodels.iolib.summary import summary_params\n\n\ndef ztost(x1, low, upp, x2=None, usevar='pooled', ddof=1.0): [MASK]\n"}
{"method_name": "_confint_riskratio_koopman", "full_method_name": "_confint_riskratio_koopman", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef _confint_riskratio_koopman(count1, nobs1, count2, nobs2, alpha=0.05,\n    correction=True):\n    \"\"\"\n    Score confidence interval for ratio or proportions, Koopman/Nam\n\n    signature not consistent with other functions\n\n    When correction is True, then the small sample correction nobs / (nobs - 1)\n    by Miettinen/Nurminen is used.\n    \"\"\"\n    x0, x1, n0, n1 = count2, count1, nobs2, nobs1\n    x = x0 + x1\n    n = n0 + n1\n    z = stats.norm.isf(alpha / 2) ** 2\n    if correction:\n        z *= n / (n - 1)\n    a1 = n0 * (n0 * n * x1 + n1 * (n0 + x1) * z)\n    a2 = -n0 * (n0 * n1 * x + 2 * n * x0 * x1 + n1 * (n0 + x0 + 2 * x1) * z)\n    a3 = 2 * n0 * n1 * x0 * x + n * x0 * x0 * x1 + n0 * n1 * x * z\n    a4 = -n1 * x0 * x0 * x\n    p_roots_ = np.sort(np.roots([a1, a2, a3, a4]))\n    p_roots = p_roots_[:2][::-1]\n    ci = (1 - (n1 - x1) * (1 - p_roots) / (x0 + n1 - n * p_roots)) / p_roots\n    res = Holder()\n    res.confint = ci\n    res._p_roots = p_roots_\n    return res", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_score_confint_koopman_nam():\n    x0, n0 = 16, 80\n    x1, n1 = 36, 40\n    results_nam = Holder()\n    results_nam.p0_roots = [0.1278, 0.2939, 0.4876]\n    results_nam.conf_int = [2.94, 7.152]\n    res = _confint_riskratio_koopman(x1, n1, x0, n0, alpha=0.05)\n    assert_allclose(res._p_roots, results_nam.p0_roots, atol=4)\n    assert_allclose(res.confint, results_nam.conf_int, atol=3)\n    table = [67, 9, 7, 16]\n    resp = smprop._confint_riskratio_paired_nam(table, alpha=0.05)\n    ci_old = [0.917832, 1.154177]\n    assert_allclose(resp.confint, ci_old, atol=3)\n\ntest_score_confint_koopman_nam()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The _confint_riskratio_koopman function calculates the score confidence interval for the ratio of two proportions using the Koopman/Nam method, which can include a small sample correction by Miettinen/Nurminen. It is designed to estimate the confidence interval for the risk ratio between two independent groups.\n\nInputs:\n- count1: int, number of successes in the first group.\n- nobs1: int, total number of observations in the first group.\n- count2: int, number of successes in the second group.\n- nobs2: int, total number of observations in the second group.\n- alpha: float, default 0.05, the significance level for the confidence interval.\n- correction: bool, default True, if True, applies the small sample correction to the calculation.\n\nOutputs:\n- A Holder object containing:\n  - confint: array_like, the lower and upper bounds of the confidence interval for the risk ratio.\n  - _p_roots: array_like, all the roots of the polynomial equation used in the calculation, sorted in ascending order. The first two roots (in reverse order) are used to calculate the confidence interval.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef _confint_riskratio_koopman(count1, nobs1, count2, nobs2, alpha=0.05,\n    correction=True): [MASK]\n"}
{"method_name": "_confint_riskratio_paired_nam", "full_method_name": "_confint_riskratio_paired_nam", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef _confint_riskratio_paired_nam(table, alpha=0.05):\n    \"\"\"\n    Confidence interval for marginal risk ratio for matched pairs\n\n    need full table\n\n             success fail  marginal\n    success    x11    x10  x1.\n    fail       x01    x00  x0.\n    marginal   x.1    x.0   n\n\n    The confidence interval is for the ratio p1 / p0 where\n    p1 = x1. / n and\n    p0 - x.1 / n\n    Todo: rename p1 to pa and p2 to pb, so we have a, b for treatment and\n    0, 1 for success/failure\n\n    current namings follow Nam 2009\n\n    status\n    testing:\n    compared to example in Nam 2009\n    internal polynomial coefficients in calculation correspond at around\n        4 decimals\n    confidence interval agrees only at 2 decimals\n\n    \"\"\"\n    x11, x10, x01, x00 = np.ravel(table)\n    n = np.sum(table)\n    p10, p01 = x10 / n, x01 / n\n    p1 = (x11 + x10) / n\n    p0 = (x11 + x01) / n\n    q00 = 1 - x00 / n\n    z2 = stats.norm.isf(alpha / 2) ** 2\n    g1 = (n * p0 + z2 / 2) * p0\n    g2 = -(2 * n * p1 * p0 + z2 * q00)\n    g3 = (n * p1 + z2 / 2) * p1\n    a0 = g1 ** 2 - (z2 * p0 / 2) ** 2\n    a1 = 2 * g1 * g2\n    a2 = g2 ** 2 + 2 * g1 * g3 + z2 ** 2 * (p1 * p0 - 2 * p10 * p01) / 2\n    a3 = 2 * g2 * g3\n    a4 = g3 ** 2 - (z2 * p1 / 2) ** 2\n    p_roots = np.sort(np.roots([a0, a1, a2, a3, a4]))\n    ci = [p_roots.min(), p_roots.max()]\n    res = Holder()\n    res.confint = ci\n    res.p = p1, p0\n    res._p_roots = p_roots\n    return res", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_score_confint_koopman_nam():\n    x0, n0 = 16, 80\n    x1, n1 = 36, 40\n    results_nam = Holder()\n    results_nam.p0_roots = [0.1278, 0.2939, 0.4876]\n    results_nam.conf_int = [2.94, 7.152]\n    res = smprop._confint_riskratio_koopman(x1, n1, x0, n0, alpha=0.05)\n    assert_allclose(res._p_roots, results_nam.p0_roots, atol=4)\n    assert_allclose(res.confint, results_nam.conf_int, atol=3)\n    table = [67, 9, 7, 16]\n    resp = _confint_riskratio_paired_nam(table, alpha=0.05)\n    ci_old = [0.917832, 1.154177]\n    assert_allclose(resp.confint, ci_old, atol=3)\n\ntest_score_confint_koopman_nam()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The _confint_riskratio_paired_nam function computes the confidence interval for the marginal risk ratio in paired samples. This ratio is calculated based on the probabilities of success (p1) and failure (p0) derived from a contingency table. The function is designed to estimate the ratio p1 / p0, where p1 and p0 are the proportions of successes in the paired samples.\n\nInputs: \n- table (np.array): A 1D numpy array or a 2x2 contingency table represented as a flattened array with the order [x11, x10, x01, x00], where x11 is the number of successes in both paired samples, x10 is the number of successes in the first sample and failures in the second, x01 is the number of failures in the first sample and successes in the second, and x00 is the number of failures in both paired samples.\n- alpha (float, optional): The significance level (default is 0.05) for calculating the confidence interval.\n\nOutputs: \n- res (Holder): An object containing the following attributes:\n    - confint (list): A list containing the lower and upper bounds of the confidence interval for the risk ratio.\n    - p (tuple): A tuple containing the proportions p1 and p0.\n    - _p_roots (np.array): An array containing all the roots found during the calculation of the confidence interval, sorted in ascending order.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef _confint_riskratio_paired_nam(table, alpha=0.05): [MASK]\n"}
{"method_name": "power_proportions_2indep", "full_method_name": "power_proportions_2indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef power_proportions_2indep(diff, prop2, nobs1, ratio=1, alpha=0.05, value\n    =0, alternative='two-sided', return_results=True):\n    \"\"\"\n    Power for ztest that two independent proportions are equal\n\n    This assumes that the variance is based on the pooled proportion\n    under the null and the non-pooled variance under the alternative\n\n    Parameters\n    ----------\n    diff : float\n        difference between proportion 1 and 2 under the alternative\n    prop2 : float\n        proportion for the reference case, prop2, proportions for the\n        first case will be computed using p2 and diff\n        p1 = p2 + diff\n    nobs1 : float or int\n        number of observations in sample 1\n    ratio : float\n        sample size ratio, nobs2 = ratio * nobs1\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    value : float\n        currently only `value=0`, i.e. equality testing, is supported\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. The one-sided test can be\n        either 'larger', 'smaller'.\n    return_results : bool\n        If true, then a results instance with extra information is returned,\n        otherwise only the computed power is returned.\n\n    Returns\n    -------\n    results : results instance or float\n        If return_results is True, then a results instance with the\n        information in attributes is returned.\n        If return_results is False, then only the power is returned.\n\n        power : float\n            Power of the test, e.g. 0.8, is one minus the probability of a\n            type II error. Power is the probability that the test correctly\n            rejects the Null Hypothesis if the Alternative Hypothesis is true.\n\n        Other attributes in results instance include :\n\n        p_pooled\n            pooled proportion, used for std_null\n        std_null\n            standard error of difference under the null hypothesis (without\n            sqrt(nobs1))\n        std_alt\n            standard error of difference under the alternative hypothesis\n            (without sqrt(nobs1))\n    \"\"\"\n    from statsmodels.stats.power import normal_power_het\n    p_pooled, std_null, std_alt = _std_2prop_power(diff, prop2, ratio=ratio,\n        alpha=alpha, value=value)\n    pow_ = normal_power_het(diff, nobs1, alpha, std_null=std_null,\n        std_alternative=std_alt, alternative=alternative)\n    if return_results:\n        res = Holder(power=pow_, p_pooled=p_pooled, std_null=std_null,\n            std_alt=std_alt, nobs1=nobs1, nobs2=ratio * nobs1, nobs_ratio=\n            ratio, alpha=alpha)\n        return res\n    else:\n        return pow_", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_power_2indep():\n    pow_ = power_proportions_2indep(-0.25, 0.75, 76.70692)\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.25, 0.75, 0.9, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 76.70692, atol=1e-05)\n    power_proportions_2indep(-0.25, 0.75, 62.33551, alternative='smaller')\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative='smaller')\n    assert_array_less(pow_.power, 0.05)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative=\n        'larger', return_results=False)\n    assert_allclose(pow_, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(-0.15, 0.65, 83.4373, return_results=False)\n    assert_allclose(pow_, 0.5, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.15, 0.65, 0.5, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 83.4373, atol=0.05)\n    from statsmodels.stats.power import normal_sample_size_one_tail\n    res = power_proportions_2indep(-0.014, 0.015, 550, ratio=1.0)\n    assert_allclose(res.power, 0.74156, atol=1e-07)\n    n = normal_sample_size_one_tail(-0.014, 0.74156, 0.05 / 2, std_null=res\n        .std_null, std_alternative=res.std_alt)\n    assert_allclose(n, 550, atol=0.05)\n    n2 = samplesize_proportions_2indep_onetail(-0.014, 0.015, 0.74156,\n        ratio=1, alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n2, n, rtol=1e-13)\n    pwr_st = 0.7995659211532175\n    n = 154\n    res = power_proportions_2indep(-0.1, 0.2, n, ratio=2.0)\n    assert_allclose(res.power, pwr_st, atol=1e-07)\n    n2 = samplesize_proportions_2indep_onetail(-0.1, 0.2, pwr_st, ratio=2)\n    assert_allclose(n2, n, rtol=0.0001)\n\ntest_power_2indep()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: \nThe power_proportions_2indep function calculates the statistical power for a z-test that compares two independent proportions. It assumes that the variance under the null hypothesis is based on the pooled proportion, while under the alternative hypothesis, the variance is non-pooled. The function can handle two-sided or one-sided tests and returns the power of the test, which is the probability that the test correctly rejects the null hypothesis given that the alternative hypothesis is true.\n\nInputs: \n- diff: A float representing the difference between proportion 1 and proportion 2 under the alternative hypothesis.\n- prop2: A float indicating the proportion for the reference case (prop2). The proportions for the first case are computed using prop2 and diff with the formula p1 = p2 + diff.\n- nobs1: A float or int representing the number of observations in sample 1.\n- ratio: A float indicating the sample size ratio, where nobs2 = ratio * nobs1. Default is 1.\n- alpha: A float in the interval (0,1) indicating the significance level, the probability of a type I error. Default is 0.05.\n- value: A float that is currently only set to 0, supporting equality testing.\n- alternative: A string indicating whether the test is two-sided (default), 'larger', or 'smaller'.\n- return_results: A boolean indicating whether to return a results instance with extra information or just the computed power. Default is True.\n\nOutputs: \nIf return_results is True, a results instance is returned with the following attributes:\n- power: A float representing the power of the test.\n- p_pooled: The pooled proportion used for std_null.\n- std_null: The standard error of the difference under the null hypothesis, not including the square root of nobs1.\n- std_alt: The standard error of the difference under the alternative hypothesis, not including the square root of nobs1.\nIf return_results is False, only the power (a float) is returned.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef power_proportions_2indep(diff, prop2, nobs1, ratio=1, alpha=0.05, value\n    =0, alternative='two-sided', return_results=True): [MASK]\n"}
{"method_name": "samplesize_proportions_2indep_onetail", "full_method_name": "samplesize_proportions_2indep_onetail", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/proportion.py", "method_code": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef samplesize_proportions_2indep_onetail(diff, prop2, power, ratio=1,\n    alpha=0.05, value=0, alternative='two-sided'):\n    \"\"\"\n    Required sample size assuming normal distribution based on one tail\n\n    This uses an explicit computation for the sample size that is required\n    to achieve a given power corresponding to the appropriate tails of the\n    normal distribution. This ignores the far tail in a two-sided test\n    which is negligible in the common case when alternative and null are\n    far apart.\n\n    Parameters\n    ----------\n    diff : float\n        Difference between proportion 1 and 2 under the alternative\n    prop2 : float\n        proportion for the reference case, prop2, proportions for the\n        first case will be computing using p2 and diff\n        p1 = p2 + diff\n    power : float\n        Power for which sample size is computed.\n    ratio : float\n        Sample size ratio, nobs2 = ratio * nobs1\n    alpha : float in interval (0,1)\n        Significance level, e.g. 0.05, is the probability of a type I\n        error, that is wrong rejections if the Null Hypothesis is true.\n    value : float\n        Currently only `value=0`, i.e. equality testing, is supported\n    alternative : string, 'two-sided' (default), 'larger', 'smaller'\n        Alternative hypothesis whether the power is calculated for a\n        two-sided (default) or one sided test. In the case of a one-sided\n        alternative, it is assumed that the test is in the appropriate tail.\n\n    Returns\n    -------\n    nobs1 : float\n        Number of observations in sample 1.\n    \"\"\"\n    from statsmodels.stats.power import normal_sample_size_one_tail\n    if alternative in ['two-sided', '2s']:\n        alpha = alpha / 2\n    _, std_null, std_alt = _std_2prop_power(diff, prop2, ratio=ratio, alpha\n        =alpha, value=value)\n    nobs = normal_sample_size_one_tail(diff, power, alpha, std_null=\n        std_null, std_alternative=std_alt)\n    return nobs", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.stats.proportion as smprop\nfrom statsmodels.stats.proportion import confint_proportions_2indep\nfrom statsmodels.stats.proportion import multinomial_proportions_confint\nfrom statsmodels.stats.proportion import power_proportions_2indep\nfrom statsmodels.stats.proportion import proportion_confint\nfrom statsmodels.stats.proportion import samplesize_proportions_2indep_onetail\nfrom statsmodels.stats.proportion import score_test_proportions_2indep\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.stats.tests.results.results_proportion import res_binom\nfrom statsmodels.stats.tests.results.results_proportion import res_binom_methods\nfrom statsmodels.stats.weightstats import zconfint\nfrom statsmodels.stats.weightstats import ztost\nfrom statsmodels.stats.power import normal_sample_size_one_tail\ndef test_power_2indep():\n    pow_ = power_proportions_2indep(-0.25, 0.75, 76.70692)\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.25, 0.75, 0.9, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 76.70692, atol=1e-05)\n    power_proportions_2indep(-0.25, 0.75, 62.33551, alternative='smaller')\n    assert_allclose(pow_.power, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative='smaller')\n    assert_array_less(pow_.power, 0.05)\n    pow_ = power_proportions_2indep(0.25, 0.5, 62.33551, alternative=\n        'larger', return_results=False)\n    assert_allclose(pow_, 0.9, atol=1e-08)\n    pow_ = power_proportions_2indep(-0.15, 0.65, 83.4373, return_results=False)\n    assert_allclose(pow_, 0.5, atol=1e-08)\n    n = samplesize_proportions_2indep_onetail(-0.15, 0.65, 0.5, ratio=1,\n        alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n, 83.4373, atol=0.05)\n    from statsmodels.stats.power import normal_sample_size_one_tail\n    res = power_proportions_2indep(-0.014, 0.015, 550, ratio=1.0)\n    assert_allclose(res.power, 0.74156, atol=1e-07)\n    n = normal_sample_size_one_tail(-0.014, 0.74156, 0.05 / 2, std_null=res\n        .std_null, std_alternative=res.std_alt)\n    assert_allclose(n, 550, atol=0.05)\n    n2 = samplesize_proportions_2indep_onetail(-0.014, 0.015, 0.74156,\n        ratio=1, alpha=0.05, value=0, alternative='two-sided')\n    assert_allclose(n2, n, rtol=1e-13)\n    pwr_st = 0.7995659211532175\n    n = 154\n    res = power_proportions_2indep(-0.1, 0.2, n, ratio=2.0)\n    assert_allclose(res.power, pwr_st, atol=1e-07)\n    n2 = samplesize_proportions_2indep_onetail(-0.1, 0.2, pwr_st, ratio=2)\n    assert_allclose(n2, n, rtol=0.0001)\n\ntest_power_2indep()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_proportion.py"}], "instruction": "Functionality: The samplesize_proportions_2indep_onetail function calculates the required sample size for a two independent samples proportion test assuming a normal distribution, based on one tail. This calculation is aimed at achieving a specified power for the test, considering the appropriate tails of the normal distribution. It ignores the far tail in a two-sided test under the condition that the alternative and null hypotheses are significantly different.\n\nInputs:\n- diff: A float representing the difference between proportion 1 and proportion 2 under the alternative hypothesis.\n- prop2: A float representing the proportion for the reference case (prop2). The proportions for the first case are computed using prop2 and diff. It is assumed that p1 = p2 + diff.\n- power: A float between 0 and 1 representing the desired power for which the sample size is computed.\n- ratio: An optional float representing the sample size ratio, where nobs2 = ratio * nobs1. The default value is 1.\n- alpha: An optional float in the interval (0,1) representing the significance level, e.g., 0.05. This is the probability of a type I error, i.e., wrongly rejecting the null hypothesis when it is true. The default value is 0.05.\n- value: An optional float representing the value under the null hypothesis. Currently, only value=0, i.e., equality testing, is supported. The default value is 0.\n- alternative: An optional string indicating the alternative hypothesis. It can be 'two-sided' (default), 'larger', or 'smaller', indicating whether the power is calculated for a two-sided test or a one-sided test in the appropriate tail.\n\nOutputs:\n- nobs1: A float representing the number of observations required in sample 1 to achieve the specified power for the given test parameters.", "method_code_mask": "from statsmodels.compat.python import lzip\nfrom typing import Callable\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize\nfrom scipy import stats\nfrom statsmodels.stats.base import AllPairsResults\nfrom statsmodels.stats.base import HolderTuple\nfrom statsmodels.stats.weightstats import _zstat_generic2\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.testing import Holder\nfrom statsmodels.tools.validation import array_like\nimport warnings\nfrom statsmodels.stats.power import normal_power_het\nfrom statsmodels.stats.power import normal_sample_size_one_tail\n\n\ndef samplesize_proportions_2indep_onetail(diff, prop2, power, ratio=1,\n    alpha=0.05, value=0, alternative='two-sided'): [MASK]\n"}
{"method_name": "_noncentrality_chisquare", "full_method_name": "_noncentrality_chisquare", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/effect_size.py", "method_code": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\ndef _noncentrality_chisquare(chi2_stat, df, alpha=0.05):\n    \"\"\"noncentrality parameter for chi-square statistic\n\n    `nc` is zero-truncated umvue\n\n    Parameters\n    ----------\n    chi2_stat : float\n        Chisquare-statistic, for example from a hypothesis test\n    df : int or float\n        Degrees of freedom\n    alpha : float in (0, 1)\n        Significance level for the confidence interval, covarage is 1 - alpha.\n\n    Returns\n    -------\n    HolderTuple\n        The main attributes are\n\n        - ``nc`` : estimate of noncentrality parameter\n        - ``confint`` : lower and upper bound of confidence interval for `nc``\n\n        Other attributes are estimates for nc by different methods.\n\n    References\n    ----------\n    .. [1] Kubokawa, T., C.P. Robert, and A.K.Md.E. Saleh. 1993. \u201cEstimation of\n        Noncentrality Parameters.\u201d\n        Canadian Journal of Statistics 21 (1): 45\u201357.\n        https://doi.org/10.2307/3315657.\n\n    .. [2] Li, Qizhai, Junjian Zhang, and Shuai Dai. 2009. \u201cOn Estimating the\n        Non-Centrality Parameter of a Chi-Squared Distribution.\u201d\n        Statistics & Probability Letters 79 (1): 98\u2013104.\n        https://doi.org/10.1016/j.spl.2008.07.025.\n\n    \"\"\"\n    alpha_half = alpha / 2\n    nc_umvue = chi2_stat - df\n    nc = np.maximum(nc_umvue, 0)\n    nc_lzd = np.maximum(nc_umvue, chi2_stat / (df + 1))\n    nc_krs = np.maximum(nc_umvue, chi2_stat * 2 / (df + 2))\n    nc_median = special.chndtrinc(chi2_stat, df, 0.5)\n    ci = special.chndtrinc(chi2_stat, df, [1 - alpha_half, alpha_half])\n    res = Holder(nc=nc, confint=ci, nc_umvue=nc_umvue, nc_lzd=nc_lzd,\n        nc_krs=nc_krs, nc_median=nc_median, name=\n        'Noncentrality for chisquare-distributed random variable')\n    return res", "test_code_list": [{"test_code": "from scipy import stats\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.effect_size import _noncentrality_chisquare\nfrom statsmodels.stats.effect_size import _noncentrality_f\nfrom statsmodels.stats.effect_size import _noncentrality_t\ndef test_noncent_chi2():\n    chi2_stat, df = 7.5, 2\n    ci_nc = [0.03349255, 20.76049805]\n    res = _noncentrality_chisquare(chi2_stat, df, alpha=0.05)\n    assert_allclose(res.confint, ci_nc, rtol=0.005)\n    mean = stats.ncx2.mean(df, res.nc)\n    assert_allclose(chi2_stat, mean, rtol=1e-08)\n    assert_allclose(stats.ncx2.cdf(chi2_stat, df, res.confint), [0.975, \n        0.025], rtol=1e-08)\n\ntest_noncent_chi2()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_effectsize.py"}], "instruction": "Functionality: This function estimates the noncentrality parameter and computes the confidence interval for a chi-square distributed random variable given the chi-square statistic, degrees of freedom, and a significance level.\n\nInputs:\n- chi2_stat: A float representing the chi-square statistic, typically from a hypothesis test.\n- df: An int or float representing the degrees of freedom of the chi-square distribution.\n- alpha: A float in the range (0, 1) representing the significance level for the confidence interval, with coverage being 1 - alpha. The default value is 0.05.\n\nOutputs:\n- HolderTuple: A container that holds the following attributes:\n  - nc: Estimate of the noncentrality parameter, truncated to zero if negative.\n  - confint: A tuple containing the lower and upper bounds of the confidence interval for the noncentrality parameter.\n  - Additional attributes include different estimates for the noncentrality parameter by various methods.", "method_code_mask": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\n\n\ndef _noncentrality_chisquare(chi2_stat, df, alpha=0.05): [MASK]\n"}
{"method_name": "_noncentrality_f", "full_method_name": "_noncentrality_f", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/effect_size.py", "method_code": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\ndef _noncentrality_f(f_stat, df1, df2, alpha=0.05):\n    \"\"\"noncentrality parameter for f statistic\n\n    `nc` is zero-truncated umvue\n\n    Parameters\n    ----------\n    fstat : float\n        f-statistic, for example from a hypothesis test\n        df : int or float\n        Degrees of freedom\n    alpha : float in (0, 1)\n        Significance level for the confidence interval, covarage is 1 - alpha.\n\n    Returns\n    -------\n    HolderTuple\n        The main attributes are\n\n        - ``nc`` : estimate of noncentrality parameter\n        - ``confint`` : lower and upper bound of confidence interval for `nc``\n\n        Other attributes are estimates for nc by different methods.\n\n    References\n    ----------\n    .. [1] Kubokawa, T., C.P. Robert, and A.K.Md.E. Saleh. 1993. \u201cEstimation of\n       Noncentrality Parameters.\u201d Canadian Journal of Statistics 21 (1): 45\u201357.\n       https://doi.org/10.2307/3315657.\n    \"\"\"\n    alpha_half = alpha / 2\n    x_s = f_stat * df1 / df2\n    nc_umvue = (df2 - 2) * x_s - df1\n    nc = np.maximum(nc_umvue, 0)\n    nc_krs = np.maximum(nc_umvue, x_s * 2 * (df2 - 1) / (df1 + 2))\n    nc_median = special.ncfdtrinc(df1, df2, 0.5, f_stat)\n    ci = special.ncfdtrinc(df1, df2, [1 - alpha_half, alpha_half], f_stat)\n    res = Holder(nc=nc, confint=ci, nc_umvue=nc_umvue, nc_krs=nc_krs,\n        nc_median=nc_median, name=\n        'Noncentrality for F-distributed random variable')\n    return res", "test_code_list": [{"test_code": "from scipy import stats\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.effect_size import _noncentrality_chisquare\nfrom statsmodels.stats.effect_size import _noncentrality_f\nfrom statsmodels.stats.effect_size import _noncentrality_t\ndef test_noncent_f():\n    f_stat, df1, df2 = 3.5, 4, 75\n    ci_nc = [0.7781436, 29.72949219]\n    res = _noncentrality_f(f_stat, df1, df2, alpha=0.05)\n    assert_allclose(res.confint, ci_nc, rtol=0.005)\n    mean = stats.ncf.mean(df1, df2, res.nc)\n    assert_allclose(f_stat, mean, rtol=1e-08)\n    assert_allclose(stats.ncf.cdf(f_stat, df1, df2, res.confint), [0.975, \n        0.025], rtol=5e-05)\n\ntest_noncent_f()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_effectsize.py"}], "instruction": "Functionality: The _noncentrality_f function estimates the noncentrality parameter for an F-distributed statistic, which is often used in the context of hypothesis testing in statistics. The function calculates the zero-truncated unbiased minimum variance unbiased estimator (UMVUE) of the noncentrality parameter, as well as additional estimates and a confidence interval.\n\nInputs: \n- f_stat: A float representing the F-statistic from a hypothesis test.\n- df1: An integer or float representing the first degrees of freedom in the F-distribution.\n- df2: An integer or float representing the second degrees of freedom in the F-distribution.\n- alpha: An optional float in the range (0, 1) specifying the significance level for the confidence interval of the noncentrality parameter. Default is 0.05.\n\nOutputs:\n- A HolderTuple object with the following attributes:\n    * nc: Estimate of the noncentrality parameter.\n    * confint: A tuple containing the lower and upper bounds of the confidence interval for the noncentrality parameter.\n    * nc_umvue: The unbiased minimum variance unbiased estimator of the noncentrality parameter.\n    * nc_krs: An additional estimate of the noncentrality parameter.\n    * nc_median: The median estimate of the noncentrality parameter.\n    * name: A descriptive name for the returned object.\n\nReferences for the method used are provided in the function's docstring.", "method_code_mask": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\n\n\ndef _noncentrality_f(f_stat, df1, df2, alpha=0.05): [MASK]\n"}
{"method_name": "_noncentrality_t", "full_method_name": "_noncentrality_t", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/effect_size.py", "method_code": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\ndef _noncentrality_t(t_stat, df, alpha=0.05):\n    \"\"\"noncentrality parameter for t statistic\n\n    Parameters\n    ----------\n    fstat : float\n        f-statistic, for example from a hypothesis test\n        df : int or float\n        Degrees of freedom\n    alpha : float in (0, 1)\n        Significance level for the confidence interval, covarage is 1 - alpha.\n\n    Returns\n    -------\n    HolderTuple\n        The main attributes are\n\n        - ``nc`` : estimate of noncentrality parameter\n        - ``confint`` : lower and upper bound of confidence interval for `nc``\n\n        Other attributes are estimates for nc by different methods.\n\n    References\n    ----------\n    .. [1] Hedges, Larry V. 2016. \u201cDistribution Theory for Glass\u2019s Estimator of\n       Effect Size and Related Estimators:\u201d\n       Journal of Educational Statistics, November.\n       https://doi.org/10.3102/10769986006002107.\n\n    \"\"\"\n    alpha_half = alpha / 2\n    gfac = np.exp(special.gammaln(df / 2.0 - 0.5) - special.gammaln(df / 2.0))\n    c11 = np.sqrt(df / 2.0) * gfac\n    nc = t_stat / c11\n    nc_median = special.nctdtrinc(df, 0.5, t_stat)\n    ci = special.nctdtrinc(df, [1 - alpha_half, alpha_half], t_stat)\n    res = Holder(nc=nc, confint=ci, nc_median=nc_median, name=\n        'Noncentrality for t-distributed random variable')\n    return res", "test_code_list": [{"test_code": "from scipy import stats\nfrom numpy.testing import assert_allclose\nfrom statsmodels.stats.effect_size import _noncentrality_chisquare\nfrom statsmodels.stats.effect_size import _noncentrality_f\nfrom statsmodels.stats.effect_size import _noncentrality_t\ndef test_noncent_t():\n    t_stat, df = 1.5, 98\n    ci_nc = [-0.474934, 3.467371]\n    res = _noncentrality_t(t_stat, df, alpha=0.05)\n    assert_allclose(res.confint, ci_nc, rtol=0.005)\n    mean = stats.nct.mean(df, res.nc)\n    assert_allclose(t_stat, mean, rtol=1e-08)\n    assert_allclose(stats.nct.cdf(t_stat, df, res.confint), [0.975, 0.025],\n        rtol=1e-06)\n\ntest_noncent_t()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_effectsize.py"}], "instruction": "Functionality: The _noncentrality_t function is designed to calculate the noncentrality parameter for a given t-statistic. This is particularly useful in hypothesis testing scenarios where the distribution is noncentral t-distributed. It also computes a confidence interval for the estimate of the noncentrality parameter.\n\nInputs: \n- t_stat: A float representing the t-statistic value from a statistical test.\n- df: An integer or float that denotes the degrees of freedom associated with the t-distribution.\n- alpha: A float within the range (0, 1) representing the significance level for the confidence interval. The default value is 0.05.\n\nOutputs:\n- HolderTuple: An object containing the following attributes:\n  - nc: Estimate of the noncentrality parameter calculated from the t-statistic.\n  - confint: A tuple representing the lower and upper bounds of the confidence interval for the noncentrality parameter.\n  - nc_median: Estimate of the noncentrality parameter using the median of the noncentral t-distribution.", "method_code_mask": "import numpy as np\nfrom scipy import special\nfrom statsmodels.stats.base import Holder\n\n\ndef _noncentrality_t(t_stat, df, alpha=0.05): [MASK]\n"}
{"method_name": "get_duncan_data", "full_method_name": "get_duncan_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_diagnostic.py", "method_code": "import json\nimport os\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.diagnostic as smsdia\nimport statsmodels.stats.outliers_influence as oi\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom pandas import DataFrame\ndef get_duncan_data():\n    labels = ['accountant', 'pilot', 'architect', 'author', 'chemist',\n        'minister', 'professor', 'dentist', 'reporter', 'engineer',\n        'undertaker', 'lawyer', 'physician', 'welfare.worker', 'teacher',\n        'conductor', 'contractor', 'factory.owner', 'store.manager',\n        'banker', 'bookkeeper', 'mail.carrier', 'insurance.agent',\n        'store.clerk', 'carpenter', 'electrician', 'RR.engineer',\n        'machinist', 'auto.repairman', 'plumber', 'gas.stn.attendant',\n        'coal.miner', 'streetcar.motorman', 'taxi.driver', 'truck.driver',\n        'machine.operator', 'barber', 'bartender', 'shoe.shiner', 'cook',\n        'soda.clerk', 'watchman', 'janitor', 'policeman', 'waiter']\n    exog = [[1.0, 62.0, 86.0], [1.0, 72.0, 76.0], [1.0, 75.0, 92.0], [1.0, \n        55.0, 90.0], [1.0, 64.0, 86.0], [1.0, 21.0, 84.0], [1.0, 64.0, 93.0\n        ], [1.0, 80.0, 100.0], [1.0, 67.0, 87.0], [1.0, 72.0, 86.0], [1.0, \n        42.0, 74.0], [1.0, 76.0, 98.0], [1.0, 76.0, 97.0], [1.0, 41.0, 84.0\n        ], [1.0, 48.0, 91.0], [1.0, 76.0, 34.0], [1.0, 53.0, 45.0], [1.0, \n        60.0, 56.0], [1.0, 42.0, 44.0], [1.0, 78.0, 82.0], [1.0, 29.0, 72.0\n        ], [1.0, 48.0, 55.0], [1.0, 55.0, 71.0], [1.0, 29.0, 50.0], [1.0, \n        21.0, 23.0], [1.0, 47.0, 39.0], [1.0, 81.0, 28.0], [1.0, 36.0, 32.0\n        ], [1.0, 22.0, 22.0], [1.0, 44.0, 25.0], [1.0, 15.0, 29.0], [1.0, \n        7.0, 7.0], [1.0, 42.0, 26.0], [1.0, 9.0, 19.0], [1.0, 21.0, 15.0],\n        [1.0, 21.0, 20.0], [1.0, 16.0, 26.0], [1.0, 16.0, 28.0], [1.0, 9.0,\n        17.0], [1.0, 14.0, 22.0], [1.0, 12.0, 30.0], [1.0, 17.0, 25.0], [\n        1.0, 7.0, 20.0], [1.0, 34.0, 47.0], [1.0, 8.0, 32.0]]\n    endog = [82.0, 83.0, 90.0, 76.0, 90.0, 87.0, 93.0, 90.0, 52.0, 88.0, \n        57.0, 89.0, 97.0, 59.0, 73.0, 38.0, 76.0, 81.0, 45.0, 92.0, 39.0, \n        34.0, 41.0, 16.0, 33.0, 53.0, 67.0, 57.0, 26.0, 29.0, 10.0, 15.0, \n        19.0, 10.0, 13.0, 24.0, 20.0, 7.0, 3.0, 16.0, 6.0, 11.0, 8.0, 41.0,\n        10.0]\n    return endog, exog, labels", "test_code_list": [{"test_code": "import json\nimport os\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.diagnostic as smsdia\nimport statsmodels.stats.outliers_influence as oi\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom pandas import DataFrame\ndef test_outlier_test():\n    endog, exog, labels = get_duncan_data()\n    ndarray_mod = OLS(endog, exog).fit()\n    rstudent = [3.1345185839, -2.397022399, 2.0438046359, -1.9309187757, \n        1.8870465798, -1.76049053, -1.7040324156, 1.6024285876, -\n        1.4332485037, -1.1044851583, 1.0688582315, 1.018527184, -\n        0.9024219332, -0.9023876471, -0.8830953936, 0.8265782334, \n        0.8089220547, 0.7682770197, 0.7319491074, -0.6665962829, \n        0.5227352794, -0.5135016547, 0.5083881518, 0.4999224372, -\n        0.4980818221, -0.4759717075, -0.429356582, -0.4114056499, -\n        0.3779540862, 0.355687403, 0.3409200462, 0.3062248646, 0.3038999429,\n        -0.3030815773, -0.1873387893, 0.1738050251, 0.1424246593, -\n        0.1292266025, 0.1272066463, -0.0798902878, 0.0788467222, \n        0.0722556991, 0.050509828, 0.0233215136, 0.0007112055]\n    unadj_p = [0.003177202, 0.021170298, 0.047432955, 0.060427645, \n        0.06624812, 0.085783008, 0.095943909, 0.116738318, 0.15936889, \n        0.275822623, 0.291386358, 0.314400295, 0.372104049, 0.37212204, \n        0.382333561, 0.413260793, 0.423229432, 0.44672537, 0.468363101, \n        0.508764039, 0.60397199, 0.610356737, 0.613905871, 0.619802317, \n        0.621087703, 0.636621083, 0.669911674, 0.682917818, 0.707414459, \n        0.723898263, 0.734904667, 0.760983108, 0.762741124, 0.763360242, \n        0.852319039, 0.862874018, 0.887442197, 0.897810225, 0.899398691, \n        0.936713197, 0.937538115, 0.942749758, 0.959961394, 0.981506948, \n        0.999435989]\n    bonf_p = [0.1429741, 0.9526634, 2.134483, 2.719244, 2.9811654, \n        3.8602354, 4.3174759, 5.2532243, 7.1716001, 12.412018, 13.1123861, \n        14.1480133, 16.7446822, 16.7454918, 17.2050103, 18.5967357, \n        19.0453245, 20.1026416, 21.0763395, 22.8943818, 27.1787396, \n        27.4660532, 27.6257642, 27.8911043, 27.9489466, 28.6479487, \n        30.1460253, 30.7313018, 31.8336506, 32.5754218, 33.07071, \n        34.2442399, 34.3233506, 34.3512109, 38.3543568, 38.8293308, \n        39.9348989, 40.4014601, 40.4729411, 42.1520939, 42.1892152, \n        42.4237391, 43.1982627, 44.1678127, 44.9746195]\n    bonf_p = np.array(bonf_p)\n    bonf_p[bonf_p > 1] = 1\n    sorted_labels = ['minister', 'reporter', 'contractor',\n        'insurance.agent', 'machinist', 'store.clerk', 'conductor',\n        'factory.owner', 'mail.carrier', 'streetcar.motorman', 'carpenter',\n        'coal.miner', 'bartender', 'bookkeeper', 'soda.clerk', 'chemist',\n        'RR.engineer', 'professor', 'electrician', 'gas.stn.attendant',\n        'auto.repairman', 'watchman', 'banker', 'machine.operator',\n        'dentist', 'waiter', 'shoe.shiner', 'welfare.worker', 'plumber',\n        'physician', 'pilot', 'engineer', 'accountant', 'lawyer',\n        'undertaker', 'barber', 'store.manager', 'truck.driver', 'cook',\n        'janitor', 'policeman', 'architect', 'teacher', 'taxi.driver', 'author'\n        ]\n    res2 = np.c_[rstudent, unadj_p, bonf_p]\n    res = oi.outlier_test(ndarray_mod, method='b', labels=labels, order=True)\n    np.testing.assert_almost_equal(res.values, res2, 7)\n    np.testing.assert_equal(res.index.tolist(), sorted_labels)\n    data = pd.DataFrame(np.column_stack((endog, exog)), columns=\n        'y const var1 var2'.split(), index=labels)\n    res_pd = OLS.from_formula('y ~ const + var1 + var2 - 0', data).fit()\n    res_outl2 = oi.outlier_test(res_pd, method='b', order=True)\n    assert_almost_equal(res_outl2.values, res2, 7)\n    assert_equal(res_outl2.index.tolist(), sorted_labels)\n    res_outl1 = res_pd.outlier_test(method='b')\n    res_outl1 = res_outl1.sort_values(['unadj_p'], ascending=True)\n    assert_almost_equal(res_outl1.values, res2, 7)\n    assert_equal(res_outl1.index.tolist(), sorted_labels)\n    assert_array_equal(res_outl2.index, res_outl1.index)\n    res_outl3 = res_pd.outlier_test(method='b', order=True)\n    assert_equal(res_outl3.index.tolist(), sorted_labels)\n    res_outl4 = res_pd.outlier_test(method='b', order=True, cutoff=0.15)\n    assert_equal(res_outl4.index.tolist(), sorted_labels[:1])\n\ntest_outlier_test()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/stats/tests/test_diagnostic.py"}], "instruction": "Functionality: The function get_duncan_data is designed to return a dataset from a classic study on prestige of occupations. This dataset includes the prestige, income, and education level of various occupations in the US in the 1950s. The function is expected to return the dependent variable (endog), the independent variables (exog), and the labels for each occupation.\n\nInputs: The function does not require any input arguments. Calling the function get_duncan_data() should return the dataset without any need for additional parameters.\n\nOutputs: The function should return three elements:\n1. endog: A list containing the values of the dependent variable, which represents the prestige of each occupation.\n2. exog: A list of lists, containing the values of the independent variables, which represent income and education for each occupation.\n3. labels: A list containing the labels of each occupation, corresponding to the positions in the exog and endog lists.", "method_code_mask": "import json\nimport os\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom pandas.testing import assert_frame_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.regression.linear_model import OLS\nimport statsmodels.stats.diagnostic as smsdia\nimport statsmodels.stats.outliers_influence as oi\nimport statsmodels.stats.sandwich_covariance as sw\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom pandas import DataFrame\n\n\ndef get_duncan_data(): [MASK]\n"}
{"method_name": "_right_squeeze", "full_method_name": "_right_squeeze", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/validation.py", "method_code": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\ndef _right_squeeze(arr, stop_dim=0):\n    \"\"\"\n    Remove trailing singleton dimensions\n\n    Parameters\n    ----------\n    arr : ndarray\n        Input array\n    stop_dim : int\n        Dimension where checking should stop so that shape[i] is not checked\n        for i < stop_dim\n\n    Returns\n    -------\n    squeezed : ndarray\n        Array with all trailing singleton dimensions (0 or 1) removed.\n        Singleton dimensions for dimension < stop_dim are retained.\n    \"\"\"\n    last = arr.ndim\n    for s in reversed(arr.shape):\n        if s > 1:\n            break\n        last -= 1\n    last = max(last, stop_dim)\n    return arr.reshape(arr.shape[:last])", "test_code_list": [{"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef test_right_squeeze():\n    x = np.empty((10, 1, 10))\n    y = _right_squeeze(x)\n    assert y.shape == (10, 1, 10)\n    x = np.empty((10, 10, 1))\n    y = _right_squeeze(x)\n    assert y.shape == (10, 10)\n    x = np.empty((10, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert y.shape == (10, 10)\n    x = np.empty((10, 1, 10, 1, 1, 1, 1, 1))\n    y = _right_squeeze(x)\n    assert y.shape == (10, 1, 10)\n\ntest_right_squeeze()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}], "instruction": "Functionality: The _right_squeeze function is designed to remove trailing singleton dimensions (dimensions with a size of 1) from the input array. This operation does not affect the dimensions up to the specified stop_dim. The function is useful for simplifying the shape of multi-dimensional arrays by eliminating unnecessary dimensions of size 1 at the end of the shape.\n\nInputs: \n- arr : ndarray\n  An input array of any dimension. This array can be a numpy array or any other array-like structure that can be converted to a numpy array.\n- stop_dim : int (optional, default=0)\n  The dimension where checking for singleton dimensions should stop. Dimensions before stop_dim (i.e., dimensions with indices less than stop_dim) will not be checked for singleton dimensions, and thus they will be retained regardless of their size.\n\nOutputs:\n- squeezed : ndarray\n  The function returns an array with all trailing singleton dimensions (sizes of 0 or 1) removed, except those dimensions with indices less than stop_dim. The returned array has the same data as the input array but with a possibly reduced number of dimensions.", "method_code_mask": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\n\n\ndef _right_squeeze(arr, stop_dim=0): [MASK]\n"}
{"method_name": "gen_data", "full_method_name": "gen_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py", "method_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef gen_data(dim, use_pandas):\n    if dim == 1:\n        out = np.empty(10)\n        if use_pandas:\n            out = pd.Series(out)\n    elif dim == 2:\n        out = np.empty((20, 10))\n        if use_pandas:\n            out = pd.DataFrame(out)\n    else:\n        out = np.empty(np.arange(5, 5 + dim))\n    return out", "test_code_list": [{"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef test_wrap_pandas_append():\n    a = gen_data(1, True)\n    a.name = 'apple'\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = 'apple_appended'\n    assert wrapped.name == expected\n    a = gen_data(2, True)\n    a.columns = [('apple_' + str(i)) for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [(c + '_appended') for c in a.columns]\n    assert list(wrapped.columns) == expected\n\ntest_wrap_pandas_append()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}, {"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef test_wrap_pandas_append_non_string():\n    a = gen_data(1, True)\n    a.name = 7\n    b = gen_data(1, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = '7_appended'\n    assert wrapped.name == expected\n    a = gen_data(2, True)\n    a.columns = [i for i in range(a.shape[1])]\n    b = gen_data(2, False)\n    wrapped = PandasWrapper(a).wrap(b, append='appended')\n    expected = [f'{c}_appended' for c in a.columns]\n    assert list(wrapped.columns) == expected\n\ntest_wrap_pandas_append_non_string()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}, {"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\n\nclass TestArrayLike():\n\tdef test_3d(self):\n\t    data = gen_data(3, False)\n\t    a = array_like(data, 'a', ndim=3)\n\t    assert a.shape == (5, 6, 7)\n\t    assert a.ndim == 3\n\t    assert type(a) is np.ndarray\n\t    a = array_like(data, 'a', ndim=3, shape=(5, None, 7))\n\t    assert a.shape == (5, 6, 7)\n\t    a = array_like(data, 'a', ndim=3, shape=(None, None, 7))\n\t    assert a.shape == (5, 6, 7)\n\t    a = array_like(data, 'a', ndim=5)\n\t    assert a.shape == (5, 6, 7, 1, 1)\n\t    with pytest.raises(ValueError, match='a is required to have shape'):\n\t        array_like(data, 'a', ndim=3, shape=(10,))\n\t    with pytest.raises(ValueError, match='a is required to have shape'):\n\t        array_like(data, 'a', ndim=3, shape=(None, None, 5))\n\t    match = 'a is required to have ndim 2 but has ndim 3'\n\t    with pytest.raises(ValueError, match=match):\n\t        array_like(data, 'a', ndim=2)\n\t    match = 'a must have ndim <= 1'\n\t    with pytest.raises(ValueError, match=match):\n\t        array_like(data, 'a', maxdim=1)\n\t    match = 'a must have ndim <= 2'\n\t    with pytest.raises(ValueError, match=match):\n\t        array_like(data, 'a', maxdim=2)\n\t\nTestArrayLike().test_3d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}], "instruction": "Functionality: The function 'gen_data' is designed to generate a data structure (either a NumPy array or a Pandas DataFrame/Series) of a specified dimension. If the dimension is 1, it creates a 1D NumPy array or a Pandas Series with a length of 10. If the dimension is 2, it creates a 2D NumPy array or a Pandas DataFrame with a shape of (20, 10). For dimensions greater than 2, it creates a NumPy array with a shape defined by the range from 5 to 5 plus the specified dimension.\n\nInputs: \n1. dim: An integer argument that specifies the dimension of the data structure to be generated. It can be any positive integer.\n2. use_pandas: A boolean argument that determines whether the output data structure should be a Pandas DataFrame or Series (if True), or a NumPy array (if False).\n\nOutputs:\nThe function returns a data structure (either a NumPy array or a Pandas DataFrame/Series) based on the input arguments. The exact dimensions of the returned data structure depend on the value provided for 'dim'.", "method_code_mask": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\n\n\ndef gen_data(dim, use_pandas): [MASK]\n"}
{"method_name": "string_like", "full_method_name": "string_like", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/validation.py", "method_code": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\ndef string_like(value, name, optional=False, options=None, lower=True):\n    \"\"\"\n    Check if object is string-like and raise if not\n\n    Parameters\n    ----------\n    value : object\n        Value to verify.\n    name : str\n        Variable name for exceptions.\n    optional : bool\n        Flag indicating whether None is allowed.\n    options : tuple[str]\n        Allowed values for input parameter `value`.\n    lower : bool\n        Convert all case-based characters in `value` into lowercase.\n\n    Returns\n    -------\n    str\n        The validated input\n\n    Raises\n    ------\n    TypeError\n        If the value is not a string or None when optional is True.\n    ValueError\n        If the input is not in ``options`` when ``options`` is set.\n    \"\"\"\n    if value is None:\n        return None\n    if not isinstance(value, str):\n        extra_text = ' or None' if optional else ''\n        raise TypeError(f'{name} must be a string{extra_text}')\n    if lower:\n        value = value.lower()\n    if options is not None and value not in options:\n        extra_text = 'If not None, ' if optional else ''\n        options_text = \"'\" + \"', '\".join(options) + \"'\"\n        msg = '{}{} must be one of: {}'.format(extra_text, name, options_text)\n        raise ValueError(msg)\n    return value", "test_code_list": [{"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef test_string():\n    out = string_like('apple', 'value')\n    assert out == 'apple'\n    out = string_like('apple', 'value', options=('apple', 'banana', 'cherry'))\n    assert out == 'apple'\n    with pytest.raises(TypeError, match='value must be a string'):\n        string_like(1, 'value')\n    with pytest.raises(TypeError, match='value must be a string'):\n        string_like(b'4', 'value')\n    with pytest.raises(ValueError, match=\n        \"value must be one of: 'apple', 'banana', 'cherry'\"):\n        string_like('date', 'value', options=('apple', 'banana', 'cherry'))\n\ntest_string()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}, {"test_code": "from collections import OrderedDict\nimport numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.validation.validation import _right_squeeze\ndef test_optional_string():\n    out = string_like('apple', 'value')\n    assert out == 'apple'\n    out = string_like('apple', 'value', options=('apple', 'banana', 'cherry'))\n    assert out == 'apple'\n    out = string_like(None, 'value', optional=True)\n    assert out is None\n    out = string_like(None, 'value', optional=True, options=('apple',\n        'banana', 'cherry'))\n    assert out is None\n    with pytest.raises(TypeError, match='value must be a string'):\n        string_like(1, 'value', optional=True)\n    with pytest.raises(TypeError, match='value must be a string'):\n        string_like(b'4', 'value', optional=True)\n\ntest_optional_string()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/validation/tests/test_validation.py"}], "instruction": "Functionality: The string_like function checks if the input value is string-like and optionally converts it to lowercase, ensuring it meets specific criteria. It raises exceptions if the input does not adhere to the defined rules.\n\nInputs: \n- value: Any type of object that needs to be verified as string-like.\n- name: A string representing the variable name for use in exception messages.\n- optional: A boolean flag indicating whether None is an acceptable value for 'value'. Default is False.\n- options: An optional tuple of strings that 'value' must match exactly if provided.\n- lower: A boolean flag indicating whether to convert 'value' to lowercase. Default is True.\n\nOutputs:\n- A string: The validated and potentially modified (lowercased) input if it passes all checks.\n\nRaises:\n- TypeError: If 'value' is not a string and optional is False, or if optional is True but None is not received.\n- ValueError: If 'options' is set and 'value' does not match any of the options.", "method_code_mask": "from typing import Any\nfrom typing import Optional\nfrom collections.abc import Mapping\nimport numpy as np\nimport pandas as pd\n\n\ndef string_like(value, name, optional=False, options=None, lower=True): [MASK]\n"}
{"method_name": "mse", "full_method_name": "mse", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef mse(x1, x2, axis=0):\n    \"\"\"mean squared error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    mse : ndarray or float\n       mean squared error along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass, for example\n    numpy matrices will silently produce an incorrect result.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.mean((x1 - x2) ** 2, axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The mse function calculates the mean squared error between two input arrays along a specified axis. This function is commonly used to measure the difference between two sets of values, typically in contexts such as model prediction accuracy. It computes the average of the squared differences between elements of x1 and x2.\n\nInputs:\n- x1, x2: array_like\n  These are the two input arrays for which the mean squared error will be calculated. They should be convertible to numpy arrays and must be broadcastable to a common shape.\n- axis: int (default is 0)\n  This parameter specifies the axis along which the mean squared error will be computed. If axis=0 (default), the calculation will be performed vertically over columns; if axis=1, horizontally over rows.\n\nOutputs:\n- mse: ndarray or float\n  The function returns the mean squared error of the input arrays along the specified axis. If the input arrays have multiple dimensions and an axis is specified, the output will be an ndarray. If the arrays are one-dimensional or the calculation is performed across all elements, the output will be a float.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef mse(x1, x2, axis=0): [MASK]\n"}
{"method_name": "rmse", "full_method_name": "rmse", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef rmse(x1, x2, axis=0):\n    \"\"\"root mean squared error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    rmse : ndarray or float\n       root mean squared error along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass, for example\n    numpy matrices will silently produce an incorrect result.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.sqrt(mse(x1, x2, axis=axis))", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The rmse function calculates the root mean squared error between two input arrays, x1 and x2, along a specified axis. This function is a measure of the differences between the values (often representing predictions) in x1 and x2.\n\nInputs: \n- x1, x2: array_like\n  These are the two arrays between which the root mean squared error is calculated. The performance measure is based on the difference between these two arrays. They must be broadcastable to a common shape.\n- axis: int, optional (default=0)\n  This determines the axis along which the summary statistic (root mean squared error) is calculated.\n\nOutputs:\n- rmse: ndarray or float\n  This is the calculated root mean squared error along the given axis. If the input arrays are not one-dimensional, the output will be an array of the root mean squared errors, one for each axis slice along the specified axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef rmse(x1, x2, axis=0): [MASK]\n"}
{"method_name": "medianbias", "full_method_name": "medianbias", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef medianbias(x1, x2, axis=0):\n    \"\"\"median bias, median error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    medianbias : ndarray or float\n       median bias, or median difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.median(x1 - x2, axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The medianbias function calculates the median bias or median difference between two input arrays along a specified axis. This function is useful for statistical analysis, performance measurement, and error calculation between two sets of data points.\n\nInputs:\n- x1, x2: These are array-like objects (lists, numpy arrays, etc.). They represent the two sets of data whose median bias is to be calculated. Both x1 and x2 must be broadcastable to a common shape for comparison.\n- axis: An integer representing the axis along which the summary statistic (median bias) is calculated. The default value is 0, indicating the operation will be performed along the first axis.\n\nOutputs:\n- medianbias: This is the output of the function, which can be either a numpy ndarray or a float, depending on the input data and the axis specified. It represents the median bias or median difference between x1 and x2 along the given axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef medianbias(x1, x2, axis=0): [MASK]\n"}
{"method_name": "bias", "full_method_name": "bias", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef bias(x1, x2, axis=0):\n    \"\"\"bias, mean error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    bias : ndarray or float\n       bias, or mean difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.mean(x1 - x2, axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The bias function calculates the mean difference, or bias, between two input arrays along a specified axis. This function is useful in determining the average error between two sets of data.\n\nInputs:\n- x1, x2: These are array-like objects (like lists, tuples, or numpy arrays) that represent the two sets of data for comparison. The performance measure is based on the difference between these two arrays. They must be broadcastable to a common shape.\n- axis: An integer representing the axis along which the summary statistic (bias) is to be calculated. The default value is 0, which means the operation will be performed along the first axis.\n\nOutputs:\n- bias: This is the output of the function, which is either an ndarray (multi-dimensional array) or a float, depending on the input arrays and the specified axis. It represents the bias or mean difference between the two input arrays along the given axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef bias(x1, x2, axis=0): [MASK]\n"}
{"method_name": "maxabs", "full_method_name": "maxabs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef maxabs(x1, x2, axis=0):\n    \"\"\"maximum absolute error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    maxabs : ndarray or float\n       maximum absolute difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.max(np.abs(x1 - x2), axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The maxabs function calculates the maximum absolute difference between two input arrays, x1 and x2, along a specified axis. It is a versatile tool for comparing the performance of two sets of data by measuring the largest discrepancy between corresponding elements.\n\nInputs:\n- x1: array_like\nFirst input array for comparison. Can be a list, tuple, or any array-like object that can be converted into a numpy array.\n- x2: array_like\nSecond input array for comparison. Can be a list, tuple, or any array-like object that can be converted into a numpy array. x1 and x2 should have shapes that can broadcast against each other.\n- axis: int, optional (default is 0)\nAxis along which the maximum absolute difference is calculated. If axis is 0, the maximum difference is computed along columns; if axis is 1, the maximum difference is computed along rows.\n\nOutputs:\n- maxabs: ndarray or float\nThe result is the maximum absolute difference between x1 and x2 along the specified axis. If the input arrays are 1-dimensional or if the specified axis is such that there is only one value along that axis, the result will be a float. Otherwise, it will be a numpy array.\n\nNote: Before performing the calculation, the input arrays are converted to numpy arrays using numpy.asanyarray to ensure compatibility. The result depends on whether the shapes of x1 and x2 can be broadcast against each other.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef maxabs(x1, x2, axis=0): [MASK]\n"}
{"method_name": "meanabs", "full_method_name": "meanabs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef meanabs(x1, x2, axis=0):\n    \"\"\"mean absolute error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    meanabs : ndarray or float\n       mean absolute difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.mean(np.abs(x1 - x2), axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The meanabs function calculates the mean absolute error between two input arrays, x1 and x2. It computes the absolute difference between each corresponding element of x1 and x2, then calculates the mean of these absolute differences along a specified axis.\n\nInputs: \n1. x1: array_like - The first input array.\n2. x2: array_like - The second input array. Note that x1 and x2 should have compatible shapes for broadcasting.\n3. axis: int, default=0 - The axis along which the mean absolute difference will be calculated.\n\nOutputs: \n1. meanabs: ndarray or float - The mean absolute difference along the specified axis. If the inputs are one-dimensional arrays, the output will be a float. If the inputs have multiple dimensions, the output will be an ndarray with the mean absolute differences computed along the specified axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef meanabs(x1, x2, axis=0): [MASK]\n"}
{"method_name": "vare", "full_method_name": "vare", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef vare(x1, x2, ddof=0, axis=0):\n    \"\"\"variance of error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    vare : ndarray or float\n       variance of difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.var(x1 - x2, ddof=ddof, axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The function 'vare' calculates the variance of the error, which is essentially the variance of the difference between two input arrays. It operates along a specified axis and can adjust the degree of freedom (ddof) for the calculation.\n\nInputs: \nx1, x2 - These are array-like objects. They can be lists, numpy arrays, or any other object that can be converted to an array. The function computes the variance of the error by calculating the difference between these two arrays.\nddof (optional) - This is an integer that represents the Delta Degrees of Freedom. This value is subtracted from the divisor in the calculation of variance. By default, ddof is set to 0.\naxis (optional) - This is an integer that indicates the axis along which the variance is calculated. The default is 0, which means the operation is performed along the first dimension of the array.\n\nOutputs:\nvare - This is a numpy ndarray or a float, depending on the input arrays and the specified axis. It represents the variance of the error, i.e., the variance of the difference between x1 and x2, calculated along the given axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef vare(x1, x2, ddof=0, axis=0): [MASK]\n"}
{"method_name": "rmspe", "full_method_name": "rmspe", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef rmspe(y, y_hat, axis=0, zeros=np.nan):\n    \"\"\"\n    Root Mean Squared Percentage Error\n\n    Parameters\n    ----------\n    y : array_like\n      The actual value.\n    y_hat : array_like\n       The predicted value.\n    axis : int\n       Axis along which the summary statistic is calculated\n    zeros : float\n       Value to assign to error where y is zero\n\n    Returns\n    -------\n    rmspe : ndarray or float\n       Root Mean Squared Percentage Error along given axis.\n    \"\"\"\n    y_hat = np.asarray(y_hat)\n    y = np.asarray(y)\n    error = y - y_hat\n    loc = y != 0\n    loc = loc.ravel()\n    percentage_error = np.full_like(error, zeros)\n    percentage_error.flat[loc] = error.flat[loc] / y.flat[loc]\n    mspe = np.nanmean(percentage_error ** 2, axis=axis) * 100\n    return np.sqrt(mspe)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The rmspe function calculates the Root Mean Squared Percentage Error between actual values and predicted values. It is a measure of the accuracy of predicted values in percentage terms, taking into account the magnitude of the actual values.\n\nInputs: \n- y: array_like. The actual observed data values.\n- y_hat: array_like. The predicted data values.\n- axis: int, optional. The axis along which the summary statistic is calculated (default is 0).\n- zeros: float, optional. The value to assign to error where y is zero (default is np.nan).\n\nOutputs:\n- rmspe: ndarray or float. The Root Mean Squared Percentage Error along the given axis.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef rmspe(y, y_hat, axis=0, zeros=np.nan): [MASK]\n"}
{"method_name": "medianabs", "full_method_name": "medianabs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/eval_measures.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import array_like\ndef medianabs(x1, x2, axis=0):\n    \"\"\"median absolute error\n\n    Parameters\n    ----------\n    x1, x2 : array_like\n       The performance measure depends on the difference between these two\n       arrays.\n    axis : int\n       axis along which the summary statistic is calculated\n\n    Returns\n    -------\n    medianabs : ndarray or float\n       median absolute difference along given axis.\n\n    Notes\n    -----\n    If ``x1`` and ``x2`` have different shapes, then they need to broadcast.\n    This uses ``numpy.asanyarray`` to convert the input. Whether this is the\n    desired result or not depends on the array subclass.\n    \"\"\"\n    x1 = np.asanyarray(x1)\n    x2 = np.asanyarray(x2)\n    return np.median(np.abs(x1 - x2), axis=axis)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.tools.eval_measures import aic\nfrom statsmodels.tools.eval_measures import aic_sigma\nfrom statsmodels.tools.eval_measures import aicc\nfrom statsmodels.tools.eval_measures import aicc_sigma\nfrom statsmodels.tools.eval_measures import bias\nfrom statsmodels.tools.eval_measures import bic\nfrom statsmodels.tools.eval_measures import bic_sigma\nfrom statsmodels.tools.eval_measures import hqic\nfrom statsmodels.tools.eval_measures import hqic_sigma\nfrom statsmodels.tools.eval_measures import iqr\nfrom statsmodels.tools.eval_measures import maxabs\nfrom statsmodels.tools.eval_measures import meanabs\nfrom statsmodels.tools.eval_measures import medianabs\nfrom statsmodels.tools.eval_measures import medianbias\nfrom statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\nfrom statsmodels.tools.eval_measures import rmspe\nfrom statsmodels.tools.eval_measures import vare\ndef test_eval_measures():\n    x = np.arange(20).reshape(4, 5)\n    y = np.ones((4, 5))\n    assert_equal(iqr(x, y), 5 * np.ones(5))\n    assert_equal(iqr(x, y, axis=1), 2 * np.ones(4))\n    assert_equal(iqr(x, y, axis=None), 9)\n    assert_equal(mse(x, y), np.array([73.5, 87.5, 103.5, 121.5, 141.5]))\n    assert_equal(mse(x, y, axis=1), np.array([3.0, 38.0, 123.0, 258.0]))\n    assert_almost_equal(rmse(x, y), np.array([8.5732141, 9.35414347, \n        10.17349497, 11.02270384, 11.89537725]))\n    assert_almost_equal(rmse(x, y, axis=1), np.array([1.73205081, 6.164414,\n        11.09053651, 16.0623784]))\n    err = x - y\n    loc = np.where(x != 0)\n    err[loc] /= x[loc]\n    err[np.where(x == 0)] = np.nan\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y), expected)\n    err[np.where(np.isnan(err))] = 0.0\n    expected = np.sqrt(np.nanmean(err ** 2, 0) * 100)\n    assert_almost_equal(rmspe(x, y, zeros=0), expected)\n    assert_equal(maxabs(x, y), np.array([14.0, 15.0, 16.0, 17.0, 18.0]))\n    assert_equal(maxabs(x, y, axis=1), np.array([3.0, 8.0, 13.0, 18.0]))\n    assert_equal(meanabs(x, y), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(meanabs(x, y, axis=1), np.array([1.4, 6.0, 11.0, 16.0]))\n    assert_equal(meanabs(x, y, axis=0), np.array([7.0, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianabs(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(bias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(bias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(medianbias(x, y), np.array([6.5, 7.5, 8.5, 9.5, 10.5]))\n    assert_equal(medianbias(x, y, axis=1), np.array([1.0, 6.0, 11.0, 16.0]))\n    assert_equal(vare(x, y), np.array([31.25, 31.25, 31.25, 31.25, 31.25]))\n    assert_equal(vare(x, y, axis=1), np.array([2.0, 2.0, 2.0, 2.0]))\n\ntest_eval_measures()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_eval_measures.py"}], "instruction": "Functionality: The medianabs function calculates the median absolute difference between two input arrays, x1 and x2, along a specified axis. This function is useful for measuring the median absolute error between two datasets, which can be particularly valuable in assessing the performance of machine learning models or other systems that predict numerical values.\n\nInputs: \n- x1, x2: These are array_like objects, meaning they can be a list, tuple, numpy array, or any object that can be converted to an array. The function will compute the median absolute difference between these two arrays. Note that x1 and x2 should be broadcastable to each other, meaning they can be of different shapes as long as numpy's broadcasting rules allow them to be compared element-wise.\n- axis: An integer specifying the axis along which the median absolute difference is calculated. If axis is 0 (default), the median is calculated column-wise for 2D arrays. For a 1D array or vector, axis should not be specified or should be 0.\n\nOutputs:\n- medianabs: A numpy ndarray or float that represents the median absolute difference between x1 and x2 along the specified axis. If the input arrays are 1D or if the calculation is along an axis that collapses the array to a single number, the output will be a float. Otherwise, it will be an ndarray containing the median absolute differences for each axis not specified.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import array_like\n\n\ndef medianabs(x1, x2, axis=0): [MASK]\n"}
{"method_name": "parallel_func", "full_method_name": "parallel_func", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/parallel.py", "method_code": "from statsmodels.tools.sm_exceptions import ModuleUnavailableWarning\nfrom statsmodels.tools.sm_exceptions import module_unavailable_doc\nfrom joblib import Parallel\nfrom joblib import delayed\nimport multiprocessing\nimport warnings\ndef parallel_func(func, n_jobs, verbose=5):\n    \"\"\"Return parallel instance with delayed function\n\n    Util function to use joblib only if available\n\n    Parameters\n    ----------\n    func : callable\n        A function\n    n_jobs : int\n        Number of jobs to run in parallel\n    verbose : int\n        Verbosity level\n\n    Returns\n    -------\n    parallel : instance of joblib.Parallel or list\n        The parallel object\n    my_func : callable\n        func if not parallel or delayed(func)\n    n_jobs : int\n        Number of jobs >= 0\n\n    Examples\n    --------\n    >>> from math import sqrt\n    >>> from statsmodels.tools.parallel import parallel_func\n    >>> parallel, p_func, n_jobs = parallel_func(sqrt, n_jobs=-1, verbose=0)\n    >>> print(n_jobs)\n    >>> parallel(p_func(i**2) for i in range(10))\n    \"\"\"\n    try:\n        try:\n            from joblib import Parallel, delayed\n        except ImportError:\n            from sklearn.externals.joblib import Parallel, delayed\n        parallel = Parallel(n_jobs, verbose=verbose)\n        my_func = delayed(func)\n        if n_jobs == -1:\n            try:\n                import multiprocessing\n                n_jobs = multiprocessing.cpu_count()\n            except (ImportError, NotImplementedError):\n                import warnings\n                warnings.warn(module_unavailable_doc.format(\n                    'multiprocessing'), ModuleUnavailableWarning)\n                n_jobs = 1\n    except ImportError:\n        import warnings\n        warnings.warn(module_unavailable_doc.format('joblib'),\n            ModuleUnavailableWarning)\n        n_jobs = 1\n        my_func = func\n        parallel = list\n    return parallel, my_func, n_jobs", "test_code_list": [{"test_code": "import warnings\nfrom statsmodels.tools.parallel import parallel_func\nfrom numpy import arange\nfrom numpy import testing\nfrom math import sqrt\ndef test_parallel():\n    x = arange(10.0)\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        parallel, p_func, n_jobs = parallel_func(sqrt, n_jobs=-1, verbose=0)\n        y = parallel(p_func(i ** 2) for i in range(10))\n    testing.assert_equal(x, y)\n\ntest_parallel()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_parallel.py"}], "instruction": "Functionality: The parallel_func function is designed to enable the parallel execution of a given function using joblib, a library for parallel computing in Python. It wraps the joblib's Parallel and delayed functions to create a parallel instance and a delayed version of the input function, allowing for the execution of multiple function calls simultaneously across different CPU cores. If joblib or multiprocessing is not available, it falls back to a sequential execution.\n\nInputs:\n- func: A callable function that will be executed in parallel. This could be any function that the user wants to run multiple times with different inputs.\n- n_jobs: An integer specifying the number of jobs to run in parallel. A value of -1 indicates that all available CPU cores should be used. If joblib is not available, this value is set to 1, indicating sequential execution.\n- verbose: An integer indicating the verbosity level of the parallel execution. The default value is 5.\n\nOutputs:\n- parallel: An instance of joblib.Parallel if joblib is available, or a list if joblib is not available. This object is used to execute the function calls in parallel or sequentially.\n- my_func: A delayed version of the input function if joblib is available, or the original function if joblib is not available. This is the function that will be executed by the parallel or list object.\n- n_jobs: The actual number of jobs that will be run in parallel or the number of sequential jobs if joblib is not available. This value is determined based on the availability of joblib and multiprocessing, and the input n_jobs value.", "method_code_mask": "from statsmodels.tools.sm_exceptions import ModuleUnavailableWarning\nfrom statsmodels.tools.sm_exceptions import module_unavailable_doc\nfrom joblib import Parallel\nfrom joblib import delayed\nimport multiprocessing\nimport warnings\n\n\ndef parallel_func(func, n_jobs, verbose=5): [MASK]\n"}
{"method_name": "_approx_fprime_cs_scalar", "full_method_name": "_approx_fprime_cs_scalar", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/numdiff.py", "method_code": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\ndef _approx_fprime_cs_scalar(x, f, epsilon=None, args=(), kwargs={}):\n    \"\"\"\n    Calculate gradient for scalar parameter with complex step derivatives.\n\n    This assumes that the function ``f`` is vectorized for a scalar parameter.\n    The function value ``f(x)`` has then the same shape as the input ``x``.\n    The derivative returned by this function also has the same shape as ``x``.\n\n    Parameters\n    ----------\n    x : ndarray\n        Parameters at which the derivative is evaluated.\n    f : function\n        `f(*((x,)+args), **kwargs)` returning either one value or 1d array.\n    epsilon : float, optional\n        Stepsize, if None, optimal stepsize is used. Optimal step-size is\n        EPS*x. See note.\n    args : tuple\n        Tuple of additional arguments for function `f`.\n    kwargs : dict\n        Dictionary of additional keyword arguments for function `f`.\n\n    Returns\n    -------\n    partials : ndarray\n       Array of derivatives, gradient evaluated for parameters ``x``.\n\n    Notes\n    -----\n    The complex-step derivative has truncation error O(epsilon**2), so\n    truncation error can be eliminated by choosing epsilon to be very small.\n    The complex-step derivative avoids the problem of round-off error with\n    small epsilon because there is no subtraction.\n    \"\"\"\n    x = np.asarray(x)\n    n = x.shape[-1]\n    epsilon = _get_epsilon(x, 1, epsilon, n)\n    eps = 1.0j * epsilon\n    partials = f(x + eps, *args, **kwargs).imag / epsilon\n    return np.array(partials)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport statsmodels.api as sm\nfrom statsmodels.tools import numdiff\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.numdiff import _approx_fprime_scalar\nfrom statsmodels.tools.numdiff import _approx_fprime_cs_scalar\ndef test_vectorized():\n\n    def f(x):\n        return 2 * x\n    desired = np.array([2, 2])\n    p = np.array([[1, 2]]).T\n    assert_allclose(_approx_fprime_scalar(p, f), desired[:, None], rtol=1e-08)\n    assert_allclose(_approx_fprime_scalar(p.squeeze(), f), desired, rtol=1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p, f), desired[:, None], rtol=\n        1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p.squeeze(), f), desired, rtol\n        =1e-08)\n    assert_allclose(approx_fprime_cs(p.T, f).squeeze(), desired, rtol=1e-08)\n\ntest_vectorized()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_numdiff.py"}], "instruction": "Functionality: The _approx_fprime_cs_scalar function calculates the gradient for a scalar parameter using complex step derivatives. This method is suitable for functions that are vectorized for a scalar parameter, where the function value and the derivative have the same shape as the input parameter.\n\nInputs:\n- x: An ndarray representing the parameters at which the derivative is evaluated.\n- f: A function that takes x and additional arguments (args and kwargs) and returns either a single value or a 1d array.\n- epsilon: An optional float representing the stepsize. If None, an optimal stepsize is used, which is EPS*x.\n- args: A tuple of additional arguments for the function f.\n- kwargs: A dictionary of additional keyword arguments for the function f.\n\nOutputs:\n- partials: An ndarray containing the array of derivatives, which represents the gradient evaluated for the parameters x.", "method_code_mask": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\n\n\ndef _approx_fprime_cs_scalar(x, f, epsilon=None, args=(), kwargs={}): [MASK]\n"}
{"method_name": "approx_fprime_cs", "full_method_name": "approx_fprime_cs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/numdiff.py", "method_code": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\ndef approx_fprime_cs(x, f, epsilon=None, args=(), kwargs={}):\n    \"\"\"\n    Calculate gradient or Jacobian with complex step derivative approximation\n\n    Parameters\n    ----------\n    x : ndarray\n        parameters at which the derivative is evaluated\n    f : function\n        `f(*((x,)+args), **kwargs)` returning either one value or 1d array\n    epsilon : float, optional\n        Stepsize, if None, optimal stepsize is used. Optimal step-size is\n        EPS*x. See note.\n    args : tuple\n        Tuple of additional arguments for function `f`.\n    kwargs : dict\n        Dictionary of additional keyword arguments for function `f`.\n\n    Returns\n    -------\n    partials : ndarray\n       array of partial derivatives, Gradient or Jacobian\n\n    Notes\n    -----\n    The complex-step derivative has truncation error O(epsilon**2), so\n    truncation error can be eliminated by choosing epsilon to be very small.\n    The complex-step derivative avoids the problem of round-off error with\n    small epsilon because there is no subtraction.\n    \"\"\"\n    n = len(x)\n    epsilon = _get_epsilon(x, 1, epsilon, n)\n    increments = np.identity(n) * 1.0j * epsilon\n    partials = [(f(x + ih, *args, **kwargs).imag / epsilon[i]) for i, ih in\n        enumerate(increments)]\n    return np.array(partials).T", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport statsmodels.api as sm\nfrom statsmodels.tools import numdiff\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.numdiff import _approx_fprime_scalar\nfrom statsmodels.tools.numdiff import _approx_fprime_cs_scalar\ndef test_vectorized():\n\n    def f(x):\n        return 2 * x\n    desired = np.array([2, 2])\n    p = np.array([[1, 2]]).T\n    assert_allclose(_approx_fprime_scalar(p, f), desired[:, None], rtol=1e-08)\n    assert_allclose(_approx_fprime_scalar(p.squeeze(), f), desired, rtol=1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p, f), desired[:, None], rtol=\n        1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p.squeeze(), f), desired, rtol\n        =1e-08)\n    assert_allclose(approx_fprime_cs(p.T, f).squeeze(), desired, rtol=1e-08)\n\ntest_vectorized()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_numdiff.py"}, {"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef test_tweedie_score():\n    np.random.seed(3242)\n    n = 500\n    x = np.random.normal(size=(n, 4))\n    lpr = np.dot(x, np.r_[1, -1, 0, 0.5])\n    mu = np.exp(lpr)\n    p0 = 1.5\n    lam = 10 * mu ** (2 - p0) / (2 - p0)\n    alp = (2 - p0) / (p0 - 1)\n    bet = 10 * mu ** (1 - p0) / (p0 - 1)\n    y = np.empty(n)\n    N = np.random.poisson(lam)\n    for i in range(n):\n        y[i] = np.random.gamma(alp, 1 / bet[i], N[i]).sum()\n    for eql in [True, False]:\n        for p in [1, 1.5, 2]:\n            if eql is False and SP_LT_17:\n                pytest.skip('skip, scipy too old, no bessel_wright')\n            fam = sm.families.Tweedie(var_power=p, eql=eql)\n            model = GLM(y, x, family=fam)\n            result = model.fit()\n            pa = result.params + 0.2 * np.random.normal(size=result.params.size\n                )\n            ngrad = approx_fprime_cs(pa, lambda x: model.loglike(x, scale=1))\n            agrad = model.score(pa, scale=1)\n            assert_allclose(ngrad, agrad, atol=1e-08, rtol=1e-08)\n            nhess = approx_hess_cs(pa, lambda x: model.loglike(x, scale=1))\n            ahess = model.hessian(pa, scale=1)\n            assert_allclose(nhess, ahess, atol=5e-08, rtol=5e-08)\n\ntest_tweedie_score()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tsa.regime_switching import markov_switching\ndef test_partials_logistic():\n    logistic = markov_switching._logistic\n    partials_logistic = markov_switching._partials_logistic\n    cases = [0, 10.0, -4]\n    for x in cases:\n        assert_allclose(partials_logistic(x), logistic(x) - logistic(x) ** 2)\n        assert_allclose(partials_logistic(x), approx_fprime_cs([x], logistic))\n    cases = [[1.0], [0, 1.0], [-2, 3.0, 1.2, -30.0]]\n    for x in cases:\n        evaluated = np.atleast_1d(logistic(x))\n        partials = np.diag(evaluated - evaluated ** 2)\n        for i in range(len(x)):\n            for j in range(i):\n                partials[i, j] = partials[j, i] = -evaluated[i] * evaluated[j]\n        assert_allclose(partials_logistic(x), partials)\n        assert_allclose(partials_logistic(x), approx_fprime_cs(x, logistic))\n    case = [[1.0]]\n    evaluated = logistic(case)\n    partial = [evaluated - evaluated ** 2]\n    assert_allclose(partials_logistic(case), partial)\n    assert_allclose(partials_logistic(case), approx_fprime_cs(case, logistic))\n    case = [[0], [1.0]]\n    evaluated = logistic(case)[:, 0]\n    partials = np.diag(evaluated - evaluated ** 2)\n    partials[0, 1] = partials[1, 0] = -np.multiply(*evaluated)\n    assert_allclose(partials_logistic(case)[:, :, 0], partials)\n    assert_allclose(partials_logistic(case), approx_fprime_cs(np.squeeze(\n        case), logistic)[..., None])\n    case = [[0, 1.0]]\n    evaluated = logistic(case)\n    partials = (evaluated - evaluated ** 2)[None, ...]\n    assert_allclose(partials_logistic(case), partials)\n    assert_allclose(partials_logistic(case), approx_fprime_cs(case, logistic).T\n        )\n    case = np.arange(2 * 3 * 4).reshape(2, 3, 4)\n    evaluated = logistic(case)\n    partials = partials_logistic(case)\n    for t in range(4):\n        for j in range(3):\n            desired = np.diag(evaluated[:, j, t] - evaluated[:, j, t] ** 2)\n            desired[0, 1] = desired[1, 0] = -np.multiply(*evaluated[:, j, t])\n            assert_allclose(partials[..., j, t], desired)\n\ntest_partials_logistic()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/regime_switching/tests/test_markov_switching.py"}], "instruction": "Functionality: The approx_fprime_cs function calculates the gradient or Jacobian of a given function with respect to its parameters using complex step derivative approximation. This method is particularly useful for avoiding round-off error and achieving high accuracy.\n\nInputs:\n- x : ndarray\n  parameters at which the derivative is evaluated\n- f : function\n  A callable function `f(*((x,)+args), **kwargs)` that returns either one value or a 1d array. This is the function for which the derivative is calculated.\n- epsilon : float, optional\n  Stepsize for the derivative calculation. If None, an optimal stepsize is used, which is `EPS*x`. EPS is a small positive number (machine epsilon).\n- args : tuple\n  A tuple containing additional arguments for function `f`.\n- kwargs : dict\n  A dictionary containing additional keyword arguments for function `f`.\n\nOutputs:\n- partials : ndarray\n  The output is an array of partial derivatives, which represents the Gradient or Jacobian of function `f` at the given parameters `x`.", "method_code_mask": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\n\n\ndef approx_fprime_cs(x, f, epsilon=None, args=(), kwargs={}): [MASK]\n"}
{"method_name": "_approx_fprime_scalar", "full_method_name": "_approx_fprime_scalar", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/numdiff.py", "method_code": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\ndef _approx_fprime_scalar(x, f, epsilon=None, args=(), kwargs={}, centered=\n    False):\n    \"\"\"\n    Gradient of function vectorized for scalar parameter.\n\n    This assumes that the function ``f`` is vectorized for a scalar parameter.\n    The function value ``f(x)`` has then the same shape as the input ``x``.\n    The derivative returned by this function also has the same shape as ``x``.\n\n    Parameters\n    ----------\n    x : ndarray\n        Parameters at which the derivative is evaluated.\n    f : function\n        `f(*((x,)+args), **kwargs)` returning either one value or 1d array\n    epsilon : float, optional\n        Stepsize, if None, optimal stepsize is used. This is EPS**(1/2)*x for\n        `centered` == False and EPS**(1/3)*x for `centered` == True.\n    args : tuple\n        Tuple of additional arguments for function `f`.\n    kwargs : dict\n        Dictionary of additional keyword arguments for function `f`.\n    centered : bool\n        Whether central difference should be returned. If not, does forward\n        differencing.\n\n    Returns\n    -------\n    grad : ndarray\n        Array of derivatives, gradient evaluated at parameters ``x``.\n    \"\"\"\n    x = np.asarray(x)\n    n = 1\n    f0 = f(*((x,) + args), **kwargs)\n    if not centered:\n        eps = _get_epsilon(x, 2, epsilon, n)\n        grad = (f(*((x + eps,) + args), **kwargs) - f0) / eps\n    else:\n        eps = _get_epsilon(x, 3, epsilon, n) / 2.0\n        grad = (f(*((x + eps,) + args), **kwargs) - f(*((x - eps,) + args),\n            **kwargs)) / (2 * eps)\n    return grad", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport statsmodels.api as sm\nfrom statsmodels.tools import numdiff\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.numdiff import _approx_fprime_scalar\nfrom statsmodels.tools.numdiff import _approx_fprime_cs_scalar\ndef test_vectorized():\n\n    def f(x):\n        return 2 * x\n    desired = np.array([2, 2])\n    p = np.array([[1, 2]]).T\n    assert_allclose(_approx_fprime_scalar(p, f), desired[:, None], rtol=1e-08)\n    assert_allclose(_approx_fprime_scalar(p.squeeze(), f), desired, rtol=1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p, f), desired[:, None], rtol=\n        1e-08)\n    assert_allclose(_approx_fprime_cs_scalar(p.squeeze(), f), desired, rtol\n        =1e-08)\n    assert_allclose(approx_fprime_cs(p.T, f).squeeze(), desired, rtol=1e-08)\n\ntest_vectorized()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_numdiff.py"}], "instruction": "Functionality: Calculate the gradient of a function with respect to a scalar parameter using either forward or central differencing.\n\nInputs:\n- x: A numpy ndarray representing the parameters at which the derivative is evaluated.\n- f: A function that takes the parameter(s) and returns either a single value or a 1d array.\n- epsilon: A positive float representing the step size for computing the derivative. If None, an optimal step size is used based on the `centered` parameter.\n- args: A tuple of additional positional arguments to be passed to the function `f`.\n- kwargs: A dictionary of additional keyword arguments to be passed to the function `f`.\n- centered: A boolean indicating whether to use central differencing (True) or forward differencing (False).\n\nOutputs:\n- grad: A numpy ndarray of the same shape as `x`, representing the gradient of the function `f` evaluated at the parameters `x`.", "method_code_mask": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\n\n\ndef _approx_fprime_scalar(x, f, epsilon=None, args=(), kwargs={}, centered=\n    False): [MASK]\n"}
{"method_name": "approx_hess_cs", "full_method_name": "approx_hess_cs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/numdiff.py", "method_code": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\ndef approx_hess_cs(x, f, epsilon=None, args=(), kwargs={}):\n    \"\"\"Calculate Hessian with complex-step derivative approximation\n\n    Parameters\n    ----------\n    x : array_like\n       value at which function derivative is evaluated\n    f : function\n       function of one array f(x)\n    epsilon : float\n       stepsize, if None, then stepsize is automatically chosen\n\n    Returns\n    -------\n    hess : ndarray\n       array of partial second derivatives, Hessian\n\n    Notes\n    -----\n    based on equation 10 in\n    M. S. RIDOUT: Statistical Applications of the Complex-step Method\n    of Numerical Differentiation, University of Kent, Canterbury, Kent, U.K.\n\n    The stepsize is the same for the complex and the finite difference part.\n    \"\"\"\n    n = len(x)\n    h = _get_epsilon(x, 3, epsilon, n)\n    ee = np.diag(h)\n    hess = np.outer(h, h)\n    n = len(x)\n    for i in range(n):\n        for j in range(i, n):\n            hess[i, j] = np.squeeze((f(*((x + 1.0j * ee[i, :] + ee[j, :],) +\n                args), **kwargs) - f(*((x + 1.0j * ee[i, :] - ee[j, :],) +\n                args), **kwargs)).imag / 2.0 / hess[i, j])\n            hess[j, i] = hess[i, j]\n    return hess", "test_code_list": [{"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef test_tweedie_score():\n    np.random.seed(3242)\n    n = 500\n    x = np.random.normal(size=(n, 4))\n    lpr = np.dot(x, np.r_[1, -1, 0, 0.5])\n    mu = np.exp(lpr)\n    p0 = 1.5\n    lam = 10 * mu ** (2 - p0) / (2 - p0)\n    alp = (2 - p0) / (p0 - 1)\n    bet = 10 * mu ** (1 - p0) / (p0 - 1)\n    y = np.empty(n)\n    N = np.random.poisson(lam)\n    for i in range(n):\n        y[i] = np.random.gamma(alp, 1 / bet[i], N[i]).sum()\n    for eql in [True, False]:\n        for p in [1, 1.5, 2]:\n            if eql is False and SP_LT_17:\n                pytest.skip('skip, scipy too old, no bessel_wright')\n            fam = sm.families.Tweedie(var_power=p, eql=eql)\n            model = GLM(y, x, family=fam)\n            result = model.fit()\n            pa = result.params + 0.2 * np.random.normal(size=result.params.size\n                )\n            ngrad = approx_fprime_cs(pa, lambda x: model.loglike(x, scale=1))\n            agrad = model.score(pa, scale=1)\n            assert_allclose(ngrad, agrad, atol=1e-08, rtol=1e-08)\n            nhess = approx_hess_cs(pa, lambda x: model.loglike(x, scale=1))\n            ahess = model.hessian(pa, scale=1)\n            assert_allclose(nhess, ahess, atol=5e-08, rtol=5e-08)\n\ntest_tweedie_score()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py"}], "instruction": "Functionality: The approx_hess_cs function calculates the Hessian matrix, which consists of second-order partial derivatives, using a complex-step derivative approximation method. This method is particularly useful for obtaining accurate numerical approximations of the Hessian, which is crucial for optimization and other numerical algorithms where the curvature of a function is important.\n\nInputs: \n- x: An array-like object representing the point at which the function's Hessian is to be evaluated.\n- f: A callable function that takes a single array argument and returns a scalar or an array. This function represents the objective function whose Hessian is to be calculated.\n- epsilon: An optional float parameter representing the step size for the numerical differentiation. If not provided, an optimal step size is automatically determined.\n- args: A tuple containing any additional positional arguments required by the function f.\n- kwargs: A dictionary containing any additional keyword arguments required by the function f.\n\nOutputs:\n- hess: A two-dimensional ndarray representing the Hessian matrix of the function f at the point x. The Hessian is a symmetric matrix where each element hess[i, j] is the second partial derivative of f with respect to x[i] and x[j].", "method_code_mask": "import numpy as np\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.compat.pandas import Substitution\n\n\ndef approx_hess_cs(x, f, epsilon=None, args=(), kwargs={}): [MASK]\n"}
{"method_name": "combine_indices", "full_method_name": "combine_indices", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/grouputils.py", "method_code": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport numpy as np\nimport pandas as pd\nimport statsmodels.tools.data as data_util\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom scipy import sparse\ndef combine_indices(groups, prefix='', sep='.', return_labels=False):\n    \"\"\"use np.unique to get integer group indices for product, intersection\n    \"\"\"\n    if isinstance(groups, tuple):\n        groups = np.column_stack(groups)\n    else:\n        groups = np.asarray(groups)\n    dt = groups.dtype\n    is2d = groups.ndim == 2\n    if is2d:\n        ncols = groups.shape[1]\n        if not groups.flags.c_contiguous:\n            groups = np.array(groups, order='C')\n        groups_ = groups.view([('', groups.dtype)] * groups.shape[1])\n    else:\n        groups_ = groups\n    uni, uni_idx, uni_inv = np.unique(groups_, return_index=True,\n        return_inverse=True)\n    if is2d:\n        uni = uni.view(dt).reshape(-1, ncols)\n    if return_labels:\n        label = [((prefix + sep.join(['%s'] * len(uni[0]))) % tuple(ii)) for\n            ii in uni]\n        return uni_inv, uni_idx, uni, label\n    else:\n        return uni_inv, uni_idx, uni", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom scipy import sparse\nfrom statsmodels.tools.grouputils import dummy_sparse\nfrom statsmodels.tools.grouputils import Grouping\nfrom statsmodels.tools.grouputils import Group\nfrom statsmodels.tools.grouputils import combine_indices\nfrom statsmodels.tools.grouputils import group_sums\nfrom statsmodels.datasets import grunfeld\nfrom statsmodels.datasets import anes96\ndef test_combine_indices():\n    np.random.seed(985367)\n    groups = np.random.randint(0, 2, size=(10, 2))\n    uv, ux, u, label = combine_indices(groups, return_labels=True)\n    uv, ux, u, label = combine_indices(groups, prefix='g1,g2=', sep=',',\n        return_labels=True)\n    group0 = np.array(['sector0', 'sector1'])[groups[:, 0]]\n    group1 = np.array(['region0', 'region1'])[groups[:, 1]]\n    uv, ux, u, label = combine_indices((group0, group1), prefix=\n        'sector,region=', sep=',', return_labels=True)\n    uv, ux, u, label = combine_indices((group0, group1), prefix='', sep='.',\n        return_labels=True)\n    group_joint = np.array(label)[uv.squeeze()]\n    group_joint_expected = np.array(['sector1.region0', 'sector0.region1',\n        'sector0.region0', 'sector0.region1', 'sector1.region1',\n        'sector0.region0', 'sector1.region0', 'sector1.region0',\n        'sector0.region1', 'sector0.region0'], dtype='|U15')\n    assert_equal(group_joint, group_joint_expected)\n\ntest_combine_indices()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_grouputils.py"}], "instruction": "Functionality: The combine_indices function is designed to process a set of group indices, typically used in data analysis for operations like product and intersection. It supports both 1D and 2D arrays of group indices and can return unique group indices, their inverse mapping, and an array of unique groups. Optionally, it can also return labels for each unique group as strings.\n\nInputs:\n- groups: A 1D or 2D numpy array representing group indices. If a tuple is provided, it will be converted to a numpy array.\n- prefix: A string prefix that will be prepended to each label if return_labels is set to True (optional, default is an empty string).\n- sep: A string separator used to join the elements of each group into a label if return_labels is set to True (optional, default is '.').\n- return_labels: A boolean indicating whether to return labels for each unique group (optional, default is False).\n\nOutputs:\n- uni_inv: An array of integers where each value is the index in the array of unique groups (uni) corresponding to the original input in groups.\n- uni_idx: An array of integers representing the indices of the first occurrences of the unique elements in the original input.\n- uni: A numpy array of unique group indices.\n- label (optional): If return_labels is set to True, this will be a list of strings, where each string is a label for a unique group, formed by joining the elements of the group with the specified separator and prepended by the prefix.", "method_code_mask": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport numpy as np\nimport pandas as pd\nimport statsmodels.tools.data as data_util\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom scipy import sparse\n\n\ndef combine_indices(groups, prefix='', sep='.', return_labels=False): [MASK]\n"}
{"method_name": "dummy_sparse", "full_method_name": "dummy_sparse", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/grouputils.py", "method_code": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport numpy as np\nimport pandas as pd\nimport statsmodels.tools.data as data_util\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom scipy import sparse\ndef dummy_sparse(groups):\n    \"\"\"create a sparse indicator from a group array with integer labels\n\n    Parameters\n    ----------\n    groups : ndarray, int, 1d (nobs,)\n        an array of group indicators for each observation. Group levels are\n        assumed to be defined as consecutive integers, i.e. range(n_groups)\n        where n_groups is the number of group levels. A group level with no\n        observations for it will still produce a column of zeros.\n\n    Returns\n    -------\n    indi : ndarray, int8, 2d (nobs, n_groups)\n        an indicator array with one row per observation, that has 1 in the\n        column of the group level for that observation\n\n    Examples\n    --------\n\n    >>> g = np.array([0, 0, 2, 1, 1, 2, 0])\n    >>> indi = dummy_sparse(g)\n    >>> indi\n    <7x3 sparse matrix of type '<type 'numpy.int8'>'\n        with 7 stored elements in Compressed Sparse Row format>\n    >>> indi.todense()\n    matrix([[1, 0, 0],\n            [1, 0, 0],\n            [0, 0, 1],\n            [0, 1, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [1, 0, 0]], dtype=int8)\n\n\n    current behavior with missing groups\n    >>> g = np.array([0, 0, 2, 0, 2, 0])\n    >>> indi = dummy_sparse(g)\n    >>> indi.todense()\n    matrix([[1, 0, 0],\n            [1, 0, 0],\n            [0, 0, 1],\n            [1, 0, 0],\n            [0, 0, 1],\n            [1, 0, 0]], dtype=int8)\n    \"\"\"\n    from scipy import sparse\n    indptr = np.arange(len(groups) + 1)\n    data = np.ones(len(groups), dtype=np.int8)\n    indi = sparse.csr_matrix((data, groups, indptr))\n    return indi", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom scipy import sparse\nfrom statsmodels.tools.grouputils import dummy_sparse\nfrom statsmodels.tools.grouputils import Grouping\nfrom statsmodels.tools.grouputils import Group\nfrom statsmodels.tools.grouputils import combine_indices\nfrom statsmodels.tools.grouputils import group_sums\nfrom statsmodels.datasets import grunfeld\nfrom statsmodels.datasets import anes96\ndef test_dummy_sparse():\n    g = np.array([0, 0, 2, 1, 1, 2, 0])\n    indi = dummy_sparse(g)\n    assert isinstance(indi, sparse.csr_matrix)\n    result = indi.todense()\n    expected = np.matrix([[1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1,\n        0], [0, 0, 1], [1, 0, 0]], dtype=np.int8)\n    assert_equal(result, expected)\n    g = np.array([0, 0, 2, 0, 2, 0])\n    indi = dummy_sparse(g)\n    result = indi.todense()\n    expected = np.matrix([[1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0,\n        1], [1, 0, 0]], dtype=np.int8)\n    assert_equal(result, expected)\n\ntest_dummy_sparse()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_grouputils.py"}], "instruction": "Functionality: The function \"dummy_sparse\" is designed to create a sparse indicator matrix from a given array of group labels. Each unique group label in the input array corresponds to a column in the output matrix, where a 1 indicates the presence of that group for the corresponding observation, and 0s indicate absence. The function ensures that even groups with no observations are represented as a column of zeros.\n\nInputs: \n- groups: A 1D numpy ndarray of integer group labels for each observation. The group labels are assumed to be consecutive integers, starting from 0.\n\nOutputs:\n- indi: A 2D scipy sparse matrix (in CSR format), where each row corresponds to an observation and each column corresponds to a group. The matrix has a size of (nobs, n_groups), where nobs is the number of observations and n_groups is the number of unique group labels. Each cell in the matrix holds an int8 value, either 1 if the group is present for that observation, or 0 if it is not.", "method_code_mask": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport numpy as np\nimport pandas as pd\nimport statsmodels.tools.data as data_util\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom scipy import sparse\n\n\ndef dummy_sparse(groups): [MASK]\n"}
{"method_name": "_generate_url", "full_method_name": "_generate_url", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/web.py", "method_code": "import webbrowser\nfrom urllib.parse import urlencode\nfrom statsmodels import __version__\ndef _generate_url(func, stable):\n    \"\"\"\n    Parse inputs and return a correctly formatted URL or raises ValueError\n    if the input is not understandable\n    \"\"\"\n    url = BASE_URL\n    if stable:\n        url += 'stable/'\n    else:\n        url += 'devel/'\n    if func is None:\n        return url\n    elif isinstance(func, str):\n        url += 'search.html?'\n        url += urlencode({'q': func})\n        url += '&check_keywords=yes&area=default'\n    else:\n        try:\n            func = func\n            func_name = func.__name__\n            func_module = func.__module__\n            if not func_module.startswith('statsmodels.'):\n                raise ValueError('Function must be from statsmodels')\n            url += 'generated/'\n            url += func_module + '.' + func_name + '.html'\n        except AttributeError:\n            raise ValueError('Input not understood')\n    return url", "test_code_list": [{"test_code": "import pytest\nfrom numpy import array\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.web import _generate_url\nfrom statsmodels.tools.web import webdoc\n\nclass TestWeb():\n\tdef test_nothing(self):\n\t    url = _generate_url(None, True)\n\t    assert url == 'https://www.statsmodels.org/stable/'\n\t    url = _generate_url(None, False)\n\t    assert url == 'https://www.statsmodels.org/devel/'\n\t\nTestWeb().test_nothing()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_web.py"}], "instruction": "Functionality: The _generate_url function is designed to create a formatted URL based on the input parameters. It can either generate a general URL for documentation, a search query URL, or a URL for a specific function within the statsmodels library. The function will raise a ValueError if the input is not understandable or if the function is not from the statsmodels library.\n\nInputs: \n1. func: This can be None, a string, or a function object. \n    - None: Generates a base URL for the documentation, adjusted by the 'stable' parameter.\n    - String: Treated as a search query. The function will append a search query URL with the given string.\n    - Function: The function will append a URL for the specific function in the statsmodels library. It checks if the function belongs to the statsmodels library.\n2. stable: A boolean value. If true, 'stable/' is appended to the URL; if false, 'devel/' is appended.\n\nOutputs:\n- Returns a correctly formatted URL as a string based on the inputs provided.", "method_code_mask": "import webbrowser\nfrom urllib.parse import urlencode\nfrom statsmodels import __version__\n\n\ndef _generate_url(func, stable): [MASK]\n"}
{"method_name": "stationary_solve", "full_method_name": "stationary_solve", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/linalg.py", "method_code": "import numpy as np\nfrom scipy import linalg\nimport warnings\ndef stationary_solve(r, b):\n    \"\"\"\n    Solve a linear system for a Toeplitz correlation matrix.\n\n    A Toeplitz correlation matrix represents the covariance of a\n    stationary series with unit variance.\n\n    Parameters\n    ----------\n    r : array_like\n        A vector describing the coefficient matrix.  r[0] is the first\n        band next to the diagonal, r[1] is the second band, etc.\n    b : array_like\n        The right-hand side for which we are solving, i.e. we solve\n        Tx = b and return b, where T is the Toeplitz coefficient matrix.\n\n    Returns\n    -------\n    The solution to the linear system.\n    \"\"\"\n    db = r[0:1]\n    dim = b.ndim\n    if b.ndim == 1:\n        b = b[:, None]\n    x = b[0:1, :]\n    for j in range(1, len(b)):\n        rf = r[0:j][::-1]\n        a = (b[j, :] - np.dot(rf, x)) / (1 - np.dot(rf, db[::-1]))\n        z = x - np.outer(db[::-1], a)\n        x = np.concatenate((z, a[None, :]), axis=0)\n        if j == len(b) - 1:\n            break\n        rn = r[j]\n        a = (rn - np.dot(rf, db)) / (1 - np.dot(rf, db[::-1]))\n        z = db - a * db[::-1]\n        db = np.concatenate((z, np.r_[a]))\n    if dim == 1:\n        x = x[:, 0]\n    return x", "test_code_list": [{"test_code": "from statsmodels.tools import linalg\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom scipy.linalg import toeplitz\ndef test_stationary_solve_1d():\n    b = np.random.uniform(size=10)\n    r = np.random.uniform(size=9)\n    t = np.concatenate((np.r_[1], r))\n    tmat = toeplitz(t)\n    soln = np.linalg.solve(tmat, b)\n    soln1 = stationary_solve(r, b)\n    assert_allclose(soln, soln1, rtol=1e-05, atol=1e-05)\n\ntest_stationary_solve_1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_linalg.py"}, {"test_code": "from statsmodels.tools import linalg\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom scipy.linalg import toeplitz\ndef test_stationary_solve_2d():\n    b = np.random.uniform(size=(10, 2))\n    r = np.random.uniform(size=9)\n    t = np.concatenate((np.r_[1], r))\n    tmat = toeplitz(t)\n    soln = np.linalg.solve(tmat, b)\n    soln1 = stationary_solve(r, b)\n    assert_allclose(soln, soln1, rtol=1e-05, atol=1e-05)\n\ntest_stationary_solve_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_linalg.py"}], "instruction": "Functionality: The stationary_solve function aims to solve a linear system for a Toeplitz correlation matrix, which represents the covariance of a stationary series with unit variance. It implements a specialized algorithm to efficiently solve the system given the Toeplitz structure.\n\nInputs:\n- r : array_like\n    A vector that describes the coefficient matrix of the Toeplitz correlation matrix. Here, r[0] represents the first band next to the diagonal, r[1] the second band, and so on.\n- b : array_like\n    The right-hand side vector for which we are solving, i.e., we aim to solve Tx = b and return x, where T is the Toeplitz coefficient matrix derived from the vector 'r'.\n\nOutputs:\n- The solution to the linear system, which is the vector x that satisfies the equation Tx = b. The output is formatted to match the dimensionality of the input vector 'b'.", "method_code_mask": "import numpy as np\nfrom scipy import linalg\nimport warnings\n\n\ndef stationary_solve(r, b): [MASK]\n"}
{"method_name": "recipr", "full_method_name": "recipr", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tools.py", "method_code": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\ndef recipr(x):\n    \"\"\"\n    Reciprocal of an array with entries less than or equal to 0 set to 0.\n\n    Parameters\n    ----------\n    x : array_like\n        The input array.\n\n    Returns\n    -------\n    ndarray\n        The array with 0-filled reciprocals.\n    \"\"\"\n    x = np.asarray(x)\n    out = np.zeros_like(x, dtype=np.float64)\n    nans = np.isnan(x.flat)\n    pos = ~nans\n    pos[pos] = pos[pos] & (x.flat[pos] > 0)\n    out.flat[pos] = 1.0 / x.flat[pos]\n    out.flat[nans] = np.nan\n    return out", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.python import lrange\nimport string\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_string_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import longley\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.tools import pinv_extended\nimport warnings\n\nclass TestTools():\n\tdef test_recipr(self):\n\t    X = np.array([[2, 1], [-1, 0]])\n\t    Y = recipr(X)\n\t    assert_almost_equal(Y, np.array([[0.5, 1], [0, 0]]))\n\t\nTestTools().test_recipr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_tools.py"}], "instruction": "Functionality: The recipr function computes the reciprocal of an input array. For elements in the array that are less than or equal to zero, their reciprocal will be set to zero. If an element is NaN (Not a Number), the result for that element will also be NaN.\n\nInputs: \n- x: array_like\n  An input array. This can be a list, a numpy array, or any other array-like object that can be converted to a numpy array.\n\nOutputs:\n- ndarray: \n  The output is a numpy array with the same shape as the input array. Each element of this array is the reciprocal of the corresponding element in the input array, except where the input array's element is less than or equal to zero, in which case the output element is 0. If the input array has a NaN value, the output array will have a NaN at the same position.", "method_code_mask": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\n\n\ndef recipr(x): [MASK]\n"}
{"method_name": "recipr0", "full_method_name": "recipr0", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tools.py", "method_code": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\ndef recipr0(x):\n    \"\"\"\n    Reciprocal of an array with entries less than 0 set to 0.\n\n    Parameters\n    ----------\n    x : array_like\n        The input array.\n\n    Returns\n    -------\n    ndarray\n        The array with 0-filled reciprocals.\n    \"\"\"\n    x = np.asarray(x)\n    out = np.zeros_like(x, dtype=np.float64)\n    nans = np.isnan(x.flat)\n    non_zero = ~nans\n    non_zero[non_zero] = non_zero[non_zero] & (x.flat[non_zero] != 0)\n    out.flat[non_zero] = 1.0 / x.flat[non_zero]\n    out.flat[nans] = np.nan\n    return out", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.python import lrange\nimport string\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_string_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import longley\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.tools import pinv_extended\nimport warnings\n\nclass TestTools():\n\tdef test_recipr0(self):\n\t    X = np.array([[2, 1], [-4, 0]])\n\t    Y = recipr0(X)\n\t    assert_almost_equal(Y, np.array([[0.5, 1], [-0.25, 0]]))\n\t\nTestTools().test_recipr0()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_tools.py"}], "instruction": "Functionality: The function recipr0 computes the reciprocal of each entry in the input array. If an entry is less than 0, it is set to 0 before computing the reciprocal. NaN values in the input array are preserved as NaN in the output array.\n\nInputs: \n- x : array_like\n    The input array which can be a list, tuple, or array-like object containing numerical values.\n\nOutputs:\n- ndarray\n    An output array where each element is the reciprocal of the corresponding element in the input array. Entries that were less than 0 in the input are set to 0 before calculating the reciprocal in the output. NaN values in the input are preserved as NaN in the output array.", "method_code_mask": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\n\n\ndef recipr0(x): [MASK]\n"}
{"method_name": "pinv_extended", "full_method_name": "pinv_extended", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tools.py", "method_code": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\ndef pinv_extended(x, rcond=1e-15):\n    \"\"\"\n    Return the pinv of an array X as well as the singular values\n    used in computation.\n\n    Code adapted from numpy.\n    \"\"\"\n    x = np.asarray(x)\n    x = x.conjugate()\n    u, s, vt = np.linalg.svd(x, False)\n    s_orig = np.copy(s)\n    m = u.shape[0]\n    n = vt.shape[1]\n    cutoff = rcond * np.maximum.reduce(s)\n    for i in range(min(n, m)):\n        if s[i] > cutoff:\n            s[i] = 1.0 / s[i]\n        else:\n            s[i] = 0.0\n    res = np.dot(np.transpose(vt), np.multiply(s[:, np.newaxis], np.\n        transpose(u)))\n    return res, s_orig", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.python import lrange\nimport string\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_string_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import longley\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.tools import pinv_extended\nimport warnings\n\nclass TestTools():\n\tdef test_extendedpinv(self):\n\t    X = standard_normal((40, 10))\n\t    np_inv = np.linalg.pinv(X)\n\t    np_sing_vals = np.linalg.svd(X, 0, 0)\n\t    sm_inv, sing_vals = pinv_extended(X)\n\t    assert_almost_equal(np_inv, sm_inv)\n\t    assert_almost_equal(np_sing_vals, sing_vals)\n\t\nTestTools().test_extendedpinv()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_tools.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.python import lrange\nimport string\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_string_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import longley\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.tools import pinv_extended\nimport warnings\n\nclass TestTools():\n\tdef test_extendedpinv_singular(self):\n\t    X = standard_normal((40, 10))\n\t    X[:, 5] = X[:, 1] + X[:, 3]\n\t    np_inv = np.linalg.pinv(X)\n\t    np_sing_vals = np.linalg.svd(X, 0, 0)\n\t    sm_inv, sing_vals = pinv_extended(X)\n\t    assert_almost_equal(np_inv, sm_inv)\n\t    assert_almost_equal(np_sing_vals, sing_vals)\n\t\nTestTools().test_extendedpinv_singular()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_tools.py"}], "instruction": "Functionality: The function pinv_extended computes the pseudo-inverse of a given matrix X and also returns the singular values that were utilized in the computation process. The singular value decomposition (SVD) is employed to calculate the pseudo-inverse, where the singular values are thresholded based on a condition number (rcond). Any singular values below rcond are set to zero to ensure numerical stability, and the remaining values are inverted before computing the pseudo-inverse.\n\nInputs: \n1. x: A 2D array-like object representing the matrix for which the pseudo-inverse is to be calculated.\n2. rcond: A positive float representing the condition number used to determine the cutoff for singular values. Singular values smaller than rcond times the maximum singular value will be set to zero in the pseudo-inverse calculation. The default value for rcond is 1e-15.\n\nOutputs:\n1. res: The pseudo-inverse of the input matrix X, calculated using the modified singular values.\n2. s_orig: An array containing the original singular values obtained from the SVD of the input matrix X before any modification based on the condition number rcond.", "method_code_mask": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\n\n\ndef pinv_extended(x, rcond=1e-15): [MASK]\n"}
{"method_name": "fullrank", "full_method_name": "fullrank", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tools.py", "method_code": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\ndef fullrank(x, r=None):\n    \"\"\"\n    Return an array whose column span is the same as x.\n\n    Parameters\n    ----------\n    x : ndarray\n        The array to adjust, 2d.\n    r : int, optional\n        The rank of x. If not provided, determined by `np.linalg.matrix_rank`.\n\n    Returns\n    -------\n    ndarray\n        The array adjusted to have full rank.\n\n    Notes\n    -----\n    If the rank of x is known it can be specified as r -- no check\n    is made to ensure that this really is the rank of x.\n    \"\"\"\n    if r is None:\n        r = np.linalg.matrix_rank(x)\n    v, d, u = np.linalg.svd(x, full_matrices=False)\n    order = np.argsort(d)\n    order = order[::-1]\n    value = []\n    for i in range(r):\n        value.append(v[:, order[i]])\n    return np.asarray(np.transpose(value)).astype(np.float64)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.python import lrange\nimport string\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_string_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import longley\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.tools import pinv_extended\nimport warnings\n\nclass TestTools():\n\tdef test_fullrank(self):\n\t    import warnings\n\t    with warnings.catch_warnings():\n\t        warnings.simplefilter('ignore')\n\t        X = standard_normal((40, 10))\n\t        X[:, 0] = X[:, 1] + X[:, 2]\n\t        Y = fullrank(X)\n\t        assert_equal(Y.shape, (40, 9))\n\t        X[:, 5] = X[:, 3] + X[:, 4]\n\t        Y = fullrank(X)\n\t        assert_equal(Y.shape, (40, 8))\n\t        warnings.simplefilter('ignore')\n\t\nTestTools().test_fullrank()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_tools.py"}], "instruction": "Functionality: The function fullrank adjusts a given 2D array 'x' so that the resulting array has full rank, meaning that it has as many linearly independent columns as possible. If the rank of 'x' is not provided, it is determined using numpy's matrix_rank function.\n\nInputs: \n- x: A 2D numpy array that needs to be adjusted to have full rank.\n- r: An optional integer representing the rank of 'x'. If not provided, the rank is calculated automatically.\n\nOutputs:\n- ndarray: The adjusted array with full rank. This array will have the same column span as the original array 'x', but with the number of columns reduced to the rank 'r', ensuring that all columns are linearly independent.", "method_code_mask": "import numpy as np\nimport pandas as pd\nimport scipy.linalg\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.tsatools import add_trend\n\n\ndef fullrank(x, r=None): [MASK]\n"}
{"method_name": "add_indep", "full_method_name": "add_indep", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/catadd.py", "method_code": "import numpy as np\ndef add_indep(x, varnames, dtype=None):\n    \"\"\"\n    construct array with independent columns\n\n    x is either iterable (list, tuple) or instance of ndarray or a subclass\n    of it.  If x is an ndarray, then each column is assumed to represent a\n    variable with observations in rows.\n    \"\"\"\n    if isinstance(x, np.ndarray) and x.ndim == 2:\n        x = x.T\n    nvars_orig = len(x)\n    nobs = len(x[0])\n    if not dtype:\n        dtype = np.asarray(x[0]).dtype\n    xout = np.zeros((nobs, nvars_orig), dtype=dtype)\n    count = 0\n    rank_old = 0\n    varnames_new = []\n    varnames_dropped = []\n    keepindx = []\n    for xi, ni in zip(x, varnames):\n        xout[:, count] = xi\n        rank_new = np.linalg.matrix_rank(xout)\n        if rank_new > rank_old:\n            varnames_new.append(ni)\n            rank_old = rank_new\n            count += 1\n        else:\n            varnames_dropped.append(ni)\n    return xout[:, :count], varnames_new", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom statsmodels.tools.catadd import add_indep\nfrom scipy import linalg\ndef test_add_indep():\n    x1 = np.array([0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\n    x2 = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n    x0 = np.ones(len(x2))\n    x = np.column_stack([x0, x1[:, None] * np.arange(3), x2[:, None] * np.\n        arange(2)])\n    varnames = ['const'] + [('var1_%d' % i) for i in np.arange(3)] + [(\n        'var2_%d' % i) for i in np.arange(2)]\n    xo, vo = add_indep(x, varnames)\n    assert_equal(xo, np.column_stack((x0, x1, x2)))\n    assert_equal((linalg.svdvals(x) > 1e-12).sum(), 3)\n    assert_equal(vo, ['const', 'var1_1', 'var2_1'])\n\ntest_add_indep()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_catadd.py"}], "instruction": "Functionality: The function 'add_indep' is designed to process input data and filter out variables that do not contribute to the linear independence of the dataset. It takes an array or iterable of arrays representing multiple variables, each with a set of observations, and returns a new array where only linearly independent variables are included. Additionally, it provides a list of variable names that correspond to the independent variables.\n\nInputs:\n- x: An array or iterable of arrays. Each array represents a variable, where each element in the array is an observation of that variable.\n- varnames: An iterable (like a list or tuple) of strings, where each string is the name of a variable corresponding to the array in the 'x' argument.\n- dtype: An optional argument specifying the data type for the output array. If not provided, the data type is determined from the first variable array.\n\nOutputs:\n- xout: A 2D numpy array containing the filtered, linearly independent variables. Each column in 'xout' corresponds to one of these independent variables.\n- varnames_new: A list of strings containing the names of the variables that were determined to be linearly independent. The order of variable names matches the order of variables in 'xout'.", "method_code_mask": "import numpy as np\n\n\ndef add_indep(x, varnames, dtype=None): [MASK]\n"}
{"method_name": "discrepancy", "full_method_name": "discrepancy", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/sequences.py", "method_code": "import numpy as np\ndef discrepancy(sample, bounds=None):\n    \"\"\"Discrepancy.\n\n    Compute the centered discrepancy on a given sample.\n    It is a measure of the uniformity of the points in the parameter space.\n    The lower the value is, the better the coverage of the parameter space is.\n\n    Parameters\n    ----------\n    sample : array_like (n_samples, k_vars)\n        The sample to compute the discrepancy from.\n    bounds : tuple or array_like ([min, k_vars], [max, k_vars])\n        Desired range of transformed data. The transformation apply the bounds\n        on the sample and not the theoretical space, unit cube. Thus min and\n        max values of the sample will coincide with the bounds.\n\n    Returns\n    -------\n    discrepancy : float\n        Centered discrepancy.\n\n    References\n    ----------\n    [1] Fang et al. \"Design and modeling for computer experiments\",\n      Computer Science and Data Analysis Series Science and Data Analysis\n      Series, 2006.\n    \"\"\"\n    sample = np.asarray(sample)\n    n_sample, dim = sample.shape\n    if bounds is not None:\n        min_ = bounds.min(axis=0)\n        max_ = bounds.max(axis=0)\n        sample = (sample - min_) / (max_ - min_)\n    abs_ = abs(sample - 0.5)\n    disc1 = np.sum(np.prod(1 + 0.5 * abs_ - 0.5 * abs_ ** 2, axis=1))\n    prod_arr = 1\n    for i in range(dim):\n        s0 = sample[:, i]\n        prod_arr *= 1 + 0.5 * abs(s0[:, None] - 0.5) + 0.5 * abs(s0 - 0.5\n            ) - 0.5 * abs(s0[:, None] - s0)\n    disc2 = prod_arr.sum()\n    c2 = (13.0 / 12.0\n        ) ** dim - 2.0 / n_sample * disc1 + 1.0 / n_sample ** 2 * disc2\n    return c2", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom statsmodels.tools import sequences\ndef test_discrepancy():\n    space_0 = [[0.1, 0.5], [0.2, 0.4], [0.3, 0.3], [0.4, 0.2], [0.5, 0.1]]\n    space_1 = [[1, 3], [2, 6], [3, 2], [4, 5], [5, 1], [6, 4]]\n    space_2 = [[1, 5], [2, 4], [3, 3], [4, 2], [5, 1], [6, 6]]\n    corners = np.array([[0.5, 0.5], [6.5, 6.5]])\n    npt.assert_allclose(discrepancy(space_0), 0.1353, atol=0.0001)\n    npt.assert_allclose(discrepancy(space_1, corners), 0.0081,\n        atol=0.0001)\n    npt.assert_allclose(discrepancy(space_2, corners), 0.0105,\n        atol=0.0001)\n\ntest_discrepancy()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_sequences.py"}], "instruction": "Functionality: \nThe discrepancy function computes the centered discrepancy on a given sample. This is a measure used to assess the uniformity of points in a parameter space. A lower discrepancy value indicates better coverage of the parameter space.\n\nInputs:\n- sample : array_like (n_samples, k_vars)\n    The sample from which to compute the discrepancy. This is a two-dimensional array where each row represents a sample point and each column represents a variable.\n- bounds : tuple or array_like ([min, k_vars], [max, k_vars]), optional\n    The desired range of transformed data. These are the minimum and maximum values for each variable in the sample. The transformation applies these bounds to the sample, aligning the sample's min and max values with the specified bounds.\n\nOutputs:\n- discrepancy : float\n    The centered discrepancy of the sample. This is a single float value representing the measure of uniformity in the sample points.\n\nReferences:\n- Fang et al. \"Design and modeling for computer experiments\", Computer Science and Data Analysis Series Science and Data Analysis Series, 2006.", "method_code_mask": "import numpy as np\n\n\ndef discrepancy(sample, bounds=None): [MASK]\n"}
{"method_name": "van_der_corput", "full_method_name": "van_der_corput", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/sequences.py", "method_code": "import numpy as np\ndef van_der_corput(n_sample, base=2, start_index=0):\n    \"\"\"Van der Corput sequence.\n\n    Pseudo-random number generator based on a b-adic expansion.\n\n    Parameters\n    ----------\n    n_sample : int\n        Number of element of the sequence.\n    base : int\n        Base of the sequence.\n    start_index : int\n        Index to start the sequence from.\n\n    Returns\n    -------\n    sequence : list (n_samples,)\n        Sequence of Van der Corput.\n    \"\"\"\n    sequence = []\n    for i in range(start_index, start_index + n_sample):\n        n_th_number, denom = 0.0, 1.0\n        quotient = i\n        while quotient > 0:\n            quotient, remainder = divmod(quotient, base)\n            denom *= base\n            n_th_number += remainder / denom\n        sequence.append(n_th_number)\n    return sequence", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom statsmodels.tools import sequences\ndef test_van_der_corput():\n    sample = van_der_corput(10)\n    out = [0.0, 0.5, 0.25, 0.75, 0.125, 0.625, 0.375, 0.875, 0.0625, 0.5625]\n    npt.assert_almost_equal(sample, out)\n    sample = van_der_corput(5, start_index=3)\n    out = [0.75, 0.125, 0.625, 0.375, 0.875]\n    npt.assert_almost_equal(sample, out)\n\ntest_van_der_corput()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_sequences.py"}], "instruction": "Functionality: The van_der_corput function generates a sequence of pseudo-random numbers using the Van der Corput sequence algorithm, which is based on a b-adic expansion. This sequence is often used in numerical integration and to create low-discrepancy sequences.\n\nInputs: \n1. n_sample : int\n   - The number of elements of the sequence to generate.\n2. base : int (default=2)\n   - The base of the sequence. Typically, this is set to a prime number to ensure a good distribution.\n3. start_index : int (default=0)\n   - The index from which to start generating the sequence. This allows for the generation of a continuous sequence over multiple calls.\n\nOutputs:\n1. sequence : list (n_samples,)\n   - A list containing the generated Van der Corput sequence. Each element in the list is a float representing a number in the Van der Corput sequence.", "method_code_mask": "import numpy as np\n\n\ndef van_der_corput(n_sample, base=2, start_index=0): [MASK]\n"}
{"method_name": "primes_from_2_to", "full_method_name": "primes_from_2_to", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/sequences.py", "method_code": "import numpy as np\ndef primes_from_2_to(n):\n    \"\"\"Prime numbers from 2 to *n*.\n\n    Parameters\n    ----------\n    n : int\n        Sup bound with ``n >= 6``.\n\n    Returns\n    -------\n    primes : list(int)\n        Primes in ``2 <= p < n``.\n\n    References\n    ----------\n    [1] `StackOverflow <https://stackoverflow.com/questions/2068372>`_.\n    \"\"\"\n    sieve = np.ones(n // 3 + (n % 6 == 2), dtype=bool)\n    for i in range(1, int(n ** 0.5) // 3 + 1):\n        if sieve[i]:\n            k = 3 * i + 1 | 1\n            sieve[k * k // 3::2 * k] = False\n            sieve[k * (k - 2 * (i & 1) + 4) // 3::2 * k] = False\n    return np.r_[2, 3, 3 * np.nonzero(sieve)[0][1:] + 1 | 1]", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom statsmodels.tools import sequences\ndef test_primes():\n    primes = primes_from_2_to(50)\n    out = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n    npt.assert_allclose(primes, out)\n\ntest_primes()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tools/tests/test_sequences.py"}], "instruction": "Functionality: \nThe function 'primes_from_2_to' is designed to generate a list of prime numbers within a specified range, from 2 up to, but not including, a given upper limit (n).\n\nInputs: \nn : int\n   The upper boundary for the range to generate prime numbers. It is assumed that n is an integer that is greater than or equal to 6.\n\nOutputs: \nprimes : list(int)\n   A list containing all the prime numbers within the range [2, n). The prime numbers are returned as integers in a list format.", "method_code_mask": "import numpy as np\n\n\ndef primes_from_2_to(n): [MASK]\n"}
{"method_name": "_next_regular", "full_method_name": "_next_regular", "method_path": "../srcdata/Computation/statsmodels/statsmodels/compat/scipy.py", "method_code": "from packaging.version import Version\nfrom packaging.version import parse\nimport numpy as np\nimport scipy\nfrom scipy.stats import multivariate_t\ndef _next_regular(target):\n    \"\"\"\n    Find the next regular number greater than or equal to target.\n    Regular numbers are composites of the prime factors 2, 3, and 5.\n    Also known as 5-smooth numbers or Hamming numbers, these are the optimal\n    size for inputs to FFTPACK.\n\n    Target must be a positive integer.\n    \"\"\"\n    if target <= 6:\n        return target\n    if not target & target - 1:\n        return target\n    match = float('inf')\n    p5 = 1\n    while p5 < target:\n        p35 = p5\n        while p35 < target:\n            quotient = -(-target // p35)\n            p2 = 2 ** (quotient - 1).bit_length()\n            N = p2 * p35\n            if N == target:\n                return N\n            elif N < match:\n                match = N\n            p35 *= 3\n            if p35 == target:\n                return p35\n        if p35 < match:\n            match = p35\n        p5 *= 5\n        if p5 == target:\n            return p5\n    if p5 < match:\n        match = p5\n    return match", "test_code_list": [{"test_code": "from numpy.testing import assert_equal\nfrom statsmodels.compat.scipy import _next_regular\ndef test_next_regular():\n    hams = {(1): 1, (2): 2, (3): 3, (4): 4, (5): 5, (6): 6, (7): 8, (8): 8,\n        (14): 15, (15): 15, (16): 16, (17): 18, (1021): 1024, (1536): 1536,\n        (51200000): 51200000, (510183360): 510183360, (510183360 + 1): \n        512000000, (511000000): 512000000, (854296875): 854296875, (\n        854296875 + 1): 859963392, (196608000000): 196608000000, (\n        196608000000 + 1): 196830000000, (8789062500000): 8789062500000, (\n        8789062500000 + 1): 8796093022208, (206391214080000): \n        206391214080000, (206391214080000 + 1): 206624260800000, (\n        470184984576000): 470184984576000, (470184984576000 + 1): \n        470715894135000, (7222041363087360): 7222041363087360, (\n        7222041363087360 + 1): 7230196133913600, (11920928955078125): \n        11920928955078125, (11920928955078125 - 1): 11920928955078125, (\n        16677181699666569): 16677181699666569, (16677181699666569 - 1): \n        16677181699666569, (18014398509481984): 18014398509481984, (\n        18014398509481984 - 1): 18014398509481984, (19200000000000000): \n        19200000000000000, (19200000000000000 + 1): 19221679687500000, (\n        288230376151711744): 288230376151711744, (288230376151711744 + 1): \n        288325195312500000, (288325195312500000 - 1): 288325195312500000, (\n        288325195312500000): 288325195312500000, (288325195312500000 + 1): \n        288555831593533440, (3 ** 83 - 1): 3 ** 83, (3 ** 83): 3 ** 83, (2 **\n        135 - 1): 2 ** 135, (2 ** 135): 2 ** 135, (5 ** 57 - 1): 5 ** 57, (\n        5 ** 57): 5 ** 57, (2 ** 96 * 3 ** 1 * 5 ** 13 - 1): 2 ** 96 * 3 **\n        1 * 5 ** 13, (2 ** 96 * 3 ** 1 * 5 ** 13): 2 ** 96 * 3 ** 1 * 5 ** \n        13, (2 ** 96 * 3 ** 1 * 5 ** 13 + 1): 2 ** 43 * 3 ** 11 * 5 ** 29,\n        (2 ** 36 * 3 ** 69 * 5 ** 7 - 1): 2 ** 36 * 3 ** 69 * 5 ** 7, (2 **\n        36 * 3 ** 69 * 5 ** 7): 2 ** 36 * 3 ** 69 * 5 ** 7, (2 ** 36 * 3 **\n        69 * 5 ** 7 + 1): 2 ** 90 * 3 ** 32 * 5 ** 9, (2 ** 37 * 3 ** 44 * \n        5 ** 42 - 1): 2 ** 37 * 3 ** 44 * 5 ** 42, (2 ** 37 * 3 ** 44 * 5 **\n        42): 2 ** 37 * 3 ** 44 * 5 ** 42, (2 ** 37 * 3 ** 44 * 5 ** 42 + 1):\n        2 ** 20 * 3 ** 106 * 5 ** 7}\n    for x, y in hams.items():\n        assert_equal(_next_regular(x), y)\n\ntest_next_regular()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/compat/tests/test_scipy_compat.py"}], "instruction": "Functionality: The function _next_regular is designed to find the next regular number that is greater than or equal to a given target. Regular numbers, also known as 5-smooth numbers or Hamming numbers, are composed of prime factors 2, 3, and 5 only. This function is particularly useful in determining optimal input sizes for FFTPACK, a package for computing Fast Fourier Transforms.\n\nInputs: The function takes a single positive integer argument, 'target', which represents the number from which the next regular number is to be found.\n\nOutputs: The function returns a positive integer, which is the next regular number greater than or equal to the 'target' input. If the input itself is a regular number, it will be returned.", "method_code_mask": "from packaging.version import Version\nfrom packaging.version import parse\nimport numpy as np\nimport scipy\nfrom scipy.stats import multivariate_t\n\n\ndef _next_regular(target): [MASK]\n"}
{"method_name": "make_hypotheses_matrices", "full_method_name": "make_hypotheses_matrices", "method_path": "../srcdata/Computation/statsmodels/statsmodels/formula/formulatools.py", "method_code": "import statsmodels.tools.data as data_util\nfrom patsy import dmatrices\nfrom patsy import NAAction\nimport numpy as np\nfrom patsy.desc import INTERCEPT\nfrom numpy import array\nfrom patsy.constraint import linear_constraint\ndef make_hypotheses_matrices(model_results, test_formula):\n    \"\"\"\n    \"\"\"\n    from patsy.constraint import linear_constraint\n    exog_names = model_results.model.exog_names\n    LC = linear_constraint(test_formula, exog_names)\n    return LC", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom io import StringIO\nimport warnings\nimport numpy as np\nimport numpy.testing as npt\nimport pandas as pd\nimport patsy\nimport pytest\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.datasets.longley import load_pandas\nfrom statsmodels.formula.api import ols\nfrom statsmodels.formula.formulatools import make_hypotheses_matrices\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tools.testing import assert_equal\nfrom pandas import read_csv\nfrom numpy import log\ndef test_tests():\n    formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n    dta = load_pandas().data\n    results = ols(formula, dta).fit()\n    test_formula = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n    LC = make_hypotheses_matrices(results, test_formula)\n    R = LC.coefs\n    Q = LC.constants\n    npt.assert_almost_equal(R, [[0, 1, -1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, \n        0], [0, 0, 0, 0, 0, 0, 1.0 / 1829]], 8)\n    npt.assert_array_equal(Q, [[0], [2], [1]])\n\ntest_tests()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/formula/tests/test_formula.py"}], "instruction": "Functionality: The make_hypotheses_matrices function generates matrices that represent linear constraints based on a given statistical model's results and a hypothesis test formula. It utilizes the linear_constraint function from the patsy constraint module to create these matrices, which can be used for hypothesis testing in statistical models, particularly for testing the joint significance of multiple regression coefficients.\n\nInputs: \n- model_results: An instance of a fitted model object (e.g., from statsmodels) that contains the exogenous variable names (exog_names) and other necessary information about the fitted model.\n- test_formula: A string representing the hypothesis test formula. The formula should follow the patsy formula syntax, specifying the constraints on the model parameters.\n\nOutputs:\n- LC: A linear constraint object that encapsulates the matrices representing the linear constraints defined by the test_formula. These matrices can be used for further statistical analysis, such as calculating the test statistic and p-value for the hypothesis test.", "method_code_mask": "import statsmodels.tools.data as data_util\nfrom patsy import dmatrices\nfrom patsy import NAAction\nimport numpy as np\nfrom patsy.desc import INTERCEPT\nfrom numpy import array\nfrom patsy.constraint import linear_constraint\n\n\ndef make_hypotheses_matrices(model_results, test_formula): [MASK]\n"}
{"method_name": "gen_endog", "full_method_name": "gen_endog", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm_weights.py", "method_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.api as sm\nfrom statsmodels.datasets.cpunish import load\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.tools import add_constant\nfrom copy import copy\nimport statsmodels.formula.api as smf\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.star98 import load\ndef gen_endog(lin_pred, family_class, link, binom_version=0):\n    np.random.seed(872)\n    fam = sm.families\n    mu = link().inverse(lin_pred)\n    if family_class == fam.Binomial:\n        if binom_version == 0:\n            endog = 1 * (np.random.uniform(size=len(lin_pred)) < mu)\n        else:\n            endog = np.empty((len(lin_pred), 2))\n            n = 10\n            endog[:, 0] = (np.random.uniform(size=(len(lin_pred), n)) < mu[\n                :, None]).sum(1)\n            endog[:, 1] = n - endog[:, 0]\n    elif family_class == fam.Poisson:\n        endog = np.random.poisson(mu)\n    elif family_class == fam.Gamma:\n        endog = np.random.gamma(2, mu)\n    elif family_class == fam.Gaussian:\n        endog = mu + np.random.normal(size=len(lin_pred))\n    elif family_class == fam.NegativeBinomial:\n        from scipy.stats.distributions import nbinom\n        endog = nbinom.rvs(mu, 0.5)\n    elif family_class == fam.InverseGaussian:\n        from scipy.stats.distributions import invgauss\n        endog = invgauss.rvs(mu)\n    elif family_class == fam.Tweedie:\n        rate = 1\n        shape = 1.0\n        scale = mu / (rate * shape)\n        endog = np.random.poisson(rate, size=scale.shape[0]) * np.random.gamma(\n            shape * scale)\n    else:\n        raise ValueError\n    return endog", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.api as sm\nfrom statsmodels.datasets.cpunish import load\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.tools import add_constant\nfrom copy import copy\nimport statsmodels.formula.api as smf\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.star98 import load\ndef test_wtd_gradient_irls():\n    np.random.seed(87342)\n    fam = sm.families\n    lnk = sm.families.links\n    families = [(fam.Binomial, [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log,\n        lnk.Cauchy]), (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]), (\n        fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]), (fam.\n        Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]), (fam.\n        InverseGaussian, [lnk.Log, lnk.Identity, lnk.InversePower, lnk.\n        InverseSquared]), (fam.NegativeBinomial, [lnk.Log, lnk.InversePower,\n        lnk.InverseSquared, lnk.Identity])]\n    n = 100\n    p = 3\n    exog = np.random.normal(size=(n, p))\n    exog[:, 0] = 1\n    skip_one = False\n    for family_class, family_links in families:\n        for link in family_links:\n            for binom_version in (0, 1):\n                method = 'bfgs'\n                if family_class != fam.Binomial and binom_version == 1:\n                    continue\n                elif family_class == fam.Binomial and link == lnk.CLogLog:\n                    continue\n                elif family_class == fam.Binomial and link == lnk.Log:\n                    continue\n                elif (family_class, link) == (fam.Poisson, lnk.Identity):\n                    lin_pred = 20 + exog.sum(1)\n                elif (family_class, link) == (fam.Binomial, lnk.Log):\n                    lin_pred = -1 + exog.sum(1) / 8\n                elif (family_class, link) == (fam.Poisson, lnk.Sqrt):\n                    lin_pred = -2 + exog.sum(1)\n                elif (family_class, link) == (fam.Gamma, lnk.Log):\n                    continue\n                elif (family_class, link) == (fam.Gamma, lnk.Identity):\n                    continue\n                elif (family_class, link) == (fam.Gamma, lnk.InversePower):\n                    continue\n                elif (family_class, link) == (fam.Gaussian, lnk.Log):\n                    continue\n                elif (family_class, link) == (fam.Gaussian, lnk.InversePower):\n                    continue\n                elif (family_class, link) == (fam.InverseGaussian, lnk.Log):\n                    lin_pred = -1 + exog.sum(1)\n                    continue\n                elif (family_class, link) == (fam.InverseGaussian, lnk.Identity\n                    ):\n                    lin_pred = 20 + 5 * exog.sum(1)\n                    lin_pred = np.clip(lin_pred, 0.0001, np.inf)\n                    continue\n                elif (family_class, link) == (fam.InverseGaussian, lnk.\n                    InverseSquared):\n                    lin_pred = 0.5 + exog.sum(1) / 5\n                    continue\n                elif (family_class, link) == (fam.InverseGaussian, lnk.\n                    InversePower):\n                    lin_pred = 1 + exog.sum(1) / 5\n                    method = 'newton'\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    Identity):\n                    lin_pred = 20 + 5 * exog.sum(1)\n                    lin_pred = np.clip(lin_pred, 0.001, np.inf)\n                    method = 'newton'\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    InverseSquared):\n                    lin_pred = 0.1 + np.random.uniform(size=exog.shape[0])\n                    continue\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    InversePower):\n                    lin_pred = 1 + exog.sum(1) / 5\n                    continue\n                elif (family_class, link) == (fam.Gaussian, lnk.InversePower):\n                    skip_one = True\n                else:\n                    lin_pred = np.random.uniform(size=exog.shape[0])\n                endog = gen_endog(lin_pred, family_class, link, binom_version)\n                if binom_version == 0:\n                    wts = np.ones_like(endog)\n                    tmp = np.random.randint(2, 5, size=(endog > endog.mean(\n                        )).sum())\n                    wts[endog > endog.mean()] = tmp\n                else:\n                    wts = np.ones(shape=endog.shape[0])\n                    y = endog[:, 0] / endog.sum(axis=1)\n                    tmp = np.random.gamma(2, size=(y > y.mean()).sum())\n                    wts[y > y.mean()] = tmp\n                with warnings.catch_warnings():\n                    warnings.simplefilter('ignore')\n                    mod_irls = sm.GLM(endog, exog, var_weights=wts, family=\n                        family_class(link=link()))\n                rslt_irls = mod_irls.fit(method='IRLS', atol=1e-10,\n                    tol_criterion='params')\n                for max_start_irls, start_params in ((0, rslt_irls.params),\n                    (3, None)):\n                    if max_start_irls > 0 and skip_one:\n                        continue\n                    with warnings.catch_warnings():\n                        warnings.simplefilter('ignore')\n                        mod_gradient = sm.GLM(endog, exog, var_weights=wts,\n                            family=family_class(link=link()))\n                    rslt_gradient = mod_gradient.fit(max_start_irls=\n                        max_start_irls, start_params=start_params, method=\n                        method)\n                    assert_allclose(rslt_gradient.params, rslt_irls.params,\n                        rtol=1e-06, atol=5e-05)\n                    assert_allclose(rslt_gradient.llf, rslt_irls.llf, rtol=\n                        1e-06, atol=1e-06)\n                    assert_allclose(rslt_gradient.scale, rslt_irls.scale,\n                        rtol=1e-06, atol=1e-06)\n                    gradient_bse = rslt_gradient.bse\n                    ehess = mod_gradient.hessian(rslt_gradient.params,\n                        observed=False)\n                    gradient_bse = np.sqrt(-np.diag(np.linalg.inv(ehess)))\n                    assert_allclose(gradient_bse, rslt_irls.bse, rtol=1e-06,\n                        atol=5e-05)\n\ntest_wtd_gradient_irls()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm_weights.py"}], "instruction": "Functionality: The gen_endog function generates synthetic endogenous variables (responses) based on a linear predictor and a specified distribution family. It is designed to simulate responses for generalized linear models (GLMs) by drawing random samples from the specified family.\n\nInputs:\n- lin_pred (array-like): A linear predictor, typically the result of a linear combination of features and coefficients.\n- family_class (class): A statsmodels family class (e.g., Binomial, Poisson, Gaussian) that determines the distribution of the response variable.\n- link (class): A statsmodels link function that defines the relationship between the linear predictor and the mean of the response variable.\n- binom_version (int, optional): Determines the version of the binomial endogenous variable generation. Default is 0.\n\nOutputs:\n- endog (array-like): An array representing the synthetic endogenous variable (response) generated according to the specified family and link function.", "method_code_mask": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nimport statsmodels.api as sm\nfrom statsmodels.datasets.cpunish import load\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.tools import add_constant\nfrom copy import copy\nimport statsmodels.formula.api as smf\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.star98 import load\n\n\ndef gen_endog(lin_pred, family_class, link, binom_version=0): [MASK]\n"}
{"method_name": "gen_endog", "full_method_name": "gen_endog", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py", "method_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef gen_endog(lin_pred, family_class, link, binom_version=0):\n    np.random.seed(872)\n    fam = sm.families\n    mu = link().inverse(lin_pred)\n    if family_class == fam.Binomial:\n        if binom_version == 0:\n            endog = 1 * (np.random.uniform(size=len(lin_pred)) < mu)\n        else:\n            endog = np.empty((len(lin_pred), 2))\n            n = 10\n            endog[:, 0] = (np.random.uniform(size=(len(lin_pred), n)) < mu[\n                :, None]).sum(1)\n            endog[:, 1] = n - endog[:, 0]\n    elif family_class == fam.Poisson:\n        endog = np.random.poisson(mu)\n    elif family_class == fam.Gamma:\n        endog = np.random.gamma(2, mu)\n    elif family_class == fam.Gaussian:\n        endog = mu + 2 * np.random.normal(size=len(lin_pred))\n    elif family_class == fam.NegativeBinomial:\n        from scipy.stats.distributions import nbinom\n        endog = nbinom.rvs(mu, 0.5)\n    elif family_class == fam.InverseGaussian:\n        from scipy.stats.distributions import invgauss\n        endog = invgauss.rvs(mu, scale=20)\n    else:\n        raise ValueError\n    return endog", "test_code_list": [{"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef test_gradient_irls_eim():\n    np.random.seed(87342)\n    fam = sm.families\n    lnk = sm.families.links\n    families = [(fam.Binomial, [lnk.Logit, lnk.Probit, lnk.CLogLog, lnk.Log,\n        lnk.Cauchy]), (fam.Poisson, [lnk.Log, lnk.Identity, lnk.Sqrt]), (\n        fam.Gamma, [lnk.Log, lnk.Identity, lnk.InversePower]), (fam.\n        Gaussian, [lnk.Identity, lnk.Log, lnk.InversePower]), (fam.\n        InverseGaussian, [lnk.Log, lnk.Identity, lnk.InversePower, lnk.\n        InverseSquared]), (fam.NegativeBinomial, [lnk.Log, lnk.InversePower,\n        lnk.InverseSquared, lnk.Identity])]\n    n = 100\n    p = 3\n    exog = np.random.normal(size=(n, p))\n    exog[:, 0] = 1\n    skip_one = False\n    for family_class, family_links in families:\n        for link in family_links:\n            for binom_version in (0, 1):\n                if family_class != fam.Binomial and binom_version == 1:\n                    continue\n                if (family_class, link) == (fam.Poisson, lnk.Identity):\n                    lin_pred = 20 + exog.sum(1)\n                elif (family_class, link) == (fam.Binomial, lnk.Log):\n                    lin_pred = -1 + exog.sum(1) / 8\n                elif (family_class, link) == (fam.Poisson, lnk.Sqrt):\n                    lin_pred = 2 + exog.sum(1)\n                elif (family_class, link) == (fam.InverseGaussian, lnk.Log):\n                    lin_pred = -1 + exog.sum(1)\n                elif (family_class, link) == (fam.InverseGaussian, lnk.Identity\n                    ):\n                    lin_pred = 20 + 5 * exog.sum(1)\n                    lin_pred = np.clip(lin_pred, 0.0001, np.inf)\n                elif (family_class, link) == (fam.InverseGaussian, lnk.\n                    InverseSquared):\n                    lin_pred = 0.5 + exog.sum(1) / 5\n                    continue\n                elif (family_class, link) == (fam.InverseGaussian, lnk.\n                    InversePower):\n                    lin_pred = 1 + exog.sum(1) / 5\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    Identity):\n                    lin_pred = 20 + 5 * exog.sum(1)\n                    lin_pred = np.clip(lin_pred, 0.0001, np.inf)\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    InverseSquared):\n                    lin_pred = 0.1 + np.random.uniform(size=exog.shape[0])\n                    continue\n                elif (family_class, link) == (fam.NegativeBinomial, lnk.\n                    InversePower):\n                    lin_pred = 1 + exog.sum(1) / 5\n                elif (family_class, link) == (fam.Gaussian, lnk.InversePower):\n                    skip_one = True\n                else:\n                    lin_pred = np.random.uniform(size=exog.shape[0])\n                endog = gen_endog(lin_pred, family_class, link, binom_version)\n                with warnings.catch_warnings():\n                    warnings.simplefilter('ignore')\n                    mod_irls = sm.GLM(endog, exog, family=family_class(link\n                        =link()))\n                rslt_irls = mod_irls.fit(method='IRLS')\n                for max_start_irls, start_params in ((0, rslt_irls.params),\n                    (3, None)):\n                    if max_start_irls > 0 and skip_one:\n                        continue\n                    with warnings.catch_warnings():\n                        warnings.simplefilter('ignore')\n                        mod_gradient = sm.GLM(endog, exog, family=\n                            family_class(link=link()))\n                    rslt_gradient = mod_gradient.fit(max_start_irls=\n                        max_start_irls, start_params=start_params, method=\n                        'newton', optim_hessian='eim')\n                    assert_allclose(rslt_gradient.params, rslt_irls.params,\n                        rtol=1e-06, atol=5e-05)\n                    assert_allclose(rslt_gradient.llf, rslt_irls.llf, rtol=\n                        1e-06, atol=1e-06)\n                    assert_allclose(rslt_gradient.scale, rslt_irls.scale,\n                        rtol=1e-06, atol=1e-06)\n                    ehess = mod_gradient.hessian(rslt_gradient.params,\n                        observed=False)\n                    gradient_bse = np.sqrt(-np.diag(np.linalg.inv(ehess)))\n                    assert_allclose(gradient_bse, rslt_irls.bse, rtol=1e-06,\n                        atol=5e-05)\n\ntest_gradient_irls_eim()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py"}], "instruction": "Functionality: The gen_endog function generates endogenous response variables based on a linear predictor and a specified distribution from the statsmodels families module. This function can simulate data for various types of generalized linear models (GLMs) by creating response variables according to the specified family class and link function.\n\nInputs:\n- lin_pred: A numpy array representing the linear predictor values. These are the predicted values from the model before transformation by the link function.\n- family_class: A statsmodels family class object specifying the distribution of the response variable. Supported classes include Binomial, Poisson, Gamma, Gaussian, NegativeBinomial, and InverseGaussian.\n- link: A statsmodels link function object that defines the relationship between the linear predictor and the mean of the response variable.\n- binom_version: An integer (default=0) that specifies the version of the binomial distribution to use. If 0, the response is generated as a Bernoulli trial for each observation. If 1, the response is a count variable based on a fixed number of trials (n) for each observation.\n\nOutputs:\n- endog: A numpy array representing the generated endogenous response variable. The shape and type of the array depend on the specified family_class. For the Binomial family with binom_version=1, the output is a 2D array where the first column is the number of successes and the second column is the number of failures.", "method_code_mask": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\n\n\ndef gen_endog(lin_pred, family_class, link, binom_version=0): [MASK]\n"}
{"method_name": "gen_tweedie", "full_method_name": "gen_tweedie", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py", "method_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef gen_tweedie(p):\n    np.random.seed(3242)\n    n = 500\n    x = np.random.normal(size=(n, 4))\n    lpr = np.dot(x, np.r_[1, -1, 0, 0.5])\n    mu = np.exp(lpr)\n    lam = 10 * mu ** (2 - p) / (2 - p)\n    alp = (2 - p) / (p - 1)\n    bet = 10 * mu ** (1 - p) / (p - 1)\n    y = np.empty(n)\n    N = np.random.poisson(lam)\n    for i in range(n):\n        y[i] = np.random.gamma(alp, 1 / bet[i], N[i]).sum()\n    return y, x", "test_code_list": [{"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\n@pytest.mark.filterwarnings('ignore:GLM ridge optimization')\ndef test_tweedie_EQL():\n    p = 1.5\n    y, x = gen_tweedie(p)\n    fam = sm.families.Tweedie(var_power=p, eql=True)\n    model1 = sm.GLM(y, x, family=fam)\n    result1 = model1.fit(method='newton')\n    assert_allclose(result1.params, np.array([1.00350497, -0.99656954, \n        0.00802702, 0.50713209]), rtol=1e-05, atol=1e-05)\n    model1x = sm.GLM(y, x, family=fam)\n    result1x = model1x.fit(method='irls')\n    assert_allclose(result1.params, result1x.params)\n    assert_allclose(result1.bse, result1x.bse, rtol=0.01)\n    model2 = sm.GLM(y, x, family=fam)\n    result2 = model2.fit_regularized(L1_wt=1, alpha=0.07, maxiter=200,\n        cnvrg_tol=0.01)\n    rtol, atol = 0.01, 0.0001\n    assert_allclose(result2.params, np.array([0.976831, -0.952854, 0.0, \n        0.470171]), rtol=rtol, atol=atol)\n    ev = np.array([1.001778, -0.99388, 0.00797, 0.506183]), np.array([\n        0.98586638, -0.96953481, 0.00749983, 0.4975267]), np.array([\n        0.206429, -0.164547, 0.000235, 0.102489])\n    for j, alpha in enumerate([0.05, 0.5, 0.7]):\n        model3 = sm.GLM(y, x, family=fam)\n        result3 = model3.fit_regularized(L1_wt=0, alpha=alpha)\n        assert_allclose(result3.params, ev[j], rtol=rtol, atol=atol)\n        result4 = model3.fit_regularized(L1_wt=0, alpha=alpha * np.ones(x.\n            shape[1]))\n        assert_allclose(result4.params, result3.params, rtol=rtol, atol=atol)\n        alpha = alpha * np.ones(x.shape[1])\n        alpha[0] = 0\n        result5 = model3.fit_regularized(L1_wt=0, alpha=alpha)\n        assert not np.allclose(result5.params, result4.params)\n\ntest_tweedie_EQL()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py"}, {"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\ndef test_tweedie_elastic_net():\n    p = 1.5\n    y, x = gen_tweedie(p)\n    fam = sm.families.Tweedie(var_power=p, eql=True)\n    model1 = sm.GLM(y, x, family=fam)\n    nnz = []\n    for alpha in np.linspace(0, 10, 20):\n        result1 = model1.fit_regularized(L1_wt=0.5, alpha=alpha)\n        nnz.append((np.abs(result1.params) > 0).sum())\n    nnz = np.unique(nnz)\n    assert len(nnz) == 5\n\ntest_tweedie_elastic_net()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_glm.py"}], "instruction": "Functionality: The gen_tweedie function is designed to generate synthetic data for a Tweedie distribution, which is a compound Poisson-gamma distribution. It is often used in insurance claim modeling or other applications where the data exhibit overdispersion and non-negative values.\n\nInputs: \n- p (float): The power parameter of the Tweedie distribution. It controls the shape of the distribution, where p=1 is Poisson, p=2 is gamma, and for 1<p<2, it is a compound Poisson-gamma distribution.\n\nOutputs: \n- y (numpy array): A numpy array containing the generated response variable (dependent variable) following the Tweedie distribution with the specified power parameter.\n- x (numpy array): A numpy array containing the independent variables used in the generation of the response variable. It is a matrix with n rows and 4 columns, where n is the number of observations.\n\nThe function performs the following steps:\n1. Sets a random seed for reproducibility.\n2. Generates a random sample of n observations from a standard normal distribution for the independent variables.\n3. Computes the linear predictor based on the dot product of the independent variables and a set of coefficients.\n4. Calculates the mean (mu) using the exponential of the linear predictor.\n5. Computes the lambda parameter of the Poisson distribution and the alpha and beta parameters of the gamma distribution based on the specified power parameter.\n6. Generates the number of claims (N) from a Poisson distribution.\n7. For each observation, generates the response variable (y) by summing up gamma-distributed random variables, where the number of gamma variables is determined by the number of claims.", "method_code_mask": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.compat.scipy import SP_LT_17\nfrom statsmodels.datasets import cpunish\nfrom statsmodels.datasets import longley\nfrom statsmodels.discrete import discrete_model as discrete\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\nfrom statsmodels.tools.numdiff import approx_hess_cs\nfrom statsmodels.tools.sm_exceptions import DomainWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import add_constant\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport copy\nfrom statsmodels.datasets.longley import load\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.datasets.star98 import load\nfrom statsmodels.datasets.scotland import load\nfrom statsmodels.datasets.committee import load\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import add_lowess\nfrom scipy.stats.distributions import nbinom\nfrom scipy.stats.distributions import invgauss\nfrom statsmodels.datasets.fair import load_pandas\nimport patsy\n\n\ndef gen_tweedie(p): [MASK]\n"}
{"method_name": "gen_simple_logit", "full_method_name": "gen_simple_logit", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py", "method_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef gen_simple_logit(nc, cs, s):\n    np.random.seed(3799)\n    exog_vc = np.kron(np.eye(nc), np.ones((cs, 1)))\n    exog_fe = np.random.normal(size=(nc * cs, 2))\n    vc = s * np.random.normal(size=nc)\n    lp = np.dot(exog_fe, np.r_[1, -1]) + np.dot(exog_vc, vc)\n    pr = 1 / (1 + np.exp(-lp))\n    y = 1 * (np.random.uniform(size=nc * cs) < pr)\n    ident = np.zeros(nc, dtype=int)\n    return y, exog_fe, exog_vc, ident", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_simple_logit_map():\n    y, exog_fe, exog_vc, ident = gen_simple_logit(10, 10, 2)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt = glmm.fit_map()\n    assert_allclose(glmm.logposterior_grad(rslt.params), np.zeros_like(rslt\n        .params), atol=0.001)\n    for linear in (False, True):\n        for exog in (None, exog_fe):\n            pr1 = rslt.predict(linear=linear, exog=exog)\n            pr2 = glmm.predict(rslt.params, linear=linear, exog=exog)\n            assert_allclose(pr1, pr2)\n            if not linear:\n                assert_equal(pr1.min() >= 0, True)\n                assert_equal(pr1.max() <= 1, True)\n\ntest_simple_logit_map()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_simple_logit_vb():\n    y, exog_fe, exog_vc, ident = gen_simple_logit(10, 10, 0)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm1 = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt1 = glmm1.fit_map()\n    glmm2 = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt2 = glmm2.fit_vb(rslt1.params)\n    rslt1.summary()\n    rslt2.summary()\n    assert_allclose(rslt1.params[0:5], np.r_[0.75330405, -0.71643228, -\n        2.49091288, -0.00959806, 0.00450254], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt2.params[0:5], np.r_[0.79338836, -0.7599833, -\n        0.64149356, -0.24772884, 0.10775366], rtol=0.0001, atol=0.0001)\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        if rslt is rslt1:\n            assert_equal(cp.shape, np.r_[p, p])\n            np.linalg.cholesky(cp)\n        else:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n\ntest_simple_logit_vb()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_scale_vb():\n    y, exog_fe, exog_vc, ident = gen_simple_logit(10, 10, 0)\n    exog_fe -= exog_fe.mean(0)\n    exog_fe /= exog_fe.std(0)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    rslts = []\n    for scale_fe in (False, True):\n        glmm = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n            fe_p=0.5)\n        rslt = glmm.fit_vb(scale_fe=scale_fe)\n        rslts.append(rslt)\n    assert_allclose(rslts[0].params, rslts[1].params, rtol=0.0001)\n\ntest_scale_vb()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_scale_map():\n    y, exog_fe, exog_vc, ident = gen_simple_logit(10, 10, 0)\n    exog_fe -= exog_fe.mean(0)\n    exog_fe /= exog_fe.std(0)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    rslts = []\n    for scale_fe in (False, True):\n        glmm = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n            fe_p=0.5)\n        rslt = glmm.fit_map(scale_fe=scale_fe)\n        rslts.append(rslt)\n    assert_allclose(rslts[0].params, rslts[1].params, rtol=0.0001)\n\ntest_scale_map()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}], "instruction": "Functionality: The gen_simple_logit function generates data for a logistic regression model with both fixed and random effects. It creates a response variable (y), fixed effects design matrix (exog_fe), random effects design matrix (exog_vc), and an identifier array for the random effects groups (ident). This function is useful for simulating data that can be used to test mixed-effects logistic regression models.\n\nInputs:\n- nc: An integer representing the number of clusters or groups in the data.\n- cs: An integer representing the number of samples or observations per cluster.\n- s: A float representing the standard deviation of the random effects.\n\nOutputs:\n- y: A 1D array of shape (nc * cs,) containing the binary response variable generated from the logistic model.\n- exog_fe: A 2D array of shape (nc * cs, 2) containing the fixed effects design matrix with normally distributed values.\n- exog_vc: A 2D array of shape (nc * cs, nc) containing the random effects design matrix created by repeating the identity matrix for each cluster.\n- ident: A 1D array of shape (nc,) containing the identifier for each cluster, with zeros representing each cluster index.", "method_code_mask": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\n\n\ndef gen_simple_logit(nc, cs, s): [MASK]\n"}
{"method_name": "gen_simple_poisson", "full_method_name": "gen_simple_poisson", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py", "method_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef gen_simple_poisson(nc, cs, s):\n    np.random.seed(3799)\n    exog_vc = np.kron(np.eye(nc), np.ones((cs, 1)))\n    exog_fe = np.random.normal(size=(nc * cs, 2))\n    vc = s * np.random.normal(size=nc)\n    lp = np.dot(exog_fe, np.r_[0.1, -0.1]) + np.dot(exog_vc, vc)\n    r = np.exp(lp)\n    y = np.random.poisson(r)\n    ident = np.zeros(nc, dtype=int)\n    return y, exog_fe, exog_vc, ident", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_simple_poisson_map():\n    y, exog_fe, exog_vc, ident = gen_simple_poisson(10, 10, 0.2)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm1 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt1 = glmm1.fit_map()\n    assert_allclose(glmm1.logposterior_grad(rslt1.params), np.zeros_like(\n        rslt1.params), atol=0.001)\n    glmm2 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt2 = glmm2.fit_map()\n    assert_allclose(rslt1.params, rslt2.params, atol=0.0001)\n    for linear in (False, True):\n        for exog in (None, exog_fe):\n            pr1 = rslt1.predict(linear=linear, exog=exog)\n            pr2 = rslt2.predict(linear=linear, exog=exog)\n            pr3 = glmm1.predict(rslt1.params, linear=linear, exog=exog)\n            pr4 = glmm2.predict(rslt2.params, linear=linear, exog=exog)\n            assert_allclose(pr1, pr2, rtol=1e-05)\n            assert_allclose(pr2, pr3, rtol=1e-05)\n            assert_allclose(pr3, pr4, rtol=1e-05)\n            if not linear:\n                assert_equal(pr1.min() >= 0, True)\n                assert_equal(pr2.min() >= 0, True)\n                assert_equal(pr3.min() >= 0, True)\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        assert_equal(cp.shape, np.r_[p, p])\n        np.linalg.cholesky(cp)\n\ntest_simple_poisson_map()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_simple_poisson_vb():\n    y, exog_fe, exog_vc, ident = gen_simple_poisson(10, 10, 1)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm1 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt1 = glmm1.fit_map()\n    glmm2 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt2 = glmm2.fit_vb(rslt1.params)\n    rslt1.summary()\n    rslt2.summary()\n    assert_allclose(rslt1.params[0:5], np.r_[-0.07233493, -0.06706505, -\n        0.47159649, 1.12575122, -1.02442201], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt1.cov_params().flat[0:5], np.r_[0.00790914, \n        0.00080666, -0.00050719, 0.00022648, 0.00046235], rtol=0.0001, atol\n        =0.0001)\n    assert_allclose(rslt2.params[0:5], np.r_[-0.07088814, -0.06373107, -\n        0.22770786, 1.12923746, -1.26161339], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt2.cov_params()[0:5], np.r_[0.00747782, 0.0092554, \n        0.04508904, 0.02934488, 0.20312746], rtol=0.0001, atol=0.0001)\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        if rslt is rslt1:\n            assert_equal(cp.shape, np.r_[p, p])\n            np.linalg.cholesky(cp)\n        else:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n\ntest_simple_poisson_vb()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}], "instruction": "Functionality: The gen_simple_poisson function is designed to generate synthetic data for a Poisson regression model. This involves creating response variables, fixed-effect covariates, and random-effect covariance matrices. The function simulates Poisson-distributed response variables based on a linear predictor that includes both fixed and random effects.\n\nInputs: \n- nc: An integer representing the number of clusters. Each cluster will have its own random effect.\n- cs: An integer representing the number of subjects per cluster. This determines how many observations are generated for each cluster.\n- s: A float representing the scale of the random effects. It affects the magnitude of the random variations associated with each cluster.\n\nOutputs:\n- y: A 1D array representing the synthetic response variable generated from a Poisson distribution.\n- exog_fe: A 2D array of fixed-effect covariates. Each row corresponds to an observation, and each column corresponds to a covariate.\n- exog_vc: A 2D array representing the design matrix for the random effects. It is structured to indicate which cluster each observation belongs to.\n- ident: A 1D array of integers indicating the cluster membership of each observation. It is used to connect the observations to their respective random effects.", "method_code_mask": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\n\n\ndef gen_simple_poisson(nc, cs, s): [MASK]\n"}
{"method_name": "gen_crossed_logit", "full_method_name": "gen_crossed_logit", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py", "method_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef gen_crossed_logit(nc, cs, s1, s2):\n    np.random.seed(3799)\n    a = np.kron(np.eye(nc), np.ones((cs, 1)))\n    b = np.kron(np.ones((cs, 1)), np.eye(nc))\n    exog_vc = np.concatenate((a, b), axis=1)\n    exog_fe = np.random.normal(size=(nc * cs, 1))\n    vc = s1 * np.random.normal(size=2 * nc)\n    vc[nc:] *= s2 / s1\n    lp = np.dot(exog_fe, np.r_[-0.5]) + np.dot(exog_vc, vc)\n    pr = 1 / (1 + np.exp(-lp))\n    y = 1 * (np.random.uniform(size=nc * cs) < pr)\n    ident = np.zeros(2 * nc, dtype=int)\n    ident[nc:] = 1\n    return y, exog_fe, exog_vc, ident", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_crossed_logit_map():\n    y, exog_fe, exog_vc, ident = gen_crossed_logit(10, 10, 1, 2)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt = glmm.fit_map()\n    assert_allclose(glmm.logposterior_grad(rslt.params), np.zeros_like(rslt\n        .params), atol=0.0001)\n    cp = rslt.cov_params()\n    p = len(rslt.params)\n    assert_equal(cp.shape, np.r_[p, p])\n    np.linalg.cholesky(cp)\n\ntest_crossed_logit_map()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_crossed_logit_vb():\n    y, exog_fe, exog_vc, ident = gen_crossed_logit(10, 10, 1, 2)\n    glmm1 = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt1 = glmm1.fit_map()\n    glmm2 = BinomialBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt2 = glmm2.fit_vb(mean=rslt1.params)\n    rslt1.summary()\n    rslt2.summary()\n    assert_allclose(rslt1.params[0:5], np.r_[-0.543073978, -2.46197518, -\n        2.36582801, -0.00964030461, 0.00232701078], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt1.cov_params().flat[0:5], np.r_[0.0412927123, -\n        0.000204448923, 4.64829219e-05, 0.000120377543, -0.000145003234],\n        rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt2.params[0:5], np.r_[-0.70834417, -0.3571011, \n        0.19126823, -0.36074489, 0.058976], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt2.cov_params()[0:5], np.r_[0.05212492, 0.04729656, \n        0.03916944, 0.25921842, 0.25782576], rtol=0.0001, atol=0.0001)\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        if rslt is rslt1:\n            assert_equal(cp.shape, np.r_[p, p])\n            np.linalg.cholesky(cp)\n        else:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n\ntest_crossed_logit_vb()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}], "instruction": "Functionality: Generate data for a crossed random effects logistic regression model.\nInputs:\n- nc: An integer specifying the number of categories for each crossed random effect.\n- cs: An integer specifying the number of observations per cell (i.e., per combination of categories).\n- s1: A float representing the standard deviation of the first random effect.\n- s2: A float representing the standard deviation of the second random effect.\n\nOutputs:\n- y: A 1D numpy array of shape (nc * cs,) containing the binary response variable.\n- exog_fe: A 2D numpy array of shape (nc * cs, 1) containing the fixed effects covariates.\n- exog_vc: A 2D numpy array of shape (nc * cs, 2 * nc) containing the random effects covariates.\n- ident: A 1D numpy array of shape (2 * nc,) containing identifiers for the two random effects.", "method_code_mask": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\n\n\ndef gen_crossed_logit(nc, cs, s1, s2): [MASK]\n"}
{"method_name": "gen_crossed_poisson", "full_method_name": "gen_crossed_poisson", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py", "method_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef gen_crossed_poisson(nc, cs, s1, s2):\n    np.random.seed(3799)\n    a = np.kron(np.eye(nc), np.ones((cs, 1)))\n    b = np.kron(np.ones((cs, 1)), np.eye(nc))\n    exog_vc = np.concatenate((a, b), axis=1)\n    exog_fe = np.random.normal(size=(nc * cs, 1))\n    vc = s1 * np.random.normal(size=2 * nc)\n    vc[nc:] *= s2 / s1\n    lp = np.dot(exog_fe, np.r_[-0.5]) + np.dot(exog_vc, vc)\n    r = np.exp(lp)\n    y = np.random.poisson(r)\n    ident = np.zeros(2 * nc, dtype=int)\n    ident[nc:] = 1\n    return y, exog_fe, exog_vc, ident", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_crossed_poisson_map():\n    y, exog_fe, exog_vc, ident = gen_crossed_poisson(10, 10, 1, 1)\n    exog_vc = sparse.csr_matrix(exog_vc)\n    glmm = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5)\n    rslt = glmm.fit_map()\n    assert_allclose(glmm.logposterior_grad(rslt.params), np.zeros_like(rslt\n        .params), atol=0.0001)\n    cp = rslt.cov_params()\n    p = len(rslt.params)\n    assert_equal(cp.shape, np.r_[p, p])\n    np.linalg.cholesky(cp)\n\ntest_crossed_poisson_map()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_crossed_poisson_vb():\n    y, exog_fe, exog_vc, ident = gen_crossed_poisson(10, 10, 1, 0.5)\n    glmm1 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt1 = glmm1.fit_map()\n    glmm2 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident, vcp_p=0.5,\n        fe_p=0.5)\n    rslt2 = glmm2.fit_vb(mean=rslt1.params)\n    rslt1.summary()\n    rslt2.summary()\n    assert_allclose(rslt1.params[0:5], np.r_[-0.54855281, 0.10458834, -\n        0.68777741, -0.01699925, 0.77200546], rtol=0.0001, atol=0.0001)\n    assert_allclose(rslt2.params[0:5], np.r_[-0.54691502, 0.22297158, -\n        0.52673802, -0.06218684, 0.74385237], rtol=0.0001, atol=0.0001)\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        if rslt is rslt1:\n            assert_equal(cp.shape, np.r_[p, p])\n            np.linalg.cholesky(cp)\n        else:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n\ntest_crossed_poisson_vb()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_poisson_formula():\n    y, exog_fe, exog_vc, ident = gen_crossed_poisson(10, 10, 1, 0.5)\n    for vb in (False, True):\n        glmm1 = PoissonBayesMixedGLM(y, exog_fe, exog_vc, ident)\n        if vb:\n            rslt1 = glmm1.fit_vb()\n        else:\n            rslt1 = glmm1.fit_map()\n        df = pd.DataFrame({'y': y, 'x1': exog_fe[:, 0]})\n        z1 = np.zeros(len(y))\n        for j, k in enumerate(np.flatnonzero(ident == 0)):\n            z1[exog_vc[:, k] == 1] = j\n        df['z1'] = z1\n        z2 = np.zeros(len(y))\n        for j, k in enumerate(np.flatnonzero(ident == 1)):\n            z2[exog_vc[:, k] == 1] = j\n        df['z2'] = z2\n        fml = 'y ~ 0 + x1'\n        vc_fml = {}\n        vc_fml['z1'] = '0 + C(z1)'\n        vc_fml['z2'] = '0 + C(z2)'\n        glmm2 = PoissonBayesMixedGLM.from_formula(fml, vc_fml, df)\n        if vb:\n            rslt2 = glmm2.fit_vb()\n        else:\n            rslt2 = glmm2.fit_map()\n        assert_allclose(rslt1.params, rslt2.params, rtol=1e-05)\n        for rslt in (rslt1, rslt2):\n            cp = rslt.cov_params()\n            p = len(rslt.params)\n            if vb:\n                assert_equal(cp.shape, np.r_[p,])\n                assert_equal(cp > 0, True * np.ones(p))\n            else:\n                assert_equal(cp.shape, np.r_[p, p])\n                np.linalg.cholesky(cp)\n\ntest_poisson_formula()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}], "instruction": "Functionality: The gen_crossed_poisson function is designed to simulate data from a Poisson regression model with crossed random effects. This function creates the necessary data structures and generates random variables to simulate observations from a Poisson distribution, where the log of the expected count is determined by a linear model with fixed and crossed random effects.\n\nInputs: \n- nc: an integer representing the number of levels for each of the two crossed random effects factors.\n- cs: an integer representing the number of observations per level combination.\n- s1: a float representing the standard deviation for the first random effect.\n- s2: a float representing the standard deviation for the second random effect.\n\nOutputs:\n- y: a 1D array of integers representing the simulated Poisson-distributed response variable.\n- exog_fe: a 2D array representing the fixed effects design matrix.\n- exog_vc: a 2D array representing the random effects design matrix.\n- ident: a 1D array of integers representing the identity categories for the random effects.", "method_code_mask": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\n\n\ndef gen_crossed_poisson(nc, cs, s1, s2): [MASK]\n"}
{"method_name": "gen_crossed_logit_pandas", "full_method_name": "gen_crossed_logit_pandas", "method_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py", "method_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef gen_crossed_logit_pandas(nc, cs, s1, s2):\n    np.random.seed(3799)\n    a = np.kron(np.arange(nc), np.ones(cs))\n    b = np.kron(np.ones(cs), np.arange(nc))\n    fe = np.ones(nc * cs)\n    vc = np.zeros(nc * cs)\n    for i in np.unique(a):\n        ii = np.flatnonzero(a == i)\n        vc[ii] += s1 * np.random.normal()\n    for i in np.unique(b):\n        ii = np.flatnonzero(b == i)\n        vc[ii] += s2 * np.random.normal()\n    lp = -0.5 * fe + vc\n    pr = 1 / (1 + np.exp(-lp))\n    y = 1 * (np.random.uniform(size=nc * cs) < pr)\n    ident = np.zeros(2 * nc, dtype=int)\n    ident[nc:] = 1\n    df = pd.DataFrame({'fe': fe, 'a': a, 'b': b, 'y': y})\n    return df", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_logit_map_crossed_formula():\n    data = gen_crossed_logit_pandas(10, 10, 1, 0.5)\n    fml = 'y ~ fe'\n    fml_vc = {'a': '0 + C(a)', 'b': '0 + C(b)'}\n    glmm = BinomialBayesMixedGLM.from_formula(fml, fml_vc, data, vcp_p=0.5)\n    rslt = glmm.fit_map()\n    assert_allclose(glmm.logposterior_grad(rslt.params), np.zeros_like(rslt\n        .params), atol=0.0001)\n    rslt.summary()\n    r = rslt.random_effects('a')\n    assert_allclose(r.iloc[0, :].values, np.r_[-0.02004904, 0.094014], atol\n        =0.0001)\n    cm = rslt.cov_params()\n    p = rslt.params.shape[0]\n    assert_equal(list(cm.shape), [p, p])\n    np.linalg.cholesky(cm)\n\ntest_logit_map_crossed_formula()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}, {"test_code": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\ndef test_crossed_logit_vb_formula():\n    data = gen_crossed_logit_pandas(10, 10, 1, 2)\n    fml = 'y ~ fe'\n    fml_vc = {'a': '0 + C(a)', 'b': '0 + C(b)'}\n    glmm1 = BinomialBayesMixedGLM.from_formula(fml, fml_vc, data, vcp_p=0.5)\n    rslt1 = glmm1.fit_vb()\n    glmm2 = BinomialBayesMixedGLM(glmm1.endog, glmm1.exog, glmm1.exog_vc,\n        glmm1.ident, vcp_p=0.5)\n    rslt2 = glmm2.fit_vb()\n    assert_allclose(rslt1.params, rslt2.params, atol=0.0001)\n    rslt1.summary()\n    rslt2.summary()\n    for rslt in (rslt1, rslt2):\n        cp = rslt.cov_params()\n        p = len(rslt.params)\n        if rslt is rslt1:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n        else:\n            assert_equal(cp.shape, np.r_[p,])\n            assert_equal(cp > 0, True * np.ones(p))\n\ntest_crossed_logit_vb_formula()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/genmod/tests/test_bayes_mixed_glm.py"}], "instruction": "Functionality: The gen_crossed_logit_pandas function is designed to generate a synthetic pandas DataFrame for testing logistic regression models with crossed random effects. It creates a dataset with a binary response variable (y), a fixed effect (fe), and two crossed random effects (a and b). The function uses random effects to induce correlation between observations.\n\nInputs: \n- nc: An integer indicating the number of levels for each of the crossed random effects.\n- cs: An integer indicating the number of times each level combination occurs in the dataset.\n- s1: A float representing the standard deviation of the random effect for the first crossed factor (a).\n- s2: A float representing the standard deviation of the random effect for the second crossed factor (b).\n\nOutputs:\n- df: A pandas DataFrame containing the generated data. The DataFrame includes the following columns:\n    - 'fe': A column of ones representing the fixed effect.\n    - 'a': A column representing the first crossed random effect with nc * cs elements.\n    - 'b': A column representing the second crossed random effect with nc * cs elements.\n    - 'y': A binary column (1 or 0) representing the response variable, generated based on the logistic transformation of the linear predictor (lp).", "method_code_mask": "import numpy as np\nfrom statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\nfrom statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\nimport pandas as pd\nfrom scipy import sparse\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\n\n\ndef gen_crossed_logit_pandas(nc, cs, s1, s2): [MASK]\n"}
{"method_name": "gen_mnlogit", "full_method_name": "gen_mnlogit", "method_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py", "method_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef gen_mnlogit(n):\n    np.random.seed(235)\n    g = np.kron(np.ones(5), np.arange(n // 5))\n    x1 = np.random.normal(size=n)\n    x2 = np.random.normal(size=n)\n    xm = np.concatenate((x1[:, None], x2[:, None]), axis=1)\n    pa = np.array([[0, 1, -1], [0, 2, -1]])\n    lpr = np.dot(xm, pa)\n    pr = np.exp(lpr)\n    pr /= pr.sum(1)[:, None]\n    cpr = pr.cumsum(1)\n    y = 2 * np.ones(n)\n    u = np.random.uniform(size=n)\n    y[u < cpr[:, 2]] = 2\n    y[u < cpr[:, 1]] = 1\n    y[u < cpr[:, 0]] = 0\n    df = pd.DataFrame({'y': y, 'x1': x1, 'x2': x2, 'g': g})\n    return df", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_conditional_mnlogit_grad():\n    df = gen_mnlogit(90)\n    model = ConditionalMNLogit.from_formula('y ~ 0 + x1 + x2', groups='g',\n        data=df)\n    for _ in range(5):\n        za = np.random.normal(size=4)\n        grad = model.score(za)\n        ngrad = approx_fprime(za, model.loglike)\n        assert_allclose(grad, ngrad, rtol=1e-05, atol=0.001)\n\ntest_conditional_mnlogit_grad()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_conditional_mnlogit_2d():\n    df = gen_mnlogit(90)\n    model = ConditionalMNLogit.from_formula('y ~ 0 + x1 + x2', groups='g',\n        data=df)\n    result = model.fit()\n    assert_allclose(result.params, np.asarray([[0.75592035, -1.58565494], [\n        1.82919869, -1.32594231]]), rtol=1e-05, atol=1e-05)\n    assert_allclose(result.bse, np.asarray([[0.68099698, 0.70142727], [\n        0.65190315, 0.59653771]]), rtol=1e-05, atol=1e-05)\n\ntest_conditional_mnlogit_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}, {"test_code": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\ndef test_conditional_mnlogit_3d():\n    df = gen_mnlogit(90)\n    df['x3'] = np.random.normal(size=df.shape[0])\n    model = ConditionalMNLogit.from_formula('y ~ 0 + x1 + x2 + x3', groups=\n        'g', data=df)\n    result = model.fit()\n    assert_allclose(result.params, np.asarray([[0.729629, -1.633673], [\n        1.879019, -1.327163], [-0.114124, -0.109378]]), atol=1e-05, rtol=1e-05)\n    assert_allclose(result.bse, np.asarray([[0.682965, 0.60472], [0.672947,\n        0.42401], [0.722631, 0.33663]]), atol=1e-05, rtol=1e-05)\n    result.summary()\n\ntest_conditional_mnlogit_3d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_conditional.py"}], "instruction": "Functionality: This function generates a dataset suitable for Multinomial Logit (MNLogit) modeling. It creates a random dataset with a dependent variable (y) and two independent variables (x1 and x2), along with a grouping variable (g). The dependent variable y is generated based on the independent variables x1 and x2 through a process that simulates the choice probabilities for a multinomial logit model.\n\nInputs: \n- n: an integer, the total number of observations in the dataset. Note that n should be a multiple of 5 for the grouping variable to work as intended.\n\nOutputs:\n- df: a pandas DataFrame containing the generated dataset. It includes the following columns:\n    - 'y': the dependent variable, representing the choices made by the subjects.\n    - 'x1': the first independent variable, a random normal variable.\n    - 'x2': the second independent variable, another random normal variable.\n    - 'g': a grouping variable that repeats every 5 observations.", "method_code_mask": "import numpy as np\nfrom statsmodels.discrete.conditional_models import ConditionalLogit\nfrom statsmodels.discrete.conditional_models import ConditionalPoisson\nfrom statsmodels.discrete.conditional_models import ConditionalMNLogit\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom numpy.testing import assert_allclose\nimport pandas as pd\n\n\ndef gen_mnlogit(n): [MASK]\n"}
{"method_name": "_iscount", "full_method_name": "_iscount", "method_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/discrete_margins.py", "method_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy.stats import norm\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import table_extend\ndef _iscount(X):\n    \"\"\"\n    Given an array X, returns the column indices for count variables.\n\n    Parameters\n    ----------\n    X : array_like\n        A 1d or 2d array of numbers\n\n    Examples\n    --------\n    >>> X = np.random.randint(0, 10, size=(15,5)).astype(float)\n    >>> X[:,1:3] = np.random.randn(15,2)\n    >>> ind = _iscount(X)\n    >>> ind\n    array([0, 3, 4])\n    \"\"\"\n    X = np.asarray(X)\n    remainder = np.logical_and(np.logical_and(np.all(X % 1.0 == 0, axis=0),\n        X.var(0) != 0), np.all(X >= 0, axis=0))\n    dummy = _isdummy(X)\n    remainder = np.where(remainder)[0].tolist()\n    for idx in dummy:\n        remainder.remove(idx)\n    return np.array(remainder)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_index_equal\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom scipy import stats\nfrom scipy.stats import nbinom\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_margins import _iscount\nfrom statsmodels.discrete.discrete_margins import _isdummy\nfrom statsmodels.discrete.discrete_model import CountModel\nfrom statsmodels.discrete.discrete_model import GeneralizedPoisson\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.discrete.discrete_model import MNLogit\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\nfrom statsmodels.discrete.discrete_model import NegativeBinomialP\nfrom statsmodels.discrete.discrete_model import Poisson\nfrom statsmodels.discrete.discrete_model import Probit\nimport statsmodels.formula.api as smf\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.transform_model import StandardizeTransform\nimport statsmodels.stats.diagnostic_gen as dia\ndef test_iscount():\n    X = np.random.random((50, 10))\n    X[:, 2] = np.random.randint(1, 10, size=50)\n    X[:, 6] = np.random.randint(1, 10, size=50)\n    X[:, 4] = np.random.randint(0, 2, size=50)\n    X[:, 1] = np.random.randint(-10, 10, size=50)\n    count_ind = _iscount(X)\n    assert_equal(count_ind, [2, 6])\n\ntest_iscount()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_discrete.py"}], "instruction": "Functionality: The _iscount function determines the column indices of count variables within a given 1d or 2d numerical array. A count variable here refers to a variable that is integer-valued, non-negative, and has a non-zero variance.\n\nInputs: \n- X: A 1d or 2d array (array_like) of numbers.\n\nOutputs: \n- An array containing the column indices of count variables in the input array X. Note that if X is 1d, it is treated as a 2d array with a single row.", "method_code_mask": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy.stats import norm\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import table_extend\n\n\ndef _iscount(X): [MASK]\n"}
{"method_name": "_isdummy", "full_method_name": "_isdummy", "method_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/discrete_margins.py", "method_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy.stats import norm\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import table_extend\ndef _isdummy(X):\n    \"\"\"\n    Given an array X, returns the column indices for the dummy variables.\n\n    Parameters\n    ----------\n    X : array_like\n        A 1d or 2d array of numbers\n\n    Examples\n    --------\n    >>> X = np.random.randint(0, 2, size=(15,5)).astype(float)\n    >>> X[:,1:3] = np.random.randn(15,2)\n    >>> ind = _isdummy(X)\n    >>> ind\n    array([0, 3, 4])\n    \"\"\"\n    X = np.asarray(X)\n    if X.ndim > 1:\n        ind = np.zeros(X.shape[1]).astype(bool)\n    max = np.max(X, axis=0) == 1\n    min = np.min(X, axis=0) == 0\n    remainder = np.all(X % 1.0 == 0, axis=0)\n    ind = min & max & remainder\n    if X.ndim == 1:\n        ind = np.asarray([ind])\n    return np.where(ind)[0]", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_index_equal\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom scipy import stats\nfrom scipy.stats import nbinom\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_margins import _iscount\nfrom statsmodels.discrete.discrete_margins import _isdummy\nfrom statsmodels.discrete.discrete_model import CountModel\nfrom statsmodels.discrete.discrete_model import GeneralizedPoisson\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.discrete.discrete_model import MNLogit\nfrom statsmodels.discrete.discrete_model import NegativeBinomial\nfrom statsmodels.discrete.discrete_model import NegativeBinomialP\nfrom statsmodels.discrete.discrete_model import Poisson\nfrom statsmodels.discrete.discrete_model import Probit\nimport statsmodels.formula.api as smf\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.transform_model import StandardizeTransform\nimport statsmodels.stats.diagnostic_gen as dia\ndef test_isdummy():\n    X = np.random.random((50, 10))\n    X[:, 2] = np.random.randint(1, 10, size=50)\n    X[:, 6] = np.random.randint(0, 2, size=50)\n    X[:, 4] = np.random.randint(0, 2, size=50)\n    X[:, 1] = np.random.randint(-10, 10, size=50)\n    count_ind = _isdummy(X)\n    assert_equal(count_ind, [4, 6])\n\ntest_isdummy()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/discrete/tests/test_discrete.py"}], "instruction": "Functionality: The _isdummy function determines the column indices of dummy variables in a given array. It checks if the maximum value of each column is 1, the minimum value is 0, and if all elements in the column are integers (no decimal places). If all these conditions are met for a column, it is identified as a dummy variable column.\n\nInputs: \nX : array_like\n    A 1D or 2D array of numbers. The function will analyze this array to identify the columns that represent dummy variables.\n\nOutputs: \narray : ndarray\n    An array containing the column indices of the dummy variables within the input array X. If the input is 1D, the output will be a single-element array.", "method_code_mask": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy.stats import norm\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_fprime\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.summary import summary_params\nfrom statsmodels.iolib.summary import table_extend\n\n\ndef _isdummy(X): [MASK]\n"}
{"method_name": "_calc_grad", "full_method_name": "_calc_grad", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _calc_grad(mod, params, alpha, L1_wt, score_kwds):\n    \"\"\"calculates the log-likelihood gradient for the debiasing\n\n    Parameters\n    ----------\n    mod : statsmodels model class instance\n        The model for the current partition.\n    params : array_like\n        The estimated coefficients for the current partition.\n    alpha : scalar or array_like\n        The penalty weight.  If a scalar, the same penalty weight\n        applies to all variables in the model.  If a vector, it\n        must have the same length as `params`, and contains a\n        penalty weight for each coefficient.\n    L1_wt : scalar\n        The fraction of the penalty given to the L1 penalty term.\n        Must be between 0 and 1 (inclusive).  If 0, the fit is\n        a ridge fit, if 1 it is a lasso fit.\n    score_kwds : dict-like or None\n        Keyword arguments for the score function.\n\n    Returns\n    -------\n    An array-like object of the same dimension as params\n\n    Notes\n    -----\n    In general:\n\n    gradient l_k(params)\n\n    where k corresponds to the index of the partition\n\n    For OLS:\n\n    X^T(y - X^T params)\n    \"\"\"\n    grad = -mod.score(np.asarray(params), **score_kwds)\n    grad += alpha * (1 - L1_wt)\n    return grad", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_calc_grad():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    beta = np.random.normal(size=3)\n    mod = OLS(y, X)\n    grad = _calc_grad(mod, beta, 0.01, 1, {})\n    assert_allclose(grad, np.array([19.75816, -6.62307, 7.324644]), atol=\n        1e-06, rtol=0)\n\ntest_calc_grad()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _calc_grad function calculates the gradient of the log-likelihood for the purpose of debiasing, focusing on a specific partition of a model. This function is essential for adjusting model coefficients during the regularization process, particularly in the context of elastic net regularization.\n\nInputs:\n- mod: A statsmodels model class instance. This represents the statistical model that the current partition is part of.\n- params: An array-like object that contains the estimated coefficients for the current partition.\n- alpha: Either a scalar or an array-like object. If a scalar, it represents the same penalty weight applied to all variables in the model. If an array-like object, it must have the same length as params and contains a penalty weight for each coefficient.\n- L1_wt: A scalar value between 0 and 1 (inclusive). This variable determines the fraction of the penalty attributed to the L1 penalty term. If 0, the fit is a ridge fit; if 1, it is a lasso fit.\n- score_kwds: A dict-like object or None. This contains keyword arguments for the score function.\n\nOutputs:\n- An array-like object of the same dimension as params, representing the gradient of the log-likelihood, which is crucial for adjusting coefficients during regularization.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _calc_grad(mod, params, alpha, L1_wt, score_kwds): [MASK]\n"}
{"method_name": "_calc_wdesign_mat", "full_method_name": "_calc_wdesign_mat", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _calc_wdesign_mat(mod, params, hess_kwds):\n    \"\"\"calculates the weighted design matrix necessary to generate\n    the approximate inverse covariance matrix\n\n    Parameters\n    ----------\n    mod : statsmodels model class instance\n        The model for the current partition.\n    params : array_like\n        The estimated coefficients for the current partition.\n    hess_kwds : dict-like or None\n        Keyword arguments for the hessian function.\n\n    Returns\n    -------\n    An array-like object, updated design matrix, same dimension\n    as mod.exog\n    \"\"\"\n    rhess = np.sqrt(mod.hessian_factor(np.asarray(params), **hess_kwds))\n    return rhess[:, None] * mod.exog", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_calc_wdesign_mat():\n    np.random.seed(435265)\n    X = np.random.normal(size=(3, 3))\n    y = np.random.randint(0, 2, size=3)\n    beta = np.random.normal(size=3)\n    mod = OLS(y, X)\n    dmat = _calc_wdesign_mat(mod, beta, {})\n    assert_allclose(dmat, np.array([[1.306314, -0.024897, 1.326498], [-\n        0.539219, -0.483028, -0.703503], [-3.327987, 0.524541, -0.139761]]),\n        atol=1e-06, rtol=0)\n    mod = GLM(y, X, family=Binomial())\n    dmat = _calc_wdesign_mat(mod, beta, {})\n    assert_allclose(dmat, np.array([[0.408616, -0.007788, 0.41493], [-\n        0.263292, -0.235854, -0.343509], [-0.11241, 0.017718, -0.004721]]),\n        atol=1e-06, rtol=0)\n\ntest_calc_wdesign_mat()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The function '_calc_wdesign_mat' computes a weighted design matrix that is essential for generating the approximate inverse covariance matrix. This is performed by multiplying the square root of the Hessian factor of the model by the model's exogenous variables.\n\nInputs: \n1. mod: A statsmodels model class instance, which represents the model for the current partition.\n2. params: An array-like structure containing the estimated coefficients for the current partition.\n3. hess_kwds: A dict-like structure or None, containing keyword arguments intended for the Hessian function.\n\nOutputs:\n1. An array-like object representing the updated design matrix, which is of the same dimension as 'mod.exog'. This updated matrix is the result of weighting the original design matrix by the square root of the Hessian factor calculated at the given parameters.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _calc_wdesign_mat(mod, params, hess_kwds): [MASK]\n"}
{"method_name": "_est_regularized_debiased", "full_method_name": "_est_regularized_debiased", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _est_regularized_debiased(mod, mnum, partitions, fit_kwds=None,\n    score_kwds=None, hess_kwds=None):\n    \"\"\"estimates the regularized fitted parameters, is the default\n    estimation_method for class DistributedModel.\n\n    Parameters\n    ----------\n    mod : statsmodels model class instance\n        The model for the current partition.\n    mnum : scalar\n        Index of current partition.\n    partitions : scalar\n        Total number of partitions.\n    fit_kwds : dict-like or None\n        Keyword arguments to be given to fit_regularized\n    score_kwds : dict-like or None\n        Keyword arguments for the score function.\n    hess_kwds : dict-like or None\n        Keyword arguments for the Hessian function.\n\n    Returns\n    -------\n    A tuple of parameters for regularized fit\n        An array-like object of the fitted parameters, params\n        An array-like object for the gradient\n        A list of array like objects for nodewise_row\n        A list of array like objects for nodewise_weight\n    \"\"\"\n    score_kwds = {} if score_kwds is None else score_kwds\n    hess_kwds = {} if hess_kwds is None else hess_kwds\n    if fit_kwds is None:\n        raise ValueError('_est_regularized_debiased currently ' +\n            'requires that fit_kwds not be None.')\n    else:\n        alpha = fit_kwds['alpha']\n    if 'L1_wt' in fit_kwds:\n        L1_wt = fit_kwds['L1_wt']\n    else:\n        L1_wt = 1\n    nobs, p = mod.exog.shape\n    p_part = int(np.ceil(1.0 * p / partitions))\n    params = mod.fit_regularized(**fit_kwds).params\n    grad = _calc_grad(mod, params, alpha, L1_wt, score_kwds) / nobs\n    wexog = _calc_wdesign_mat(mod, params, hess_kwds)\n    nodewise_row_l = []\n    nodewise_weight_l = []\n    for idx in range(mnum * p_part, min((mnum + 1) * p_part, p)):\n        nodewise_row = _calc_nodewise_row(wexog, idx, alpha)\n        nodewise_row_l.append(nodewise_row)\n        nodewise_weight = _calc_nodewise_weight(wexog, nodewise_row, idx, alpha\n            )\n        nodewise_weight_l.append(nodewise_weight)\n    return params, grad, nodewise_row_l, nodewise_weight_l", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_est_regularized_debiased():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    beta = np.random.normal(size=3)\n    mod = OLS(y, X)\n    res = _est_regularized_debiased(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    bhat = res[0]\n    grad = res[1]\n    ghat_l = res[2]\n    that_l = res[3]\n    assert_(isinstance(res, tuple))\n    assert_equal(bhat.shape, beta.shape)\n    assert_equal(grad.shape, beta.shape)\n    assert_(isinstance(ghat_l, list))\n    assert_(isinstance(that_l, list))\n    assert_equal(len(ghat_l), len(that_l))\n    assert_equal(ghat_l[0].shape, (2,))\n    assert_(isinstance(that_l[0], float))\n    mod = GLM(y, X, family=Binomial())\n    res = _est_regularized_debiased(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    bhat = res[0]\n    grad = res[1]\n    ghat_l = res[2]\n    that_l = res[3]\n    assert_(isinstance(res, tuple))\n    assert_equal(bhat.shape, beta.shape)\n    assert_equal(grad.shape, beta.shape)\n    assert_(isinstance(ghat_l, list))\n    assert_(isinstance(that_l, list))\n    assert_equal(len(ghat_l), len(that_l))\n    assert_equal(ghat_l[0].shape, (2,))\n    assert_(isinstance(that_l[0], float))\n\ntest_est_regularized_debiased()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_join_debiased():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = OLS(y, X)\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_debiased(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_debiased(res_l)\n    assert_allclose(joined, np.array([-0.167548, -0.016567, -0.34414]),\n        atol=1e-06, rtol=0)\n    mod = GLM(y, X, family=Binomial())\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_debiased(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_debiased(res_l)\n    assert_allclose(joined, np.array([-0.164515, -0.412854, -0.223955]),\n        atol=1e-06, rtol=0)\n\ntest_join_debiased()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _est_regularized_debiased function computes regularized fitted parameters, gradients, and nodewise interactions for a partition of data within a distributed computing framework. It is designed to work with statsmodels models and is used for estimating parameters with regularization, particularly in the context of high dimensional datasets.\n\nInputs: \n- mod: A statsmodels model class instance, representing the model for the current partition of data.\n- mnum: An integer scalar, indicating the index of the current partition.\n- partitions: An integer scalar, specifying the total number of partitions the data is divided into.\n- fit_kwds: A dictionary, optional, containing keyword arguments to be passed to the fit_regularized method of the model. It must not be None.\n- score_kwds: A dictionary, optional, containing keyword arguments for the score function of the model.\n- hess_kwds: A dictionary, optional, containing keyword arguments for the Hessian function of the model.\n\nOutputs:\n- A tuple containing the following elements:\n    - params: An array-like object, representing the fitted parameters obtained from the regularized fit.\n    - grad: An array-like object, representing the gradient of the cost function computed at the fitted parameters.\n    - nodewise_row_l: A list of array-like objects, each containing the nodewise row interactions for the subset of parameters.\n    - nodewise_weight_l: A list of array-like objects, each containing the nodewise weights for the subset of parameters.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _est_regularized_debiased(mod, mnum, partitions, fit_kwds=None,\n    score_kwds=None, hess_kwds=None): [MASK]\n"}
{"method_name": "_est_regularized_naive", "full_method_name": "_est_regularized_naive", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _est_regularized_naive(mod, pnum, partitions, fit_kwds=None):\n    \"\"\"estimates the regularized fitted parameters.\n\n    Parameters\n    ----------\n    mod : statsmodels model class instance\n        The model for the current partition.\n    pnum : scalar\n        Index of current partition\n    partitions : scalar\n        Total number of partitions\n    fit_kwds : dict-like or None\n        Keyword arguments to be given to fit_regularized\n\n    Returns\n    -------\n    An array of the parameters for the regularized fit\n    \"\"\"\n    if fit_kwds is None:\n        raise ValueError('_est_regularized_naive currently ' +\n            'requires that fit_kwds not be None.')\n    return mod.fit_regularized(**fit_kwds).params", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_est_regularized_naive():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    beta = np.random.normal(size=3)\n    mod = OLS(y, X)\n    res = _est_regularized_naive(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    assert_equal(res.shape, beta.shape)\n    mod = GLM(y, X, family=Binomial())\n    res = _est_regularized_naive(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    assert_equal(res.shape, beta.shape)\n\ntest_est_regularized_naive()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_join_naive():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = OLS(y, X)\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_naive(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_naive(res_l)\n    assert_allclose(joined, np.array([-0.020757, 0.0, 0.0]), atol=1e-06, rtol=0\n        )\n    mod = GLM(y, X, family=Binomial())\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_naive(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_naive(res_l)\n    assert_allclose(joined, np.array([0.0, 0.0, 0.0]), atol=1e-06, rtol=0)\n\ntest_join_naive()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _est_regularized_naive function is designed to estimate the regularized fitted parameters for a given partition of a dataset using a specified statsmodels model instance. This function is particularly useful in scenarios where data is too large to be processed in one go, and thus, partitioning the data and estimating parameters for each partition separately is required.\n\nInputs:\n- mod: A statsmodels model class instance. This is the model that will be used to estimate the parameters for the current partition.\n- pnum: A scalar representing the index of the current partition being processed.\n- partitions: A scalar indicating the total number of partitions into which the data is divided.\n- fit_kwds: A dict-like object or None. This contains keyword arguments that will be passed to the fit_regularized method of the model instance. It is mandatory for fit_kwds to not be None when calling this function.\n\nOutputs:\n- An array of the parameters resulting from the regularized fit. These parameters are estimated for the specific partition identified by pnum and are obtained by fitting the given model instance with the regularization applied, as specified in fit_kwds.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _est_regularized_naive(mod, pnum, partitions, fit_kwds=None): [MASK]\n"}
{"method_name": "_est_unregularized_naive", "full_method_name": "_est_unregularized_naive", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _est_unregularized_naive(mod, pnum, partitions, fit_kwds=None):\n    \"\"\"estimates the unregularized fitted parameters.\n\n    Parameters\n    ----------\n    mod : statsmodels model class instance\n        The model for the current partition.\n    pnum : scalar\n        Index of current partition\n    partitions : scalar\n        Total number of partitions\n    fit_kwds : dict-like or None\n        Keyword arguments to be given to fit\n\n    Returns\n    -------\n    An array of the parameters for the fit\n    \"\"\"\n    if fit_kwds is None:\n        raise ValueError('_est_unregularized_naive currently ' +\n            'requires that fit_kwds not be None.')\n    return mod.fit(**fit_kwds).params", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_est_unregularized_naive():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    beta = np.random.normal(size=3)\n    mod = OLS(y, X)\n    res = _est_unregularized_naive(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    assert_equal(res.shape, beta.shape)\n    mod = GLM(y, X, family=Binomial())\n    res = _est_unregularized_naive(mod, 0, 2, fit_kwds={'alpha': 0.5})\n    assert_equal(res.shape, beta.shape)\n\ntest_est_unregularized_naive()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The function _est_unregularized_naive is designed to estimate the unregularized fitted parameters for a given model partition. It utilizes a statsmodels model class instance to perform the fitting process and returns the parameters obtained from the fit.\n\nInputs:\n- mod: A statsmodels model class instance. This model is used to fit the data and should be of the appropriate type for the data being analyzed.\n- pnum: A scalar representing the index of the current partition. This is used when the data is divided into multiple partitions for parallel processing.\n- partitions: A scalar indicating the total number of partitions into which the data is divided. This is necessary for coordinating the fitting process across multiple partitions.\n- fit_kwds: A dictionary-like object or None. This contains keyword arguments that are passed to the fit method of the model. If None, the function will raise a ValueError as it requires specific fitting options to be provided.\n\nOutputs:\n- An array of parameters resulting from the fit. These parameters represent the unregularized fitted parameters obtained from the model fit for the given partition.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _est_unregularized_naive(mod, pnum, partitions, fit_kwds=None): [MASK]\n"}
{"method_name": "_join_debiased", "full_method_name": "_join_debiased", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _join_debiased(results_l, threshold=0):\n    \"\"\"joins the results from each run of _est_regularized_debiased\n    and returns the debiased estimate of the coefficients\n\n    Parameters\n    ----------\n    results_l : list\n        A list of tuples each one containing the params, grad,\n        nodewise_row and nodewise_weight values for each partition.\n    threshold : scalar\n        The threshold at which the coefficients will be cut.\n    \"\"\"\n    p = len(results_l[0][0])\n    partitions = len(results_l)\n    params_mn = np.zeros(p)\n    grad_mn = np.zeros(p)\n    nodewise_row_l = []\n    nodewise_weight_l = []\n    for r in results_l:\n        params_mn += r[0]\n        grad_mn += r[1]\n        nodewise_row_l.extend(r[2])\n        nodewise_weight_l.extend(r[3])\n    nodewise_row_l = np.array(nodewise_row_l)\n    nodewise_weight_l = np.array(nodewise_weight_l)\n    params_mn /= partitions\n    grad_mn *= -1.0 / partitions\n    approx_inv_cov = _calc_approx_inv_cov(nodewise_row_l, nodewise_weight_l)\n    debiased_params = params_mn + approx_inv_cov.dot(grad_mn)\n    debiased_params[np.abs(debiased_params) < threshold] = 0\n    return debiased_params", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_join_debiased():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = OLS(y, X)\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_debiased(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_debiased(res_l)\n    assert_allclose(joined, np.array([-0.167548, -0.016567, -0.34414]),\n        atol=1e-06, rtol=0)\n    mod = GLM(y, X, family=Binomial())\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_debiased(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_debiased(res_l)\n    assert_allclose(joined, np.array([-0.164515, -0.412854, -0.223955]),\n        atol=1e-06, rtol=0)\n\ntest_join_debiased()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _join_debiased function is designed to combine the results from multiple runs of a debiasing estimation process (presumably _est_regularized_debiased) and to compute the debiased estimate of the coefficients. This process includes averaging the parameters and gradients from each run, constructing the approximate inverse covariance matrix, and applying a threshold to set small coefficients to zero.\n\nInputs:\n- results_l: A list of tuples. Each tuple contains the following elements:\n  1. params: An array-like object with the estimated parameters for a single run.\n  2. grad: An array-like object with the gradient information for a single run.\n  3. nodewise_row: An array-like object containing nodewise row information for each run.\n  4. nodewise_weight: An array-like object containing nodewise weight information for each run.\n- threshold: A scalar value. This threshold is used to zero out coefficients whose absolute value is less than this threshold.\n\nOutputs:\n- debiased_params: An array-like object containing the debiased parameter estimates. Coefficients with absolute values smaller than the threshold are set to zero.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _join_debiased(results_l, threshold=0): [MASK]\n"}
{"method_name": "_join_naive", "full_method_name": "_join_naive", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/distributed_estimation.py", "method_code": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\ndef _join_naive(params_l, threshold=0):\n    \"\"\"joins the results from each run of _est_<type>_naive\n    and returns the mean estimate of the coefficients\n\n    Parameters\n    ----------\n    params_l : list\n        A list of arrays of coefficients.\n    threshold : scalar\n        The threshold at which the coefficients will be cut.\n    \"\"\"\n    p = len(params_l[0])\n    partitions = len(params_l)\n    params_mn = np.zeros(p)\n    for params in params_l:\n        params_mn += params\n    params_mn /= partitions\n    params_mn[np.abs(params_mn) < threshold] = 0\n    return params_mn", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_join_naive():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = OLS(y, X)\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_naive(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_naive(res_l)\n    assert_allclose(joined, np.array([-0.020757, 0.0, 0.0]), atol=1e-06, rtol=0\n        )\n    mod = GLM(y, X, family=Binomial())\n    res_l = []\n    for i in range(2):\n        res = _est_regularized_naive(mod, i, 2, fit_kwds={'alpha': 0.1})\n        res_l.append(res)\n    joined = _join_naive(res_l)\n    assert_allclose(joined, np.array([0.0, 0.0, 0.0]), atol=1e-06, rtol=0)\n\ntest_join_naive()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _join_naive function is designed to aggregate and average the results from multiple runs of a coefficient estimation process. It takes a list of coefficient arrays, averages them, and then applies a threshold to set small coefficients to zero.\n\nInputs:\n- params_l : list\n    A list of arrays, where each array contains the coefficients estimated from a separate run of the coefficient estimation process.\n- threshold : scalar (default is 0)\n    A scalar value representing the threshold below which the absolute value of coefficients will be set to zero.\n\nOutputs:\n- params_mn : numpy array\n    An array of averaged coefficients, where coefficients smaller than the specified threshold in absolute value have been set to zero.", "method_code_mask": "from statsmodels.base.elastic_net import RegularizedResults\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_row\nfrom statsmodels.stats.regularized_covariance import _calc_nodewise_weight\nfrom statsmodels.stats.regularized_covariance import _calc_approx_inv_cov\nfrom statsmodels.base.model import LikelihoodModelResults\nfrom statsmodels.regression.linear_model import OLS\nimport numpy as np\nfrom statsmodels.tools.parallel import parallel_func\n\n\ndef _join_naive(params_l, threshold=0): [MASK]\n"}
{"method_name": "_data_gen", "full_method_name": "_data_gen", "method_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py", "method_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef _data_gen(endog, exog, partitions):\n    \"\"\"partitions data\"\"\"\n    n_exog = exog.shape[0]\n    n_part = np.ceil(n_exog / partitions)\n    n_part = np.floor(n_exog / partitions)\n    rem = n_exog - n_part * partitions\n    stp = 0\n    while stp < partitions - 1:\n        ii = int(n_part * stp)\n        jj = int(n_part * (stp + 1))\n        yield endog[ii:jj], exog[ii:jj, :]\n        stp += 1\n    ii = int(n_part * stp)\n    jj = int(n_part * (stp + 1) + rem)\n    yield endog[ii:jj], exog[ii:jj, :]", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_fit_sequential():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = DistributedModel(1, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 1), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.191606, -0.012565, -0.351398]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(2, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 2), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.157416, -0.029643, -0.471653]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(3, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 3), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.124891, -0.050934, -0.403354]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(1, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 1), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.164515, -0.412854, -0.223955]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(2, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 2), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.142513, -0.360324, -0.295485]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(3, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 3), parallel_method='sequential',\n        fit_kwds={'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.110487, -0.306431, -0.243921]),\n        atol=1e-06, rtol=0)\n\ntest_fit_sequential()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_fit_joblib():\n    np.random.seed(435265)\n    X = np.random.normal(size=(50, 3))\n    y = np.random.randint(0, 2, size=50)\n    mod = DistributedModel(1, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 1), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.191606, -0.012565, -0.351398]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(2, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 2), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.157416, -0.029643, -0.471653]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(3, model_class=OLS)\n    fit = mod.fit(_data_gen(y, X, 3), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.124891, -0.050934, -0.403354]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(1, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 1), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.164515, -0.412854, -0.223955]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(2, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 2), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.142513, -0.360324, -0.295485]),\n        atol=1e-06, rtol=0)\n    mod = DistributedModel(3, model_class=GLM, init_kwds={'family': Binomial()}\n        )\n    fit = mod.fit(_data_gen(y, X, 3), parallel_method='joblib', fit_kwds={\n        'alpha': 0.5})\n    assert_allclose(fit.params, np.array([-0.110487, -0.306431, -0.243921]),\n        atol=1e-06, rtol=0)\n\ntest_fit_joblib()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_single_partition():\n    np.random.seed(435265)\n    N = 200\n    p = 10\n    m = 1\n    beta = np.random.normal(size=p)\n    beta = beta * np.random.randint(0, 2, p)\n    X = np.random.normal(size=(N, p))\n    y = X.dot(beta) + np.random.normal(size=N)\n    db_mod = DistributedModel(m)\n    fitOLSdb = db_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0})\n    nv_mod = DistributedModel(m, estimation_method=_est_regularized_naive,\n        join_method=_join_naive)\n    fitOLSnv = nv_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0})\n    ols_mod = OLS(y, X)\n    fitOLS = ols_mod.fit(alpha=0)\n    assert_allclose(fitOLSdb.params, fitOLS.params)\n    assert_allclose(fitOLSnv.params, fitOLS.params)\n    nv_mod = DistributedModel(m, estimation_method=_est_regularized_naive,\n        join_method=_join_naive)\n    fitOLSnv = nv_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.1})\n    ols_mod = OLS(y, X)\n    fitOLS = ols_mod.fit_regularized(alpha=0.1)\n    assert_allclose(fitOLSnv.params, fitOLS.params)\n\ntest_single_partition()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_larger_p():\n    np.random.seed(435265)\n    N = 40\n    p = 40\n    m = 5\n    beta = np.random.normal(size=p)\n    beta = beta * np.random.randint(0, 2, p)\n    X = np.random.normal(size=(N, p))\n    y = X.dot(beta) + np.random.normal(size=N)\n    db_mod = DistributedModel(m)\n    fitOLSdb = db_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.1})\n    assert_equal(np.sum(np.isnan(fitOLSdb.params)), 0)\n    nv_mod = DistributedModel(m, estimation_method=_est_regularized_naive,\n        join_method=_join_naive)\n    fitOLSnv = nv_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.1})\n    assert_equal(np.sum(np.isnan(fitOLSnv.params)), 0)\n\ntest_larger_p()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_non_zero_params():\n    np.random.seed(435265)\n    N = 200\n    p = 10\n    m = 5\n    beta = np.random.normal(size=p)\n    beta = beta * np.random.randint(0, 2, p)\n    X = np.random.normal(size=(N, p))\n    y = X.dot(beta) + np.random.normal(size=N)\n    db_mod = DistributedModel(m, join_kwds={'threshold': 0.13})\n    fitOLSdb = db_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.1})\n    ols_mod = OLS(y, X)\n    fitOLS = ols_mod.fit_regularized(alpha=0.1)\n    nz_params_db = 1 * (fitOLSdb.params != 0)\n    nz_params_ols = 1 * (fitOLS.params != 0)\n    assert_allclose(nz_params_db, nz_params_ols)\n\ntest_non_zero_params()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\ndef test_debiased_v_average():\n    np.random.seed(435265)\n    N = 200\n    p = 10\n    m = 4\n    beta = np.random.normal(size=p)\n    beta = beta * np.random.randint(0, 2, p)\n    X = np.random.normal(size=(N, p))\n    y = X.dot(beta) + np.random.normal(size=N)\n    db_mod = DistributedModel(m)\n    fitOLSdb = db_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.2})\n    olsdb = np.linalg.norm(fitOLSdb.params - beta)\n    n_mod = DistributedModel(m, estimation_method=_est_regularized_naive,\n        join_method=_join_naive)\n    fitOLSn = n_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.2})\n    olsn = np.linalg.norm(fitOLSn.params - beta)\n    assert_(olsdb < olsn)\n    prob = 1 / (1 + np.exp(-X.dot(beta) + np.random.normal(size=N)))\n    y = 1.0 * (prob > 0.5)\n    db_mod = DistributedModel(m, model_class=GLM, init_kwds={'family':\n        Binomial()})\n    fitGLMdb = db_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.2})\n    glmdb = np.linalg.norm(fitGLMdb.params - beta)\n    n_mod = DistributedModel(m, model_class=GLM, init_kwds={'family':\n        Binomial()}, estimation_method=_est_regularized_naive, join_method=\n        _join_naive)\n    fitGLMn = n_mod.fit(_data_gen(y, X, m), fit_kwds={'alpha': 0.2})\n    glmn = np.linalg.norm(fitGLMn.params - beta)\n    assert_(glmdb < glmn)\n\ntest_debiased_v_average()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_distributed_estimation.py"}], "instruction": "Functionality: The _data_gen function is designed to partition a dataset into smaller chunks for distributed processing. This is particularly useful for large datasets that need to be processed in parallel across multiple machines. The function takes a dependent variable array (endog) and an independent variable matrix (exog) and divides them into partitions specified by the user.\n\nInputs: \n1. endog (1D array): The dependent variable array. This should be a 1D NumPy array.\n2. exog (2D array): The independent variable matrix. This should be a 2D NumPy array where each column represents a different independent variable.\n3. partitions (int): The number of partitions to divide the dataset into. This should be a positive integer.\n\nOutputs: \nThe function yields (returns in a generator format) a series of tuples, each containing a chunk of the dependent variable array (endog) and the corresponding chunk of the independent variable matrix (exog). The size of each chunk is determined by dividing the total number of observations in the dataset by the number of partitions. If the dataset does not divide evenly, the last chunk will include the remainder of the observations.", "method_code_mask": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families import Binomial\nfrom statsmodels.base.distributed_estimation import _calc_grad\nfrom statsmodels.base.distributed_estimation import _calc_wdesign_mat\nfrom statsmodels.base.distributed_estimation import _est_regularized_debiased\nfrom statsmodels.base.distributed_estimation import _join_debiased\nfrom statsmodels.base.distributed_estimation import _est_regularized_naive\nfrom statsmodels.base.distributed_estimation import _est_unregularized_naive\nfrom statsmodels.base.distributed_estimation import _join_naive\nfrom statsmodels.base.distributed_estimation import DistributedModel\n\n\ndef _data_gen(endog, exog, partitions): [MASK]\n"}
{"method_name": "handle_formula_data", "full_method_name": "handle_formula_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/formula/formulatools.py", "method_code": "import statsmodels.tools.data as data_util\nfrom patsy import dmatrices\nfrom patsy import NAAction\nimport numpy as np\nfrom patsy.desc import INTERCEPT\nfrom numpy import array\nfrom patsy.constraint import linear_constraint\ndef handle_formula_data(Y, X, formula, depth=0, missing='drop'):\n    \"\"\"\n    Returns endog, exog, and the model specification from arrays and formula.\n\n    Parameters\n    ----------\n    Y : array_like\n        Either endog (the LHS) of a model specification or all of the data.\n        Y must define __getitem__ for now.\n    X : array_like\n        Either exog or None. If all the data for the formula is provided in\n        Y then you must explicitly set X to None.\n    formula : str or patsy.model_desc\n        You can pass a handler by import formula_handler and adding a\n        key-value pair where the key is the formula object class and\n        the value is a function that returns endog, exog, formula object.\n\n    Returns\n    -------\n    endog : array_like\n        Should preserve the input type of Y,X.\n    exog : array_like\n        Should preserve the input type of Y,X. Could be None.\n    \"\"\"\n    if isinstance(formula, tuple(formula_handler.keys())):\n        return formula_handler[type(formula)]\n    na_action = NAAction(on_NA=missing)\n    if X is not None:\n        if data_util._is_using_pandas(Y, X):\n            result = dmatrices(formula, (Y, X), depth, return_type=\n                'dataframe', NA_action=na_action)\n        else:\n            result = dmatrices(formula, (Y, X), depth, return_type=\n                'dataframe', NA_action=na_action)\n    elif data_util._is_using_pandas(Y, None):\n        result = dmatrices(formula, Y, depth, return_type='dataframe',\n            NA_action=na_action)\n    else:\n        result = dmatrices(formula, Y, depth, return_type='dataframe',\n            NA_action=na_action)\n    missing_mask = getattr(na_action, 'missing_mask', None)\n    if not np.any(missing_mask):\n        missing_mask = None\n    if len(result) > 1:\n        design_info = result[1].design_info\n    else:\n        design_info = None\n    return result, missing_mask, design_info", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nimport numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.base import data as sm_data\nfrom statsmodels.formula import handle_formula_data\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod import families\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.datasets.macrodata import load_pandas\nfrom statsmodels.datasets.longley import load_pandas\nfrom statsmodels.tools.sm_exceptions import MissingDataError\ndef test_formula_missing_extra_arrays():\n    np.random.seed(1)\n    y = np.random.randn(10)\n    y_missing = y.copy()\n    y_missing[[2, 5]] = np.nan\n    X = np.random.randn(10)\n    X_missing = X.copy()\n    X_missing[[1, 3]] = np.nan\n    weights = np.random.uniform(size=10)\n    weights_missing = weights.copy()\n    weights_missing[[6]] = np.nan\n    weights_wrong_size = np.random.randn(12)\n    data = {'y': y, 'X': X, 'y_missing': y_missing, 'X_missing': X_missing,\n        'weights': weights, 'weights_missing': weights_missing}\n    data = pd.DataFrame.from_dict(data)\n    data['constant'] = 1\n    formula = 'y_missing ~ X_missing'\n    (endog, exog), missing_idx, design_info = handle_formula_data(data,\n        None, formula, depth=2, missing='drop')\n    kwargs = {'missing_idx': missing_idx, 'missing': 'drop', 'weights':\n        data['weights_missing']}\n    model_data = sm_data.handle_data(endog, exog, **kwargs)\n    data_nona = data.dropna()\n    assert_equal(data_nona['y'].values, model_data.endog)\n    assert_equal(data_nona[['constant', 'X']].values, model_data.exog)\n    assert_equal(data_nona['weights'].values, model_data.weights)\n    tmp = handle_formula_data(data, None, formula, depth=2, missing='drop')\n    (endog, exog), missing_idx, design_info = tmp\n    weights_2d = np.random.randn(10, 10)\n    weights_2d[[8, 7], [7, 8]] = np.nan\n    kwargs.update({'weights': weights_2d, 'missing_idx': missing_idx})\n    model_data2 = sm_data.handle_data(endog, exog, **kwargs)\n    good_idx = [0, 4, 6, 9]\n    assert_equal(data.loc[good_idx, 'y'], model_data2.endog)\n    assert_equal(data.loc[good_idx, ['constant', 'X']], model_data2.exog)\n    assert_equal(weights_2d[good_idx][:, good_idx], model_data2.weights)\n    tmp = handle_formula_data(data, None, formula, depth=2, missing='drop')\n    (endog, exog), missing_idx, design_info = tmp\n    kwargs.update({'weights': weights_wrong_size, 'missing_idx': missing_idx})\n    assert_raises(ValueError, sm_data.handle_data, endog, exog, **kwargs)\n\ntest_formula_missing_extra_arrays()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/base/tests/test_data.py"}], "instruction": "Functionality: The handle_formula_data function processes input data and a formula to return endogenous (dependent) variables, exogenous (independent) variables, and the model specification. It can handle various input data types and missing data handling strategies.\n\nInputs:\n- Y: An array-like object representing either the endogenous (LHS) variable of a model specification or the entire dataset. Y must implement the __getitem__ method.\n- X: An array-like object representing the exogenous variables or None if the entire data for the formula is provided in Y.\n- formula: A string or a patsy.model_desc object specifying the model formula.\n- depth: An optional integer specifying the depth of data manipulation. Default is 0.\n- missing: A string specifying how to handle missing values. Default is 'drop'.\n\nOutputs:\n- endog: An array-like object representing the endogenous variables, preserving the input type of Y and X.\n- exog: An array-like object representing the exogenous variables, preserving the input type of Y and X. It can be None if not applicable.\n- The function also returns a missing_mask indicating if any data is missing and a design_info object that includes metadata about the design matrix.", "method_code_mask": "import statsmodels.tools.data as data_util\nfrom patsy import dmatrices\nfrom patsy import NAAction\nimport numpy as np\nfrom patsy.desc import INTERCEPT\nfrom numpy import array\nfrom patsy.constraint import linear_constraint\n\n\ndef handle_formula_data(Y, X, formula, depth=0, missing='drop'): [MASK]\n"}
{"method_name": "_toy", "full_method_name": "_toy", "method_path": "../srcdata/Computation/statsmodels/statsmodels/multivariate/tests/test_ml_factor.py", "method_code": "import numpy as np\nfrom statsmodels.multivariate.factor import Factor\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\nimport warnings\ndef _toy():\n    uniq = np.r_[4, 9, 16]\n    load = np.asarray([[3, 1, 2], [2, 5, 8]]).T\n    par = np.r_[2, 3, 4, 3, 1, 2, 2, 5, 8]\n    corr = np.asarray([[1, 0.5, 0.25], [0.5, 1, 0.5], [0.25, 0.5, 1]])\n    return uniq, load, corr, par", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.multivariate.factor import Factor\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\nimport warnings\ndef test_loglike():\n    uniq, load, corr, par = _toy()\n    fa = Factor(n_factor=2, corr=corr)\n    ll1 = fa.loglike((load, uniq))\n    ll2 = fa.loglike(par)\n    assert_allclose(ll1, ll2)\n\ntest_loglike()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/multivariate/tests/test_ml_factor.py"}, {"test_code": "import numpy as np\nfrom statsmodels.multivariate.factor import Factor\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\nimport warnings\ndef test_score():\n    uniq, load, corr, par = _toy()\n    fa = Factor(n_factor=2, corr=corr)\n\n    def f(par):\n        return fa.loglike(par)\n    par2 = np.r_[0.1, 0.2, 0.3, 0.4, 0.3, 0.1, 0.2, -0.2, 0, 0.8, 0.5, 0]\n    for pt in (par, par2):\n        g1 = approx_fprime(pt, f, 1e-08)\n        g2 = fa.score(pt)\n        assert_allclose(g1, g2, atol=0.001)\n\ntest_score()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/multivariate/tests/test_ml_factor.py"}], "instruction": "Functionality: The _toy function is designed to generate a set of data commonly used in factor analysis or principal component analysis. It aims to return unique variances, factor loadings, correlation matrix, and parameter vector that can be used to test the implementation of factor analysis or similar statistical models.\n\nInputs: The function does not require any input arguments. It is a self-contained function that generates and returns the specified outputs without needing external data.\n\nOutputs: The function returns four outputs:\n1. uniq: A 1D numpy array containing unique variances for each factor. In this case, it will return an array with values [4, 9, 16].\n2. load: A 2D numpy array representing the factor loadings. Each column corresponds to a factor, and each row corresponds to a variable. The returned array will be:\n   [[3, 1, 2],\n    [2, 5, 8]]\n   Transposed to:\n   [[3, 2],\n    [1, 5],\n    [2, 8]]\n3. corr: A 2D numpy array representing the correlation matrix of the variables. This array is symmetric and has a dimension equal to the number of variables. The returned array will be:\n   [[1, 0.5, 0.25],\n    [0.5, 1, 0.5],\n    [0.25, 0.5, 1]]\n4. par: A 1D numpy array containing the parameters from which the load and uniq are derived. In this case, it will return an array with values [2, 3, 4, 3, 1, 2, 2, 5, 8].", "method_code_mask": "import numpy as np\nfrom statsmodels.multivariate.factor import Factor\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy.optimize import approx_fprime\nimport warnings\n\n\ndef _toy(): [MASK]\n"}
{"method_name": "mad", "full_method_name": "mad", "method_path": "../srcdata/Computation/statsmodels/statsmodels/robust/scale.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.stats import norm as Gaussian\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import float_like\ndef mad(a, c=Gaussian.ppf(3 / 4.0), axis=0, center=np.median):\n    \"\"\"\n    The Median Absolute Deviation along given axis of an array\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    c : float, optional\n        The normalization constant.  Defined as scipy.stats.norm.ppf(3/4.),\n        which is approximately 0.6745.\n    axis : int, optional\n        The default is 0. Can also be None.\n    center : callable or float\n        If a callable is provided, such as the default `np.median` then it\n        is expected to be called center(a). The axis argument will be applied\n        via np.apply_over_axes. Otherwise, provide a float.\n\n    Returns\n    -------\n    mad : float\n        `mad` = median(abs(`a` - center))/`c`\n    \"\"\"\n    a = array_like(a, 'a', ndim=None)\n    c = float_like(c, 'c')\n    if not a.size:\n        center_val = 0.0\n    elif callable(center):\n        if axis is not None:\n            center_val = np.apply_over_axes(center, a, axis)\n        else:\n            center_val = center(a.ravel())\n    else:\n        center_val = float_like(center, 'center')\n    err = np.abs(a - center_val) / c\n    if not err.size:\n        if axis is None or err.ndim == 1:\n            return np.nan\n        else:\n            shape = list(err.shape)\n            shape.pop(axis)\n            return np.empty(shape)\n    return np.median(err, axis=axis)", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport pytest\nimport pandas as pd\nfrom scipy.stats import norm as Gaussian\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.robust.scale as scale\nfrom statsmodels.robust.scale import mad\nimport statsmodels.robust.norms as rnorms\ndef test_mad_axis_none():\n    a = np.array([[0, 1, 2], [2, 3, 2]])\n\n    def m(x):\n        return np.median(x)\n    direct = mad(a=a, axis=None)\n    custom = mad(a=a, axis=None, center=m)\n    axis0 = mad(a=a.ravel(), axis=0)\n    np.testing.assert_allclose(direct, custom)\n    np.testing.assert_allclose(direct, axis0)\n\ntest_mad_axis_none()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_scale.py"}, {"test_code": "import os\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport pytest\nimport pandas as pd\nfrom scipy.stats import norm as Gaussian\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.robust.scale as scale\nfrom statsmodels.robust.scale import mad\nimport statsmodels.robust.norms as rnorms\n\nclass TestMad():\n\tdef test_mad_empty(self):\n\t    empty = np.empty(0)\n\t    assert np.isnan(mad(empty))\n\t    empty = np.empty((10, 100, 0))\n\t    assert_equal(mad(empty, axis=1), np.empty((10, 0)))\n\t    empty = np.empty((100, 100, 0, 0))\n\t    assert_equal(mad(empty, axis=-1), np.empty((100, 100, 0)))\n\t\nTestMad().test_mad_empty()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_scale.py"}], "instruction": "Functionality: The mad function computes the Median Absolute Deviation of an input array along a specified axis. This is a measure of variability that is less sensitive to outliers compared to the standard deviation. The deviation is normalized by a constant, which by default is derived from the inverse cumulative distribution function (CDF) of the standard normal distribution at 3/4.\n\nInputs: \n1. a: Array-like input data on which the median absolute deviation is to be computed.\n2. c: Optional float that represents the normalization constant. Defaults to scipy.stats.norm.ppf(3/4.), approximately 0.6745.\n3. axis: Optional integer specifying the axis along which the MAD is computed. Defaults to 0. If None, the input array is flattened before computation.\n4. center: Function or float to determine the central value used in MAD computation. If a function is provided (e.g., np.median), it is applied over the array. If a float is provided, it is directly used as the center.\n\nOutputs:\n1. mad: A float representing the median absolute deviation of the input array, normalized by the constant `c`. The output shape depends on the input array's dimensions and the specified axis. If the input array is empty or the computation results in an empty array, np.nan or an empty array of the appropriate shape is returned.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.stats import norm as Gaussian\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import float_like\n\n\ndef mad(a, c=Gaussian.ppf(3 / 4.0), axis=0, center=np.median): [MASK]\n"}
{"method_name": "qn_scale", "full_method_name": "qn_scale", "method_path": "../srcdata/Computation/statsmodels/statsmodels/robust/scale.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy.stats import norm as Gaussian\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import float_like\ndef qn_scale(a, c=1 / (np.sqrt(2) * Gaussian.ppf(5 / 8)), axis=0):\n    \"\"\"\n    Computes the Qn robust estimator of scale\n\n    The Qn scale estimator is a more efficient alternative to the MAD.\n    The Qn scale estimator of an array a of length n is defined as\n    c * {abs(a[i] - a[j]): i<j}_(k), for k equal to [n/2] + 1 choose 2. Thus,\n    the Qn estimator is the k-th order statistic of the absolute differences\n    of the array. The optional constant is used to normalize the estimate\n    as explained below. The implementation follows the algorithm described\n    in Croux and Rousseeuw (1992).\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    c : float, optional\n        The normalization constant. The default value is used to get consistent\n        estimates of the standard deviation at the normal distribution.\n    axis : int, optional\n        The default is 0.\n\n    Returns\n    -------\n    {float, ndarray}\n        The Qn robust estimator of scale\n    \"\"\"\n    a = array_like(a, 'a', ndim=None, dtype=np.float64, contiguous=True,\n        order='C')\n    c = float_like(c, 'c')\n    if a.ndim == 0:\n        raise ValueError('a should have at least one dimension')\n    elif a.size == 0:\n        return np.nan\n    else:\n        out = np.apply_along_axis(_qn, axis=axis, arr=a, c=c)\n        if out.ndim == 0:\n            return float(out)\n        return out", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.random import standard_normal\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport pytest\nimport pandas as pd\nfrom scipy.stats import norm as Gaussian\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.robust.scale as scale\nfrom statsmodels.robust.scale import mad\nimport statsmodels.robust.norms as rnorms\n\nclass TestQn():\n\tdef test_qn_empty(self):\n\t    empty = np.empty(0)\n\t    assert np.isnan(qn_scale(empty))\n\t    empty = np.empty((10, 100, 0))\n\t    assert_equal(qn_scale(empty, axis=1), np.empty((10, 0)))\n\t    empty = np.empty((100, 100, 0, 0))\n\t    assert_equal(qn_scale(empty, axis=-1), np.empty((100, 100, 0)))\n\t    empty = np.empty(shape=())\n\t    with pytest.raises(ValueError):\n\t        scale.iqr(empty)\n\t\nTestQn().test_qn_empty()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_scale.py"}], "instruction": "Functionality: Computes the Qn robust estimator of scale for an input array. The Qn scale estimator is a more efficient alternative to the MAD, defined as c * {abs(a[i] - a[j]): i<j}_(k), where k is the [n/2] + 1 choose 2-th order statistic of the absolute differences of the array. The constant c is used to normalize the estimate.\n\nInputs:\n- a : array_like\n    Input array for which the Qn robust estimator of scale is to be calculated.\n- c : float, optional (default=1 / (np.sqrt(2) * Gaussian.ppf(5 / 8)))\n    The normalization constant to get consistent estimates of standard deviation, by default set to normalize the estimator for a normal distribution.\n- axis : int, optional (default=0)\n    The axis along which the Qn robust estimator of scale is calculated.\n\nOutputs:\n- {float, ndarray}\n    Returns the Qn robust estimator of scale. If the output is a single value, it is returned as a float. If the output is an array, it is returned as an ndarray.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy.stats import norm as Gaussian\nfrom statsmodels.tools import tools\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import float_like\n\n\ndef qn_scale(a, c=1 / (np.sqrt(2) * Gaussian.ppf(5 / 8)), axis=0): [MASK]\n"}
{"method_name": "_var_normal_jump", "full_method_name": "_var_normal_jump", "method_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tools.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy import integrate\nfrom scipy import optimize\nfrom statsmodels.tools.testing import Holder\ndef _var_normal_jump(norm):\n    \"\"\"Variance factor for asymptotic relative efficiency of mean M-estimator.\n\n    The reference distribution is the standard normal distribution.\n    This allows for the case when the psi function is not continuous, i.e.\n    has jumps as in TrimmedMean norm.\n\n    Relative efficiency is 1 / var_normal\n\n    Parameters\n    ----------\n    norm : instance of a RobustNorm subclass.\n        Norm for which variance for relative efficiency is computed.\n\n    Returns\n    -------\n    Variance factor.\n\n    Notes\n    -----\n    This function does not verify that the assumption on the psi function and\n    it's derivative hold.\n\n    Examples\n    --------\n\n    >>> import statsmodels.robust import norms\n    >>> v = _var_normal_jump(norms.HuberT())\n    >>> eff = 1 / v\n    >>> v, eff\n    (1.0526312908510451, 0.950000260007003)\n\n    Reference\n    ---------\n    Menenez et al., but it's also in all text books for robust statistics.\n\n\n    \"\"\"\n    num = stats.norm.expect(lambda x: norm.psi(x) ** 2)\n\n    def func(x):\n        return norm.psi(x) * (-x * np.exp(-x ** 2 / 2) / np.sqrt(2 * np.pi))\n    denom = integrate.quad(func, -np.inf, np.inf)[0]\n    return num / denom ** 2", "test_code_list": [{"test_code": "import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom statsmodels.robust.norms import AndrewWave\nfrom statsmodels.robust.norms import TrimmedMean\nfrom statsmodels.robust.norms import TukeyBiweight\nfrom statsmodels.robust.norms import Hampel\nfrom statsmodels.robust.norms import HuberT\ndef test_hampel_eff():\n    eff = 0.95\n    res_eff = 1 / _var_normal_jump(Hampel(a=1.35, b=2.7, c=5.4))\n    assert_allclose(res_eff, eff, atol=0.005)\n\ntest_hampel_eff()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_tools.py"}], "instruction": "Functionality: Computes the variance factor for the asymptotic relative efficiency of a mean M-estimator when the reference distribution is the standard normal distribution. This includes cases where the psi function is not continuous, such as in TrimmedMean norm.\n\nInputs:\n- norm: An instance of a RobustNorm subclass. This norm specifies the psi function for which the variance factor for the relative efficiency is to be calculated.\n\nOutputs:\n- Variance factor: A floating-point number representing the variance factor. This factor is used to determine the relative efficiency of the mean M-estimator. The relative efficiency is calculated as the inverse of this variance factor.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy import integrate\nfrom scipy import optimize\nfrom statsmodels.tools.testing import Holder\n\n\ndef _var_normal_jump(norm): [MASK]\n"}
{"method_name": "mahalanobis", "full_method_name": "mahalanobis", "method_path": "../srcdata/Computation/statsmodels/statsmodels/robust/covariance.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy import linalg\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.robust.norms as rnorms\nimport statsmodels.robust.scale as rscale\nfrom statsmodels.tools.testing import Holder\nimport warnings\ndef mahalanobis(data, cov=None, cov_inv=None, sqrt=False):\n    \"\"\"Mahalanobis distance squared\n\n    Note: this is without taking the square root.\n    assumes data is already centered.\n\n    Parameters\n    ----------\n    data : array-like\n        Multivariate data with observation in rows.\n    cov : None or ndarray\n        Covariance matrix used in computing distance.\n        This is only used if cov_inv is None.\n    cov_inv : None or ndarray\n        Inverse ovariance matrix used in computing distance.\n        One of cov and cov_inv needs to be provided.\n    sqrt : bool\n        If False, then the squared distance is returned.\n        If True, then the square root is returmend.\n\n    Return\n    ------\n    ndarray : Mahalanobis distances or squared distance.\n    \"\"\"\n    x = np.asarray(data)\n    if cov_inv is not None:\n        d = (x * cov_inv.dot(x.T).T).sum(1)\n    elif cov is not None:\n        d = (x * np.linalg.solve(cov, x.T).T).sum(1)\n    else:\n        raise ValueError('either cov or cov_inv needs to be given')\n    if sqrt:\n        d = np.sqrt(d)\n    return d", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom scipy import linalg\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom statsmodels import robust\nimport statsmodels.robust.norms as robnorms\nimport statsmodels.robust.scale as robscale\ndef test_mahalanobis():\n    np.random.seed(987676453)\n    x = np.random.randn(10, 3)\n    d1 = (x ** 2).sum(1)\n    d0 = mahalanobis(x, np.eye(3))\n    assert_allclose(d0, d1, rtol=1e-10)\n    d2 = mahalanobis(x, cov_inv=np.eye(3))\n    assert_allclose(d2, d1, rtol=1e-10)\n    d3 = mahalanobis(x, 2 * np.eye(3))\n    assert_allclose(d3, 0.5 * d1, rtol=1e-10)\n    d4 = mahalanobis(x, cov_inv=2 * np.eye(3))\n    assert_allclose(d4, 2 * d1, rtol=1e-10)\n\ntest_mahalanobis()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_covariance.py"}], "instruction": "Functionality: Calculate the Mahalanobis distance squared for multivariate data. This function aims to compute the distance of each observation (row) in the data from the mean, taking into account the covariance structure of the data. It does not take the square root by default, but this option is available.\n\nInputs:\n- data: array-like, represents the multivariate data with observations in rows.\n- cov: None or ndarray, an optional covariance matrix used in computing the distance. This parameter is only utilized if cov_inv is not provided.\n- cov_inv: None or ndarray, an optional inverse covariance matrix used in computing the distance. At least one of cov and cov_inv must be provided.\n- sqrt: bool, a flag indicating whether to return the square root of the Mahalanobis distance. If False, the squared distance is returned; if True, the square root is returned.\n\nOutputs:\n- ndarray: an array containing the Mahalanobis distances or squared distances for each observation in the data.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy import linalg\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.robust.norms as rnorms\nimport statsmodels.robust.scale as rscale\nfrom statsmodels.tools.testing import Holder\nimport warnings\n\n\ndef mahalanobis(data, cov=None, cov_inv=None, sqrt=False): [MASK]\n"}
{"method_name": "_outlier_gy", "full_method_name": "_outlier_gy", "method_path": "../srcdata/Computation/statsmodels/statsmodels/robust/covariance.py", "method_code": "import numpy as np\nfrom scipy import stats\nfrom scipy import linalg\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.robust.norms as rnorms\nimport statsmodels.robust.scale as rscale\nfrom statsmodels.tools.testing import Holder\nimport warnings\ndef _outlier_gy(d, distr=None, k_endog=1, trim_prob=0.975):\n    \"\"\"determine outlier fraction given reference distribution\n\n    This implements the outlier cutoff of Gervini and Yohai 2002\n    for use in efficient reweighting.\n\n    Parameters\n    ----------\n    d : array_like, 1-D\n        array of squared standardized residuals or Mahalanobis distance\n    distr : None or distribution instance\n        reference distribution of d, needs cdf and ppf methods.\n        If None, then chisquare with k_endog degrees of freedom is\n        used. Otherwise, it should be a callable that provides the\n        cdf function\n    k_endog : int or float\n        used only if cdf is None. In that case, it provides the degrees\n        of freedom for the chisquare distribution.\n    trim_prob : float in (0.5, 1)\n        threshold for the tail probability at which the search for\n        trimming or outlier fraction starts.\n\n    Returns\n    -------\n    frac : float\n        fraction of outliers\n    cutoff : float\n        cutoff value, values with `d > cutoff` are considered outliers\n    ntail : int\n        number of outliers\n    ntail0 : int\n        initial number of outliers based on trim tail probability.\n    cutoff0 : float\n        initial cutoff value based on trim tail probability.\n\n    Notes\n    -----\n    This does not fully correct for multiple testing and does not\n    maintain a familywise error rate or false discovery rate.\n    The error rate goes to zero asymptotically under the null model,\n    i.e. if there are no outliers.\n\n    This might not handle threshold points correctly with discrete\n    distribution.\n    TODO: check weak versus strict inequalities (e.g. in isf)\n\n    This only checks the upper tail of the distribution and of `d`.\n\n    \"\"\"\n    d = np.asarray(d)\n    nobs = d.shape[0]\n    if distr is None:\n        distr = stats.chi2(k_endog)\n    threshold = distr.isf(1 - trim_prob)\n    dtail = np.sort(d[d >= threshold])\n    ntail0 = len(dtail)\n    if ntail0 == 0:\n        return 0, threshold, 0, 0, threshold\n    ranks = np.arange(nobs - ntail0, nobs) / nobs\n    frac = np.maximum(0, distr.cdf(dtail) - ranks).max()\n    ntail = int(nobs * frac)\n    if ntail > 0:\n        cutoff = dtail[-ntail - 1]\n    else:\n        cutoff = dtail[-1] + 1e-15\n    if (dtail > cutoff).sum() < ntail:\n        import warnings\n        warnings.warn(\n            'ties at cutoff, cutoff rule produces feweroutliers than `ntail`')\n    return frac, cutoff, ntail, ntail0, threshold", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom scipy import linalg\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nfrom statsmodels import robust\nimport statsmodels.robust.norms as robnorms\nimport statsmodels.robust.scale as robscale\ndef test_outliers_gy():\n    seed = 567812\n    np.random.seed(seed)\n    nobs = 1000\n    x = np.random.randn(nobs)\n    d = x ** 2\n    d2 = d.copy()\n    n_outl = 10\n    d2[:n_outl] += 10\n    res = _outlier_gy(d2, distr=None, k_endog=1, trim_prob=0.975)\n    res1 = [0.01786544429608583, 8.416367423905008, 17.0, 42.0, \n        5.023886187314888]\n    assert_allclose(res, res1, rtol=1e-13)\n    reject_thr = (d2 > res[1]).sum()\n    reject_float = nobs * res[0]\n    assert_equal(reject_thr, res[2])\n    assert_equal(int(reject_float), res[2])\n    assert_equal((d2 > res[4]).sum(), res[3])\n    assert_allclose(res[3], nobs * 0.025 + n_outl, rtol=0.5)\n    x3 = x[:-1].reshape(-1, 3)\n    x3 = (x3 - x3.mean(0)) / x3.std(0)\n    d3 = (x3 ** 2).sum(1)\n    nobs = len(d3)\n    n_outl = 0\n    res = _outlier_gy(d3, distr=None, k_endog=3, trim_prob=0.975)\n    res1 = [0.008598069552744558, 12.605802816238732, 2.0, 9.0, \n        9.348403604496148]\n    assert_allclose(res, res1, rtol=1e-13)\n    reject_thr = (d3 > res[1]).sum()\n    reject_float = nobs * res[0]\n    assert_equal(reject_thr, res[2])\n    assert_equal(int(reject_float), res[2])\n    assert_equal((d3 > res[4]).sum(), res[3])\n    assert_allclose(res[3], nobs * 0.025 + n_outl, rtol=0.5)\n\ntest_outliers_gy()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/robust/tests/test_covariance.py"}], "instruction": "Functionality: The _outlier_gy function is designed to determine the fraction of outliers in a dataset based on the squared standardized residuals or Mahalanobis distance, using the methodology outlined by Gervini and Yohai in 2002. This function is particularly useful for efficient reweighting in statistical models.\n\nInputs: \n- d: An array_like, 1-D array of squared standardized residuals or Mahalanobis distance.\n- distr: An optional distribution instance that serves as the reference distribution for d. This parameter requires a callable with cdf (cumulative distribution function) and ppf (percent point function) methods. If None, a chi-square distribution with k_endog degrees of freedom is used.\n- k_endog: An int or float that specifies the degrees of freedom for the chi-square distribution when distr is None.\n- trim_prob: A float within the range (0.5, 1) indicating the threshold tail probability from which the search for the trimming or outlier fraction begins.\n\nOutputs:\n- frac: A float representing the fraction of outliers.\n- cutoff: A float indicating the cutoff value. Observations with a d value greater than this cutoff are considered outliers.\n- ntail: An int denoting the number of outliers.\n- ntail0: An int representing the initial number of outliers based on the trim tail probability.\n- cutoff0: A float representing the initial cutoff value determined by the trim tail probability.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nfrom scipy import linalg\nfrom scipy.linalg.lapack import dtrtri\nimport statsmodels.robust.norms as rnorms\nimport statsmodels.robust.scale as rscale\nfrom statsmodels.tools.testing import Holder\nimport warnings\n\n\ndef _outlier_gy(d, distr=None, k_endog=1, trim_prob=0.975): [MASK]\n"}
{"method_name": "multivariate_sample_data", "full_method_name": "multivariate_sample_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py", "method_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef multivariate_sample_data(seed=1):\n    n = 1000\n    x1 = np.linspace(-1, 1, n)\n    x2 = np.linspace(-10, 10, n)\n    x = np.vstack([x1, x2]).T\n    np.random.seed(seed)\n    y = x1 * x1 * x1 + x2 + np.random.normal(0, 0.01, n)\n    degree1 = 4\n    degree2 = 3\n    degrees = [degree1, degree2]\n    pol = PolynomialSmoother(x, degrees)\n    return x, y, pol", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_multivariate_penalty():\n    alphas = [1, 2]\n    weights = [1, 1]\n    np.random.seed(1)\n    x, y, pol = multivariate_sample_data()\n    univ_pol1 = UnivariatePolynomialSmoother(x[:, 0], degree=pol.degrees[0])\n    univ_pol2 = UnivariatePolynomialSmoother(x[:, 1], degree=pol.degrees[1])\n    gp1 = UnivariateGamPenalty(alpha=alphas[0], univariate_smoother=univ_pol1)\n    gp2 = UnivariateGamPenalty(alpha=alphas[1], univariate_smoother=univ_pol2)\n    with pytest.warns(UserWarning, match='weights is currently ignored'):\n        mgp = MultivariateGamPenalty(multivariate_smoother=pol, alpha=\n            alphas, weights=weights)\n    for i in range(10):\n        params1 = np.random.randint(-3, 3, pol.smoothers[0].dim_basis)\n        params2 = np.random.randint(-3, 3, pol.smoothers[1].dim_basis)\n        params = np.concatenate([params1, params2])\n        c1 = gp1.func(params1)\n        c2 = gp2.func(params2)\n        c = mgp.func(params)\n        assert_allclose(c, c1 + c2, atol=1e-10, rtol=1e-10)\n        d1 = gp1.deriv(params1)\n        d2 = gp2.deriv(params2)\n        d12 = np.concatenate([d1, d2])\n        d = mgp.deriv(params)\n        assert_allclose(d, d12)\n        h1 = gp1.deriv2(params1)\n        h2 = gp2.deriv2(params2)\n        h12 = block_diag(h1, h2)\n        h = mgp.deriv2(params)\n        assert_allclose(h, h12)\n\ntest_multivariate_penalty()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}, {"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_generic_smoother():\n    x, y, poly = multivariate_sample_data()\n    alphas = [0.4, 0.7]\n    weights = [1, 1]\n    gs = GenericSmoothers(poly.x, poly.smoothers)\n    gam_gs = GLMGam(y, smoother=gs, alpha=alphas)\n    gam_gs_res = gam_gs.fit()\n    gam_poly = GLMGam(y, smoother=poly, alpha=alphas)\n    gam_poly_res = gam_poly.fit()\n    assert_allclose(gam_gs_res.params, gam_poly_res.params)\n\ntest_generic_smoother()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}, {"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_zero_penalty():\n    x, y, poly = multivariate_sample_data()\n    alphas = [0, 0]\n    gam_gs = GLMGam(y, smoother=poly, alpha=alphas)\n    gam_gs_res = gam_gs.fit()\n    y_est_gam = gam_gs_res.predict()\n    glm = GLM(y, poly.basis).fit()\n    y_est = glm.predict()\n    assert_allclose(y_est, y_est_gam)\n\ntest_zero_penalty()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}], "instruction": "Functionality: Generates multivariate sample data for testing and analysis, including input data and a target variable, along with a polynomial smoother object to be used with the generated data.\n\nInputs:\n- seed: An integer representing the seed for the numpy random number generator. Default is 1. This argument ensures reproducibility of the data.\n\nOutputs:\n- x: A numpy array of shape (n, 2) containing the input data. The first column is x1, which is a linearly spaced array from -1 to 1, and the second column is x2, which is a linearly spaced array from -10 to 10.\n- y: A numpy array of shape (n,) representing the target variable. It is calculated as y = x1^3 + x2 + noise, where noise is normally distributed with mean 0 and standard deviation 0.01.\n- pol: A PolynomialSmoother object from statsmodels, initialized with the input data 'x' and degrees [4, 3] for the two variables, respectively. This object can be used for smoothing and fitting polynomial models to the data.", "method_code_mask": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\n\n\ndef multivariate_sample_data(seed=1): [MASK]\n"}
{"method_name": "matrix_sqrt", "full_method_name": "matrix_sqrt", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tools/linalg.py", "method_code": "import numpy as np\nfrom scipy import linalg\nimport warnings\ndef matrix_sqrt(mat, inverse=False, full=False, nullspace=False, threshold=\n    1e-15):\n    \"\"\"matrix square root for symmetric matrices\n\n    Usage is for decomposing a covariance function S into a square root R\n    such that\n\n        R' R = S if inverse is False, or\n        R' R = pinv(S) if inverse is True\n\n    Parameters\n    ----------\n    mat : array_like, 2-d square\n        symmetric square matrix for which square root or inverse square\n        root is computed.\n        There is no checking for whether the matrix is symmetric.\n        A warning is issued if some singular values are negative, i.e.\n        below the negative of the threshold.\n    inverse : bool\n        If False (default), then the matrix square root is returned.\n        If inverse is True, then the matrix square root of the inverse\n        matrix is returned.\n    full : bool\n        If full is False (default, then the square root has reduce number\n        of rows if the matrix is singular, i.e. has singular values below\n        the threshold.\n    nullspace : bool\n        If nullspace is true, then the matrix square root of the null space\n        of the matrix is returned.\n    threshold : float\n        Singular values below the threshold are dropped.\n\n    Returns\n    -------\n    msqrt : ndarray\n        matrix square root or square root of inverse matrix.\n    \"\"\"\n    u, s, v = np.linalg.svd(mat)\n    if np.any(s < -threshold):\n        import warnings\n        warnings.warn('some singular values are negative')\n    if not nullspace:\n        mask = s > threshold\n        s[s < threshold] = 0\n    else:\n        mask = s < threshold\n        s[s > threshold] = 0\n    sqrt_s = np.sqrt(s[mask])\n    if inverse:\n        sqrt_s = 1 / np.sqrt(s[mask])\n    if full:\n        b = np.dot(u[:, mask], np.dot(np.diag(sqrt_s), v[mask]))\n    else:\n        b = np.dot(np.diag(sqrt_s), v[mask])\n    return b", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_get_sqrt():\n    n = 1000\n    np.random.seed(1)\n    x = np.random.normal(0, 1, (n, 3))\n    x2 = np.dot(x.T, x)\n    sqrt_x2 = matrix_sqrt(x2)\n    x2_reconstruction = np.dot(sqrt_x2.T, sqrt_x2)\n    assert_allclose(x2_reconstruction, x2)\n\ntest_get_sqrt()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}, {"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_make_augmented_matrix():\n    np.random.seed(1)\n    n = 500\n    x = np.random.uniform(-1, 1, (n, 3))\n    s = np.dot(x.T, x)\n    y = np.array(list(range(n)))\n    w = np.random.uniform(0, 1, n)\n    nobs, n_columns = x.shape\n    alpha = 0\n    aug_y, aug_x, aug_w = make_augmented_matrix(y, x, alpha * s, w)\n    expected_aug_x = x\n    assert_allclose(aug_x, expected_aug_x)\n    expected_aug_y = y\n    expected_aug_y[:nobs] = y\n    assert_allclose(aug_y, expected_aug_y)\n    expected_aug_w = w\n    assert_allclose(aug_w, expected_aug_w)\n    alpha = 1\n    aug_y, aug_x, aug_w = make_augmented_matrix(y, x, s, w)\n    rs = matrix_sqrt(alpha * s)\n    assert_allclose(np.dot(rs.T, rs), alpha * s)\n    expected_aug_x = np.vstack([x, rs])\n    assert_allclose(aug_x, expected_aug_x)\n    expected_aug_y = np.zeros(shape=(nobs + n_columns,))\n    expected_aug_y[:nobs] = y\n    assert_allclose(aug_y, expected_aug_y)\n    expected_aug_w = np.concatenate((w, [1] * n_columns), axis=0)\n    assert_allclose(aug_w, expected_aug_w)\n\ntest_make_augmented_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}], "instruction": "Functionality: This function computes the square root of a symmetric matrix or the square root of its inverse. It can also return the matrix square root of the null space of the matrix. The function allows for computing the square root of the matrix or its inverse, with an option to return a full matrix or a reduced one if the matrix is singular. \n\nInputs: \n- mat: An array-like 2-D square matrix for which the square root or inverse square root is to be computed. It must be symmetric, but the function does not check for symmetry.\n- inverse: A boolean, default False. If True, it computes the square root of the inverse matrix.\n- full: A boolean, default False. If True, it returns a full matrix even if the matrix is singular.\n- nullspace: A boolean, default False. If True, it returns the matrix square root of the null space of the matrix.\n- threshold: A float, default 1e-15. Singular values below this threshold are dropped.\n\nOutputs: \n- msqrt: An ndarray representing the matrix square root or square root of the inverse matrix, depending on the parameters provided.", "method_code_mask": "import numpy as np\nfrom scipy import linalg\nimport warnings\n\n\ndef matrix_sqrt(mat, inverse=False, full=False, nullspace=False, threshold=\n    1e-15): [MASK]\n"}
{"method_name": "make_augmented_matrix", "full_method_name": "make_augmented_matrix", "method_path": "../srcdata/Computation/statsmodels/statsmodels/gam/generalized_additive_model.py", "method_code": "from collections.abc import Iterable\nimport copy\nimport numpy as np\nfrom scipy import optimize\nimport pandas as pd\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import GLMResults\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import _check_convergence\nimport statsmodels.regression.linear_model as lm\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.base._penalized import PenalizedMixin\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom patsy import dmatrix\nimport warnings\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\ndef make_augmented_matrix(endog, exog, penalty_matrix, weights):\n    \"\"\"augment endog, exog and weights with stochastic restriction matrix\n\n    Parameters\n    ----------\n    endog : ndarray\n        response or endogenous variable\n    exog : ndarray\n        design matrix, matrix of exogenous or explanatory variables\n    penalty_matrix : ndarray, 2-Dim square\n        penality matrix for quadratic penalization\n    weights : ndarray\n        weights for WLS\n\n    Returns\n    -------\n    endog_aug : ndarray\n        augmented response variable\n    exog_aug : ndarray\n        augmented design matrix\n    weights_aug : ndarray\n        augmented weights for WLS\n    \"\"\"\n    y, x, s = endog, exog, penalty_matrix\n    nobs = x.shape[0]\n    rs = matrix_sqrt(s)\n    x1 = np.vstack([x, rs])\n    n_samp1es_x1 = x1.shape[0]\n    y1 = np.array([0.0] * n_samp1es_x1)\n    y1[:nobs] = y\n    id1 = np.array([1.0] * rs.shape[0])\n    w1 = np.concatenate([weights, id1])\n    return y1, x1, w1", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_make_augmented_matrix():\n    np.random.seed(1)\n    n = 500\n    x = np.random.uniform(-1, 1, (n, 3))\n    s = np.dot(x.T, x)\n    y = np.array(list(range(n)))\n    w = np.random.uniform(0, 1, n)\n    nobs, n_columns = x.shape\n    alpha = 0\n    aug_y, aug_x, aug_w = make_augmented_matrix(y, x, alpha * s, w)\n    expected_aug_x = x\n    assert_allclose(aug_x, expected_aug_x)\n    expected_aug_y = y\n    expected_aug_y[:nobs] = y\n    assert_allclose(aug_y, expected_aug_y)\n    expected_aug_w = w\n    assert_allclose(aug_w, expected_aug_w)\n    alpha = 1\n    aug_y, aug_x, aug_w = make_augmented_matrix(y, x, s, w)\n    rs = matrix_sqrt(alpha * s)\n    assert_allclose(np.dot(rs.T, rs), alpha * s)\n    expected_aug_x = np.vstack([x, rs])\n    assert_allclose(aug_x, expected_aug_x)\n    expected_aug_y = np.zeros(shape=(nobs + n_columns,))\n    expected_aug_y[:nobs] = y\n    assert_allclose(aug_y, expected_aug_y)\n    expected_aug_w = np.concatenate((w, [1] * n_columns), axis=0)\n    assert_allclose(aug_w, expected_aug_w)\n\ntest_make_augmented_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}], "instruction": "Functionality: The make_augmented_matrix function augments the input matrices, endog (endogenous variable), exog (explanatory variables), and weights, with a stochastic restriction matrix, penalty_matrix. The augmentation is used for applying quadratic penalization in Weighted Least Squares (WLS) regression analysis.\n\nInputs:\n1. endog: An ndarray representing the response or endogenous variable.\n2. exog: An ndarray representing the design matrix, matrix of exogenous or explanatory variables.\n3. penalty_matrix: An ndarray of 2-Dim square shape, which is the penalty matrix for quadratic penalization.\n4. weights: An ndarray representing the weights for WLS.\n\nOutputs:\n1. endog_aug: An augmented ndarray representing the response variable.\n2. exog_aug: An augmented ndarray representing the design matrix.\n3. weights_aug: An augmented ndarray representing the weights for WLS.", "method_code_mask": "from collections.abc import Iterable\nimport copy\nimport numpy as np\nfrom scipy import optimize\nimport pandas as pd\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import GLMResults\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import _check_convergence\nimport statsmodels.regression.linear_model as lm\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.base._penalized import PenalizedMixin\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom patsy import dmatrix\nimport warnings\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\n\n\ndef make_augmented_matrix(endog, exog, penalty_matrix, weights): [MASK]\n"}
{"method_name": "penalized_wls", "full_method_name": "penalized_wls", "method_path": "../srcdata/Computation/statsmodels/statsmodels/gam/generalized_additive_model.py", "method_code": "from collections.abc import Iterable\nimport copy\nimport numpy as np\nfrom scipy import optimize\nimport pandas as pd\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import GLMResults\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import _check_convergence\nimport statsmodels.regression.linear_model as lm\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.base._penalized import PenalizedMixin\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom patsy import dmatrix\nimport warnings\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\ndef penalized_wls(endog, exog, penalty_matrix, weights):\n    \"\"\"weighted least squares with quadratic penalty\n\n    Parameters\n    ----------\n    endog : ndarray\n        response or endogenous variable\n    exog : ndarray\n        design matrix, matrix of exogenous or explanatory variables\n    penalty_matrix : ndarray, 2-Dim square\n        penality matrix for quadratic penalization. Note, the penalty_matrix\n        is multiplied by two to match non-pirls fitting methods.\n    weights : ndarray\n        weights for WLS\n\n    Returns\n    -------\n    results : Results instance of WLS\n    \"\"\"\n    y, x, s = endog, exog, penalty_matrix\n    aug_y, aug_x, aug_weights = make_augmented_matrix(y, x, 2 * s, weights)\n    wls_results = lm.WLS(aug_y, aug_x, aug_weights).fit()\n    wls_results.params = wls_results.params.ravel()\n    return wls_results", "test_code_list": [{"test_code": "import os\nimport numpy as np\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nfrom scipy.linalg import block_diag\nimport pytest\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.gam.smooth_basis import UnivariatePolynomialSmoother\nfrom statsmodels.gam.smooth_basis import PolynomialSmoother\nfrom statsmodels.gam.smooth_basis import BSplines\nfrom statsmodels.gam.smooth_basis import GenericSmoothers\nfrom statsmodels.gam.smooth_basis import UnivariateCubicSplines\nfrom statsmodels.gam.smooth_basis import CyclicCubicSplines\nfrom statsmodels.gam.generalized_additive_model import GLMGam\nfrom statsmodels.gam.generalized_additive_model import LogitGam\nfrom statsmodels.gam.generalized_additive_model import make_augmented_matrix\nfrom statsmodels.gam.generalized_additive_model import penalized_wls\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCV\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import _split_train_test_smoothers\nfrom statsmodels.gam.gam_penalties import UnivariateGamPenalty\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.families.family import Gaussian\nfrom statsmodels.genmod.generalized_linear_model import lm\nfrom statsmodels.gam.smooth_basis import CubicSplines\ndef test_penalized_wls():\n    np.random.seed(1)\n    n = 20\n    p = 3\n    x = np.random.normal(0, 1, (n, 3))\n    y = x[:, 1] - x[:, 2] + np.random.normal(0, 0.1, n)\n    y -= y.mean()\n    weights = np.ones(shape=(n,))\n    s = np.random.normal(0, 1, (p, p))\n    pen_wls_res = penalized_wls(y, x, 0 * s, weights)\n    ls_res = lm.OLS(y, x).fit()\n    assert_allclose(ls_res.params, pen_wls_res.params)\n\ntest_penalized_wls()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/gam/tests/test_gam.py"}], "instruction": "Functionality: The penalized_wls function implements weighted least squares (WLS) regression with an additional quadratic penalty. This function is particularly useful for cases where the regression model may benefit from penalizing large parameter estimates, which can help in reducing overfitting. The function modifies the input data by augmenting it with the penalty matrix and then fits a WLS model to the augmented data.\n\nInputs:\n    endog : ndarray\n        A one-dimensional array representing the response or endogenous variable in the regression model.\n    exog : ndarray\n        A two-dimensional array serving as the design matrix. This matrix contains the exogenous or explanatory variables used to predict the endogenous variable.\n    penalty_matrix : ndarray, 2-Dim square\n        A square matrix used to apply a quadratic penalty to the regression coefficients. This penalty matrix is multiplied by two for compatibility with non-penalized least squares fitting methods.\n    weights : ndarray\n        A one-dimensional array of weights for each observation in the WLS model. These weights affect how much each observation contributes to the fitting of the model.\n\nOutputs:\n    results : Results instance of WLS\n        The output is an instance of the Results class from statsmodels, which encapsulates the results of the WLS regression with penalty. This includes the estimated coefficients, standard errors, p-values, and other statistical measures that help in assessing the quality of the fit.", "method_code_mask": "from collections.abc import Iterable\nimport copy\nimport numpy as np\nfrom scipy import optimize\nimport pandas as pd\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.discrete.discrete_model import Logit\nfrom statsmodels.genmod.generalized_linear_model import GLM\nfrom statsmodels.genmod.generalized_linear_model import GLMResults\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import _check_convergence\nimport statsmodels.regression.linear_model as lm\nfrom statsmodels.tools.sm_exceptions import PerfectSeparationError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.linalg import matrix_sqrt\nfrom statsmodels.base._penalized import PenalizedMixin\nfrom statsmodels.gam.gam_penalties import MultivariateGamPenalty\nfrom statsmodels.gam.gam_cross_validation.gam_cross_validation import MultivariateGAMCVPath\nfrom statsmodels.gam.gam_cross_validation.cross_validators import KFold\nfrom patsy import dmatrix\nimport warnings\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\n\n\ndef penalized_wls(endog, exog, penalty_matrix, weights): [MASK]\n"}
{"method_name": "gendat", "full_method_name": "gendat", "method_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py", "method_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\ndef gendat():\n    \"\"\"\n    Create a data set with missing values.\n    \"\"\"\n    gen = np.random.RandomState(34243)\n    n = 200\n    p = 5\n    exog = gen.normal(size=(n, p))\n    exog[:, 0] = exog[:, 1] - exog[:, 2] + 2 * exog[:, 4]\n    exog[:, 0] += gen.normal(size=n)\n    exog[:, 2] = 1 * (exog[:, 2] > 0)\n    endog = exog.sum(1) + gen.normal(size=n)\n    df = pd.DataFrame(exog)\n    df.columns = [('x%d' % k) for k in range(1, p + 1)]\n    df['y'] = endog\n    df.loc[0:59, 'x1'] = np.nan\n    df.loc[0:39, 'x2'] = np.nan\n    df.loc[10:29:2, 'x3'] = np.nan\n    df.loc[20:49:3, 'x4'] = np.nan\n    df.loc[40:44, 'x5'] = np.nan\n    df.loc[30:99:2, 'y'] = np.nan\n    return df", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICEData():\n\tdef test_default(self):\n\t    df = gendat()\n\t    orig = df.copy()\n\t    mx = pd.notnull(df)\n\t    imp_data = mice.MICEData(df)\n\t    nrow, ncol = df.shape\n\t    assert_allclose(imp_data.ix_miss['x1'], np.arange(60))\n\t    assert_allclose(imp_data.ix_obs['x1'], np.arange(60, 200))\n\t    assert_allclose(imp_data.ix_miss['x2'], np.arange(40))\n\t    assert_allclose(imp_data.ix_miss['x3'], np.arange(10, 30, 2))\n\t    assert_allclose(imp_data.ix_obs['x3'], np.concatenate((np.arange(10),\n\t        np.arange(11, 30, 2), np.arange(30, 200))))\n\t    assert_equal([set(imp_data.data[col]) for col in imp_data.data], [set(\n\t        df[col].dropna()) for col in df])\n\t    for k in range(3):\n\t        imp_data.update_all()\n\t        assert_equal(imp_data.data.shape[0], nrow)\n\t        assert_equal(imp_data.data.shape[1], ncol)\n\t        assert_allclose(orig[mx], imp_data.data[mx])\n\t        assert_equal([set(imp_data.data[col]) for col in imp_data.data], [\n\t            set(df[col].dropna()) for col in df])\n\t    fml = 'x1 ~ x2 + x3 + x4 + x5 + y'\n\t    assert_equal(imp_data.conditional_formula['x1'], fml)\n\t    assert tuple(imp_data._cycle_order) in (('x5', 'x3', 'x4', 'y', 'x2',\n\t        'x1'), ('x5', 'x4', 'x3', 'y', 'x2', 'x1'))\n\t    assert df is not imp_data.data\n\t    endog_obs, exog_obs, exog_miss, predict_obs_kwds, predict_miss_kwds = (\n\t        imp_data.get_split_data('x3'))\n\t    assert_equal(len(endog_obs), 190)\n\t    assert_equal(exog_obs.shape, [190, 6])\n\t    assert_equal(exog_miss.shape, [10, 6])\n\t\nTestMICEData().test_default()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICEData():\n\tdef test_settingwithcopywarning(self):\n\t    \"\"\"Test that MICEData does not throw a SettingWithCopyWarning when imputing (https://github.com/statsmodels/statsmodels/issues/5430)\"\"\"\n\t    df = gendat()\n\t    df['intcol'] = np.arange(len(df))\n\t    df['intcol'] = df.intcol.astype('int32')\n\t    miceData = mice.MICEData(df)\n\t    with pd.option_context('mode.chained_assignment', 'warn'):\n\t        with warnings.catch_warnings(record=True) as ws:\n\t            warnings.simplefilter('always')\n\t            miceData.update_all()\n\t            ws = [w for w in ws if '\\\\pandas\\\\' in w.filename]\n\t            assert len(ws) == 0\n\t\nTestMICEData().test_settingwithcopywarning()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICEData():\n\tdef test_next_sample(self):\n\t    df = gendat()\n\t    imp_data = mice.MICEData(df)\n\t    all_x = []\n\t    for j in range(2):\n\t        x = imp_data.next_sample()\n\t        assert isinstance(x, pd.DataFrame)\n\t        assert_equal(df.shape, x.shape)\n\t        all_x.append(x)\n\t    assert all_x[0] is all_x[1]\n\t\nTestMICEData().test_next_sample()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICEData():\n\tdef test_pertmeth(self):\n\t    df = gendat()\n\t    orig = df.copy()\n\t    mx = pd.notnull(df)\n\t    nrow, ncol = df.shape\n\t    for pert_meth in ('gaussian', 'boot'):\n\t        imp_data = mice.MICEData(df, perturbation_method=pert_meth)\n\t        for k in range(2):\n\t            imp_data.update_all()\n\t            assert_equal(imp_data.data.shape[0], nrow)\n\t            assert_equal(imp_data.data.shape[1], ncol)\n\t            assert_allclose(orig[mx], imp_data.data[mx])\n\t    assert tuple(imp_data._cycle_order) in (('x5', 'x3', 'x4', 'y', 'x2',\n\t        'x1'), ('x5', 'x4', 'x3', 'y', 'x2', 'x1'))\n\t\nTestMICEData().test_pertmeth()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICEData():\n\tdef test_set_imputer(self):\n\t    from statsmodels.regression.linear_model import RegressionResultsWrapper\n\t    from statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\t    df = gendat()\n\t    orig = df.copy()\n\t    mx = pd.notnull(df)\n\t    nrow, ncol = df.shape\n\t    imp_data = mice.MICEData(df)\n\t    imp_data.set_imputer('x1', 'x3 + x4 + x3*x4')\n\t    imp_data.set_imputer('x2', 'x4 + I(x5**2)')\n\t    imp_data.set_imputer('x3', model_class=sm.GLM, init_kwds={'family': sm.\n\t        families.Binomial()})\n\t    imp_data.update_all()\n\t    assert_equal(imp_data.data.shape[0], nrow)\n\t    assert_equal(imp_data.data.shape[1], ncol)\n\t    assert_allclose(orig[mx], imp_data.data[mx])\n\t    for j in range(1, 6):\n\t        if j == 3:\n\t            assert_equal(isinstance(imp_data.models['x3'], sm.GLM), True)\n\t            assert_equal(isinstance(imp_data.models['x3'].family, sm.\n\t                families.Binomial), True)\n\t            assert_equal(isinstance(imp_data.results['x3'],\n\t                GLMResultsWrapper), True)\n\t        else:\n\t            assert_equal(isinstance(imp_data.models['x%d' % j], sm.OLS), True)\n\t            assert_equal(isinstance(imp_data.results['x%d' % j],\n\t                RegressionResultsWrapper), True)\n\t    fml = 'x1 ~ x3 + x4 + x3*x4'\n\t    assert_equal(imp_data.conditional_formula['x1'], fml)\n\t    fml = 'x4 ~ x1 + x2 + x3 + x5 + y'\n\t    assert_equal(imp_data.conditional_formula['x4'], fml)\n\t    assert tuple(imp_data._cycle_order) in (('x5', 'x3', 'x4', 'y', 'x2',\n\t        'x1'), ('x5', 'x4', 'x3', 'y', 'x2', 'x1'))\n\t\nTestMICEData().test_set_imputer()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICE():\n\tdef test_MICE(self):\n\t    df = gendat()\n\t    imp_data = mice.MICEData(df)\n\t    mi = mice.MICE('y ~ x1 + x2 + x1:x2', sm.OLS, imp_data)\n\t    result = mi.fit(1, 3)\n\t    assert issubclass(result.__class__, mice.MICEResults)\n\t    smr = result.summary()\n\t\nTestMICE().test_MICE()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICE():\n\tdef test_MICE1(self):\n\t    df = gendat()\n\t    imp_data = mice.MICEData(df)\n\t    mi = mice.MICE('y ~ x1 + x2 + x1:x2', sm.OLS, imp_data)\n\t    from statsmodels.regression.linear_model import RegressionResultsWrapper\n\t    for j in range(3):\n\t        x = mi.next_sample()\n\t        assert issubclass(x.__class__, RegressionResultsWrapper)\n\t\nTestMICE().test_MICE1()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\nclass TestMICE():\n\tdef test_MICE2(self):\n\t    from statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\t    df = gendat()\n\t    imp_data = mice.MICEData(df)\n\t    mi = mice.MICE('x3 ~ x1 + x2', sm.GLM, imp_data, init_kwds={'family':\n\t        sm.families.Binomial()})\n\t    for j in range(3):\n\t        x = mi.next_sample()\n\t        assert isinstance(x, GLMResultsWrapper)\n\t        assert isinstance(x.family, sm.families.Binomial)\n\t\nTestMICE().test_MICE2()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_mice.py"}], "instruction": "Functionality: Create a data set with missing values for a given set of features and an outcome variable. This function is designed to generate a synthetic data set that can be used for testing data analysis and machine learning methods that deal with missing data.\n\nInputs: None. The function uses default parameters for generating the data set.\n\nOutputs: A pandas DataFrame containing the synthetic data set. The DataFrame includes p columns of independent variables named 'x1' to 'x5' and one dependent variable named 'y'. The values for 'x1', 'x2', 'x3', 'x4', and 'x5' are generated using np.random.normal and specific manipulations, while the values for 'y' are the sum of the other columns plus some random noise. The function also intentionally introduces missing values at specific rows for 'x1', 'x2', 'x3', 'x4', 'x5', and 'y'.", "method_code_mask": "import numpy as np\nimport pandas as pd\nimport pytest\nfrom statsmodels.imputation import mice\nimport statsmodels.api as sm\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom statsmodels.duration.hazard_regression import PHReg\nfrom statsmodels.regression.linear_model import RegressionResultsWrapper\nfrom statsmodels.genmod.generalized_linear_model import GLMResultsWrapper\n\n\ndef gendat(): [MASK]\n"}
{"method_name": "_ros_group_rank", "full_method_name": "_ros_group_rank", "method_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/ros.py", "method_code": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef _ros_group_rank(df, dl_idx, censorship):\n    \"\"\"\n    Ranks each observation within the data groups.\n\n    In this case, the groups are defined by the record's detection\n    limit index and censorship status.\n\n    Parameters\n    ----------\n    df : DataFrame\n\n    dl_idx : str\n        Name of the column in the dataframe the index of the\n        observations' corresponding detection limit in the `cohn`\n        dataframe.\n\n    censorship : str\n        Name of the column in the dataframe that indicates that a\n        observation is left-censored. (i.e., True -> censored,\n        False -> uncensored)\n\n    Returns\n    -------\n    ranks : ndarray\n        Array of ranks for the dataset.\n    \"\"\"\n    ranks = df.copy()\n    ranks.loc[:, 'rank'] = 1\n    ranks = ranks.groupby(by=[dl_idx, censorship])['rank'].transform(lambda\n        g: g.cumsum())\n    return ranks", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef test__ros_group_rank():\n    df = pandas.DataFrame({'dl_idx': [1] * 12, 'params': list('AABCCCDE') +\n        list('DCBA'), 'values': list(range(12))})\n    result = _ros_group_rank(df, 'dl_idx', 'params')\n    expected = pandas.Series([1, 2, 1, 1, 2, 3, 1, 1, 2, 4, 2, 3], name='rank')\n    assert_series_equal(result.astype(int), expected.astype(int))\n\ntest__ros_group_rank()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py"}], "instruction": "Functionality: The function _ros_group_rank is designed to rank each observation within data groups based on the record's detection limit index and censorship status. It processes a DataFrame, grouping observations by the detection limit index and censorship status, then assigns cumulative ranks to each observation within these groups.\n\nInputs:\n- df : DataFrame\n    The input DataFrame containing the data to be ranked.\n- dl_idx : str\n    The name of the column in the DataFrame that holds the index of the observations' corresponding detection limit in the `cohn` dataframe.\n- censorship : str\n    The name of the column in the DataFrame that indicates if an observation is left-censored. True represents a censored observation, and False represents an uncensored one.\n\nOutputs:\n- ranks : ndarray\n    An array containing the ranks for each observation in the dataset. The ranks are assigned based on the cumulative sum of occurrences within each group defined by the detection limit index and censorship status.", "method_code_mask": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\n\ndef _ros_group_rank(df, dl_idx, censorship): [MASK]\n"}
{"method_name": "_norm_plot_pos", "full_method_name": "_norm_plot_pos", "method_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/ros.py", "method_code": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\ndef _norm_plot_pos(observations):\n    \"\"\"\n    Computes standard normal (Gaussian) plotting positions using scipy.\n\n    Parameters\n    ----------\n    observations : array_like\n        Sequence of observed quantities.\n\n    Returns\n    -------\n    plotting_position : array of floats\n    \"\"\"\n    ppos, sorted_res = stats.probplot(observations, fit=False)\n    return stats.norm.cdf(ppos)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef test__norm_plot_pos():\n    result = _norm_plot_pos([1, 2, 3, 4])\n    expected = numpy.array([0.159104, 0.385452, 0.614548, 0.840896])\n    npt.assert_array_almost_equal(result, expected)\n\ntest__norm_plot_pos()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py"}], "instruction": "Functionality: This function computes standard normal (Gaussian) plotting positions for a given set of observations. It uses the scipy library to calculate the plotting positions and then applies the cumulative distribution function (CDF) of the standard normal distribution to these positions.\n\nInputs: \n- observations: An array-like object representing a sequence of observed quantities. This could be a list, numpy array, or any iterable container of numerical values.\n\nOutputs:\n- plotting_position: An array of floats representing the plotting positions that are calculated from the input observations. These positions are transformed using the CDF of the standard normal distribution.", "method_code_mask": "import warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\n\ndef _norm_plot_pos(observations): [MASK]\n"}
{"method_name": "load_advanced_data", "full_method_name": "load_advanced_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py", "method_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef load_advanced_data():\n    df = pandas.DataFrame([{'Zprelim': -1.4456202174142005, 'censored': \n        True, 'conc': 5.0, 'det_limit_index': 1, 'plot_pos': \n        0.07414187643020594, 'rank': 1}, {'Zprelim': -1.2201035333697587,\n        'censored': True, 'conc': 5.0, 'det_limit_index': 1, 'plot_pos': \n        0.11121281464530891, 'rank': 2}, {'Zprelim': -1.043822530159519,\n        'censored': True, 'conc': 5.5, 'det_limit_index': 2, 'plot_pos': \n        0.14828375286041187, 'rank': 1}, {'Zprelim': -1.0438225301595188,\n        'censored': True, 'conc': 5.75, 'det_limit_index': 3, 'plot_pos': \n        0.1482837528604119, 'rank': 1}, {'Zprelim': -0.8109553641377003,\n        'censored': True, 'conc': 9.5, 'det_limit_index': 4, 'plot_pos': \n        0.20869565217391303, 'rank': 1}, {'Zprelim': -0.4046779045300476,\n        'censored': True, 'conc': 9.5, 'det_limit_index': 4, 'plot_pos': \n        0.34285714285714286, 'rank': 2}, {'Zprelim': -0.20857169501420522,\n        'censored': True, 'conc': 11.0, 'det_limit_index': 5, 'plot_pos': \n        0.41739130434782606, 'rank': 1}, {'Zprelim': -1.5927654676048002,\n        'censored': False, 'conc': 2.0, 'det_limit_index': 0, 'plot_pos': \n        0.055606407322654455, 'rank': 1}, {'Zprelim': -1.2201035333697587,\n        'censored': False, 'conc': 4.2, 'det_limit_index': 0, 'plot_pos': \n        0.11121281464530891, 'rank': 2}, {'Zprelim': -0.9668111610681008,\n        'censored': False, 'conc': 4.62, 'det_limit_index': 0, 'plot_pos': \n        0.16681922196796337, 'rank': 3}, {'Zprelim': -0.6835186393930371,\n        'censored': False, 'conc': 5.57, 'det_limit_index': 2, 'plot_pos': \n        0.24713958810068648, 'rank': 1}, {'Zprelim': -0.6072167256926887,\n        'censored': False, 'conc': 5.66, 'det_limit_index': 2, 'plot_pos': \n        0.27185354691075514, 'rank': 2}, {'Zprelim': -0.44953240276543616,\n        'censored': False, 'conc': 5.86, 'det_limit_index': 3, 'plot_pos': \n        0.3265238194299979, 'rank': 1}, {'Zprelim': -0.36788328223414807,\n        'censored': False, 'conc': 6.65, 'det_limit_index': 3, 'plot_pos': \n        0.35648013313917204, 'rank': 2}, {'Zprelim': -0.28861907892223937,\n        'censored': False, 'conc': 6.78, 'det_limit_index': 3, 'plot_pos': \n        0.38643644684834616, 'rank': 3}, {'Zprelim': -0.21113039741112186,\n        'censored': False, 'conc': 6.79, 'det_limit_index': 3, 'plot_pos': \n        0.4163927605575203, 'rank': 4}, {'Zprelim': -0.1348908823006299,\n        'censored': False, 'conc': 7.5, 'det_limit_index': 3, 'plot_pos': \n        0.4463490742666944, 'rank': 5}, {'Zprelim': -0.05942854708257491,\n        'censored': False, 'conc': 7.5, 'det_limit_index': 3, 'plot_pos': \n        0.4763053879758685, 'rank': 6}, {'Zprelim': 0.015696403006170083,\n        'censored': False, 'conc': 7.5, 'det_limit_index': 3, 'plot_pos': \n        0.5062617016850427, 'rank': 7}, {'Zprelim': 0.09091016994359362,\n        'censored': False, 'conc': 8.63, 'det_limit_index': 3, 'plot_pos': \n        0.5362180153942168, 'rank': 8}, {'Zprelim': 0.16664251178856201,\n        'censored': False, 'conc': 8.71, 'det_limit_index': 3, 'plot_pos': \n        0.5661743291033909, 'rank': 9}, {'Zprelim': 0.24334426739770573,\n        'censored': False, 'conc': 8.99, 'det_limit_index': 3, 'plot_pos': \n        0.596130642812565, 'rank': 10}, {'Zprelim': 0.3744432988606558,\n        'censored': False, 'conc': 9.85, 'det_limit_index': 4, 'plot_pos': \n        0.6459627329192545, 'rank': 1}, {'Zprelim': 0.4284507519609981,\n        'censored': False, 'conc': 10.82, 'det_limit_index': 4, 'plot_pos':\n        0.6658385093167701, 'rank': 2}, {'Zprelim': 0.5589578655042562,\n        'censored': False, 'conc': 11.25, 'det_limit_index': 5, 'plot_pos':\n        0.7119047619047619, 'rank': 1}, {'Zprelim': 0.6374841609623771,\n        'censored': False, 'conc': 11.25, 'det_limit_index': 5, 'plot_pos':\n        0.7380952380952381, 'rank': 2}, {'Zprelim': 0.7201566171385521,\n        'censored': False, 'conc': 12.2, 'det_limit_index': 5, 'plot_pos': \n        0.7642857142857142, 'rank': 3}, {'Zprelim': 0.8080746339118065,\n        'censored': False, 'conc': 14.92, 'det_limit_index': 5, 'plot_pos':\n        0.7904761904761904, 'rank': 4}, {'Zprelim': 0.9027347916438648,\n        'censored': False, 'conc': 16.77, 'det_limit_index': 5, 'plot_pos':\n        0.8166666666666667, 'rank': 5}, {'Zprelim': 1.0062699858608395,\n        'censored': False, 'conc': 17.81, 'det_limit_index': 5, 'plot_pos':\n        0.8428571428571429, 'rank': 6}, {'Zprelim': 1.1219004674623523,\n        'censored': False, 'conc': 19.16, 'det_limit_index': 5, 'plot_pos':\n        0.8690476190476191, 'rank': 7}, {'Zprelim': 1.2548759122271174,\n        'censored': False, 'conc': 19.19, 'det_limit_index': 5, 'plot_pos':\n        0.8952380952380953, 'rank': 8}, {'Zprelim': 1.414746425534976,\n        'censored': False, 'conc': 19.64, 'det_limit_index': 5, 'plot_pos':\n        0.9214285714285714, 'rank': 9}, {'Zprelim': 1.622193585315426,\n        'censored': False, 'conc': 20.18, 'det_limit_index': 5, 'plot_pos':\n        0.9476190476190476, 'rank': 10}, {'Zprelim': 1.9399896117517081,\n        'censored': False, 'conc': 22.97, 'det_limit_index': 5, 'plot_pos':\n        0.9738095238095239, 'rank': 11}])\n    return df", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef test__impute():\n    expected = numpy.array([3.11279729, 3.60634338, 4.04602788, 4.04602788,\n        4.71008116, 6.14010906, 6.97841457, 2.0, 4.2, 4.62, 5.57, 5.66, \n        5.86, 6.65, 6.78, 6.79, 7.5, 7.5, 7.5, 8.63, 8.71, 8.99, 9.85, \n        10.82, 11.25, 11.25, 12.2, 14.92, 16.77, 17.81, 19.16, 19.19, 19.64,\n        20.18, 22.97])\n    df = load_advanced_data()\n    df = ros._impute(df, 'conc', 'censored', numpy.log, numpy.exp)\n    result = df['final'].values\n    npt.assert_array_almost_equal(result, expected)\n\ntest__impute()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py"}], "instruction": "Functionality: The 'load_advanced_data' function is designed to generate a pandas DataFrame containing a specific set of data. This data is organized into a dictionary for each row, and these dictionaries are then combined into a DataFrame. The DataFrame consists of several columns, including 'Zprelim', 'censored', 'conc', 'det_limit_index', 'plot_pos', and 'rank'. Each row represents an observation with these attributes.\n\nInputs: There are no input arguments for this function. It is designed to be called without any parameters.\n\nOutputs: The function returns a pandas DataFrame. This DataFrame contains 42 rows, each with the following columns: 'Zprelim', 'censored', 'conc', 'det_limit_index', 'plot_pos', and 'rank'. The 'Zprelim' column holds the preliminary z-score values, 'censored' indicates whether the observation is censored (True or False), 'conc' holds the concentration value, 'det_limit_index' is an index related to detection limits, 'plot_pos' represents the plotting position, and 'rank' is the rank of the observation.", "method_code_mask": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\n\n\ndef load_advanced_data(): [MASK]\n"}
{"method_name": "load_basic_data", "full_method_name": "load_basic_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py", "method_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef load_basic_data():\n    raw_csv = StringIO(\n        \"\"\"res,qual\n2.00,=\n4.20,=\n4.62,=\n5.00,ND\n5.00,ND\n5.50,ND\n5.57,=\n5.66,=\n5.75,ND\n5.86,=\n6.65,=\n6.78,=\n6.79,=\n7.50,=\n7.50,=\n7.50,=\n8.63,=\n8.71,=\n8.99,=\n9.50,ND\n9.50,ND\n9.85,=\n10.82,=\n11.00,ND\n11.25,=\n11.25,=\n12.20,=\n14.92,=\n16.77,=\n17.81,=\n19.16,=\n19.19,=\n19.64,=\n20.18,=\n22.97,=\n\"\"\"\n        )\n    df = pandas.read_csv(raw_csv)\n    df.loc[:, 'conc'] = df['res']\n    df.loc[:, 'censored'] = df['qual'] == 'ND'\n    return df", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\ndef test__do_ros():\n    expected = numpy.array([3.11279729, 3.60634338, 4.04602788, 4.04602788,\n        4.71008116, 6.14010906, 6.97841457, 2.0, 4.2, 4.62, 5.57, 5.66, \n        5.86, 6.65, 6.78, 6.79, 7.5, 7.5, 7.5, 8.63, 8.71, 8.99, 9.85, \n        10.82, 11.25, 11.25, 12.2, 14.92, 16.77, 17.81, 19.16, 19.19, 19.64,\n        20.18, 22.97])\n    df = load_basic_data()\n    df = ros._do_ros(df, 'conc', 'censored', numpy.log, numpy.exp)\n    result = df['final'].values\n    npt.assert_array_almost_equal(result, expected)\n\ntest__do_ros()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/imputation/tests/test_ros.py"}], "instruction": "Functionality: The load_basic_data function is designed to load a predefined CSV data string into a pandas DataFrame. This data contains two columns: 'res' and 'qual'. The function processes this data by creating a new column 'conc' which is a copy of the 'res' column, and another column 'censored' which is a boolean indicating whether the quality ('qual') is 'ND' (Not Detectable). \n\nInputs: None\n\nOutputs: A pandas DataFrame with the following columns:\n- 'res': Represents the result values from the CSV data.\n- 'qual': Represents the quality indicators from the CSV data ('=' for detected, 'ND' for not detectable).\n- 'conc': A copy of the 'res' column.\n- 'censored': A boolean column indicating if 'qual' is 'ND' (True for 'ND', False for '=').", "method_code_mask": "from statsmodels.compat.pandas import assert_series_equal\nfrom statsmodels.compat.pandas import assert_frame_equal\nfrom io import StringIO\nfrom textwrap import dedent\nimport numpy as np\nimport numpy.testing as npt\nimport numpy\nfrom numpy.testing import assert_equal\nimport pandas\nimport pytest\nfrom statsmodels.imputation import ros\n\n\ndef load_basic_data(): [MASK]\n"}
{"method_name": "tukey_pvalues", "full_method_name": "tukey_pvalues", "method_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/stats/multicomp.py", "method_code": "from collections import namedtuple\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lrange\nimport copy\nimport math\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nfrom scipy import interpolate\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.stats.multitest import _ecdf as ecdf\nfrom statsmodels.stats.multitest import fdrcorrection as fdrcorrection0\nfrom statsmodels.stats.multitest import fdrcorrection_twostage\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom scipy.stats import studentized_range\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport warnings\nfrom statsmodels.sandbox.distributions.multivariate import mvstdtprob\ndef tukey_pvalues(std_range, nm, df):\n    contr = contrast_allpairs(nm)\n    corr = np.dot(contr, contr.T) / 2.0\n    tstat = std_range / np.sqrt(2) * np.ones(corr.shape[0])\n    return multicontrast_pvalues(tstat, corr, df=df)", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom statsmodels.sandbox.stats.multicomp import tukey_pvalues\ndef test_tukey_pvalues():\n    res = tukey_pvalues(3.649, 3, 16)\n    assert_almost_equal(0.05, res[0], 3)\n    assert_almost_equal(0.05 * np.ones(3), res[1], 3)\n\ntest_tukey_pvalues()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/stats/tests/test_multicomp.py"}], "instruction": "Functionality: The tukey_pvalues function is designed to calculate the p-values for a set of pairwise comparisons using Tukey's HSD (Honestly Significant Difference) test. This test is particularly useful in the context of post-hoc analysis after an ANOVA, where it allows for the comparison of all pairs of means while controlling the family-wise error rate.\n\nInputs: The function expects three arguments:\n1. std_range: An array-like object representing the studentized range for each comparison.\n2. nm: An integer indicating the number of means being compared.\n3. df: An integer representing the degrees of freedom associated with the error term from the ANOVA.\n\nOutputs: The function returns a single output:\n1. A NumPy array or list containing the p-values for each pairwise comparison. These p-values can be used to determine which means are significantly different from each other at a specified confidence level.", "method_code_mask": "from collections import namedtuple\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.python import lrange\nimport copy\nimport math\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nfrom scipy import interpolate\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.stats.multitest import multipletests\nfrom statsmodels.stats.multitest import _ecdf as ecdf\nfrom statsmodels.stats.multitest import fdrcorrection as fdrcorrection0\nfrom statsmodels.stats.multitest import fdrcorrection_twostage\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom scipy.stats import studentized_range\nfrom statsmodels.stats.libqsturng import qsturng\nfrom statsmodels.stats.libqsturng import psturng\nimport warnings\nfrom statsmodels.sandbox.distributions.multivariate import mvstdtprob\n\n\ndef tukey_pvalues(std_range, nm, df): [MASK]\n"}
{"method_name": "bootstrap", "full_method_name": "bootstrap", "method_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/distributions/gof_new.py", "method_code": "from statsmodels.compat.python import lmap\nimport numpy as np\nfrom scipy.stats import distributions\nfrom statsmodels.tools.decorators import cache_readonly\nfrom scipy.special import kolmogorov as ksprob\nfrom collections import defaultdict\nfrom scipy import stats\ndef bootstrap(distr, args=(), nobs=200, nrep=100, value=None, batch_size=None):\n    \"\"\"Monte Carlo (or parametric bootstrap) p-values for gof\n\n    currently hardcoded for A^2 only\n\n    assumes vectorized fit_vec method,\n    builds and analyses (nobs, nrep) sample in one step\n\n    rename function to less generic\n\n    this works also with nrep=1\n\n    \"\"\"\n    if batch_size is not None:\n        if value is None:\n            raise ValueError('using batching requires a value')\n        n_batch = int(np.ceil(nrep / float(batch_size)))\n        count = 0\n        for irep in range(n_batch):\n            rvs = distr.rvs(args, **{'size': (batch_size, nobs)})\n            params = distr.fit_vec(rvs, axis=1)\n            params = lmap(lambda x: np.expand_dims(x, 1), params)\n            cdfvals = np.sort(distr.cdf(rvs, params), axis=1)\n            stat = asquare(cdfvals, axis=1)\n            count += (stat >= value).sum()\n        return count / float(n_batch * batch_size)\n    else:\n        rvs = distr.rvs(args, **{'size': (nrep, nobs)})\n        params = distr.fit_vec(rvs, axis=1)\n        params = lmap(lambda x: np.expand_dims(x, 1), params)\n        cdfvals = np.sort(distr.cdf(rvs, params), axis=1)\n        stat = asquare(cdfvals, axis=1)\n        if value is None:\n            stat_sorted = np.sort(stat)\n            return stat_sorted\n        else:\n            return (stat >= value).mean()", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom statsmodels.sandbox.distributions.gof_new import bootstrap\nfrom statsmodels.sandbox.distributions.gof_new import NewNorm\ndef test_loop_vectorized_batch_equivalence():\n    nobs = 200\n    np.random.seed(8765679)\n    resu1 = bootstrap(NewNorm(), args=(0, 1), nobs=nobs, nrep=100, value=\n        0.576 / (1 + 4.0 / nobs - 25.0 / nobs ** 2))\n    np.random.seed(8765679)\n    tmp = [bootstrap(NewNorm(), args=(0, 1), nobs=nobs, nrep=1) for _ in\n        range(100)]\n    resu2 = (np.array(tmp) > 0.576 / (1 + 4.0 / nobs - 25.0 / nobs ** 2)).mean(\n        )\n    np.random.seed(8765679)\n    tmp = [bootstrap(NewNorm(), args=(0, 1), nobs=nobs, nrep=1, value=0.576 /\n        (1 + 4.0 / nobs - 25.0 / nobs ** 2), batch_size=10) for _ in range(10)]\n    resu3 = np.array(tmp).mean()\n    assert_array_almost_equal(resu1, resu2, 15)\n    assert_array_almost_equal(resu2, resu3, 15)\n\ntest_loop_vectorized_batch_equivalence()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/sandbox/distributions/tests/test_gof_new.py"}], "instruction": "Functionality: The bootstrap function performs a Monte Carlo simulation, also known as parametric bootstrap, to estimate p-values for goodness of fit tests, specifically designed for the A^2 statistic. It assumes a vectorized fit_vec method for the distribution and generates a (nobs, nrep) sample in one step. The function supports batching for more efficient computation.\n\nInputs:\n- distr: The distribution object for which to perform the goodness of fit test. This object should have rvs, fit_vec, and cdf methods.\n- args: A tuple of arguments passed to the distribution's methods.\n- nobs: An integer specifying the number of observations to generate per replication. Default is 200.\n- nrep: An integer specifying the number of replications to perform. Default is 100.\n- value: The test statistic value against which to compare the bootstrapped statistics. If None, the function returns sorted bootstrapped statistics. Default is None.\n- batch_size: An integer specifying the size of batches for the Monte Carlo simulation. If None, no batching is performed. Default is None.\n\nOutputs:\n- If value is not provided (None), the function returns a sorted NumPy array of bootstrapped statistics.\n- If value is provided, the function returns a float representing the proportion of bootstrapped statistics greater than or equal to the provided value, which is the estimated p-value.", "method_code_mask": "from statsmodels.compat.python import lmap\nimport numpy as np\nfrom scipy.stats import distributions\nfrom statsmodels.tools.decorators import cache_readonly\nfrom scipy.special import kolmogorov as ksprob\nfrom collections import defaultdict\nfrom scipy import stats\n\n\ndef bootstrap(distr, args=(), nobs=200, nrep=100, value=None, batch_size=None\n    ): [MASK]\n"}
{"method_name": "plot_pacf", "full_method_name": "plot_pacf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tsaplots.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\ndef plot_pacf(x, ax=None, lags=None, alpha=0.05, method='ywm', use_vlines=\n    True, title='Partial Autocorrelation', zero=True, vlines_kwargs=None,\n    **kwargs):\n    \"\"\"\n    Plot the partial autocorrelation function\n\n    Parameters\n    ----------\n    x : array_like\n        Array of time-series values\n    ax : AxesSubplot, optional\n        If given, this subplot is used to plot in instead of a new figure being\n        created.\n    lags : {int, array_like}, optional\n        An int or array of lag values, used on horizontal axis. Uses\n        np.arange(lags) when lags is an int.  If not provided,\n        ``lags=np.arange(len(corr))`` is used.\n    alpha : float, optional\n        If a number is given, the confidence intervals for the given level are\n        returned. For instance if alpha=.05, 95 % confidence intervals are\n        returned where the standard deviation is computed according to\n        1/sqrt(len(x))\n    method : str\n        Specifies which method for the calculations to use:\n\n        - \"ywm\" or \"ywmle\" : Yule-Walker without adjustment. Default.\n        - \"yw\" or \"ywadjusted\" : Yule-Walker with sample-size adjustment in\n          denominator for acovf. Default.\n        - \"ols\" : regression of time series on lags of it and on constant.\n        - \"ols-inefficient\" : regression of time series on lags using a single\n          common sample to estimate all pacf coefficients.\n        - \"ols-adjusted\" : regression of time series on lags with a bias\n          adjustment.\n        - \"ld\" or \"ldadjusted\" : Levinson-Durbin recursion with bias\n          correction.\n        - \"ldb\" or \"ldbiased\" : Levinson-Durbin recursion without bias\n          correction.\n\n    use_vlines : bool, optional\n        If True, vertical lines and markers are plotted.\n        If False, only markers are plotted.  The default marker is 'o'; it can\n        be overridden with a ``marker`` kwarg.\n    title : str, optional\n        Title to place on plot.  Default is 'Partial Autocorrelation'\n    zero : bool, optional\n        Flag indicating whether to include the 0-lag autocorrelation.\n        Default is True.\n    vlines_kwargs : dict, optional\n        Optional dictionary of keyword arguments that are passed to vlines.\n    **kwargs : kwargs, optional\n        Optional keyword arguments that are directly passed on to the\n        Matplotlib ``plot`` and ``axhline`` functions.\n\n    Returns\n    -------\n    Figure\n        If `ax` is None, the created figure.  Otherwise the figure to which\n        `ax` is connected.\n\n    See Also\n    --------\n    matplotlib.pyplot.xcorr\n    matplotlib.pyplot.acorr\n\n    Notes\n    -----\n    Plots lags on the horizontal and the correlations on vertical axis.\n    Adapted from matplotlib's `xcorr`.\n\n    Data are plotted as ``plot(lags, corr, **kwargs)``\n\n    kwargs is used to pass matplotlib optional arguments to both the line\n    tracing the autocorrelations and for the horizontal line at 0. These\n    options must be valid for a Line2D object.\n\n    vlines_kwargs is used to pass additional optional arguments to the\n    vertical lines connecting each autocorrelation to the axis.  These options\n    must be valid for a LineCollection object.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> import matplotlib.pyplot as plt\n    >>> import statsmodels.api as sm\n\n    >>> dta = sm.datasets.sunspots.load_pandas().data\n    >>> dta.index = pd.Index(sm.tsa.datetools.dates_from_range('1700', '2008'))\n    >>> del dta[\"YEAR\"]\n    >>> sm.graphics.tsa.plot_pacf(dta.values.squeeze(), lags=40, method=\"ywm\")\n    >>> plt.show()\n\n    .. plot:: plots/graphics_tsa_plot_pacf.py\n    \"\"\"\n    fig, ax = utils.create_mpl_ax(ax)\n    vlines_kwargs = {} if vlines_kwargs is None else vlines_kwargs\n    lags, nlags, irregular = _prepare_data_corr_plot(x, lags, zero)\n    confint = None\n    if alpha is None:\n        acf_x = pacf(x, nlags=nlags, alpha=alpha, method=method)\n    else:\n        acf_x, confint = pacf(x, nlags=nlags, alpha=alpha, method=method)\n    _plot_corr(ax, title, acf_x, confint, lags, irregular, use_vlines,\n        vlines_kwargs, **kwargs)\n    return fig", "test_code_list": [{"test_code": "from statsmodels.compat.python import lmap\nimport calendar\nfrom io import BytesIO\nimport locale\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.graphics.tsaplots import month_plot\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.tsaplots import plot_predict\nfrom statsmodels.graphics.tsaplots import quarter_plot\nfrom statsmodels.graphics.tsaplots import seasonal_plot\nfrom statsmodels.tsa import arima_process as tsp\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom matplotlib import pyplot as plt\n@pytest.mark.matplotlib\ndef test_plot_pacf_kwargs():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ar = np.r_[1.0, -0.9]\n    ma = np.r_[1.0, 0.9]\n    armaprocess = tsp.ArmaProcess(ar, ma)\n    rs = np.random.RandomState(1234)\n    pacf = armaprocess.generate_sample(100, distrvs=rs.standard_normal)\n    buff = BytesIO()\n    plot_pacf(pacf, ax=ax)\n    fig.savefig(buff, format='rgba')\n    buff_linestyle = BytesIO()\n    fig_linestyle = plt.figure()\n    ax = fig_linestyle.add_subplot(111)\n    plot_pacf(pacf, ax=ax, ls='-')\n    fig_linestyle.savefig(buff_linestyle, format='rgba')\n    buff_with_vlines = BytesIO()\n    fig_with_vlines = plt.figure()\n    ax = fig_with_vlines.add_subplot(111)\n    vlines_kwargs = {'linestyles': 'dashdot'}\n    plot_pacf(pacf, ax=ax, vlines_kwargs=vlines_kwargs)\n    fig_with_vlines.savefig(buff_with_vlines, format='rgba')\n    buff.seek(0)\n    buff_linestyle.seek(0)\n    buff_with_vlines.seek(0)\n    plain = buff.read()\n    linestyle = buff_linestyle.read()\n    with_vlines = buff_with_vlines.read()\n    assert_(plain != linestyle)\n    assert_(with_vlines != plain)\n    assert_(linestyle != with_vlines)\n\ntest_plot_pacf_kwargs()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_tsaplots.py"}], "instruction": "Functionality: The plot_pacf function is designed to plot the partial autocorrelation function (PACF) of a given time series. It computes the PACF and visualizes it, often to understand the significance of lags in a time series in the presence of other lags.\n\nInputs: \n   - x: An array of time-series values, which is the primary data for which the PACF is to be plotted.\n   - ax: An optional AxesSubplot object. If provided, the PACF plot will be generated on this subplot instead of creating a new figure.\n   - lags: An integer or array of lag values that are used on the horizontal axis. If not provided, lags are generated based on the length of the autocorrelation function.\n   - alpha: A float that specifies the confidence level for the confidence intervals of the PACF. Default is 0.05, which corresponds to 95% confidence intervals.\n   - method: A string specifying the method to calculate the PACF. The default is \"ywm\" (Yule-Walker method). Other options include \"yw\", \"ols\", \"ols-adjusted\", \"ld\", and others.\n   - use_vlines: A boolean indicating whether to draw vertical lines for each lag. By default, it is True.\n   - title: A string specifying the title of the plot. The default is 'Partial Autocorrelation'.\n   - zero: A boolean indicating whether to include the 0-lag autocorrelation. Default is True.\n   - vlines_kwargs: An optional dictionary for keyword arguments to pass to the vertical lines that connect each PACF to the axis.\n   - **kwargs: Additional keyword arguments that are directly passed to the Matplotlib plot and axhline functions.\n\nOutputs: \n   - A figure object is returned. If ax is None, the function returns the newly created figure. If ax is provided, the figure it is connected to will be returned.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\n\n\ndef plot_pacf(x, ax=None, lags=None, alpha=0.05, method='ywm', use_vlines=\n    True, title='Partial Autocorrelation', zero=True, vlines_kwargs=None,\n    **kwargs): [MASK]\n"}
{"method_name": "plot_acf", "full_method_name": "plot_acf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tsaplots.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\n@deprecate_kwarg('unbiased', 'adjusted')\ndef plot_acf(x, ax=None, lags=None, *, alpha=0.05, use_vlines=True,\n    adjusted=False, fft=False, missing='none', title='Autocorrelation',\n    zero=True, auto_ylims=False, bartlett_confint=True, vlines_kwargs=None,\n    **kwargs):\n    \"\"\"\n    Plot the autocorrelation function\n\n    Plots lags on the horizontal and the correlations on vertical axis.\n\n    Parameters\n    ----------\n    x : array_like\n        Array of time-series values\n    ax : AxesSubplot, optional\n        If given, this subplot is used to plot in instead of a new figure being\n        created.\n    lags : {int, array_like}, optional\n        An int or array of lag values, used on horizontal axis. Uses\n        np.arange(lags) when lags is an int.  If not provided,\n        ``lags=np.arange(len(corr))`` is used.\n    alpha : scalar, optional\n        If a number is given, the confidence intervals for the given level are\n        returned. For instance if alpha=.05, 95 % confidence intervals are\n        returned where the standard deviation is computed according to\n        Bartlett's formula. If None, no confidence intervals are plotted.\n    use_vlines : bool, optional\n        If True, vertical lines and markers are plotted.\n        If False, only markers are plotted.  The default marker is 'o'; it can\n        be overridden with a ``marker`` kwarg.\n    adjusted : bool\n        If True, then denominators for autocovariance are n-k, otherwise n\n    fft : bool, optional\n        If True, computes the ACF via FFT.\n    missing : str, optional\n        A string in ['none', 'raise', 'conservative', 'drop'] specifying how\n        the NaNs are to be treated.\n    title : str, optional\n        Title to place on plot.  Default is 'Autocorrelation'\n    zero : bool, optional\n        Flag indicating whether to include the 0-lag autocorrelation.\n        Default is True.\n    auto_ylims : bool, optional\n        If True, adjusts automatically the y-axis limits to ACF values.\n    bartlett_confint : bool, default True\n        Confidence intervals for ACF values are generally placed at 2\n        standard errors around r_k. The formula used for standard error\n        depends upon the situation. If the autocorrelations are being used\n        to test for randomness of residuals as part of the ARIMA routine,\n        the standard errors are determined assuming the residuals are white\n        noise. The approximate formula for any lag is that standard error\n        of each r_k = 1/sqrt(N). See section 9.4 of [1] for more details on\n        the 1/sqrt(N) result. For more elementary discussion, see section\n        5.3.2 in [2].\n        For the ACF of raw data, the standard error at a lag k is\n        found as if the right model was an MA(k-1). This allows the\n        possible interpretation that if all autocorrelations past a\n        certain lag are within the limits, the model might be an MA of\n        order defined by the last significant autocorrelation. In this\n        case, a moving average model is assumed for the data and the\n        standard errors for the confidence intervals should be\n        generated using Bartlett's formula. For more details on\n        Bartlett formula result, see section 7.2 in [1].\n    vlines_kwargs : dict, optional\n        Optional dictionary of keyword arguments that are passed to vlines.\n    **kwargs : kwargs, optional\n        Optional keyword arguments that are directly passed on to the\n        Matplotlib ``plot`` and ``axhline`` functions.\n\n    Returns\n    -------\n    Figure\n        If `ax` is None, the created figure.  Otherwise the figure to which\n        `ax` is connected.\n\n    See Also\n    --------\n    matplotlib.pyplot.xcorr\n    matplotlib.pyplot.acorr\n\n    Notes\n    -----\n    Adapted from matplotlib's `xcorr`.\n\n    Data are plotted as ``plot(lags, corr, **kwargs)``\n\n    kwargs is used to pass matplotlib optional arguments to both the line\n    tracing the autocorrelations and for the horizontal line at 0. These\n    options must be valid for a Line2D object.\n\n    vlines_kwargs is used to pass additional optional arguments to the\n    vertical lines connecting each autocorrelation to the axis.  These options\n    must be valid for a LineCollection object.\n\n    References\n    ----------\n    [1] Brockwell and Davis, 1987. Time Series Theory and Methods\n    [2] Brockwell and Davis, 2010. Introduction to Time Series and\n    Forecasting, 2nd edition.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> import matplotlib.pyplot as plt\n    >>> import statsmodels.api as sm\n\n    >>> dta = sm.datasets.sunspots.load_pandas().data\n    >>> dta.index = pd.Index(sm.tsa.datetools.dates_from_range('1700', '2008'))\n    >>> del dta[\"YEAR\"]\n    >>> sm.graphics.tsa.plot_acf(dta.values.squeeze(), lags=40)\n    >>> plt.show()\n\n    .. plot:: plots/graphics_tsa_plot_acf.py\n    \"\"\"\n    fig, ax = utils.create_mpl_ax(ax)\n    lags, nlags, irregular = _prepare_data_corr_plot(x, lags, zero)\n    vlines_kwargs = {} if vlines_kwargs is None else vlines_kwargs\n    confint = None\n    acf_x = acf(x, nlags=nlags, alpha=alpha, fft=fft, bartlett_confint=\n        bartlett_confint, adjusted=adjusted, missing=missing)\n    if alpha is not None:\n        acf_x, confint = acf_x[:2]\n    _plot_corr(ax, title, acf_x, confint, lags, irregular, use_vlines,\n        vlines_kwargs, auto_ylims=auto_ylims, **kwargs)\n    return fig", "test_code_list": [{"test_code": "from statsmodels.compat.python import lmap\nimport calendar\nfrom io import BytesIO\nimport locale\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.graphics.tsaplots import month_plot\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.tsaplots import plot_predict\nfrom statsmodels.graphics.tsaplots import quarter_plot\nfrom statsmodels.graphics.tsaplots import seasonal_plot\nfrom statsmodels.tsa import arima_process as tsp\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom matplotlib import pyplot as plt\n@pytest.mark.matplotlib\ndef test_plot_acf_kwargs():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ar = np.r_[1.0, -0.9]\n    ma = np.r_[1.0, 0.9]\n    armaprocess = tsp.ArmaProcess(ar, ma)\n    rs = np.random.RandomState(1234)\n    acf = armaprocess.generate_sample(100, distrvs=rs.standard_normal)\n    buff = BytesIO()\n    plot_acf(acf, ax=ax)\n    fig.savefig(buff, format='rgba')\n    buff_with_vlines = BytesIO()\n    fig_with_vlines = plt.figure()\n    ax = fig_with_vlines.add_subplot(111)\n    vlines_kwargs = {'linestyles': 'dashdot'}\n    plot_acf(acf, ax=ax, vlines_kwargs=vlines_kwargs)\n    fig_with_vlines.savefig(buff_with_vlines, format='rgba')\n    buff.seek(0)\n    buff_with_vlines.seek(0)\n    plain = buff.read()\n    with_vlines = buff_with_vlines.read()\n    assert_(with_vlines != plain)\n\ntest_plot_acf_kwargs()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_tsaplots.py"}, {"test_code": "from statsmodels.compat.python import lmap\nimport calendar\nfrom io import BytesIO\nimport locale\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.graphics.tsaplots import month_plot\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.tsaplots import plot_predict\nfrom statsmodels.graphics.tsaplots import quarter_plot\nfrom statsmodels.graphics.tsaplots import seasonal_plot\nfrom statsmodels.tsa import arima_process as tsp\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom matplotlib import pyplot as plt\n@pytest.mark.matplotlib\ndef test_plot_acf_missing():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ar = np.r_[1.0, -0.9]\n    ma = np.r_[1.0, 0.9]\n    armaprocess = tsp.ArmaProcess(ar, ma)\n    rs = np.random.RandomState(1234)\n    acf = armaprocess.generate_sample(100, distrvs=rs.standard_normal)\n    acf[::13] = np.nan\n    buff = BytesIO()\n    plot_acf(acf, ax=ax, missing='drop')\n    fig.savefig(buff, format='rgba')\n    buff.seek(0)\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    buff_conservative = BytesIO()\n    plot_acf(acf, ax=ax, missing='conservative')\n    fig.savefig(buff_conservative, format='rgba')\n    buff_conservative.seek(0)\n    assert_(buff.read() != buff_conservative.read())\n\ntest_plot_acf_missing()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_tsaplots.py"}], "instruction": "Functionality: Plot the autocorrelation function (ACF) for a given time series. This function visualizes the correlation between a time series and lagged versions of itself to identify patterns in the data that could indicate seasonality or trends.\n\nInputs: \n- x: array_like - Array of time-series values for which the ACF is to be calculated and plotted.\n- ax: AxesSubplot, optional - If given, this subplot is used to plot in instead of creating a new figure.\n- lags: {int, array_like}, optional - An int or array of lag values, used on the horizontal axis. If an int, uses np.arange(lags). If not provided, lags are determined based on the length of the autocorrelation.\n- alpha: scalar, optional - If a number is given, the confidence intervals for the given level are returned. For instance, if alpha=.05, 95 % confidence intervals are returned.\n- use_vlines: bool, optional - If True, vertical lines and markers are plotted; if False, only markers are plotted.\n- adjusted: bool - If True, then denominators for autocovariance are n-k, otherwise n.\n- fft: bool, optional - If True, computes the ACF via FFT.\n- missing: str, optional - Determines how the NaNs are to be treated in the data.\n- title: str, optional - Title to be placed on the plot. Default is 'Autocorrelation'.\n- zero: bool, optional - Flag indicating whether to include the 0-lag autocorrelation. Default is True.\n- auto_ylims: bool, optional - If True, adjusts automatically the y-axis limits to ACF values.\n- bartlett_confint: bool, default True - Determines the method of calculating confidence intervals for the autocorrelation function.\n- vlines_kwargs: dict, optional - Optional dictionary of keyword arguments that are passed to vlines for vertical lines.\n- **kwargs: kwargs, optional - Additional keyword arguments that are directly passed on to the Matplotlib plot and axhline functions.\n\nOutputs: \n- Figure: If `ax` is None, returns the created figure. Otherwise, returns the figure to which `ax` is connected.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\n\n\n@deprecate_kwarg('unbiased', 'adjusted')\ndef plot_acf(x, ax=None, lags=None, *, alpha=0.05, use_vlines=True,\n    adjusted=False, fft=False, missing='none', title='Autocorrelation',\n    zero=True, auto_ylims=False, bartlett_confint=True, vlines_kwargs=None,\n    **kwargs): [MASK]\n"}
{"method_name": "seasonal_plot", "full_method_name": "seasonal_plot", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tsaplots.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\ndef seasonal_plot(grouped_x, xticklabels, ylabel=None, ax=None):\n    \"\"\"\n    Consider using one of month_plot or quarter_plot unless you need\n    irregular plotting.\n\n    Parameters\n    ----------\n    grouped_x : iterable of DataFrames\n        Should be a GroupBy object (or similar pair of group_names and groups\n        as DataFrames) with a DatetimeIndex or PeriodIndex\n    xticklabels : list of str\n        List of season labels, one for each group.\n    ylabel : str\n        Lable for y axis\n    ax : AxesSubplot, optional\n        If given, this subplot is used to plot in instead of a new figure being\n        created.\n    \"\"\"\n    fig, ax = utils.create_mpl_ax(ax)\n    start = 0\n    ticks = []\n    for season, df in grouped_x:\n        df = df.copy()\n        df.sort_index()\n        nobs = len(df)\n        x_plot = np.arange(start, start + nobs)\n        ticks.append(x_plot.mean())\n        ax.plot(x_plot, df.values, 'k')\n        ax.hlines(df.values.mean(), x_plot[0], x_plot[-1], colors='r',\n            linewidth=3)\n        start += nobs\n    ax.set_xticks(ticks)\n    ax.set_xticklabels(xticklabels)\n    ax.set_ylabel(ylabel)\n    ax.margins(0.1, 0.05)\n    return fig", "test_code_list": [{"test_code": "from statsmodels.compat.python import lmap\nimport calendar\nfrom io import BytesIO\nimport locale\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.graphics.tsaplots import month_plot\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.tsaplots import plot_predict\nfrom statsmodels.graphics.tsaplots import quarter_plot\nfrom statsmodels.graphics.tsaplots import seasonal_plot\nfrom statsmodels.tsa import arima_process as tsp\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom matplotlib import pyplot as plt\n@pytest.mark.matplotlib\ndef test_seasonal_plot():\n    rs = np.random.RandomState(1234)\n    data = rs.randn(20, 12)\n    data += 6 * np.sin(np.arange(12.0) / 11 * np.pi)[None, :]\n    data = data.ravel()\n    months = np.tile(np.arange(1, 13), (20, 1))\n    months = months.ravel()\n    df = pd.DataFrame([data, months], index=['data', 'months']).T\n    grouped = df.groupby('months')['data']\n    labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n        'Oct', 'Nov', 'Dec']\n    fig = seasonal_plot(grouped, labels)\n    ax = fig.get_axes()[0]\n    output = [tl.get_text() for tl in ax.get_xticklabels()]\n    assert_equal(labels, output)\n\ntest_seasonal_plot()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_tsaplots.py"}], "instruction": "Functionality: The seasonal_plot function is designed to create a plot for visualizing seasonal patterns in time series data. It is particularly useful for irregularly spaced time series data, although for regularly spaced monthly or quarterly data, the month_plot or quarter_plot functions are more appropriate. This function accepts a grouped dataset, typically from a GroupBy operation, and plots the series for each group (season) on the same figure, providing a comparative view of seasonal patterns.\n\nInputs:\n- grouped_x: An iterable of DataFrames. This should be a GroupBy object or similar structure that holds groups of data along with their group names, such as those obtained from a pandas GroupBy operation. The data in each group must have a DatetimeIndex or PeriodIndex to represent the time component of the series.\n- xticklabels: A list of strings. Each string provides a label for the x-axis ticks, corresponding to the seasons or group names of the data in grouped_x.\n- ylabel: A string representing the label for the y-axis. This is optional and can be left as None if no specific y-axis label is required.\n- ax: An AxesSubplot object from matplotlib. This is optional and allows the user to specify an existing subplot to be used for plotting, rather than creating a new figure.\n\nOutputs:\n- The function returns a matplotlib figure object (fig) that contains the seasonal plot. This figure can be displayed or saved to a file using matplotlib's functions.\n\nNote: Ensure that the grouped_x input is properly formatted with the correct time index and that the xticklabels list corresponds to the number of groups in the grouped_x input. The function will sort each group by index before plotting to maintain the time order of the data.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nimport calendar\nimport numpy as np\nimport pandas as pd\nfrom statsmodels.graphics import utils\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.data import _check_period_index\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.graphics.utils import create_mpl_ax\nfrom statsmodels.tsa.base.prediction import PredictionResults\n\n\ndef seasonal_plot(grouped_x, xticklabels, ylabel=None, ax=None): [MASK]\n"}
{"method_name": "_recode", "full_method_name": "_recode", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/factorplots.py", "method_code": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom statsmodels.graphics.plottools import rainbow\nimport statsmodels.graphics.utils as utils\nfrom pandas import DataFrame\nfrom pandas import Series\ndef _recode(x, levels):\n    \"\"\" Recode categorial data to int factor.\n\n    Parameters\n    ----------\n    x : array_like\n        array like object supporting with numpy array methods of categorially\n        coded data.\n    levels : dict\n        mapping of labels to integer-codings\n\n    Returns\n    -------\n    out : instance numpy.ndarray\n    \"\"\"\n    from pandas import Series\n    name = None\n    index = None\n    if isinstance(x, Series):\n        name = x.name\n        index = x.index\n        x = x.values\n    if x.dtype.type not in [np.str_, np.object_]:\n        raise ValueError(\n            'This is not a categorial factor. Array of str type required.')\n    elif not isinstance(levels, dict):\n        raise ValueError('This is not a valid value for levels. Dict required.'\n            )\n    elif not (np.unique(x) == np.unique(list(levels.keys()))).all():\n        raise ValueError('The levels do not match the array values.')\n    else:\n        out = np.empty(x.shape[0], dtype=int)\n        for level, coding in levels.items():\n            out[x == level] = coding\n        if name:\n            out = Series(out, name=name, index=index)\n        return out", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom pandas import Series\nimport pytest\nfrom statsmodels.graphics.factorplots import _recode\nfrom statsmodels.graphics.factorplots import interaction_plot\nimport matplotlib.pyplot as plt\n\nclass TestInteractionPlot():\n\tdef test_recode_series(self):\n\t    series = Series(['a', 'b'] * 10, index=np.arange(0, 40, 2), name=\n\t        'index_test')\n\t    series_ = _recode(series, {'a': 0, 'b': 1})\n\t    assert_equal(series_.index.values, series.index.values, err_msg=\n\t        '_recode changed the index')\n\t\nTestInteractionPlot().test_recode_series()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_factorplots.py"}], "instruction": "Functionality: Recode categorial data to integer factors based on a provided mapping.\n\nInputs:\n- x : array_like\n  An array-like object, such as a list or numpy array, containing categorially coded data that should be of string type.\n- levels : dict\n  A dictionary mapping each unique label in 'x' to an integer code.\n\nOutputs:\n- out : numpy.ndarray or pandas.Series\n  The output is a numpy array with integer codes corresponding to the categorial values in 'x'. If 'x' is a pandas Series, the output will also be a Series with the original index preserved.\n\nExceptions:\n- ValueError: The function will raise a ValueError if 'x' is not an array-like object with string or object dtype, if 'levels' is not a dictionary, or if the keys of 'levels' do not match the unique values in 'x'.", "method_code_mask": "from statsmodels.compat.python import lrange\nimport numpy as np\nfrom statsmodels.graphics.plottools import rainbow\nimport statsmodels.graphics.utils as utils\nfrom pandas import DataFrame\nfrom pandas import Series\n\n\ndef _recode(x, levels): [MASK]\n"}
{"method_name": "qqplot_2samples", "full_method_name": "qqplot_2samples", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/gofplots.py", "method_code": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy import stats\nfrom statsmodels.distributions import ECDF\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import add_constant\ndef qqplot_2samples(data1, data2, xlabel=None, ylabel=None, line=None, ax=None\n    ):\n    \"\"\"\n    Q-Q Plot of two samples' quantiles.\n\n    Can take either two `ProbPlot` instances or two array-like objects. In the\n    case of the latter, both inputs will be converted to `ProbPlot` instances\n    using only the default values - so use `ProbPlot` instances if\n    finer-grained control of the quantile computations is required.\n\n    Parameters\n    ----------\n    data1 : {array_like, ProbPlot}\n        Data to plot along x axis. If the sample sizes are unequal, the longer\n        series is always plotted along the x-axis.\n    data2 : {array_like, ProbPlot}\n        Data to plot along y axis. Does not need to have the same number of\n        observations as data 1. If the sample sizes are unequal, the longer\n        series is always plotted along the x-axis.\n    xlabel : {None, str}\n        User-provided labels for the x-axis. If None (default),\n        other values are used.\n    ylabel : {None, str}\n        User-provided labels for the y-axis. If None (default),\n        other values are used.\n    line : {None, \"45\", \"s\", \"r\", q\"}\n        Options for the reference line to which the data is compared:\n\n        - \"45\" - 45-degree line\n        - \"s\" - standardized line, the expected order statistics are scaled\n          by the standard deviation of the given sample and have the mean\n          added to them\n        - \"r\" - A regression line is fit\n        - \"q\" - A line is fit through the quartiles.\n        - None - by default no reference line is added to the plot.\n\n    ax : AxesSubplot, optional\n        If given, this subplot is used to plot in instead of a new figure being\n        created.\n\n    Returns\n    -------\n    Figure\n        If `ax` is None, the created figure.  Otherwise the figure to which\n        `ax` is connected.\n\n    See Also\n    --------\n    scipy.stats.probplot\n\n    Notes\n    -----\n    1) Depends on matplotlib.\n    2) If `data1` and `data2` are not `ProbPlot` instances, instances will be\n       created using the default parameters. Therefore, it is recommended to use\n       `ProbPlot` instance if fine-grained control is needed in the computation\n       of the quantiles.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> import numpy as np\n    >>> import matplotlib.pyplot as plt\n    >>> from statsmodels.graphics.gofplots import qqplot_2samples\n    >>> x = np.random.normal(loc=8.5, scale=2.5, size=37)\n    >>> y = np.random.normal(loc=8.0, scale=3.0, size=37)\n    >>> pp_x = sm.ProbPlot(x)\n    >>> pp_y = sm.ProbPlot(y)\n    >>> qqplot_2samples(pp_x, pp_y)\n    >>> plt.show()\n\n    .. plot:: plots/graphics_gofplots_qqplot_2samples.py\n\n    >>> fig = qqplot_2samples(pp_x, pp_y, xlabel=None, ylabel=None,\n    ...                       line=None, ax=None)\n    \"\"\"\n    if not isinstance(data1, ProbPlot):\n        data1 = ProbPlot(data1)\n    if not isinstance(data2, ProbPlot):\n        data2 = ProbPlot(data2)\n    if data2.data.shape[0] > data1.data.shape[0]:\n        fig = data1.qqplot(xlabel=ylabel, ylabel=xlabel, line=line, other=\n            data2, ax=ax)\n    else:\n        fig = data2.qqplot(xlabel=ylabel, ylabel=xlabel, line=line, other=\n            data1, ax=ax, swap=True)\n    return fig", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as nptest\nfrom numpy.testing import assert_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.graphics import gofplots\nfrom statsmodels.graphics.gofplots import ProbPlot\nfrom statsmodels.graphics.gofplots import qqline\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.graphics.gofplots import qqplot_2samples\nfrom statsmodels.graphics.utils import _import_mpl\nimport matplotlib.pyplot as plt\n@pytest.mark.matplotlib\ndef test_qqplot_unequal():\n    rs = np.random.RandomState(0)\n    data1 = rs.standard_normal(100)\n    data2 = rs.standard_normal(200)\n    fig1 = qqplot_2samples(data1, data2)\n    fig2 = qqplot_2samples(data2, data1)\n    x1, y1 = fig1.get_axes()[0].get_children()[0].get_data()\n    x2, y2 = fig2.get_axes()[0].get_children()[0].get_data()\n    np.testing.assert_allclose(x1, x2)\n    np.testing.assert_allclose(y1, y2)\n    numobj1 = len(fig1.get_axes()[0].get_children())\n    numobj2 = len(fig2.get_axes()[0].get_children())\n    assert numobj1 == numobj2\n\n    @pytest.mark.matplotlib\n    def test_qqplot(self, close_figures):\n        qqplot(self.res, line='r')\n\n    @pytest.mark.matplotlib\n    def test_qqplot_2samples_prob_plot_obj(self, close_figures):\n        for line in ['r', 'q', '45', 's']:\n            qqplot_2samples(self.prbplt, self.other_prbplot, line=line)\n\n    @pytest.mark.matplotlib\n    def test_qqplot_2samples_arrays(self, close_figures):\n        for line in ['r', 'q', '45', 's']:\n            qqplot_2samples(self.res, self.other_array, line=line)\n\ntest_qqplot_unequal()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_gofplots.py"}, {"test_code": "import numpy as np\nimport numpy.testing as nptest\nfrom numpy.testing import assert_equal\nimport pytest\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.graphics import gofplots\nfrom statsmodels.graphics.gofplots import ProbPlot\nfrom statsmodels.graphics.gofplots import qqline\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.graphics.gofplots import qqplot_2samples\nfrom statsmodels.graphics.utils import _import_mpl\nimport matplotlib.pyplot as plt\n@pytest.mark.matplotlib\ndef test_axis_order():\n    xx = np.random.normal(10, 1, (100,))\n    xy = np.random.normal(1, 0.01, (100,))\n    fig = qqplot_2samples(xx, xy, 'x', 'y')\n    ax = fig.get_axes()[0]\n    y_range = np.diff(ax.get_ylim())[0]\n    x_range = np.diff(ax.get_xlim())[0]\n    assert y_range < x_range\n    xx_long = np.random.normal(10, 1, (1000,))\n    fig = qqplot_2samples(xx_long, xy, 'x', 'y')\n    ax = fig.get_axes()[0]\n    y_range = np.diff(ax.get_ylim())[0]\n    x_range = np.diff(ax.get_xlim())[0]\n    assert y_range < x_range\n    xy_long = np.random.normal(1, 0.01, (1000,))\n    fig = qqplot_2samples(xx, xy_long, 'x', 'y')\n    ax = fig.get_axes()[0]\n    y_range = np.diff(ax.get_ylim())[0]\n    x_range = np.diff(ax.get_xlim())[0]\n    assert x_range < y_range\n\ntest_axis_order()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_gofplots.py"}], "instruction": "Functionality: Generates a Q-Q Plot comparing the quantiles of two samples. The function can either accept two array-like objects, which will be converted to ProbPlot instances with default parameters, or two ProbPlot instances for more control over the quantile computation. A reference line can be added to the plot based on the specified option.\n\nInputs:\n    data1 : {array_like, ProbPlot}\n        Data for the x-axis. If sample sizes differ, the larger data set is plotted on the x-axis.\n    data2 : {array_like, ProbPlot}\n        Data for the y-axis. Sample size does not have to match data1; the larger set is always on the x-axis.\n    xlabel : {None, str}\n        Optional label for the x-axis. Default is None, which will use automatically generated labels.\n    ylabel : {None, str}\n        Optional label for the y-axis. Default is None, which will use automatically generated labels.\n    line : {None, \"45\", \"s\", \"r\", \"q\"}\n        Type of reference line to compare data against, with various options including a 45-degree line, standardized line, regression line, line through quartiles, or no line.\n    ax : AxesSubplot, optional\n        An optional subplot to plot on instead of creating a new figure. Default is None.\n\nOutputs:\n    Figure\n        If `ax` is not provided, the function returns the newly created figure. If `ax` is given, the figure associated with `ax` is returned.", "method_code_mask": "from statsmodels.compat.python import lzip\nimport numpy as np\nfrom scipy import stats\nfrom statsmodels.distributions import ECDF\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.tools import add_constant\n\n\ndef qqplot_2samples(data1, data2, xlabel=None, ylabel=None, line=None, ax=None\n    ): [MASK]\n"}
{"method_name": "banddepth", "full_method_name": "banddepth", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/functional.py", "method_code": "from statsmodels.compat.numpy import NP_LT_123\nimport numpy as np\nfrom scipy.special import comb\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.multivariate.pca import PCA\nfrom statsmodels.nonparametric.kernel_density import KDEMultivariate\nfrom scipy.optimize import brute\nfrom scipy.optimize import differential_evolution\nfrom scipy.optimize import fmin\nimport itertools\nfrom multiprocessing import Pool\nfrom matplotlib.cm import rainbow_r\ndef banddepth(data, method='MBD'):\n    \"\"\"\n    Calculate the band depth for a set of functional curves.\n\n    Band depth is an order statistic for functional data (see `fboxplot`), with\n    a higher band depth indicating larger \"centrality\".  In analog to scalar\n    data, the functional curve with highest band depth is called the median\n    curve, and the band made up from the first N/2 of N curves is the 50%\n    central region.\n\n    Parameters\n    ----------\n    data : ndarray\n        The vectors of functions to create a functional boxplot from.\n        The first axis is the function index, the second axis the one along\n        which the function is defined.  So ``data[0, :]`` is the first\n        functional curve.\n    method : {'MBD', 'BD2'}, optional\n        Whether to use the original band depth (with J=2) of [1]_ or the\n        modified band depth.  See Notes for details.\n\n    Returns\n    -------\n    ndarray\n        Depth values for functional curves.\n\n    Notes\n    -----\n    Functional band depth as an order statistic for functional data was\n    proposed in [1]_ and applied to functional boxplots and bagplots in [2]_.\n\n    The method 'BD2' checks for each curve whether it lies completely inside\n    bands constructed from two curves.  All permutations of two curves in the\n    set of curves are used, and the band depth is normalized to one.  Due to\n    the complete curve having to fall within the band, this method yields a lot\n    of ties.\n\n    The method 'MBD' is similar to 'BD2', but checks the fraction of the curve\n    falling within the bands.  It therefore generates very few ties.\n\n    The algorithm uses the efficient implementation proposed in [3]_.\n\n    References\n    ----------\n    .. [1] S. Lopez-Pintado and J. Romo, \"On the Concept of Depth for\n           Functional Data\", Journal of the American Statistical Association,\n           vol.  104, pp. 718-734, 2009.\n    .. [2] Y. Sun and M.G. Genton, \"Functional Boxplots\", Journal of\n           Computational and Graphical Statistics, vol. 20, pp. 1-19, 2011.\n    .. [3] Y. Sun, M. G. Gentonb and D. W. Nychkac, \"Exact fast computation\n           of band depth for large functional datasets: How quickly can one\n           million curves be ranked?\", Journal for the Rapid Dissemination\n           of Statistics Research, vol. 1, pp. 68-74, 2012.\n    \"\"\"\n    n, p = data.shape\n    rv = np.argsort(data, axis=0)\n    rmat = np.argsort(rv, axis=0) + 1\n\n    def _fbd2():\n        down = np.min(rmat, axis=1) - 1\n        up = n - np.max(rmat, axis=1)\n        return (up * down + n - 1) / comb(n, 2)\n\n    def _fmbd():\n        down = rmat - 1\n        up = n - rmat\n        return (np.sum(up * down, axis=1) / p + n - 1) / comb(n, 2)\n    if method == 'BD2':\n        depth = _fbd2()\n    elif method == 'MBD':\n        depth = _fmbd()\n    else:\n        raise ValueError('Unknown input value for parameter `method`.')\n    return depth", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.graphics.functional import banddepth\nfrom statsmodels.graphics.functional import fboxplot\nfrom statsmodels.graphics.functional import hdrboxplot\nfrom statsmodels.graphics.functional import rainbowplot\nimport matplotlib.pyplot as plt\ndef test_banddepth_BD2():\n    xx = np.arange(500) / 150.0\n    y1 = 1 + 0.5 * np.sin(xx)\n    y2 = 0.3 + np.sin(xx + np.pi / 6)\n    y3 = -0.5 + np.sin(xx + np.pi / 6)\n    y4 = -1 + 0.3 * np.cos(xx + np.pi / 6)\n    data = np.asarray([y1, y2, y3, y4])\n    depth = banddepth(data, method='BD2')\n    expected_depth = [0.5, 5.0 / 6, 5.0 / 6, 0.5]\n    assert_almost_equal(depth, expected_depth)\n\ntest_banddepth_BD2()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_functional.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pytest\nfrom statsmodels.datasets import elnino\nfrom statsmodels.graphics.functional import banddepth\nfrom statsmodels.graphics.functional import fboxplot\nfrom statsmodels.graphics.functional import hdrboxplot\nfrom statsmodels.graphics.functional import rainbowplot\nimport matplotlib.pyplot as plt\ndef test_banddepth_MBD():\n    xx = np.arange(5001) / 5000.0\n    y1 = np.zeros(xx.shape)\n    y2 = 2 * xx - 1\n    y3 = np.ones(xx.shape) * 0.5\n    y4 = np.ones(xx.shape) * -0.25\n    data = np.asarray([y1, y2, y3, y4])\n    depth = banddepth(data, method='MBD')\n    expected_depth = [5.0 / 6, (2 * (0.75 - 3.0 / 8) + 3) / 6, 3.5 / 6, (2 *\n        3.0 / 8 + 3) / 6]\n    assert_almost_equal(depth, expected_depth, decimal=4)\n\ntest_banddepth_MBD()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_functional.py"}], "instruction": "Functionality: Calculate the band depth for a set of functional curves, providing an order statistic for functional data akin to centrality measures in scalar data. This function supports two methods, 'MBD' for the modified band depth and 'BD2' for the original band depth as proposed in various statistical literature.\n\nInputs: \n- data: A two-dimensional ndarray representing a collection of functional curves. The first dimension indexes the function, and the second dimension indexes the points along which the function is defined.\n- method: A string specifying the method to use for the band depth calculation. It can be 'MBD' for the modified band depth or 'BD2' for the original band depth with J=2. The default is 'MBD'.\n\nOutputs: \n- An ndarray containing the depth values for each of the functional curves in the input data. The depth values are normalized and indicate the centrality of each curve within the set of all curves.", "method_code_mask": "from statsmodels.compat.numpy import NP_LT_123\nimport numpy as np\nfrom scipy.special import comb\nfrom statsmodels.graphics.utils import _import_mpl\nfrom statsmodels.multivariate.pca import PCA\nfrom statsmodels.nonparametric.kernel_density import KDEMultivariate\nfrom scipy.optimize import brute\nfrom scipy.optimize import differential_evolution\nfrom scipy.optimize import fmin\nimport itertools\nfrom multiprocessing import Pool\nfrom matplotlib.cm import rainbow_r\n\n\ndef banddepth(data, method='MBD'): [MASK]\n"}
{"method_name": "_hierarchical_split", "full_method_name": "_hierarchical_split", "method_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/mosaicplot.py", "method_code": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nfrom itertools import product\nimport numpy as np\nfrom numpy import array\nfrom numpy import cumsum\nfrom numpy import iterable\nfrom numpy import r_\nfrom pandas import DataFrame\nfrom statsmodels.graphics import utils\nfrom matplotlib.colors import hsv_to_rgb\nfrom matplotlib.patches import Rectangle\ndef _hierarchical_split(count_dict, horizontal=True, gap=0.05):\n    \"\"\"\n    Split a square in a hierarchical way given a contingency table.\n\n    Hierarchically split the unit square in alternate directions\n    in proportion to the subdivision contained in the contingency table\n    count_dict.  This is the function that actually perform the tiling\n    for the creation of the mosaic plot.  If the gap array has been specified\n    it will insert a corresponding amount of space (proportional to the\n    unit length), while retaining the proportionality of the tiles.\n\n    Parameters\n    ----------\n    count_dict : dict\n        Dictionary containing the contingency table.\n        Each category should contain a non-negative number\n        with a tuple as index.  It expects that all the combination\n        of keys to be represents; if that is not true, will\n        automatically consider the missing values as 0\n    horizontal : bool\n        The starting direction of the split (by default along\n        the horizontal axis)\n    gap : float or array of floats\n        The list of gaps to be applied on each subdivision.\n        If the length of the given array is less of the number\n        of subcategories (or if it's a single number) it will extend\n        it with exponentially decreasing gaps\n\n    Returns\n    -------\n    base_rect : dict\n        A dictionary containing the result of the split.\n        To each key is associated a 4-tuple of coordinates\n        that are required to create the corresponding rectangle:\n\n            0 - x position of the lower left corner\n            1 - y position of the lower left corner\n            2 - width of the rectangle\n            3 - height of the rectangle\n    \"\"\"\n    base_rect = dict([(tuple(), (0, 0, 1, 1))])\n    categories_levels = _categories_level(list(count_dict.keys()))\n    L = len(categories_levels)\n    if not np.iterable(gap):\n        gap = [(gap / 1.5 ** idx) for idx in range(L)]\n    if len(gap) < L:\n        last = gap[-1]\n        gap = list(*gap) + [(last / 1.5 ** idx) for idx in range(L)]\n    gap = gap[:L]\n    count_ordered = {k: count_dict[k] for k in list(product(*\n        categories_levels))}\n    for cat_idx, cat_enum in enumerate(categories_levels):\n        base_keys = list(product(*categories_levels[:cat_idx]))\n        for key in base_keys:\n            part_count = [_reduce_dict(count_ordered, key + (partial,)) for\n                partial in cat_enum]\n            new_gap = gap[cat_idx]\n            base_rect = _key_splitting(base_rect, cat_enum, part_count, key,\n                horizontal, new_gap)\n        horizontal = not horizontal\n    return base_rect", "test_code_list": [{"test_code": "from statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom itertools import product\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.api import datasets\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import _hierarchical_split\nfrom statsmodels.graphics.mosaicplot import _key_splitting\nfrom statsmodels.graphics.mosaicplot import _normalize_split\nfrom statsmodels.graphics.mosaicplot import _reduce_dict\nfrom statsmodels.graphics.mosaicplot import _split_rect\nfrom statsmodels.graphics.mosaicplot import mosaic\nimport pandas\nfrom numpy.random import rand\ndef test_recursive_split():\n    keys = list(product('mf'))\n    data = dict(zip(keys, [1] * len(keys)))\n    res = _hierarchical_split(data, gap=0)\n    assert_(list(res.keys()) == keys)\n    res['m',] = 0.0, 0.0, 0.5, 1.0\n    res['f',] = 0.5, 0.0, 0.5, 1.0\n    keys = list(product('mf', 'yao'))\n    data = dict(zip(keys, [1] * len(keys)))\n    res = _hierarchical_split(data, gap=0)\n    assert_(list(res.keys()) == keys)\n    res['m', 'y'] = 0.0, 0.0, 0.5, 1 / 3\n    res['m', 'a'] = 0.0, 1 / 3, 0.5, 1 / 3\n    res['m', 'o'] = 0.0, 2 / 3, 0.5, 1 / 3\n    res['f', 'y'] = 0.5, 0.0, 0.5, 1 / 3\n    res['f', 'a'] = 0.5, 1 / 3, 0.5, 1 / 3\n    res['f', 'o'] = 0.5, 2 / 3, 0.5, 1 / 3\n\ntest_recursive_split()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/graphics/tests/test_mosaicplot.py"}], "instruction": "Functionality: The _hierarchical_split function is designed to split the unit square in a hierarchical manner, guided by a contingency table provided as a dictionary. This function is crucial for generating mosaic plots, where the area of each rectangle represents the frequency or size of the category it represents in the data. It alternates the splitting direction based on the 'horizontal' parameter and can introduce gaps between rectangles to enhance visual separation.\n\nInputs:\n- count_dict (dict): A dictionary representing the contingency table, where keys are tuples of categories and values are non-negative numbers indicating frequencies or sizes.\n- horizontal (bool, optional): A boolean indicating the starting direction of the split. True for horizontal (default), False for vertical.\n- gap (float or array of floats, optional): A single number or an array of numbers specifying the gaps to be inserted between subcategories. If an array is too short, it will be extended with exponentially decreasing gaps. If a single number, it will be applied uniformly.\n\nOutputs:\n- base_rect (dict): A dictionary mapping each category tuple to a 4-tuple representing the coordinates and dimensions of the corresponding rectangle in the mosaic plot. The 4-tuple consists of:\n    0 - x position of the lower left corner,\n    1 - y position of the lower left corner,\n    2 - width of the rectangle,\n    3 - height of the rectangle.", "method_code_mask": "from statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nfrom itertools import product\nimport numpy as np\nfrom numpy import array\nfrom numpy import cumsum\nfrom numpy import iterable\nfrom numpy import r_\nfrom pandas import DataFrame\nfrom statsmodels.graphics import utils\nfrom matplotlib.colors import hsv_to_rgb\nfrom matplotlib.patches import Rectangle\n\n\ndef _hierarchical_split(count_dict, horizontal=True, gap=0.05): [MASK]\n"}
{"method_name": "_debyem1_expansion", "full_method_name": "_debyem1_expansion", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/copula/archimedean.py", "method_code": "import sys\nimport numpy as np\nfrom scipy import stats\nfrom scipy import integrate\nfrom scipy import optimize\nfrom statsmodels.tools.rng_qrng import check_random_state\nimport warnings\ndef _debyem1_expansion(x):\n    \"\"\"Debye function minus 1, Taylor series approximation around zero\n\n    function is not used\n    \"\"\"\n    x = np.asarray(x)\n    dm1 = (-x / 4 + x ** 2 / 36 - x ** 4 / 3600 + x ** 6 / 211680 - x ** 8 /\n        10886400 + x ** 10 / 526901760 - x ** 12 * 691 / 16999766784000)\n    return dm1", "test_code_list": [{"test_code": "import warnings\nfrom statsmodels.compat.pytest import pytest_warns\nfrom statsmodels.compat.scipy import SP_LT_15\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_array_almost_equal\nimport pytest\nfrom scipy import stats\nfrom statsmodels.distributions.copula.archimedean import ArchimedeanCopula\nfrom statsmodels.distributions.copula.archimedean import ClaytonCopula\nfrom statsmodels.distributions.copula.archimedean import FrankCopula\nfrom statsmodels.distributions.copula.archimedean import GumbelCopula\nfrom statsmodels.distributions.copula.archimedean import _debyem1_expansion\nfrom statsmodels.distributions.copula.copulas import CopulaDistribution\nimport statsmodels.distributions.copula.depfunc_ev as trev\nfrom statsmodels.distributions.copula.elliptical import GaussianCopula\nfrom statsmodels.distributions.copula.elliptical import StudentTCopula\nfrom statsmodels.distributions.copula.extreme_value import ExtremeValueCopula\nfrom statsmodels.distributions.copula.extreme_value import copula_bv_ev\nfrom statsmodels.distributions.copula.other_copulas import IndependenceCopula\nimport statsmodels.distributions.copula.transforms as tra\nfrom statsmodels.distributions.tools import approx_copula_pdf\nfrom statsmodels.distributions.tools import frequencies_fromdata\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom statsmodels.tools.numdiff import approx_hess\n\nclass TestFrank():\n\tdef test_tau(self):\n\t    copula = FrankCopula(k_dim=2)\n\t    theta = [2, 1, 0.01, 0.0001, 1e-05, 1e-06]\n\t    tau_r = [0.2138945692196201, 0.110018536448993, 0.001111110000028503, \n\t        1.111110992013664e-05, 1.111104651951855e-06, 1.108825244955369e-07]\n\t    tau_cop = [copula.tau(th) for th in theta]\n\t    assert_allclose(tau_cop[:-1], tau_r[:-1], rtol=1e-05)\n\t    taud = 1 + 4 * _debyem1_expansion(theta) / theta\n\t    assert_allclose(taud, tau_cop, rtol=1e-05)\n\t\nTestFrank().test_tau()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/copula/tests/test_copula.py"}], "instruction": "Functionality: The function _debyem1_expansion(x) calculates the Debye function minus 1 using a Taylor series approximation around zero. The function approximates the behavior of the Debye function for small values of x by using a polynomial series expansion.\n\nInputs: \n- x: A scalar or an array-like collection of numerical values for which the Debye function minus 1 is to be calculated. The input can be a numpy array.\n\nOutputs: \n- dm1: The result of the Debye function minus 1 approximation for the input value(s) x. The output will be a scalar if the input is a scalar, or an array if the input is an array-like collection.", "method_code_mask": "import sys\nimport numpy as np\nfrom scipy import stats\nfrom scipy import integrate\nfrom scipy import optimize\nfrom statsmodels.tools.rng_qrng import check_random_state\nimport warnings\n\n\ndef _debyem1_expansion(x): [MASK]\n"}
{"method_name": "mv_mixture_rvs", "full_method_name": "mv_mixture_rvs", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/mixture_rvs.py", "method_code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\ndef mv_mixture_rvs(prob, size, dist, nvars, **kwargs):\n    \"\"\"\n    Sample from a mixture of multivariate distributions.\n\n    Parameters\n    ----------\n    prob : array_like\n        Probability of sampling from each distribution in dist\n    size : int\n        The length of the returned sample.\n    dist : array_like\n        An iterable of distributions instances with callable method rvs.\n    nvargs : int\n        dimension of the multivariate distribution, could be inferred instead\n    kwargs : tuple of dicts, optional\n        ignored\n\n    Examples\n    --------\n    Say we want 2000 random variables from mixture of normals with two\n    multivariate normal distributions, and we want to sample from the\n    first with probability .4 and the second with probability .6.\n\n    import statsmodels.sandbox.distributions.mv_normal as mvd\n\n    cov3 = np.array([[ 1.  ,  0.5 ,  0.75],\n                       [ 0.5 ,  1.5 ,  0.6 ],\n                       [ 0.75,  0.6 ,  2.  ]])\n\n    mu = np.array([-1, 0.0, 2.0])\n    mu2 = np.array([4, 2.0, 2.0])\n    mvn3 = mvd.MVNormal(mu, cov3)\n    mvn32 = mvd.MVNormal(mu2, cov3/2., 4)\n    rvs = mix.mv_mixture_rvs([0.4, 0.6], 2000, [mvn3, mvn32], 3)\n    \"\"\"\n    if len(prob) != len(dist):\n        raise ValueError(\n            'You must provide as many probabilities as distributions')\n    if not np.allclose(np.sum(prob), 1):\n        raise ValueError('prob does not sum to 1')\n    if kwargs is None:\n        kwargs = ({},) * len(prob)\n    idx = _make_index(prob, size)\n    sample = np.empty((size, nvars))\n    for i in range(len(prob)):\n        sample_idx = idx[..., i]\n        sample_size = sample_idx.sum()\n        sample[sample_idx] = dist[i].rvs(size=int(sample_size))\n    return sample", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom statsmodels.distributions.mixture_rvs import mv_mixture_rvs\nfrom statsmodels.distributions.mixture_rvs import MixtureDistribution\nimport statsmodels.sandbox.distributions.mv_normal as mvd\nfrom scipy import stats\n\nclass TestMixtureDistributions():\n\tdef test_mv_mixture_rvs_random(self):\n\t    cov3 = np.array([[1.0, 0.5, 0.75], [0.5, 1.5, 0.6], [0.75, 0.6, 2.0]])\n\t    mu = np.array([-1, 0.0, 2.0])\n\t    mu2 = np.array([4, 2.0, 2.0])\n\t    mvn3 = mvd.MVNormal(mu, cov3)\n\t    mvn32 = mvd.MVNormal(mu2, cov3 / 2.0)\n\t    np.random.seed(0)\n\t    res = mv_mixture_rvs([0.4, 0.6], 5000, [mvn3, mvn32], 3)\n\t    npt.assert_almost_equal(np.array([res.std(), res.mean(), res.var()]),\n\t        np.array([1.874, 1.733, 3.512]), decimal=1)\n\t\nTestMixtureDistributions().test_mv_mixture_rvs_random()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_mixture.py"}, {"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom statsmodels.distributions.mixture_rvs import mv_mixture_rvs\nfrom statsmodels.distributions.mixture_rvs import MixtureDistribution\nimport statsmodels.sandbox.distributions.mv_normal as mvd\nfrom scipy import stats\n\nclass TestMixtureDistributions():\n\tdef test_mv_mixture_rvs_fixed(self):\n\t    np.random.seed(1234)\n\t    cov3 = np.array([[1.0, 0.5, 0.75], [0.5, 1.5, 0.6], [0.75, 0.6, 2.0]])\n\t    mu = np.array([-1, 0.0, 2.0])\n\t    mu2 = np.array([4, 2.0, 2.0])\n\t    mvn3 = mvd.MVNormal(mu, cov3)\n\t    mvn32 = mvd.MVNormal(mu2, cov3 / 2)\n\t    res = mv_mixture_rvs([0.2, 0.8], 10, [mvn3, mvn32], 3)\n\t    npt.assert_almost_equal(res, np.array([[-0.23955497, 1.73426482, \n\t        0.36100243], [2.52063189, 1.0832677, 1.89947131], [4.36755379, \n\t        2.14480498, 2.22003966], [3.1141545, 1.21250505, 2.58511199], [\n\t        4.1980202, 2.50017561, 1.87324933], [3.48717503, 0.91847424, \n\t        2.14004598], [3.55904133, 2.74367622, 0.68619582], [3.60521933, \n\t        1.57316531, 0.82784584], [3.86102275, 0.6211812, 1.33016426], [\n\t        3.91074761, 2.037155, 2.22247051]]))\n\t\nTestMixtureDistributions().test_mv_mixture_rvs_fixed()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_mixture.py"}], "instruction": "Functionality: The mv_mixture_rvs function generates a sample from a mixture of multivariate distributions. It allows sampling from different distributions with specified probabilities.\n\nInputs:\n- prob: An array-like object representing the probability of sampling from each distribution in the dist parameter.\n- size: An integer indicating the length of the returned sample.\n- dist: An array-like object containing instances of distributions with a callable method rvs. These distributions will be mixed based on the prob parameter.\n- nvars: An integer specifying the dimension of the multivariate distribution.\n\nOutputs:\n- A NumPy array of shape (size, nvars) containing the sampled values from the mixture of distributions. Each row in the array represents a single sample, and the number of columns (nvars) corresponds to the dimension of the multivariate distribution.", "method_code_mask": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n\ndef mv_mixture_rvs(prob, size, dist, nvars, **kwargs): [MASK]\n"}
{"method_name": "monotone_fn_inverter", "full_method_name": "monotone_fn_inverter", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/empirical_distribution.py", "method_code": "import numpy as np\nfrom scipy.interpolate import interp1d\ndef monotone_fn_inverter(fn, x, vectorized=True, **keywords):\n    \"\"\"\n    Given a monotone function fn (no checking is done to verify monotonicity)\n    and a set of x values, return an linearly interpolated approximation\n    to its inverse from its values on x.\n    \"\"\"\n    x = np.asarray(x)\n    if vectorized:\n        y = fn(x, **keywords)\n    else:\n        y = []\n        for _x in x:\n            y.append(fn(_x, **keywords))\n        y = np.array(y)\n    a = np.argsort(y)\n    return interp1d(y[a], x[a])", "test_code_list": [{"test_code": "import numpy as np\nimport numpy.testing as npt\nfrom numpy.testing import assert_raises\nfrom statsmodels.distributions import StepFunction\nfrom statsmodels.distributions import monotone_fn_inverter\nfrom statsmodels.distributions import ECDFDiscrete\n\nclass TestDistributions():\n\tdef test_monotone_fn_inverter(self):\n\t    x = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n\t    fn = lambda x: 1.0 / x\n\t    y = fn(np.array(x))\n\t    f = monotone_fn_inverter(fn, x)\n\t    npt.assert_array_equal(f.y, x[::-1])\n\t    npt.assert_array_equal(f.x, y[::-1])\n\t\nTestDistributions().test_monotone_fn_inverter()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_ecdf.py"}], "instruction": "Functionality: The function \"monotone_fn_inverter\" is designed to approximate the inverse of a monotone function. Given a monotone function \"fn\" and a set of x values, this function computes the linearly interpolated approximation to the inverse of \"fn\" based on its values on the provided x values.\n\nInputs:\n1. fn: A callable function representing the monotone function for which the inverse is to be approximated. It is assumed that \"fn\" is monotonic, but no internal checks are conducted to verify this property.\n2. x: An array-like object containing the x values on which the function \"fn\" will be evaluated.\n3. vectorized (optional): A boolean parameter indicating whether the function \"fn\" can be applied to an array (True) or if it should be applied to each element individually (False). Default is True.\n4. **keywords: Additional keyword arguments that will be passed to the function \"fn\" during evaluation.\n\nOutputs:\n1. The function returns an interpolator object, specifically an instance of the interp1d class from the scipy.interpolate module. This interpolator object can be used to evaluate the approximated inverse function at any desired y value within the range of the input function \"fn\".", "method_code_mask": "import numpy as np\nfrom scipy.interpolate import interp1d\n\n\ndef monotone_fn_inverter(fn, x, vectorized=True, **keywords): [MASK]\n"}
{"method_name": "prob2cdf_grid", "full_method_name": "prob2cdf_grid", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tools.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef prob2cdf_grid(probs):\n    \"\"\"Cumulative probabilities from cell provabilites on a grid\n\n    Parameters\n    ----------\n    probs : array_like\n        Rectangular grid of cell probabilities.\n\n    Returns\n    -------\n    cdf : ndarray\n        Grid of cumulative probabilities with same shape as probs.\n    \"\"\"\n    cdf = np.asarray(probs).copy()\n    k = cdf.ndim\n    for i in range(k):\n        cdf = cdf.cumsum(axis=i)\n    return cdf", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.distributions.tools as dt\ndef test_grid():\n    k1, k2 = 3, 5\n    xg1 = np.arange(k1) / (k1 - 1)\n    xg2 = np.arange(k2) / (k2 - 1)\n    distr1 = stats.beta(2, 5)\n    distr2 = stats.beta(4, 3)\n    cdf1 = distr1.cdf(xg1)\n    cdf2 = distr2.cdf(xg2)\n    prob1 = np.diff(cdf1, prepend=0)\n    prob2 = np.diff(cdf2, prepend=0)\n    cd2d = cdf1[:, None] * cdf2\n    pd2d = prob1[:, None] * prob2\n    probs = dt.cdf2prob_grid(cd2d)\n    cdfs = prob2cdf_grid(pd2d)\n    assert_allclose(cdfs, cd2d, atol=1e-12)\n    assert_allclose(probs, pd2d, atol=1e-12)\n    nobs = 1000\n    np.random.seed(789123)\n    rvs = np.column_stack([distr1.rvs(size=nobs), distr2.rvs(size=nobs)])\n    hist = np.histogramdd(rvs, [xg1, xg2])\n    assert_allclose(probs[1:, 1:], hist[0] / len(rvs), atol=0.02)\n\ntest_grid()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_tools.py"}], "instruction": "Functionality: The prob2cdf_grid function is designed to calculate the cumulative probabilities from cell probabilities that are arranged on a grid. This function iterates through each dimension of the input grid, cumulatively summing the probabilities along each axis to produce a cumulative distribution function (CDF) grid that retains the same shape as the input.\n\nInputs: \n- probs : array_like\n    A rectangular grid of cell probabilities. It should be a multidimensional array representing the probability distribution over a grid. The dimensions of the array correspond to the different axes of the probability grid.\n\nOutputs: \n- cdf : ndarray\n    A grid of cumulative probabilities with the same shape as the input probs. The resulting array will be populated with the cumulative probabilities along each axis of the grid.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\n\n\ndef prob2cdf_grid(probs): [MASK]\n"}
{"method_name": "cdf2prob_grid", "full_method_name": "cdf2prob_grid", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tools.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef cdf2prob_grid(cdf, prepend=0):\n    \"\"\"Cell probabilities from cumulative probabilities on a grid.\n\n    Parameters\n    ----------\n    cdf : array_like\n        Grid of cumulative probabilities with same shape as probs.\n\n    Returns\n    -------\n    probs : ndarray\n        Rectangular grid of cell probabilities.\n\n    \"\"\"\n    if prepend is None:\n        prepend = np._NoValue\n    prob = np.asarray(cdf).copy()\n    k = prob.ndim\n    for i in range(k):\n        prob = np.diff(prob, prepend=prepend, axis=i)\n    return prob", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.distributions.tools as dt\ndef test_grid():\n    k1, k2 = 3, 5\n    xg1 = np.arange(k1) / (k1 - 1)\n    xg2 = np.arange(k2) / (k2 - 1)\n    distr1 = stats.beta(2, 5)\n    distr2 = stats.beta(4, 3)\n    cdf1 = distr1.cdf(xg1)\n    cdf2 = distr2.cdf(xg2)\n    prob1 = np.diff(cdf1, prepend=0)\n    prob2 = np.diff(cdf2, prepend=0)\n    cd2d = cdf1[:, None] * cdf2\n    pd2d = prob1[:, None] * prob2\n    probs = cdf2prob_grid(cd2d)\n    cdfs = dt.prob2cdf_grid(pd2d)\n    assert_allclose(cdfs, cd2d, atol=1e-12)\n    assert_allclose(probs, pd2d, atol=1e-12)\n    nobs = 1000\n    np.random.seed(789123)\n    rvs = np.column_stack([distr1.rvs(size=nobs), distr2.rvs(size=nobs)])\n    hist = np.histogramdd(rvs, [xg1, xg2])\n    assert_allclose(probs[1:, 1:], hist[0] / len(rvs), atol=0.02)\n\ntest_grid()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_tools.py"}], "instruction": "Functionality: The function cdf2prob_grid is designed to convert a grid of cumulative probabilities into a grid of cell probabilities. It essentially computes the differences between successive values along each dimension of the input array, effectively transforming cumulative distribution function (CDF) values into probability density function (PDF) values for each cell in the grid.\n\nInputs: \n- cdf : array_like\n  A grid of cumulative probabilities. The input must have the same shape as the output grid of probabilities intended to be returned. This input is mandatory.\n\n- prepend : scalar or array_like of shape (1,), optional\n  Value(s) to be prepended to the input array along the specified axis. If None, a default value is used. This input is optional and defaults to 0 if not provided.\n\nOutputs: \n- probs : ndarray\n  A rectangular grid of cell probabilities. The output will have the same shape as the input cdf. Each element in the output array represents the probability of the corresponding cell in the grid.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\n\n\ndef cdf2prob_grid(cdf, prepend=0): [MASK]\n"}
{"method_name": "average_grid", "full_method_name": "average_grid", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tools.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef average_grid(values, coords=None, _method='slicing'):\n    \"\"\"Compute average for each cell in grid using endpoints\n\n    Parameters\n    ----------\n    values : array_like\n        Values on a grid that will average over corner points of each cell.\n    coords : None or list of array_like\n        Grid coordinates for each axis use to compute volumne of cell.\n        If None, then averaged values are not rescaled.\n    _method : {\"slicing\", \"convolve\"}\n        Grid averaging is implemented using numpy \"slicing\" or using\n        scipy.signal \"convolve\".\n\n    Returns\n    -------\n    Grid with averaged cell values.\n    \"\"\"\n    k_dim = values.ndim\n    if _method == 'slicing':\n        p = values.copy()\n        for d in range(k_dim):\n            sl1 = [slice(None, None, None)] * k_dim\n            sl2 = [slice(None, None, None)] * k_dim\n            sl1[d] = slice(None, -1, None)\n            sl2[d] = slice(1, None, None)\n            sl1 = tuple(sl1)\n            sl2 = tuple(sl2)\n            p = (p[sl1] + p[sl2]) / 2\n    elif _method == 'convolve':\n        from scipy import signal\n        p = signal.convolve(values, 0.5 ** k_dim * np.ones([2] * k_dim),\n            mode='valid')\n    if coords is not None:\n        dx = np.array(1)\n        for d in range(k_dim):\n            dx = dx[..., None] * np.diff(coords[d])\n        p = p * dx\n    return p", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.distributions.tools as dt\ndef test_average_grid():\n    x1 = np.arange(1, 4)\n    x2 = np.arange(4)\n    y = x1[:, None] * x2\n    res1 = np.array([[0.75, 2.25, 3.75], [1.25, 3.75, 6.25]])\n    res0 = average_grid(y, coords=[x1, x2])\n    assert_allclose(res0, res1, rtol=1e-13)\n    res0 = average_grid(y, coords=[x1, x2], _method='slicing')\n    assert_allclose(res0, res1, rtol=1e-13)\n    res0 = average_grid(y, coords=[x1, x2], _method='convolve')\n    assert_allclose(res0, res1, rtol=1e-13)\n    res0 = average_grid(y, coords=[x1 / x1.max(), x2 / x2.max()])\n    assert_allclose(res0, res1 / x1.max() / x2.max(), rtol=1e-13)\n    res0 = average_grid(y, coords=[x1 / x1.max(), x2 / x2.max()],\n        _method='convolve')\n    assert_allclose(res0, res1 / x1.max() / x2.max(), rtol=1e-13)\n\ntest_average_grid()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_tools.py"}], "instruction": "Functionality: The function 'average_grid' computes the average values for each cell in a grid by considering the corner points of each cell. This is particularly useful for interpolating data or smoothing out values over a grid.\n\nInputs: \n- values: An array-like object representing the values on a grid that will be averaged over corner points of each cell.\n- coords: An optional list of array-like objects that represent the grid coordinates for each axis. These are used to compute the volume of each cell. If set to None, the averaged values will not be rescaled according to cell volumes.\n- _method: A string argument that specifies the method to be used for averaging the grid values. It can be either 'slicing' (default), which uses numpy slicing operations, or 'convolve', which uses the scipy.signal convolve function.\n\nOutputs: \n- A grid array with averaged cell values. If 'coords' is provided, the averaged values are scaled by the volume of each cell.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\n\n\ndef average_grid(values, coords=None, _method='slicing'): [MASK]\n"}
{"method_name": "_eval_bernstein_1d", "full_method_name": "_eval_bernstein_1d", "method_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tools.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\ndef _eval_bernstein_1d(x, fvals, method='binom'):\n    \"\"\"Evaluate 1-dimensional bernstein polynomial given grid of values.\n\n    experimental, comparing methods\n\n    Parameters\n    ----------\n    x : array_like\n        Values at which to evaluate the Bernstein polynomial.\n    fvals : ndarray\n        Grid values of coefficients for Bernstein polynomial basis in the\n        weighted sum.\n    method: \"binom\", \"beta\" or \"bpoly\"\n        Method to construct Bernstein polynomial basis, used for comparison\n        of parameterizations.\n\n        - \"binom\" uses pmf of Binomial distribution\n        - \"beta\" uses pdf of Beta distribution\n        - \"bpoly\" uses one interval in scipy.interpolate.BPoly\n\n    Returns\n    -------\n    Bernstein polynomial at evaluation points, weighted sum of Bernstein\n    polynomial basis.\n    \"\"\"\n    k_terms = fvals.shape[-1]\n    xx = np.asarray(x)\n    k = np.arange(k_terms).astype(float)\n    n = k_terms - 1.0\n    if method.lower() == 'binom':\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', RuntimeWarning)\n            poly_base = stats.binom.pmf(k, n, xx[..., None])\n        bp_values = (fvals * poly_base).sum(-1)\n    elif method.lower() == 'bpoly':\n        bpb = interpolate.BPoly(fvals[:, None], [0.0, 1])\n        bp_values = bpb(x)\n    elif method.lower() == 'beta':\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', RuntimeWarning)\n            poly_base = stats.beta.pdf(xx[..., None], k + 1, n - k + 1) / (n +\n                1)\n        bp_values = (fvals * poly_base).sum(-1)\n    else:\n        raise ValueError('method not recogized')\n    return bp_values", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom scipy import stats\nimport statsmodels.distributions.tools as dt\ndef test_bernstein_1d():\n    k = 5\n    xg1 = np.arange(k) / (k - 1)\n    xg2 = np.arange(2 * k) / (2 * k - 1)\n    res_bp = _eval_bernstein_1d(xg2, xg1)\n    assert_allclose(res_bp, xg2, atol=1e-12)\n    res_bp = _eval_bernstein_1d(xg2, xg1, method='beta')\n    assert_allclose(res_bp, xg2, atol=1e-12)\n    res_bp = _eval_bernstein_1d(xg2, xg1, method='bpoly')\n    assert_allclose(res_bp, xg2, atol=1e-12)\n\ntest_bernstein_1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/distributions/tests/test_tools.py"}], "instruction": "Functionality: \nThe _eval_bernstein_1d function evaluates a 1-dimensional Bernstein polynomial at specified points x, given a grid of coefficients (fvals) for the polynomial. It supports three different methods for constructing the Bernstein polynomial basis: \"binom\", \"beta\", and \"bpoly\". The function is intended for experimental comparison of these basis methods.\n\nInputs:\nx : array_like\n    The points at which the Bernstein polynomial will be evaluated.\nfvals : ndarray\n    The grid of coefficients for the Bernstein polynomial basis in the weighted sum. This is a one-dimensional array of length n+1, where n is the degree of the polynomial.\nmethod: str, default='binom'\n    A string indicating the method to use for constructing the Bernstein polynomial basis. Options are 'binom' (uses pmf of Binomial distribution), 'beta' (uses pdf of Beta distribution), and 'bpoly' (uses one interval in scipy.interpolate.BPoly).\n\nOutputs:\nBernstein polynomial at evaluation points: ndarray\n    The function returns an array of the evaluated Bernstein polynomial at each point x. This is a weighted sum of the Bernstein polynomial basis.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import signal\nfrom statsmodels.tools.sm_exceptions import ConvergenceWarning\n\n\ndef _eval_bernstein_1d(x, fvals, method='binom'): [MASK]\n"}
{"method_name": "_make_var_names", "full_method_name": "_make_var_names", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/x13.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nimport os\nimport subprocess\nimport tempfile\nimport re\nfrom warnings import warn\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import X13NotFoundError\nfrom statsmodels.tools.sm_exceptions import IOWarning\nfrom statsmodels.tools.sm_exceptions import X13Error\nfrom statsmodels.tools.sm_exceptions import X13Warning\nfrom statsmodels.base.data import _make_exog_names\nfrom io import StringIO\nfrom pandas import read_csv\nfrom pandas.tseries.api import infer_freq\nfrom statsmodels.graphics.utils import _import_mpl\ndef _make_var_names(exog):\n    if hasattr(exog, 'name'):\n        var_names = [exog.name]\n    elif hasattr(exog, 'columns'):\n        var_names = exog.columns\n    else:\n        raise ValueError('exog is not a Series or DataFrame or is unnamed.')\n    try:\n        var_names = ' '.join(var_names)\n    except TypeError:\n        from statsmodels.base.data import _make_exog_names\n        if exog.ndim == 1:\n            var_names = 'x1'\n        else:\n            var_names = ' '.join(_make_exog_names(exog))\n    return var_names", "test_code_list": [{"test_code": "import pandas as pd\nfrom statsmodels.tsa.x13 import _make_var_names\ndef test_make_var_names():\n    exog = pd.Series([1, 2, 3], name='abc')\n    assert _make_var_names(exog) == exog.name\n\ntest_make_var_names()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tests/test_x13.py"}], "instruction": "Functionality: The function _make_var_names is designed to generate variable names for the given exogenous data (exog) which can be a pandas Series or DataFrame. It extracts the name of a Series or the column names of a DataFrame. If the exog is not named or is neither a Series nor a DataFrame, it raises a ValueError. In case of a 1D array-like object without names, it falls back to a default naming convention.\n\nInputs: \n- exog: This is a required input. It can be a pandas Series or DataFrame that potentially contains the names of the variables or the data itself. If the data is named (i.e., has a name attribute for Series or column names for DataFrame), the function will use these names. If not, it will generate names based on the default naming convention.\n\nOutputs:\n- var_names: A string representing the variable names. If the input is a Series or DataFrame with names, it returns a space-separated string of these names. If the input is a 1D array-like object without names, it returns a string with a default name 'x1'. For multi-dimensional array-like objects without names, it generates names using a predefined naming convention.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nimport os\nimport subprocess\nimport tempfile\nimport re\nfrom warnings import warn\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.sm_exceptions import X13NotFoundError\nfrom statsmodels.tools.sm_exceptions import IOWarning\nfrom statsmodels.tools.sm_exceptions import X13Error\nfrom statsmodels.tools.sm_exceptions import X13Warning\nfrom statsmodels.base.data import _make_exog_names\nfrom io import StringIO\nfrom pandas import read_csv\nfrom pandas.tseries.api import infer_freq\nfrom statsmodels.graphics.utils import _import_mpl\n\n\ndef _make_var_names(exog): [MASK]\n"}
{"method_name": "get_dummy_mod", "full_method_name": "get_dummy_mod", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_mlemodel.py", "method_code": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef get_dummy_mod(fit=True, pandas=False):\n    endog = np.arange(100) * 1.0\n    exog = 2 * endog\n    if pandas:\n        index = pd.date_range('1960-01-01', periods=100, freq='MS')\n        endog = pd.Series(endog, index=index)\n        exog = pd.Series(exog, index=index)\n    mod = sarimax.SARIMAX(endog, exog=exog, order=(0, 0, 0),\n        time_varying_regression=True, mle_regression=False,\n        use_exact_diffuse=True)\n    if fit:\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            res = mod.fit(disp=-1)\n    else:\n        res = None\n    return mod, res", "test_code_list": [{"test_code": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_wrapping():\n    mod, _ = get_dummy_mod(fit=False)\n    assert_equal(mod['design', 0, 0], 2.0 * np.arange(100))\n    mod['design', 0, 0, :] = 2\n    assert_equal(mod.ssm['design', 0, 0, :], 2)\n    assert_equal(mod.ssm['design'].shape, (1, 1, 100))\n    mod['design'] = [[3.0]]\n    assert_equal(mod.ssm['design', 0, 0], 3.0)\n    assert_equal(mod.ssm['design'].shape, (1, 1))\n    assert_equal(mod.loglikelihood_burn, 0)\n    mod.loglikelihood_burn = 1\n    assert_equal(mod.ssm.loglikelihood_burn, 1)\n    assert_equal(mod.tolerance, mod.ssm.tolerance)\n    mod.tolerance = 0.123\n    assert_equal(mod.ssm.tolerance, 0.123)\n    assert_equal(mod.initial_variance, 10000000000.0)\n    mod.initial_variance = 1000000000000.0\n    assert_equal(mod.ssm.initial_variance, 1000000000000.0)\n    assert_equal(isinstance(mod.initialization, object), True)\n    mod.initialize_default()\n    mod.initialize_approximate_diffuse(100000.0)\n    assert_equal(mod.initialization.initialization_type, 'approximate_diffuse')\n    assert_equal(mod.initialization.approximate_diffuse_variance, 100000.0)\n    mod.initialize_known([5.0], [[40]])\n    assert_equal(mod.initialization.initialization_type, 'known')\n    assert_equal(mod.initialization.constant, [5.0])\n    assert_equal(mod.initialization.stationary_cov, [[40]])\n    mod.initialize_stationary()\n    assert_equal(mod.initialization.initialization_type, 'stationary')\n    assert_equal(mod.ssm.filter_method, kalman_filter.FILTER_CONVENTIONAL)\n    assert_equal(mod.ssm.stability_method, kalman_filter.\n        STABILITY_FORCE_SYMMETRY)\n    assert_equal(mod.ssm.conserve_memory, kalman_filter.MEMORY_STORE_ALL)\n    assert_equal(mod.ssm.smoother_output, kalman_smoother.SMOOTHER_ALL)\n    mod.ssm._initialize_filter()\n    kf = mod.ssm._kalman_filter\n    assert_equal(kf.filter_method, kalman_filter.FILTER_CONVENTIONAL)\n    assert_equal(kf.stability_method, kalman_filter.STABILITY_FORCE_SYMMETRY)\n    assert_equal(kf.conserve_memory, kalman_filter.MEMORY_STORE_ALL)\n    mod.set_filter_method(100)\n    mod.set_stability_method(101)\n    mod.set_conserve_memory(102)\n    mod.set_smoother_output(103)\n    assert_equal(mod.ssm.filter_method, 100)\n    assert_equal(mod.ssm.stability_method, 101)\n    assert_equal(mod.ssm.conserve_memory, 102)\n    assert_equal(mod.ssm.smoother_output, 103)\n    assert_equal(kf.filter_method, kalman_filter.FILTER_CONVENTIONAL)\n    assert_equal(kf.stability_method, kalman_filter.STABILITY_FORCE_SYMMETRY)\n    assert_equal(kf.conserve_memory, kalman_filter.MEMORY_STORE_ALL)\n    mod.set_filter_method(1)\n    mod.ssm._initialize_filter()\n    kf = mod.ssm._kalman_filter\n    assert_equal(kf.filter_method, 1)\n    assert_equal(kf.stability_method, 101)\n    assert_equal(kf.conserve_memory, 102)\n\ntest_wrapping()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_mlemodel.py"}, {"test_code": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_fit_misc():\n    true = results_sarimax.wpi1_stationary\n    endog = np.diff(true['data'])[1:]\n    mod = sarimax.SARIMAX(endog, order=(1, 0, 1), trend='c')\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        res1 = mod.fit(method='ncg', disp=0, optim_hessian='opg',\n            optim_complex_step=False)\n        res2 = mod.fit(method='ncg', disp=0, optim_hessian='oim',\n            optim_complex_step=False)\n    assert_allclose(res1.llf, res2.llf, rtol=0.01)\n    mod, _ = get_dummy_mod(fit=False)\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        res_params = mod.fit(disp=-1, return_params=True)\n    assert_almost_equal(res_params, [0, 0], 5)\n\ntest_fit_misc()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_mlemodel.py"}, {"test_code": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_cov_params():\n    mod, res = get_dummy_mod()\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        res = mod.fit(res.params, disp=-1, cov_type='none')\n        assert_equal(res.cov_kwds['description'],\n            'Covariance matrix not calculated.')\n        res = mod.fit(res.params, disp=-1, cov_type='approx')\n        assert_equal(res.cov_type, 'approx')\n        assert_equal(res.cov_kwds['description'],\n            'Covariance matrix calculated using numerical (complex-step) differentiation.'\n            )\n        res = mod.fit(res.params, disp=-1, cov_type='oim')\n        assert_equal(res.cov_type, 'oim')\n        assert_equal(res.cov_kwds['description'],\n            'Covariance matrix calculated using the observed information matrix (complex-step) described in Harvey (1989).'\n            )\n        res = mod.fit(res.params, disp=-1, cov_type='opg')\n        assert_equal(res.cov_type, 'opg')\n        assert_equal(res.cov_kwds['description'],\n            'Covariance matrix calculated using the outer product of gradients (complex-step).'\n            )\n        res = mod.fit(res.params, disp=-1, cov_type='robust')\n        assert_equal(res.cov_type, 'robust')\n        assert_equal(res.cov_kwds['description'],\n            'Quasi-maximum likelihood covariance matrix used for robustness to some misspecifications; calculated using the observed information matrix (complex-step) described in Harvey (1989).'\n            )\n        res = mod.fit(res.params, disp=-1, cov_type='robust_oim')\n        assert_equal(res.cov_type, 'robust_oim')\n        assert_equal(res.cov_kwds['description'],\n            'Quasi-maximum likelihood covariance matrix used for robustness to some misspecifications; calculated using the observed information matrix (complex-step) described in Harvey (1989).'\n            )\n        res = mod.fit(res.params, disp=-1, cov_type='robust_approx')\n        assert_equal(res.cov_type, 'robust_approx')\n        assert_equal(res.cov_kwds['description'],\n            'Quasi-maximum likelihood covariance matrix used for robustness to some misspecifications; calculated using numerical (complex-step) differentiation.'\n            )\n        with pytest.raises(NotImplementedError):\n            mod.fit(res.params, disp=-1, cov_type='invalid_cov_type')\n\ntest_cov_params()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_mlemodel.py"}, {"test_code": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_diagnostics():\n    mod, res = get_dummy_mod()\n    shape = res.filter_results._standardized_forecasts_error.shape\n    res.filter_results._standardized_forecasts_error = np.random.normal(size\n        =shape)\n    actual = res.test_normality(method=None)\n    desired = res.test_normality(method='jarquebera')\n    assert_allclose(actual, desired)\n    assert_raises(NotImplementedError, res.test_normality, method='invalid')\n    actual = res.test_heteroskedasticity(method=None)\n    desired = res.test_heteroskedasticity(method='breakvar')\n    assert_allclose(actual, desired)\n    with pytest.raises(ValueError):\n        res.test_heteroskedasticity(method=None, alternative='invalid')\n    with pytest.raises(NotImplementedError):\n        res.test_heteroskedasticity(method='invalid')\n    actual = res.test_serial_correlation(method=None)\n    desired = res.test_serial_correlation(method='ljungbox')\n    assert_allclose(actual, desired)\n    with pytest.raises(NotImplementedError):\n        res.test_serial_correlation(method='invalid')\n    res.test_heteroskedasticity(method=None, alternative='d', use_f=False)\n    res.test_serial_correlation(method='boxpierce')\n\ntest_diagnostics()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_mlemodel.py"}], "instruction": "Functionality: \nThe get_dummy_mod function is designed to create a dummy SARIMAX model from the statsmodels library for time series analysis. The model is created using an endogenous (endog) and an exogenous (exog) variable, both generated as simple linear sequences. The function also allows the option to fit the model and return both the model and the results, along with the capability to convert these variables into pandas Series for handling time-series data.\n\nInputs:\n- fit (boolean): Determines whether the SARIMAX model should be fitted. True indicates that the model should be fitted, and False indicates that it should not be.\n- pandas (boolean): Determines the format of the input data. True indicates that the data should be in pandas Series format, with a date range index starting from '1960-01-01', and False indicates that the data should be in numpy array format.\n\nOutputs:\n- mod (SARIMAX model): The SARIMAX model object created using the specified endog and exog variables. The model is time-varying with regression enabled, with no maximum likelihood estimation for regression coefficients, and uses exact diffuse initialization for the Kalman filter.\n- res (MLEModel results or None): The results of fitting the model if 'fit' is True. This includes optimized parameters, log-likelihood values, covariance matrices, etc. If 'fit' is False, 'res' will be None.", "method_code_mask": "import os\nimport re\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import nile\nfrom statsmodels.tsa.statespace import kalman_filter\nfrom statsmodels.tsa.statespace import kalman_smoother\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.statespace.mlemodel import MLEModel\nfrom statsmodels.tsa.statespace.mlemodel import MLEResultsWrapper\nfrom statsmodels.tsa.statespace.tests.results import results_sarimax\nfrom statsmodels.tsa.statespace.tests.results import results_var_misc\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\ndef get_dummy_mod(fit=True, pandas=False): [MASK]\n"}
{"method_name": "get_macrodata", "full_method_name": "get_macrodata", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/tests/test_var.py", "method_code": "from statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom io import StringIO\nimport os\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import macrodata\nimport statsmodels.tools.data as data_util\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tsa.base.datetools import dates_from_str\nimport statsmodels.tsa.vector_ar.util as util\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import var_acf\nimport datetime\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\ndef get_macrodata():\n    data = macrodata.load_pandas().data[['realgdp', 'realcons', 'realinv']]\n    data = data.to_records(index=False)\n    nd = data.view((float, 3), type=np.ndarray)\n    nd = np.diff(np.log(nd), axis=0)\n    return nd.ravel().view(data.dtype, type=np.ndarray)", "test_code_list": [{"test_code": "import warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nimport pandas as pd\nimport pytest\nfrom scipy.stats import ortho_group\nfrom statsmodels.tools.sm_exceptions import EstimationWarning\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import mlemodel\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import structural\nfrom statsmodels.tsa.statespace import varmax\nfrom statsmodels.tsa.vector_ar.tests.test_var import get_macrodata\ndef test_varmax():\n    steps = 10\n    varmax.__warningregistry__ = {}\n    mod1 = varmax.VARMAX([[0]], order=(2, 0), trend='n')\n    mod2 = sarimax.SARIMAX([0], order=(2, 0, 0))\n    actual = mod1.impulse_responses([0.5, 0.2, 1], steps)\n    desired = mod2.impulse_responses([0.5, 0.2, 1], steps)\n    assert_allclose(actual, desired)\n    mod1 = varmax.VARMAX([[0]], order=(0, 2), trend='n')\n    mod2 = sarimax.SARIMAX([0], order=(0, 0, 2))\n    actual = mod1.impulse_responses([0.5, 0.2, 1], steps)\n    desired = mod2.impulse_responses([0.5, 0.2, 1], steps)\n    assert_allclose(actual, desired)\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        mod1 = varmax.VARMAX([[0]], order=(2, 2), trend='n')\n    mod2 = sarimax.SARIMAX([0], order=(2, 0, 2))\n    actual = mod1.impulse_responses([0.5, 0.2, 0.1, -0.2, 1], steps)\n    desired = mod2.impulse_responses([0.5, 0.2, 0.1, -0.2, 1], steps)\n    assert_allclose(actual, desired)\n    warning = EstimationWarning\n    match = 'VARMA\\\\(p,q\\\\) models is not'\n    with pytest.warns(warning, match=match):\n        mod1 = varmax.VARMAX([[0]], order=(2, 2), trend='c')\n    mod2 = sarimax.SARIMAX([0], order=(2, 0, 2), trend='c')\n    actual = mod1.impulse_responses([10, 0.5, 0.2, 0.1, -0.2, 1], steps)\n    desired = mod2.impulse_responses([10, 0.5, 0.2, 0.1, -0.2, 1], steps)\n    assert_allclose(actual, desired)\n    params = [-0.00122728, 0.01503679, -0.22741923, 0.71030531, -0.11596357,\n        0.51494891, 0.05974659, 0.02094608, 0.05635125, 0.08332519, \n        0.04297918, 0.00159473, 0.01096298]\n    irf_00 = [1, -0.227419, -0.021806, 0.093362, -0.001875, -0.00906, \n        0.009605, 0.001323, -0.001041, 0.000769, 0.00032]\n    irf_01 = [0, 0.059747, 0.044015, -0.008218, 0.007845, 0.004629, \n        0.000104, 0.000451, 0.000638, 6.3e-05, 4.2e-05]\n    irf_10 = [0, 0.710305, 0.36829, -0.065697, 0.084398, 0.043038, 0.000533,\n        0.005755, 0.006051, 0.000548, 0.000526]\n    irf_11 = [1, 0.020946, 0.126202, 0.066419, 0.028735, 0.007477, 0.009878,\n        0.003287, 0.001266, 0.000986, 0.0005]\n    oirf_00 = [0.042979, -0.008642, -0.00035, 0.003908, 5.4e-05, -0.000321,\n        0.000414, 6.6e-05, -3.5e-05, 3.4e-05, 1.5e-05]\n    oirf_01 = [0.001595, 0.002601, 0.002093, -0.000247, 0.000383, 0.000211,\n        2e-05, 2.5e-05, 2.9e-05, 4.3e-06, 2.6e-06]\n    oirf_10 = [0, 0.007787, 0.004037, -0.00072, 0.000925, 0.000472, 5.8e-06,\n        6.3e-05, 6.6e-05, 6e-06, 5.8e-06]\n    oirf_11 = [0.010963, 0.00023, 0.001384, 0.000728, 0.000315, 8.2e-05, \n        0.000108, 3.6e-05, 1.4e-05, 1.1e-05, 5.5e-06]\n    mod = varmax.VARMAX([[0, 0]], order=(2, 0), trend='c')\n    actual = mod.impulse_responses(params, steps, impulse=0)\n    assert_allclose(actual, np.c_[irf_00, irf_01], atol=1e-06)\n    actual = mod.impulse_responses(params, steps, impulse=1)\n    assert_allclose(actual, np.c_[irf_10, irf_11], atol=1e-06)\n    actual = mod.impulse_responses(params, steps, impulse=0, orthogonalized\n        =True)\n    assert_allclose(actual, np.c_[oirf_00, oirf_01], atol=1e-06)\n    actual = mod.impulse_responses(params, steps, impulse=1, orthogonalized\n        =True)\n    assert_allclose(actual, np.c_[oirf_10, oirf_11], atol=1e-06)\n    data = get_macrodata().view((float, 3), type=np.ndarray)\n    df = pd.DataFrame({'a': data[:, 0], 'b': data[:, 1], 'c': data[:, 2]})\n    mod1 = varmax.VARMAX(df, order=(1, 0), trend='c')\n    mod1_result = mod1.fit()\n    mod2 = varmax.VARMAX(data, order=(1, 0), trend='c')\n    mod2_result = mod2.fit()\n    with pytest.raises(ValueError, match='Endog must be pd.DataFrame.'):\n        mod2_result.impulse_responses(6, impulse='b')\n    response1 = mod1_result.impulse_responses(6, impulse='b')\n    response2 = mod1_result.impulse_responses(6, impulse=[0, 1, 0])\n    assert_allclose(response1, response2)\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        mod = varmax.VARMAX(np.random.normal(size=(steps, 2)), order=(2, 2),\n            trend='c', exog=np.ones(steps), enforce_stationarity=False,\n            enforce_invertibility=False)\n    mod.impulse_responses(mod.start_params, steps)\n\ntest_varmax()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_impulse_responses.py"}, {"test_code": "from statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom io import StringIO\nimport os\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import macrodata\nimport statsmodels.tools.data as data_util\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tsa.base.datetools import dates_from_str\nimport statsmodels.tsa.vector_ar.util as util\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import var_acf\nimport datetime\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\ndef test_irf_trend():\n    data = get_macrodata().view((float, 3), type=np.ndarray)\n    model = VAR(data)\n    results = model.fit(4)\n    irf = results.irf(10)\n    data_nc = data - data.mean(0)\n    model_nc = VAR(data_nc)\n    results_nc = model_nc.fit(4, trend='n')\n    irf_nc = results_nc.irf(10)\n    assert_allclose(irf_nc.stderr()[1:4], irf.stderr()[1:4], rtol=0.01)\n    trend = 0.001 * np.arange(len(data)) / (len(data) - 1)\n    data_t = data + trend[:, None]\n    model_t = VAR(data_t)\n    results_t = model_t.fit(4, trend='ct')\n    irf_t = results_t.irf(10)\n    assert_allclose(irf_t.stderr()[1:4], irf.stderr()[1:4], rtol=0.03)\n\ntest_irf_trend()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/tests/test_var.py"}], "instruction": "Functionality: The 'get_macrodata' function is designed to preprocess and retrieve macroeconomic data for time series analysis, specifically focusing on three variables: real GDP, real consumption, and real investment. It loads a pandas DataFrame containing these variables, transforms the data into logarithmic differences, and returns it in a format suitable for further statistical analysis.\n\nInputs: The function does not take any input arguments. It operates on an internal dataset provided by the 'statsmodels.datasets.macrodata' module.\n\nOutputs: The function returns a NumPy ndarray. This array contains the log-differenced values of the 'realgdp', 'realcons', and 'realinv' variables from the macroeconomic dataset. The data is structured in a way that each row represents a time period, and each column corresponds to one of the three variables.", "method_code_mask": "from statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom io import StringIO\nimport os\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import macrodata\nimport statsmodels.tools.data as data_util\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tsa.base.datetools import dates_from_str\nimport statsmodels.tsa.vector_ar.util as util\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import var_acf\nimport datetime\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\n\n\ndef get_macrodata(): [MASK]\n"}
{"method_name": "get_sarimax_models", "full_method_name": "get_sarimax_models", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_concentrated.py", "method_code": "import numpy as np\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_allclose\ndef get_sarimax_models(endog, filter_univariate=False, **kwargs):\n    kwargs.setdefault('tolerance', 0)\n    mod_conc = sarimax.SARIMAX(endog, **kwargs)\n    mod_conc.ssm.filter_concentrated = True\n    mod_conc.ssm.filter_univariate = filter_univariate\n    params_conc = mod_conc.start_params\n    params_conc[-1] = 1\n    res_conc = mod_conc.smooth(params_conc)\n    scale = res_conc.scale\n    mod_orig = sarimax.SARIMAX(endog, **kwargs)\n    mod_orig.ssm.filter_univariate = filter_univariate\n    params_orig = params_conc.copy()\n    k_vars = 1 + kwargs.get('measurement_error', False)\n    params_orig[-k_vars:] = scale * params_conc[-k_vars:]\n    res_orig = mod_orig.smooth(params_orig)\n    return Bunch(**{'mod_conc': mod_conc, 'params_conc': params_conc,\n        'mod_orig': mod_orig, 'params_orig': params_orig, 'res_conc':\n        res_conc, 'res_orig': res_orig, 'scale': scale})", "test_code_list": [{"test_code": "import numpy as np\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_allclose\ndef test_concentrated_loglike_sarimax():\n    nobs = 30\n    np.random.seed(28953)\n    endog = np.random.normal(size=nobs)\n    kwargs = {}\n    out = get_sarimax_models(endog)\n    assert_allclose(out.res_conc.llf, out.res_orig.llf)\n    assert_allclose(out.res_conc.llf_obs, out.res_orig.llf_obs)\n    assert_allclose(out.mod_conc.loglike(out.params_conc), out.mod_orig.\n        loglike(out.params_orig))\n    assert_allclose(out.mod_conc.loglikeobs(out.params_conc), out.mod_orig.\n        loglikeobs(out.params_orig))\n    endog[2:10] = np.nan\n    out = get_sarimax_models(endog)\n    assert_allclose(out.res_conc.llf, out.res_orig.llf)\n    assert_allclose(out.res_conc.llf_obs, out.res_orig.llf_obs)\n    assert_allclose(out.mod_conc.loglike(out.params_conc), out.mod_orig.\n        loglike(out.params_orig))\n    assert_allclose(out.mod_conc.loglikeobs(out.params_conc), out.mod_orig.\n        loglikeobs(out.params_orig))\n    kwargs['seasonal_order'] = 1, 1, 1, 2\n    out = get_sarimax_models(endog, **kwargs)\n    assert_allclose(out.res_conc.llf, out.res_orig.llf)\n    assert_allclose(out.res_conc.llf_obs[2:], out.res_orig.llf_obs[2:])\n    assert_allclose(out.mod_conc.loglike(out.params_conc), out.mod_orig.\n        loglike(out.params_orig))\n    assert_allclose(out.mod_conc.loglikeobs(out.params_conc)[2:], out.\n        mod_orig.loglikeobs(out.params_orig)[2:])\n    kwargs['loglikelihood_burn'] = 5\n    kwargs['trend'] = 'c'\n    kwargs['exog'] = np.arange(nobs)\n    out = get_sarimax_models(endog, **kwargs)\n    assert_allclose(out.res_conc.llf, out.res_orig.llf)\n    assert_allclose(out.res_conc.llf_obs[2:], out.res_orig.llf_obs[2:])\n    assert_allclose(out.mod_conc.loglike(out.params_conc), out.mod_orig.\n        loglike(out.params_orig))\n    assert_allclose(out.mod_conc.loglikeobs(out.params_conc)[2:], out.\n        mod_orig.loglikeobs(out.params_orig)[2:])\n\ntest_concentrated_loglike_sarimax()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_concentrated.py"}, {"test_code": "import numpy as np\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_allclose\ndef test_concentrated_predict_sarimax():\n    nobs = 30\n    np.random.seed(28953)\n    endog = np.random.normal(size=nobs)\n    out = get_sarimax_models(endog)\n    assert_allclose(out.res_conc.predict(), out.res_orig.predict())\n    assert_allclose(out.res_conc.forecast(5), out.res_orig.forecast(5))\n    assert_allclose(out.res_conc.predict(start=0, end=45, dynamic=10), out.\n        res_orig.predict(start=0, end=45, dynamic=10))\n\ntest_concentrated_predict_sarimax()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_concentrated.py"}], "instruction": "Functionality: The get_sarimax_models function generates two SARIMAX models and computes their results given a univariate or multivariate time series 'endog'. The first model uses a concentrated Kalman filter, while the second model uses the original Kalman filter. The function returns a Bunch object containing both models, their parameters, results from smoothing, and the scale factor.\n\nInputs:\n    endog: array_like\n        The observed time-series process. Can be either univariate or multivariate.\n    filter_univariate: bool, default=False\n        Indicates whether to use the univariate Kalman filter.\n    **kwargs: other keyword arguments\n        These include additional arguments for SARIMAX model configuration, such as 'order', 'seasonal_order', 'measurement_error', etc.\n\nOutputs:\n    A Bunch object with the following attributes:\n        mod_conc: SARIMAX model with a concentrated Kalman filter.\n        params_conc: array_like\n            Parameters estimated for the concentrated Kalman filter model.\n        mod_orig: SARIMAX model with the original Kalman filter.\n        params_orig: array_like\n            Parameters estimated for the original Kalman filter model.\n        res_conc: SARIMAXResults object\n            Results from smoothing using the concentrated Kalman filter model.\n        res_orig: SARIMAXResults object\n            Results from smoothing using the original Kalman filter model.\n        scale: float\n            The scale factor used to adjust the parameters from the concentrated to the original Kalman filter model.", "method_code_mask": "import numpy as np\nimport pandas as pd\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace import varmax\nfrom numpy.testing import assert_raises\nfrom numpy.testing import assert_allclose\n\n\ndef get_sarimax_models(endog, filter_univariate=False, **kwargs): [MASK]\n"}
{"method_name": "model_common_level", "full_method_name": "model_common_level", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_exact_diffuse_filtering.py", "method_code": "from statsmodels.compat.platform import PLATFORM_WIN\nimport numpy as np\nimport pandas as pd\nimport pytest\nimport os\nfrom statsmodels import datasets\nfrom statsmodels.tsa.statespace.initialization import Initialization\nfrom statsmodels.tsa.statespace.kalman_smoother import KalmanSmoother\nfrom statsmodels.tsa.statespace.varmax import VARMAX\nfrom statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\nfrom statsmodels.tsa.statespace.structural import UnobservedComponents\nfrom statsmodels.tsa.statespace.tests.test_impulse_responses import TVSS\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\ndef model_common_level(endog=None, params=None, restricted=False):\n    if endog is None:\n        y11 = 10.2394\n        y21 = 8.2304\n        endog = np.column_stack([np.r_[y11, [1] * 9], np.r_[y21, [1] * 9]])\n    if params is None:\n        params = [0.1111, 3.2324]\n    theta, sigma2_mu = params\n    if not restricted:\n        ssm = KalmanSmoother(k_endog=2, k_states=2, k_posdef=1)\n        ssm.bind(endog.T)\n        init = Initialization(ssm.k_states, initialization_type='diffuse')\n        ssm.initialize(init)\n        ssm['design'] = np.array([[1, 0], [theta, 1]])\n        ssm['obs_cov'] = np.eye(2)\n        ssm['transition'] = np.eye(2)\n        ssm['selection', 0, 0] = 1\n        ssm['state_cov', 0, 0] = sigma2_mu\n    else:\n        ssm = KalmanSmoother(k_endog=2, k_states=1, k_posdef=1)\n        ssm.bind(endog.T)\n        init = Initialization(ssm.k_states, initialization_type='diffuse')\n        ssm.initialize(init)\n        ssm['design'] = np.array([[1, theta]]).T\n        ssm['obs_cov'] = np.eye(2)\n        ssm['transition', :] = 1\n        ssm['selection', :] = 1\n        ssm['state_cov', :] = sigma2_mu\n    return ssm", "test_code_list": [{"test_code": "from statsmodels.compat.platform import PLATFORM_WIN\nimport numpy as np\nimport pandas as pd\nimport pytest\nimport os\nfrom statsmodels import datasets\nfrom statsmodels.tsa.statespace.initialization import Initialization\nfrom statsmodels.tsa.statespace.kalman_smoother import KalmanSmoother\nfrom statsmodels.tsa.statespace.varmax import VARMAX\nfrom statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\nfrom statsmodels.tsa.statespace.structural import UnobservedComponents\nfrom statsmodels.tsa.statespace.tests.test_impulse_responses import TVSS\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\ndef test_common_level_analytic():\n    mod = model_common_level()\n    y11, y21 = mod.endog[:, 0]\n    theta = mod['design', 1, 0]\n    sigma2_mu = mod['state_cov', 0, 0]\n    res = mod.smooth()\n    assert_allclose(res.predicted_state_cov[..., 0], np.zeros((2, 2)))\n    assert_allclose(res.predicted_diffuse_state_cov[..., 0], np.eye(2))\n    assert_allclose(res.predicted_state[:, 1], [y11, y21 - theta * y11])\n    P2 = np.array([[1 + sigma2_mu, -theta], [-theta, 1 + theta ** 2]])\n    assert_allclose(res.predicted_state_cov[..., 1], P2)\n    assert_allclose(res.predicted_diffuse_state_cov[..., 1], np.zeros((2, 2)))\n    assert_equal(res.nobs_diffuse, 1)\n\ntest_common_level_analytic()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_exact_diffuse_filtering.py"}, {"test_code": "from statsmodels.compat.platform import PLATFORM_WIN\nimport numpy as np\nimport pandas as pd\nimport pytest\nimport os\nfrom statsmodels import datasets\nfrom statsmodels.tsa.statespace.initialization import Initialization\nfrom statsmodels.tsa.statespace.kalman_smoother import KalmanSmoother\nfrom statsmodels.tsa.statespace.varmax import VARMAX\nfrom statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\nfrom statsmodels.tsa.statespace.structural import UnobservedComponents\nfrom statsmodels.tsa.statespace.tests.test_impulse_responses import TVSS\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\ndef test_common_level_restricted_analytic():\n    mod = model_common_level(restricted=True)\n    y11, y21 = mod.endog[:, 0]\n    theta = mod['design', 1, 0]\n    sigma2_mu = mod['state_cov', 0, 0]\n    res = mod.smooth()\n    assert_allclose(res.predicted_state_cov[..., 0], 0)\n    assert_allclose(res.predicted_diffuse_state_cov[..., 0], 1)\n    phi = 1 / (1 + theta ** 2)\n    assert_allclose(res.predicted_state[:, 1], phi * (y11 + theta * y21))\n    assert_allclose(res.predicted_state_cov[..., 1], phi + sigma2_mu)\n    assert_allclose(res.predicted_diffuse_state_cov[..., 1], 0)\n    assert_equal(res.nobs_diffuse, 1)\n\ntest_common_level_restricted_analytic()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_exact_diffuse_filtering.py"}], "instruction": "Functionality: The model_common_level function is designed to create a state space model using the KalmanSmoother class from the statsmodels library, given the provided parameters and data. It supports two modes: 'unrestricted' and 'restricted', which differ in the number of states they model and how they model the transition of the endogenous variable. In the unrestricted mode, the function models two states, one for the level and another for the slope. In the restricted mode, the function models only the level, which is assumed to be common to all endogenous variables.\n\nInputs: \n1. endog (optional): An array-like object containing the endogenous variables to be modeled. If not provided, default data is used.\n2. params (optional): A list of model parameters. If not provided, default parameters are used.\n3. restricted (bool, optional): A boolean flag to indicate whether the model should be built in the restricted mode (only level modeled) or unrestricted mode (level and slope modeled). Default is set to False for the unrestricted mode.\n\nOutputs: \n1. ssm (KalmanSmoother object): A fully configured KalmanSmoother object, ready for fitting to the provided endogenous data (or default data if not provided).", "method_code_mask": "from statsmodels.compat.platform import PLATFORM_WIN\nimport numpy as np\nimport pandas as pd\nimport pytest\nimport os\nfrom statsmodels import datasets\nfrom statsmodels.tsa.statespace.initialization import Initialization\nfrom statsmodels.tsa.statespace.kalman_smoother import KalmanSmoother\nfrom statsmodels.tsa.statespace.varmax import VARMAX\nfrom statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\nfrom statsmodels.tsa.statespace.structural import UnobservedComponents\nfrom statsmodels.tsa.statespace.tests.test_impulse_responses import TVSS\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\n\n\ndef model_common_level(endog=None, params=None, restricted=False): [MASK]\n"}
{"method_name": "gen_dfm_data", "full_method_name": "gen_dfm_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py", "method_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef gen_dfm_data(k_endog=2, nobs=1000):\n    if k_endog > 10:\n        raise ValueError('Only allows for k_endog <= 10')\n    ix = pd.period_range(start='1950-01', periods=1, freq='M')\n    faux = pd.DataFrame([[0] * k_endog], index=ix)\n    mod = dynamic_factor.DynamicFactor(faux, k_factors=1, factor_order=1)\n    loadings = [0.5, -0.9, 0.2, 0.7, -0.1, -0.1, 0.4, 0.4, 0.8, 0.8][:k_endog]\n    phi = 0.5\n    sigma2 = 1.0\n    idio_ar1 = [0] * k_endog\n    idio_var = [1.0, 0.2, 1.5, 0.8, 0.8, 1.4, 0.1, 0.2, 0.4, 0.5][:k_endog]\n    params = np.r_[loadings, idio_var, phi]\n    endog = mod.simulate(params, nobs)\n    return endog, loadings, phi, sigma2, idio_ar1, idio_var", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef test_results_factors():\n    endog, _, _, _, _, _ = gen_dfm_data(k_endog=2, nobs=1000)\n    mod_dfm = dynamic_factor_mq.DynamicFactorMQ(endog, factors=['global'],\n        factor_multiplicities=2, standardize=False, idiosyncratic_ar1=False)\n    res_dfm = mod_dfm.smooth(mod_dfm.start_params)\n    assert_allclose(res_dfm.factors.smoothed, res_dfm.states.smoothed[[\n        'global.1', 'global.2']])\n    assert_allclose(res_dfm.factors.smoothed_cov.values, res_dfm.states.\n        smoothed_cov.values, atol=1e-12)\n\ntest_results_factors()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef test_coefficient_of_determination():\n    endog, _, _, _, _, _ = gen_dfm_data(k_endog=3, nobs=1000)\n    endog.iloc[0, 10:20] = np.nan\n    endog.iloc[2, 15:25] = np.nan\n    factors = {(0): ['global', 'block'], (1): ['global', 'block'], (2): [\n        'global']}\n    mod = dynamic_factor_mq.DynamicFactorMQ(endog, factors=factors,\n        standardize=False, idiosyncratic_ar1=False)\n    res = mod.smooth(mod.start_params)\n    factors = res.factors.smoothed\n    actual = res.get_coefficients_of_determination(method='individual')\n    desired = pd.DataFrame(np.zeros((3, 2)), index=[0, 1, 2], columns=[\n        'global', 'block'])\n    for i in range(3):\n        for j in range(2):\n            if i == 2 and j == 1:\n                desired.iloc[i, j] = np.nan\n            else:\n                y = endog.iloc[:, i]\n                X = add_constant(factors.iloc[:, j])\n                mod_ols = OLS(y, X, missing='drop')\n                res_ols = mod_ols.fit()\n                desired.iloc[i, j] = res_ols.rsquared\n    assert_(actual.index.equals(desired.index))\n    assert_(actual.columns.equals(desired.columns))\n    assert_allclose(actual, desired)\n    actual = res.get_coefficients_of_determination(method='joint')\n    desired = pd.Series(np.zeros(3), index=[0, 1, 2])\n    for i in range(3):\n        y = endog.iloc[:, i]\n        if i == 2:\n            X = add_constant(factors.iloc[:, 0])\n        else:\n            X = add_constant(factors)\n        mod_ols = OLS(y, X, missing='drop')\n        res_ols = mod_ols.fit()\n        desired.iloc[i] = res_ols.rsquared\n    assert_(actual.index.equals(desired.index))\n    assert_allclose(actual, desired)\n    actual = res.get_coefficients_of_determination(method='cumulative')\n    desired = pd.DataFrame(np.zeros((3, 2)), index=[0, 1, 2], columns=[\n        'global', 'block'])\n    for i in range(3):\n        for j in range(2):\n            if i == 2 and j == 1:\n                desired.iloc[i, j] = np.nan\n            else:\n                y = endog.iloc[:, i]\n                X = add_constant(factors.iloc[:, :j + 1])\n                mod_ols = OLS(y, X, missing='drop')\n                res_ols = mod_ols.fit()\n                desired.iloc[i, j] = res_ols.rsquared\n    assert_(actual.index.equals(desired.index))\n    assert_(actual.columns.equals(desired.columns))\n    assert_allclose(actual, desired)\n    factors = res.factors.filtered\n    actual = res.get_coefficients_of_determination(method='individual',\n        which='filtered')\n    desired = pd.DataFrame(np.zeros((3, 2)), index=[0, 1, 2], columns=[\n        'global', 'block'])\n    for i in range(3):\n        for j in range(2):\n            if i == 2 and j == 1:\n                desired.iloc[i, j] = np.nan\n            else:\n                y = endog.iloc[:, i]\n                X = add_constant(factors.iloc[:, j])\n                mod_ols = OLS(y, X, missing='drop')\n                res_ols = mod_ols.fit()\n                desired.iloc[i, j] = res_ols.rsquared\n    assert_allclose(actual, desired)\n    try:\n        import matplotlib.pyplot as plt\n        try:\n            from pandas.plotting import register_matplotlib_converters\n            register_matplotlib_converters()\n        except ImportError:\n            pass\n        fig1 = plt.figure()\n        res.plot_coefficients_of_determination(method='individual', fig=fig1)\n        fig2 = plt.figure()\n        res.plot_coefficients_of_determination(method='joint', fig=fig2)\n        fig3 = plt.figure()\n        res.plot_coefficients_of_determination(method='cumulative', fig=fig3)\n        fig4 = plt.figure()\n        res.plot_coefficients_of_determination(which='filtered', fig=fig4)\n    except ImportError:\n        pass\n\ntest_coefficient_of_determination()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\n@pytest.mark.filterwarnings('ignore:Log-likelihood decreased')\ndef test_quasi_newton_fitting():\n    endog, _, _, _, _, _ = gen_dfm_data(k_endog=2, nobs=1000)\n    mod_dfm = dynamic_factor_mq.DynamicFactorMQ(endog, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=False)\n    mod_dfm_ar1 = dynamic_factor_mq.DynamicFactorMQ(endog, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=True)\n    x = mod_dfm_ar1.start_params\n    y = mod_dfm_ar1.untransform_params(x)\n    z = mod_dfm_ar1.transform_params(y)\n    assert_allclose(x, z)\n    res_lbfgs = mod_dfm.fit(method='lbfgs')\n    params_lbfgs = res_lbfgs.params.copy()\n    start_params = params_lbfgs.copy()\n    start_params['L1.0->0'] += 0.01\n    start_params['fb(0).cov.chol[1,1]'] += 0.01\n    res_em = mod_dfm.fit(start_params, em_initialization=False)\n    params_em = res_em.params.copy()\n    assert_allclose(res_lbfgs.llf, res_em.llf, atol=0.05, rtol=1e-05)\n    assert_allclose(params_lbfgs, params_em, atol=0.05, rtol=1e-05)\n    res_lbfgs = mod_dfm_ar1.fit(method='lbfgs')\n    params_lbfgs = res_lbfgs.params.copy()\n    start_params = params_lbfgs.copy()\n    start_params['L1.0->0'] += 0.01\n    start_params['fb(0).cov.chol[1,1]'] += 0.01\n    res_em = mod_dfm_ar1.fit(params_lbfgs, em_initialization=False)\n    params_em = res_em.params.copy()\n    assert_allclose(res_lbfgs.llf, res_em.llf, atol=0.05, rtol=1e-05)\n    assert_allclose(params_lbfgs, params_em, atol=0.05, rtol=1e-05)\n\ntest_quasi_newton_fitting()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef test_summary():\n    endog, _, _, _, _, _ = gen_dfm_data(k_endog=10, nobs=100)\n    mod_dfm = dynamic_factor_mq.DynamicFactorMQ(endog, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=False)\n    res_dfm = mod_dfm.smooth(mod_dfm.start_params)\n    mod_dfm_ar1 = dynamic_factor_mq.DynamicFactorMQ(endog, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=True)\n    res_dfm_ar1 = mod_dfm_ar1.smooth(mod_dfm_ar1.start_params)\n    mod_dfm.summary()\n    assert_equal(str(mod_dfm), str(mod_dfm.summary()))\n    res_dfm.summary()\n    mod_dfm_ar1.summary()\n    res_dfm_ar1.summary()\n\ntest_summary()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef test_append_extend_apply():\n    endog, loadings, phi, sigma2, _, idio_var = gen_dfm_data(k_endog=10,\n        nobs=100)\n    endog1 = endog.iloc[:-10]\n    endog2 = endog.iloc[-10:]\n    mod = dynamic_factor_mq.DynamicFactorMQ(endog1, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=False)\n    params = np.r_[loadings, phi, sigma2, idio_var]\n    res = mod.smooth(params)\n    msg = 'Cannot append data of a different dimension to a model.'\n    with pytest.raises(ValueError, match=msg):\n        res.append(endog2.iloc[:, :3])\n    with pytest.raises(ValueError, match=msg):\n        res.extend(endog2.iloc[:, :3])\n    mod.initialize_known([0.1], [[1.0]])\n    res2 = mod.smooth(params)\n    assert_allclose(res.filter_results.initial_state, 0)\n    assert_allclose(res.filter_results.initial_state_cov, 4 / 3.0)\n    assert_allclose(res2.filter_results.initial_state, 0.1)\n    assert_allclose(res2.filter_results.initial_state_cov, 1.0)\n    res3 = res2.append(endog2, copy_initialization=False)\n    assert_allclose(res3.filter_results.initial_state, 0)\n    assert_allclose(res3.filter_results.initial_state_cov, 4 / 3.0)\n    res4 = res2.append(endog2, copy_initialization=True)\n    assert_allclose(res4.filter_results.initial_state, 0.1)\n    assert_allclose(res4.filter_results.initial_state_cov, 1.0)\n    res5 = res2.apply(endog, copy_initialization=False)\n    assert_allclose(res5.filter_results.initial_state, 0)\n    assert_allclose(res5.filter_results.initial_state_cov, 4 / 3.0)\n    res6 = res2.apply(endog, copy_initialization=True)\n    assert_allclose(res6.filter_results.initial_state, 0.1)\n    assert_allclose(res6.filter_results.initial_state_cov, 1.0)\n\ntest_append_extend_apply()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\ndef test_news_monthly():\n    endog, _, _, _, _, _ = gen_dfm_data(k_endog=10, nobs=100)\n    endog_pre = endog.iloc[:-1].copy()\n    endog_pre.iloc[-1, 0] *= 1.2\n    endog_pre.iloc[-1, 1] = np.nan\n    mod = dynamic_factor_mq.DynamicFactorMQ(endog_pre, factor_orders=1,\n        standardize=False, idiosyncratic_ar1=False)\n    params = mod.start_params\n    res = mod.smooth(params)\n    mod2 = mod.clone(endog)\n    res2 = mod2.smooth(params)\n    desired = res2.news(res, start=endog.index[-1], periods=1,\n        comparison_type='previous')\n    actual = res.news(endog, start=endog.index[-1], periods=1,\n        comparison_type='updated')\n    attributes = ['total_impacts', 'update_impacts', 'revision_impacts',\n        'news', 'weights', 'update_forecasts', 'update_realized',\n        'prev_impacted_forecasts', 'post_impacted_forecasts',\n        'revisions_iloc', 'revisions_ix', 'updates_iloc', 'updates_ix']\n    for attr in attributes:\n        w = getattr(actual, attr)\n        x = getattr(desired, attr)\n        if isinstance(x, pd.Series):\n            assert_series_equal(w, x)\n        else:\n            assert_frame_equal(w, x)\n\ntest_news_monthly()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_dynamic_factor_mq.py"}], "instruction": "Functionality: The gen_dfm_data function is designed to generate synthetic time series data for use in testing and analyzing dynamic factor models. It creates time series data with specified characteristics, including the number of endogenous variables and the length of the time series. The function then simulates data based on given parameters such as factor loadings, autoregressive parameters, and variance components.\n\nInputs:\n- k_endog: An integer indicating the number of endogenous variables in the data. It should not exceed 10.\n- nobs: An integer indicating the number of observations in the time series.\n\nOutputs:\n- endog: A pandas DataFrame containing the simulated time series data for the specified number of endogenous variables.\n- loadings: A list of floats representing the factor loadings for each endogenous variable.\n- phi: A float representing the autoregressive parameter for the factor.\n- sigma2: A float representing the variance of the disturbance term for the factor.\n- idio_ar1: A list of floats representing the autoregressive parameters for the idiosyncratic disturbances of each variable.\n- idio_var: A list of floats representing the variances of the idiosyncratic disturbances for each of the endogenous variables.", "method_code_mask": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom statsmodels.tsa.statespace import dynamic_factor\nfrom statsmodels.tsa.statespace import dynamic_factor_mq\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.statespace.tests import test_dynamic_factor_mq_monte_carlo\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\n\n\ndef gen_dfm_data(k_endog=2, nobs=1000): [MASK]\n"}
{"method_name": "_compute_multivariate_sample_acovf", "full_method_name": "_compute_multivariate_sample_acovf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tools.py", "method_code": "import numpy as np\nfrom scipy.linalg import solve_sylvester\nimport pandas as pd\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.tools.data import _is_using_pandas\nfrom scipy.linalg.blas import find_best_blas_type\nfrom scipy import linalg\ndef _compute_multivariate_sample_acovf(endog, maxlag):\n    \"\"\"\n    Computer multivariate sample autocovariances\n\n    Parameters\n    ----------\n    endog : array_like\n        Sample data on which to compute sample autocovariances. Shaped\n        `nobs` x `k_endog`.\n    maxlag : int\n        Maximum lag to use when computing the sample autocovariances.\n\n    Returns\n    -------\n    sample_autocovariances : list\n        A list of the first `maxlag` sample autocovariance matrices. Each\n        matrix is shaped `k_endog` x `k_endog`.\n\n    Notes\n    -----\n    This function computes the forward sample autocovariances:\n\n    .. math::\n\n        \\\\hat \\\\Gamma(s) = \\\\frac{1}{n} \\\\sum_{t=1}^{n-s}\n        (Z_t - \\\\bar Z) (Z_{t+s} - \\\\bar Z)'\n\n    See page 353 of Wei (1990). This function is primarily implemented for\n    checking the partial autocorrelation functions below, and so is quite slow.\n\n    References\n    ----------\n    .. [*] Wei, William. 1990.\n       Time Series Analysis : Univariate and Multivariate Methods. Boston:\n       Pearson.\n    \"\"\"\n    endog = np.array(endog)\n    if endog.ndim == 1:\n        endog = endog[:, np.newaxis]\n    endog -= np.mean(endog, axis=0)\n    nobs, k_endog = endog.shape\n    sample_autocovariances = []\n    for s in range(maxlag + 1):\n        sample_autocovariances.append(np.zeros((k_endog, k_endog)))\n        for t in range(nobs - s):\n            sample_autocovariances[s] += np.outer(endog[t], endog[t + s])\n        sample_autocovariances[s] /= nobs\n    return sample_autocovariances", "test_code_list": [{"test_code": "import pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_array_less\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_almost_equal\nimport pandas as pd\nfrom scipy.linalg import solve_discrete_lyapunov\nfrom statsmodels.tsa.statespace import tools\nfrom statsmodels.tsa.stattools import acovf\ndef test_multivariate_acovf():\n    _acovf = tools._compute_multivariate_acovf_from_coefficients\n    Sigma_u = np.array([[2.25, 0, 0], [0, 1.0, 0.5], [0, 0.5, 0.74]])\n    Phi_1 = np.array([[0.5, 0, 0], [0.1, 0.1, 0.3], [0, 0.2, 0.3]])\n    Gamma_0 = np.array([[3.0, 0.161, 0.019], [0.161, 1.172, 0.674], [0.019,\n        0.674, 0.954]])\n    assert_allclose(_acovf([Phi_1], Sigma_u)[0], Gamma_0, atol=0.001)\n    Sigma_u = np.diag([0.09, 0.04])\n    Phi_1 = np.array([[0.5, 0.1], [0.4, 0.5]])\n    Phi_2 = np.array([[0, 0], [0.25, 0]])\n    Gamma_0 = np.array([[0.131, 0.066], [0.066, 0.181]])\n    Gamma_1 = np.array([[0.072, 0.051], [0.104, 0.143]])\n    Gamma_2 = np.array([[0.046, 0.04], [0.113, 0.108]])\n    Gamma_3 = np.array([[0.035, 0.031], [0.093, 0.083]])\n    assert_allclose(_acovf([Phi_1, Phi_2], Sigma_u, maxlag=0), [Gamma_0],\n        atol=0.001)\n    assert_allclose(_acovf([Phi_1, Phi_2], Sigma_u, maxlag=1), [Gamma_0,\n        Gamma_1], atol=0.001)\n    assert_allclose(_acovf([Phi_1, Phi_2], Sigma_u), [Gamma_0, Gamma_1],\n        atol=0.001)\n    assert_allclose(_acovf([Phi_1, Phi_2], Sigma_u, maxlag=2), [Gamma_0,\n        Gamma_1, Gamma_2], atol=0.001)\n    assert_allclose(_acovf([Phi_1, Phi_2], Sigma_u, maxlag=3), [Gamma_0,\n        Gamma_1, Gamma_2, Gamma_3], atol=0.001)\n    x = np.arange(20) * 1.0\n    assert_allclose(np.squeeze(_compute_multivariate_sample_acovf(x,\n        maxlag=4)), acovf(x, fft=False)[:5])\n\ntest_multivariate_acovf()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/statespace/tests/test_tools.py"}], "instruction": "Functionality: Compute multivariate sample autocovariances for a given dataset up to a specified maximum lag. This function calculates the forward sample autocovariances as per the formula on page 353 of Wei (1990), primarily for validation purposes and may not be optimized for speed.\n\nInputs: \n1. endog: array_like\n   - Sample data on which to compute sample autocovariances. It should be shaped `nobs` x `k_endog`, where `nobs` is the number of observations and `k_endog` is the number of endogenous variables.\n2. maxlag: int\n   - Maximum lag to use when computing the sample autocovariances.\n\nOutputs:\n1. sample_autocovariances: list\n   - A list containing the first `maxlag` sample autocovariance matrices. Each matrix is shaped `k_endog` x `k_endog`, representing the autocovariance at each lag up to and including `maxlag`.", "method_code_mask": "import numpy as np\nfrom scipy.linalg import solve_sylvester\nimport pandas as pd\nfrom statsmodels.compat.pandas import Appender\nfrom statsmodels.tools.data import _is_using_pandas\nfrom scipy.linalg.blas import find_best_blas_type\nfrom scipy import linalg\n\n\ndef _compute_multivariate_sample_acovf(endog, maxlag): [MASK]\n"}
{"method_name": "statespace", "full_method_name": "statespace", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/statespace.py", "method_code": "import numpy as np\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\ndef statespace(endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, \n    0), include_constant=True, enforce_stationarity=True,\n    enforce_invertibility=True, concentrate_scale=False, start_params=None,\n    fit_kwargs=None):\n    \"\"\"\n    Estimate SARIMAX parameters using state space methods.\n\n    Parameters\n    ----------\n    endog : array_like\n        Input time series array.\n    order : tuple, optional\n        The (p,d,q) order of the model for the number of AR parameters,\n        differences, and MA parameters. Default is (0, 0, 0).\n    seasonal_order : tuple, optional\n        The (P,D,Q,s) order of the seasonal component of the model for the\n        AR parameters, differences, MA parameters, and periodicity. Default\n        is (0, 0, 0, 0).\n    include_constant : bool, optional\n        Whether to add a constant term in `exog` if it's not already there.\n        The estimate of the constant will then appear as one of the `exog`\n        parameters. If `exog` is None, then the constant will represent the\n        mean of the process.\n    enforce_stationarity : bool, optional\n        Whether or not to transform the AR parameters to enforce stationarity\n        in the autoregressive component of the model. Default is True.\n    enforce_invertibility : bool, optional\n        Whether or not to transform the MA parameters to enforce invertibility\n        in the moving average component of the model. Default is True.\n    concentrate_scale : bool, optional\n        Whether or not to concentrate the scale (variance of the error term)\n        out of the likelihood. This reduces the number of parameters estimated\n        by maximum likelihood by one.\n    start_params : array_like, optional\n        Initial guess of the solution for the loglikelihood maximization. The\n        AR polynomial must be stationary. If `enforce_invertibility=True` the\n        MA poylnomial must be invertible. If not provided, default starting\n        parameters are computed using the Hannan-Rissanen method.\n    fit_kwargs : dict, optional\n        Arguments to pass to the state space model's `fit` method.\n\n    Returns\n    -------\n    parameters : SARIMAXParams object\n    other_results : Bunch\n        Includes two components, `spec`, containing the `SARIMAXSpecification`\n        instance corresponding to the input arguments; and\n        `state_space_results`, corresponding to the results from the underlying\n        state space model and Kalman filter / smoother.\n\n    Notes\n    -----\n    The primary reference is [1]_.\n\n    References\n    ----------\n    .. [1] Durbin, James, and Siem Jan Koopman. 2012.\n       Time Series Analysis by State Space Methods: Second Edition.\n       Oxford University Press.\n    \"\"\"\n    if include_constant:\n        exog = np.ones_like(endog) if exog is None else add_constant(exog)\n    spec = SARIMAXSpecification(endog, exog=exog, order=order,\n        seasonal_order=seasonal_order, enforce_stationarity=\n        enforce_stationarity, enforce_invertibility=enforce_invertibility,\n        concentrate_scale=concentrate_scale)\n    endog = spec.endog\n    exog = spec.exog\n    p = SARIMAXParams(spec=spec)\n    if start_params is not None:\n        sp = SARIMAXParams(spec=spec)\n        sp.params = start_params\n        if spec.enforce_stationarity and not sp.is_stationary:\n            raise ValueError(\n                'Given starting parameters imply a non-stationary AR process with `enforce_stationarity=True`.'\n                )\n        if spec.enforce_invertibility and not sp.is_invertible:\n            raise ValueError(\n                'Given starting parameters imply a non-invertible MA process with `enforce_invertibility=True`.'\n                )\n    mod = SARIMAX(endog, exog=exog, order=spec.order, seasonal_order=spec.\n        seasonal_order, enforce_stationarity=spec.enforce_stationarity,\n        enforce_invertibility=spec.enforce_invertibility, concentrate_scale\n        =spec.concentrate_scale)\n    if fit_kwargs is None:\n        fit_kwargs = {}\n    fit_kwargs.setdefault('disp', 0)\n    res_ss = mod.fit(start_params=start_params, **fit_kwargs)\n    p.params = res_ss.params\n    res = Bunch({'spec': spec, 'statespace_results': res_ss})\n    return p, res", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.statespace import statespace\ndef test_basic():\n    endog = lake.copy()\n    exog = np.arange(1, len(endog) + 1) * 1.0\n    p, res = statespace(endog, exog=exog, order=(1, 0, 0), include_constant\n        =True, concentrate_scale=False)\n    mod_ss = sarimax.SARIMAX(endog, exog=add_constant(exog), order=(1, 0, 0))\n    res_ss = mod_ss.filter(p.params)\n    assert_allclose(res.statespace_results.llf, res_ss.llf)\n    p, res = statespace(endog, exog=exog, order=(1, 0, 0), include_constant\n        =False, concentrate_scale=False)\n    mod_ss = sarimax.SARIMAX(endog, exog=exog, order=(1, 0, 0))\n    res_ss = mod_ss.filter(p.params)\n    assert_allclose(res.statespace_results.llf, res_ss.llf)\n    p, res = statespace(endog, exog=exog, order=(1, 0, 0), include_constant\n        =True, concentrate_scale=True)\n    mod_ss = sarimax.SARIMAX(endog, exog=add_constant(exog), order=(1, 0, 0\n        ), concentrate_scale=True)\n    res_ss = mod_ss.filter(p.params)\n    assert_allclose(res.statespace_results.llf, res_ss.llf)\n\ntest_basic()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_statespace.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.statespace import statespace\ndef test_start_params():\n    endog = lake.copy()\n    p, _ = statespace(endog, order=(1, 0, 0), start_params=[0, 0, 1.0])\n    p, _ = statespace(endog, order=(1, 0, 0), start_params=[0, 1.0, 1.0],\n        enforce_stationarity=False)\n    p, _ = statespace(endog, order=(0, 0, 1), start_params=[0, 1.0, 1.0],\n        enforce_invertibility=False)\n    assert_raises(ValueError, statespace, endog, order=(1, 0, 0),\n        start_params=[0, 1.0, 1.0])\n    assert_raises(ValueError, statespace, endog, order=(0, 0, 1),\n        start_params=[0, 1.0, 1.0])\n\ntest_start_params()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_statespace.py"}], "instruction": "Functionality: Estimate SARIMAX parameters using state space methods for a given time series data, allowing for autoregressive (AR), moving average (MA), and seasonal components.\n\nInputs:\n- endog: array_like\n    The input time series array on which the model is to be fit.\n- exog: array_like, optional\n    Optional array of exogenous variables to include in the model. If not provided (None), assumes no exogenous variables are present.\n- order: tuple, optional\n    The (p,d,q) order of the model for the number of AR parameters, differences, and MA parameters. Default is (0, 0, 0).\n- seasonal_order: tuple, optional\n    The (P,D,Q,s) order of the seasonal component of the model for the AR parameters, differences, MA parameters, and periodicity. Default is (0, 0, 0, 0).\n- include_constant: bool, optional\n    Whether to add a constant term in 'exog' if it's not already present. Default is True.\n- enforce_stationarity: bool, optional\n    Whether to enforce stationarity in the autoregressive component of the model. Default is True.\n- enforce_invertibility: bool, optional\n    Whether to enforce invertibility in the moving average component of the model. Default is True.\n- concentrate_scale: bool, optional\n    Whether to concentrate the scale (variance of the error term) out of the likelihood. Default is False.\n- start_params: array_like, optional\n    Initial guess of the solution for the loglikelihood maximization. If not provided, default starting parameters are computed using the Hannan-Rissanen method.\n- fit_kwargs: dict, optional\n    Arguments to pass to the state space model's 'fit' method.\n\nOutputs:\n- parameters: SARIMAXParams object\n    The estimated parameters for the SARIMAX model.\n- other_results: Bunch\n    A structured object containing:\n    - spec: SARIMAXSpecification\n        The SARIMAX model specification corresponding to the input arguments.\n    - state_space_results\n        Results from the underlying state space model and Kalman filter / smoother.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\n\n\ndef statespace(endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, \n    0), include_constant=True, enforce_stationarity=True,\n    enforce_invertibility=True, concentrate_scale=False, start_params=None,\n    fit_kwargs=None): [MASK]\n"}
{"method_name": "yule_walker", "full_method_name": "yule_walker", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/yule_walker.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.regression import linear_model\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\n@deprecate_kwarg('unbiased', 'adjusted')\ndef yule_walker(endog, ar_order=0, demean=True, adjusted=False):\n    \"\"\"\n    Estimate AR parameters using Yule-Walker equations.\n\n    Parameters\n    ----------\n    endog : array_like or SARIMAXSpecification\n        Input time series array, assumed to be stationary.\n    ar_order : int, optional\n        Autoregressive order. Default is 0.\n    demean : bool, optional\n        Whether to estimate and remove the mean from the process prior to\n        fitting the autoregressive coefficients. Default is True.\n    adjusted : bool, optional\n        Whether to use the adjusted autocovariance estimator, which uses\n        n - h degrees of freedom rather than n. For some processes this option\n        may  result in a non-positive definite autocovariance matrix. Default\n        is False.\n\n    Returns\n    -------\n    parameters : SARIMAXParams object\n        Contains the parameter estimates from the final iteration.\n    other_results : Bunch\n        Includes one component, `spec`, which is the `SARIMAXSpecification`\n        instance corresponding to the input arguments.\n\n    Notes\n    -----\n    The primary reference is [1]_, section 5.1.1.\n\n    This procedure assumes that the series is stationary.\n\n    For a description of the effect of the adjusted estimate of the\n    autocovariance function, see 2.4.2 of [1]_.\n\n    References\n    ----------\n    .. [1] Brockwell, Peter J., and Richard A. Davis. 2016.\n       Introduction to Time Series and Forecasting. Springer.\n    \"\"\"\n    spec = SARIMAXSpecification(endog, ar_order=ar_order)\n    endog = spec.endog\n    p = SARIMAXParams(spec=spec)\n    if not spec.is_ar_consecutive:\n        raise ValueError(\n            'Yule-Walker estimation unavailable for models with seasonal or non-consecutive AR orders.'\n            )\n    method = 'adjusted' if adjusted else 'mle'\n    p.ar_params, sigma = linear_model.yule_walker(endog, order=ar_order,\n        demean=demean, method=method)\n    p.sigma2 = sigma ** 2\n    other_results = Bunch({'spec': spec})\n    return p, other_results", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.yule_walker import yule_walker\n@pytest.mark.low_precision(\n    'Test against Example 5.1.1 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_511():\n    endog = dowj.diff().iloc[1:]\n    assert_equal(len(endog), 77)\n    desired = [0.17992, 0.0759, 0.04885]\n    assert_allclose(acovf(endog, fft=True, nlag=2), desired, atol=1e-05)\n    yw, _ = yule_walker(endog, ar_order=1, demean=True)\n    assert_allclose(yw.ar_params, [0.4219], atol=0.0001)\n    assert_allclose(yw.sigma2, 0.1479, atol=0.0001)\n\ntest_brockwell_davis_example_511()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_yule_walker.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.yule_walker import yule_walker\n@pytest.mark.low_precision(\n    'Test against Example 5.1.4 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_514():\n    endog = lake.copy()\n    res, _ = yule_walker(endog, ar_order=2, demean=True)\n    assert_allclose(res.ar_params, [1.0538, -0.2668], atol=0.0001)\n    assert_allclose(res.sigma2, 0.492, atol=0.0001)\n\ntest_brockwell_davis_example_514()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_yule_walker.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.yule_walker import yule_walker\ndef check_itsmr():\n    yw, _ = yule_walker(lake, 5)\n    desired = [1.08213598501, -0.39658257147, 0.11793957728, -0.03326633983,\n        0.06209208707]\n    assert_allclose(yw.ar_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=yw.\n        ar_params, sigma2=1)\n    desired_sigma2 = 0.4716322564\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_yule_walker.py"}], "instruction": "Functionality: Estimate AR parameters using Yule-Walker equations for input time series data, assuming the series is stationary.\n\nInputs:\n- endog: array_like or SARIMAXSpecification, the input time series array, assumed to be stationary.\n- ar_order: int, optional (default=0), the autoregressive order.\n- demean: bool, optional (default=True), whether to estimate and remove the mean from the process prior to fitting the autoregressive coefficients.\n- adjusted: bool, optional (default=False), whether to use the adjusted autocovariance estimator, which uses n - h degrees of freedom rather than n.\n\nOutputs:\n- parameters: SARIMAXParams object, contains the parameter estimates from the final iteration.\n- other_results: Bunch, includes one component, 'spec', which is the SARIMAXSpecification instance corresponding to the input arguments.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.regression import linear_model\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\n\n\n@deprecate_kwarg('unbiased', 'adjusted')\ndef yule_walker(endog, ar_order=0, demean=True, adjusted=False): [MASK]\n"}
{"method_name": "arma_innovations", "full_method_name": "arma_innovations", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/innovations/arma_innovations.py", "method_code": "import numpy as np\nfrom statsmodels.tsa import arima_process\nfrom statsmodels.tsa.statespace.tools import prefix_dtype_map\nfrom statsmodels.tools.numdiff import _get_epsilon\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom scipy.linalg.blas import find_best_blas_type\ndef arma_innovations(endog, ar_params=None, ma_params=None, sigma2=1,\n    normalize=False, prefix=None):\n    \"\"\"\n    Compute innovations using a given ARMA process.\n\n    Parameters\n    ----------\n    endog : ndarray\n        The observed time-series process, may be univariate or multivariate.\n    ar_params : ndarray, optional\n        Autoregressive parameters.\n    ma_params : ndarray, optional\n        Moving average parameters.\n    sigma2 : ndarray, optional\n        The ARMA innovation variance. Default is 1.\n    normalize : bool, optional\n        Whether or not to normalize the returned innovations. Default is False.\n    prefix : str, optional\n        The BLAS prefix associated with the datatype. Default is to find the\n        best datatype based on given input. This argument is typically only\n        used internally.\n\n    Returns\n    -------\n    innovations : ndarray\n        Innovations (one-step-ahead prediction errors) for the given `endog`\n        series with predictions based on the given ARMA process. If\n        `normalize=True`, then the returned innovations have been \"whitened\" by\n        dividing through by the square root of the mean square error.\n    innovations_mse : ndarray\n        Mean square error for the innovations.\n    \"\"\"\n    endog = np.require(endog, requirements='W')\n    squeezed = endog.ndim == 1\n    if squeezed:\n        endog = endog[:, None]\n    ar_params = np.atleast_1d([] if ar_params is None else ar_params)\n    ma_params = np.atleast_1d([] if ma_params is None else ma_params)\n    nobs, k_endog = endog.shape\n    ar = np.r_[1, -ar_params]\n    ma = np.r_[1, ma_params]\n    if prefix is None:\n        prefix, dtype, _ = find_best_blas_type([endog, ar_params, ma_params,\n            np.array(sigma2)])\n    dtype = prefix_dtype_map[prefix]\n    endog = np.asfortranarray(endog, dtype=dtype)\n    ar_params = np.asfortranarray(ar_params, dtype=dtype)\n    ma_params = np.asfortranarray(ma_params, dtype=dtype)\n    sigma2 = dtype(sigma2).item()\n    arma_transformed_acovf_fast = getattr(_arma_innovations, prefix +\n        'arma_transformed_acovf_fast')\n    arma_innovations_algo_fast = getattr(_arma_innovations, prefix +\n        'arma_innovations_algo_fast')\n    arma_innovations_filter = getattr(_arma_innovations, prefix +\n        'arma_innovations_filter')\n    arma_acovf = arima_process.arma_acovf(ar, ma, sigma2=sigma2, nobs=nobs\n        ) / sigma2\n    acovf, acovf2 = arma_transformed_acovf_fast(ar, ma, arma_acovf)\n    theta, v = arma_innovations_algo_fast(nobs, ar_params, ma_params, acovf,\n        acovf2)\n    v = np.array(v)\n    if np.any(v < 0) or not np.isfinite(theta).all() or not np.isfinite(v).all(\n        ):\n        raise ValueError(NON_STATIONARY_ERROR)\n    u = []\n    for i in range(k_endog):\n        u_i = np.array(arma_innovations_filter(endog[:, i], ar_params,\n            ma_params, theta))\n        u.append(u_i)\n    u = np.vstack(u).T\n    if normalize:\n        u /= v[:, None] ** 0.5\n    if squeezed:\n        u = u.squeeze()\n    return u, v", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.yule_walker import yule_walker\ndef check_itsmr():\n    yw, _ = yule_walker(lake, 5)\n    desired = [1.08213598501, -0.39658257147, 0.11793957728, -0.03326633983,\n        0.06209208707]\n    assert_allclose(yw.ar_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=yw.\n        ar_params, sigma2=1)\n    desired_sigma2 = 0.4716322564\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_yule_walker.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _validate_fixed_params\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _package_fixed_and_free_params_info\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _stitch_fixed_and_free_params\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tools.tools import Bunch\n@pytest.mark.low_precision(\n    'Test against Example 5.1.7 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_517():\n    endog = lake.copy()\n    hr, _ = hannan_rissanen(endog, ar_order=1, ma_order=1, demean=True,\n        initial_ar_order=22, unbiased=False)\n    assert_allclose(hr.ar_params, [0.6961], atol=0.0001)\n    assert_allclose(hr.ma_params, [0.3788], atol=0.0001)\n    u, v = arma_innovations(endog - endog.mean(), hr.ar_params, hr.\n        ma_params, sigma2=1)\n    tmp = u / v ** 0.5\n    assert_allclose(np.inner(tmp, tmp) / len(u), 0.4774, atol=0.0001)\n\ntest_brockwell_davis_example_517()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _validate_fixed_params\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _package_fixed_and_free_params_info\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import _stitch_fixed_and_free_params\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tools.tools import Bunch\ndef test_itsmr():\n    endog = lake.copy()\n    hr, _ = hannan_rissanen(endog, ar_order=1, ma_order=1, demean=True,\n        initial_ar_order=22, unbiased=False)\n    assert_allclose(hr.ar_params, [0.69607715], atol=0.0001)\n    assert_allclose(hr.ma_params, [0.3787969217], atol=0.0001)\n    u, v = arma_innovations(endog - endog.mean(), hr.ar_params, hr.\n        ma_params, sigma2=1)\n    tmp = u / v ** 0.5\n    assert_allclose(np.inner(tmp, tmp) / len(u), 0.4773580109, atol=0.0001)\n\ntest_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_hannan_rissanen.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.durbin_levinson import durbin_levinson\ndef check_itsmr():\n    dl, _ = durbin_levinson(lake, 5)\n    assert_allclose(dl[0].params, np.var(lake))\n    assert_allclose(dl[1].ar_params, [0.8319112104])\n    assert_allclose(dl[2].ar_params, [1.0538248798, -0.2667516276])\n    desired = [1.0887037577, -0.4045435867, 0.1307541335]\n    assert_allclose(dl[3].ar_params, desired)\n    desired = [1.0842506581, -0.39076602696, 0.09367609911, 0.03405704644]\n    assert_allclose(dl[4].ar_params, desired)\n    desired = [1.08213598501, -0.39658257147, 0.11793957728, -0.03326633983,\n        0.06209208707]\n    assert_allclose(dl[5].ar_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=dl[5]\n        .ar_params, sigma2=1)\n    desired_sigma2 = 0.4716322564\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_durbin_levinson.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import oshorts\nfrom statsmodels.tsa.arima.estimators.burg import burg\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.innovations import innovations\nfrom statsmodels.tsa.arima.estimators.innovations import innovations_mle\ndef check_innovations_ma_itsmr():\n    ia, _ = innovations(lake, 10, demean=True)\n    desired = [1.0816255264, 0.7781248438, 0.536716443, 0.3291559246, \n        0.316003985, 0.251375455, 0.2051536531, 0.1441070313, 0.343186834, \n        0.1827400798]\n    assert_allclose(ia[10].ma_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ma_params=ia[10\n        ].ma_params, sigma2=1)\n    desired_sigma2 = 0.4523684344\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_innovations_ma_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_innovations.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\ndef check_itsmr():\n    res, _ = burg(lake, 10, demean=True)\n    desired_ar_params = [1.05853631096, -0.32639150878, 0.04784765122, \n        0.02620476111, 0.04444511374, -0.04134010262, 0.0225117897, -\n        0.01427524694, 0.22223486915, -0.20935524387]\n    assert_allclose(res.ar_params, desired_ar_params)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=res.\n        ar_params, sigma2=1)\n    desired_sigma2 = 0.4458956354\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\ndef test_nonstationary_series():\n    endog = np.arange(1, 12) * 1.0\n    res, _ = burg(endog, 2, demean=False)\n    desired_ar_params = [1.9669331547, -0.9892846679]\n    assert_allclose(res.ar_params, desired_ar_params)\n    desired_sigma2 = 0.02143066427\n    assert_allclose(res.sigma2, desired_sigma2)\n    u, v = arma_innovations(endog, ar_params=res.ar_params, sigma2=1)\n    desired_sigma2 = 0.02191056906\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ntest_nonstationary_series()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}], "instruction": "Functionality: Compute innovations using a given ARMA (Autoregressive Moving Average) process for a given time-series data. This function calculates the one-step-ahead prediction errors (innovations) for the observed time-series process based on the provided ARMA parameters.\n\nInputs:\n- endog: An ndarray representing the observed time-series process, which can be either univariate or multivariate.\n- ar_params: An optional ndarray representing autoregressive parameters.\n- ma_params: An optional ndarray representing moving average parameters.\n- sigma2: An optional ndarray representing the innovation variance of the ARMA process. The default is 1.\n- normalize: A boolean option indicating whether to normalize the returned innovations by dividing them by the square root of the mean square error (MSE). Default is False.\n- prefix: An optional string representing the BLAS prefix associated with the datatype. This argument is typically used internally to optimize performance.\n\nOutputs:\n- innovations: An ndarray containing the innovations (prediction errors) for the given `endog` series. If `normalize=True`, the innovations are \"whitened\" by dividing through by the square root of the MSE.\n- innovations_mse: An ndarray representing the mean square error for the innovations.", "method_code_mask": "import numpy as np\nfrom statsmodels.tsa import arima_process\nfrom statsmodels.tsa.statespace.tools import prefix_dtype_map\nfrom statsmodels.tools.numdiff import _get_epsilon\nfrom statsmodels.tools.numdiff import approx_fprime_cs\nfrom scipy.linalg.blas import find_best_blas_type\n\n\ndef arma_innovations(endog, ar_params=None, ma_params=None, sigma2=1,\n    normalize=False, prefix=None): [MASK]\n"}
{"method_name": "durbin_levinson", "full_method_name": "durbin_levinson", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/durbin_levinson.py", "method_code": "from statsmodels.compat.pandas import deprecate_kwarg\nimport numpy as np\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.stattools import acovf\n@deprecate_kwarg('unbiased', 'adjusted')\ndef durbin_levinson(endog, ar_order=0, demean=True, adjusted=False):\n    \"\"\"\n    Estimate AR parameters at multiple orders using Durbin-Levinson recursions.\n\n    Parameters\n    ----------\n    endog : array_like or SARIMAXSpecification\n        Input time series array, assumed to be stationary.\n    ar_order : int, optional\n        Autoregressive order. Default is 0.\n    demean : bool, optional\n        Whether to estimate and remove the mean from the process prior to\n        fitting the autoregressive coefficients. Default is True.\n    adjusted : bool, optional\n        Whether to use the \"adjusted\" autocovariance estimator, which uses\n        n - h degrees of freedom rather than n. This option can result in\n        a non-positive definite autocovariance matrix. Default is False.\n\n    Returns\n    -------\n    parameters : list of SARIMAXParams objects\n        List elements correspond to estimates at different `ar_order`. For\n        example, parameters[0] is an `SARIMAXParams` instance corresponding to\n        `ar_order=0`.\n    other_results : Bunch\n        Includes one component, `spec`, containing the `SARIMAXSpecification`\n        instance corresponding to the input arguments.\n\n    Notes\n    -----\n    The primary reference is [1]_, section 2.5.1.\n\n    This procedure assumes that the series is stationary.\n\n    References\n    ----------\n    .. [1] Brockwell, Peter J., and Richard A. Davis. 2016.\n       Introduction to Time Series and Forecasting. Springer.\n    \"\"\"\n    spec = max_spec = SARIMAXSpecification(endog, ar_order=ar_order)\n    endog = max_spec.endog\n    if not max_spec.is_ar_consecutive:\n        raise ValueError(\n            'Durbin-Levinson estimation unavailable for models with seasonal or otherwise non-consecutive AR orders.'\n            )\n    gamma = acovf(endog, adjusted=adjusted, fft=True, demean=demean, nlag=\n        max_spec.ar_order)\n    if max_spec.ar_order == 0:\n        ar_params = [None]\n        sigma2 = [gamma[0]]\n    else:\n        Phi = np.zeros((max_spec.ar_order, max_spec.ar_order))\n        v = np.zeros(max_spec.ar_order + 1)\n        Phi[0, 0] = gamma[1] / gamma[0]\n        v[0] = gamma[0]\n        v[1] = v[0] * (1 - Phi[0, 0] ** 2)\n        for i in range(1, max_spec.ar_order):\n            tmp = Phi[i - 1, :i]\n            Phi[i, i] = (gamma[i + 1] - np.dot(tmp, gamma[i:0:-1])) / v[i]\n            Phi[i, :i] = tmp - Phi[i, i] * tmp[::-1]\n            v[i + 1] = v[i] * (1 - Phi[i, i] ** 2)\n        ar_params = [None] + [Phi[i, :i + 1] for i in range(max_spec.ar_order)]\n        sigma2 = v\n    out = []\n    for i in range(max_spec.ar_order + 1):\n        spec = SARIMAXSpecification(ar_order=i)\n        p = SARIMAXParams(spec=spec)\n        if i == 0:\n            p.params = sigma2[i]\n        else:\n            p.params = np.r_[ar_params[i], sigma2[i]]\n        out.append(p)\n    other_results = Bunch({'spec': spec})\n    return out, other_results", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.durbin_levinson import durbin_levinson\n@pytest.mark.low_precision(\n    'Test against Example 5.1.1 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_511():\n    endog = dowj.diff().iloc[1:]\n    dl, _ = durbin_levinson(endog, ar_order=2, demean=True)\n    assert_allclose(dl[0].params, np.var(endog))\n    assert_allclose(dl[1].params, [0.4219, 0.1479], atol=0.0001)\n    assert_allclose(dl[2].params, [0.3739, 0.1138, 0.146], atol=0.0001)\n\ntest_brockwell_davis_example_511()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_durbin_levinson.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.durbin_levinson import durbin_levinson\ndef check_itsmr():\n    dl, _ = durbin_levinson(lake, 5)\n    assert_allclose(dl[0].params, np.var(lake))\n    assert_allclose(dl[1].ar_params, [0.8319112104])\n    assert_allclose(dl[2].ar_params, [1.0538248798, -0.2667516276])\n    desired = [1.0887037577, -0.4045435867, 0.1307541335]\n    assert_allclose(dl[3].ar_params, desired)\n    desired = [1.0842506581, -0.39076602696, 0.09367609911, 0.03405704644]\n    assert_allclose(dl[4].ar_params, desired)\n    desired = [1.08213598501, -0.39658257147, 0.11793957728, -0.03326633983,\n        0.06209208707]\n    assert_allclose(dl[5].ar_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=dl[5]\n        .ar_params, sigma2=1)\n    desired_sigma2 = 0.4716322564\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_durbin_levinson.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.durbin_levinson import durbin_levinson\ndef test_nonstationary_series():\n    endog = np.arange(1, 12) * 1.0\n    res, _ = durbin_levinson(endog, 2, demean=False)\n    desired_ar_params = [0.92318534179, -0.06166314306]\n    assert_allclose(res[2].ar_params, desired_ar_params)\n\ntest_nonstationary_series()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_durbin_levinson.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.durbin_levinson import durbin_levinson\ndef test_misc():\n    endog = lake.copy()\n    res, _ = durbin_levinson(endog)\n    assert_allclose(res[0].params, np.var(endog))\n    endog = np.array([1, 2, 5, 3, -2, 1, -3, 5, 2, 3, -1], dtype=int)\n    res_int, _ = durbin_levinson(endog, 2, demean=False)\n    res_float, _ = durbin_levinson(endog * 1.0, 2, demean=False)\n    assert_allclose(res_int[0].params, res_float[0].params)\n    assert_allclose(res_int[1].params, res_float[1].params)\n    assert_allclose(res_int[2].params, res_float[2].params)\n\ntest_misc()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_durbin_levinson.py"}], "instruction": "Functionality: Estimate AR parameters at multiple orders using Durbin-Levinson recursions. This function is designed to fit autoregressive coefficients to a stationary time series, with options to handle demeaning and adjusted autocovariance estimation.\n\nInputs: \n- endog: array_like or SARIMAXSpecification - Input time series array or specification, assumed to be stationary.\n- ar_order: int (optional) - Autoregressive order. Default is 0.\n- demean: bool (optional) - Whether to estimate and remove the mean from the process. Default is True.\n- adjusted: bool (optional) - Whether to use the \"adjusted\" autocovariance estimator. Default is False.\n\nOutputs: \n- parameters: list of SARIMAXParams objects - List elements correspond to estimates at different `ar_order`. For example, parameters[0] is an `SARIMAXParams` instance corresponding to `ar_order=0`.\n- other_results: Bunch - Includes one component, `spec`, containing the `SARIMAXSpecification` instance corresponding to the input arguments.", "method_code_mask": "from statsmodels.compat.pandas import deprecate_kwarg\nimport numpy as np\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.stattools import acovf\n\n\n@deprecate_kwarg('unbiased', 'adjusted')\ndef durbin_levinson(endog, ar_order=0, demean=True, adjusted=False): [MASK]\n"}
{"method_name": "innovations", "full_method_name": "innovations", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/innovations.py", "method_code": "import warnings\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.innovations import arma_innovations\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.statespace.tools import diff\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\ndef innovations(endog, ma_order=0, demean=True):\n    \"\"\"\n    Estimate MA parameters using innovations algorithm.\n\n    Parameters\n    ----------\n    endog : array_like or SARIMAXSpecification\n        Input time series array, assumed to be stationary.\n    ma_order : int, optional\n        Maximum moving average order. Default is 0.\n    demean : bool, optional\n        Whether to estimate and remove the mean from the process prior to\n        fitting the moving average coefficients. Default is True.\n\n    Returns\n    -------\n    parameters : list of SARIMAXParams objects\n        List elements correspond to estimates at different `ma_order`. For\n        example, parameters[0] is an `SARIMAXParams` instance corresponding to\n        `ma_order=0`.\n    other_results : Bunch\n        Includes one component, `spec`, containing the `SARIMAXSpecification`\n        instance corresponding to the input arguments.\n\n    Notes\n    -----\n    The primary reference is [1]_, section 5.1.3.\n\n    This procedure assumes that the series is stationary.\n\n    References\n    ----------\n    .. [1] Brockwell, Peter J., and Richard A. Davis. 2016.\n       Introduction to Time Series and Forecasting. Springer.\n    \"\"\"\n    spec = max_spec = SARIMAXSpecification(endog, ma_order=ma_order)\n    endog = max_spec.endog\n    if demean:\n        endog = endog - endog.mean()\n    if not max_spec.is_ma_consecutive:\n        raise ValueError(\n            'Innovations estimation unavailable for models with seasonal or otherwise non-consecutive MA orders.'\n            )\n    sample_acovf = acovf(endog, fft=True)\n    theta, v = innovations_algo(sample_acovf, nobs=max_spec.ma_order + 1)\n    ma_params = [theta[i, :i] for i in range(1, max_spec.ma_order + 1)]\n    sigma2 = v\n    out = []\n    for i in range(max_spec.ma_order + 1):\n        spec = SARIMAXSpecification(ma_order=i)\n        p = SARIMAXParams(spec=spec)\n        if i == 0:\n            p.params = sigma2[i]\n        else:\n            p.params = np.r_[ma_params[i - 1], sigma2[i]]\n        out.append(p)\n    other_results = Bunch({'spec': spec})\n    return out, other_results", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import oshorts\nfrom statsmodels.tsa.arima.estimators.burg import burg\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.innovations import innovations\nfrom statsmodels.tsa.arima.estimators.innovations import innovations_mle\n@pytest.mark.low_precision(\n    'Test against Example 5.1.5 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_515():\n    endog = dowj.diff().iloc[1:]\n    p, _ = innovations(endog, ma_order=17, demean=True)\n    assert_allclose(p[17].ma_params[:2], [0.4269, 0.2704], atol=0.0001)\n    assert_allclose(p[17].sigma2, 0.1122, atol=0.0001)\n    desired = [0.4269, 0.2704, 0.1183, 0.1589, 0.1355, 0.1568, 0.1284, -\n        0.006, 0.0148, -0.0017, 0.1974, -0.0463, 0.2023, 0.1285, -0.0213, -\n        0.2575, 0.076]\n    assert_allclose(p[17].ma_params, desired, atol=0.0001)\n\ntest_brockwell_davis_example_515()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_innovations.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import oshorts\nfrom statsmodels.tsa.arima.estimators.burg import burg\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.innovations import innovations\nfrom statsmodels.tsa.arima.estimators.innovations import innovations_mle\ndef check_innovations_ma_itsmr():\n    ia, _ = innovations(lake, 10, demean=True)\n    desired = [1.0816255264, 0.7781248438, 0.536716443, 0.3291559246, \n        0.316003985, 0.251375455, 0.2051536531, 0.1441070313, 0.343186834, \n        0.1827400798]\n    assert_allclose(ia[10].ma_params, desired)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ma_params=ia[10\n        ].ma_params, sigma2=1)\n    desired_sigma2 = 0.4523684344\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_innovations_ma_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_innovations.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import oshorts\nfrom statsmodels.tsa.arima.estimators.burg import burg\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.innovations import innovations\nfrom statsmodels.tsa.arima.estimators.innovations import innovations_mle\n@pytest.mark.low_precision(\n    'Test against Example 5.4.1 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_541():\n    endog = oshorts.copy()\n    initial, _ = innovations(endog, ma_order=1, demean=True)\n    p, _ = innovations_mle(endog, order=(0, 0, 1), demean=True,\n        start_params=initial[1].params)\n    assert_allclose(p.ma_params, -0.818, atol=0.001)\n\ntest_brockwell_davis_example_541()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_innovations.py"}], "instruction": "Functionality: Estimate MA parameters using the innovations algorithm for a given time series.\n\nInputs:\n- endog: array_like or SARIMAXSpecification\n  Input time series array, assumed to be stationary.\n- ma_order: int, optional\n  Maximum moving average order. Default is 0.\n- demean: bool, optional\n  Whether to estimate and remove the mean from the process prior to fitting the moving average coefficients. Default is True.\n\nOutputs:\n- parameters: list of SARIMAXParams objects\n  List elements correspond to estimates at different `ma_order`. For example, parameters[0] is an `SARIMAXParams` instance corresponding to `ma_order=0`.\n- other_results: Bunch\n  Includes one component, `spec`, containing the `SARIMAXSpecification` instance corresponding to the input arguments.", "method_code_mask": "import warnings\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.innovations import arma_innovations\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.statespace.tools import diff\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\n\n\ndef innovations(endog, ma_order=0, demean=True): [MASK]\n"}
{"method_name": "burg", "full_method_name": "burg", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/burg.py", "method_code": "import numpy as np\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.regression import linear_model\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\ndef burg(endog, ar_order=0, demean=True):\n    \"\"\"\n    Estimate AR parameters using Burg technique.\n\n    Parameters\n    ----------\n    endog : array_like or SARIMAXSpecification\n        Input time series array, assumed to be stationary.\n    ar_order : int, optional\n        Autoregressive order. Default is 0.\n    demean : bool, optional\n        Whether to estimate and remove the mean from the process prior to\n        fitting the autoregressive coefficients.\n\n    Returns\n    -------\n    parameters : SARIMAXParams object\n        Contains the parameter estimates from the final iteration.\n    other_results : Bunch\n        Includes one component, `spec`, which is the `SARIMAXSpecification`\n        instance corresponding to the input arguments.\n\n    Notes\n    -----\n    The primary reference is [1]_, section 5.1.2.\n\n    This procedure assumes that the series is stationary.\n\n    This function is a light wrapper around `statsmodels.linear_model.burg`.\n\n    References\n    ----------\n    .. [1] Brockwell, Peter J., and Richard A. Davis. 2016.\n       Introduction to Time Series and Forecasting. Springer.\n    \"\"\"\n    spec = SARIMAXSpecification(endog, ar_order=ar_order)\n    endog = spec.endog\n    if np.issubdtype(endog.dtype, np.dtype(int)):\n        endog = endog * 1.0\n    if not spec.is_ar_consecutive:\n        raise ValueError(\n            'Burg estimation unavailable for models with seasonal or otherwise non-consecutive AR orders.'\n            )\n    p = SARIMAXParams(spec=spec)\n    if ar_order == 0:\n        p.sigma2 = np.var(endog)\n    else:\n        p.ar_params, p.sigma2 = linear_model.burg(endog, order=ar_order,\n            demean=demean)\n    other_results = Bunch({'spec': spec})\n    return p, other_results", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_warns\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.statespace import sarimax\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import oshorts\nfrom statsmodels.tsa.arima.estimators.burg import burg\nfrom statsmodels.tsa.arima.estimators.hannan_rissanen import hannan_rissanen\nfrom statsmodels.tsa.arima.estimators.innovations import innovations\nfrom statsmodels.tsa.arima.estimators.innovations import innovations_mle\n@pytest.mark.low_precision(\n    'Test against Example 5.2.4 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_524():\n    endog = dowj.diff().iloc[1:]\n    initial, _ = burg(endog, ar_order=1, demean=True)\n    p, _ = innovations_mle(endog, order=(1, 0, 0), demean=True,\n        start_params=initial.params)\n    assert_allclose(p.ar_params, 0.4471, atol=0.0001)\n\ntest_brockwell_davis_example_524()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_innovations.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\n@pytest.mark.low_precision(\n    'Test against Example 5.1.3 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_513():\n    endog = dowj.diff().iloc[1:]\n    res, _ = burg(endog, ar_order=1, demean=True)\n    assert_allclose(res.ar_params, [0.4371], atol=0.0001)\n    assert_allclose(res.sigma2, 0.1423, atol=0.0001)\n\ntest_brockwell_davis_example_513()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\n@pytest.mark.low_precision(\n    'Test against Example 5.1.4 in Brockwell and Davis (2016)')\ndef test_brockwell_davis_example_514():\n    endog = lake.copy()\n    assert_equal(len(endog), 98)\n    desired = 9.0041\n    assert_allclose(endog.mean(), desired, atol=0.0001)\n    res, _ = burg(endog, ar_order=2, demean=True)\n    assert_allclose(res.ar_params, [1.0449, -0.2456], atol=0.0001)\n    assert_allclose(res.sigma2, 0.4706, atol=0.0001)\n\ntest_brockwell_davis_example_514()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\ndef check_itsmr():\n    res, _ = burg(lake, 10, demean=True)\n    desired_ar_params = [1.05853631096, -0.32639150878, 0.04784765122, \n        0.02620476111, 0.04444511374, -0.04134010262, 0.0225117897, -\n        0.01427524694, 0.22223486915, -0.20935524387]\n    assert_allclose(res.ar_params, desired_ar_params)\n    u, v = arma_innovations(np.array(lake) - np.mean(lake), ar_params=res.\n        ar_params, sigma2=1)\n    desired_sigma2 = 0.4458956354\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ncheck_itsmr()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\ndef test_nonstationary_series():\n    endog = np.arange(1, 12) * 1.0\n    res, _ = burg(endog, 2, demean=False)\n    desired_ar_params = [1.9669331547, -0.9892846679]\n    assert_allclose(res.ar_params, desired_ar_params)\n    desired_sigma2 = 0.02143066427\n    assert_allclose(res.sigma2, desired_sigma2)\n    u, v = arma_innovations(endog, ar_params=res.ar_params, sigma2=1)\n    desired_sigma2 = 0.02191056906\n    assert_allclose(np.sum(u ** 2 / v) / len(u), desired_sigma2)\n\ntest_nonstationary_series()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.innovations.arma_innovations import arma_innovations\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import dowj\nfrom statsmodels.tsa.arima.datasets.brockwell_davis_2002 import lake\nfrom statsmodels.tsa.arima.estimators.burg import burg\ndef test_misc():\n    endog = lake.copy()\n    res, _ = burg(endog)\n    assert_allclose(res.params, np.var(endog))\n    endog = np.array([1, 2, 5, 3, -2, 1, -3, 5, 2, 3, -1], dtype=int)\n    res_int, _ = burg(endog, 2)\n    res_float, _ = burg(endog * 1.0, 2)\n    assert_allclose(res_int.params, res_float.params)\n\ntest_misc()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/estimators/tests/test_burg.py"}], "instruction": "Functionality: The burg function estimates the parameters of an autoregressive (AR) model using the Burg technique. This method is particularly useful for spectral estimation and time series analysis, assuming the series is stationary. The function wraps around the statsmodels.linear_model.burg method, providing a more detailed output structure.\n\nInputs:\n- endog: An array-like object or a SARIMAXSpecification instance representing the input time series data. It is assumed that the series is stationary.\n- ar_order: An optional integer specifying the autoregressive order of the model. The default value is 0, implying no AR components.\n- demean: An optional boolean flag. If True (default), the function will estimate and remove the mean from the process before fitting the AR coefficients.\n\nOutputs:\n- parameters: A SARIMAXParams object containing the parameter estimates from the final iteration. This includes AR parameters (if applicable) and the variance estimate (sigma2).\n- other_results: A Bunch object containing additional results. The Bunch includes one component named 'spec', which is the SARIMAXSpecification instance corresponding to the input arguments and the model configuration.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.regression import linear_model\nfrom statsmodels.tsa.arima.specification import SARIMAXSpecification\nfrom statsmodels.tsa.arima.params import SARIMAXParams\n\n\ndef burg(endog, ar_order=0, demean=True): [MASK]\n"}
{"method_name": "standardize_lag_order", "full_method_name": "standardize_lag_order", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tools.py", "method_code": "import numpy as np\ndef standardize_lag_order(order, title=None):\n    \"\"\"\n    Standardize lag order input.\n\n    Parameters\n    ----------\n    order : int or array_like\n        Maximum lag order (if integer) or iterable of specific lag orders.\n    title : str, optional\n        Description of the order (e.g. \"autoregressive\") to use in error\n        messages.\n\n    Returns\n    -------\n    order : int or list of int\n        Maximum lag order if consecutive lag orders were specified, otherwise\n        a list of integer lag orders.\n\n    Notes\n    -----\n    It is ambiguous if order=[1] is meant to be a boolean list or\n    a list of lag orders to include, but this is irrelevant because either\n    interpretation gives the same result.\n\n    Order=[0] would be ambiguous, except that 0 is not a valid lag\n    order to include, so there is no harm in interpreting as a boolean\n    list, in which case it is the same as order=0, which seems like\n    reasonable behavior.\n\n    Examples\n    --------\n    >>> standardize_lag_order(3)\n    3\n    >>> standardize_lag_order(np.arange(1, 4))\n    3\n    >>> standardize_lag_order([1, 3])\n    [1, 3]\n    \"\"\"\n    order = np.array(order)\n    title = 'order' if title is None else '%s order' % title\n    if not np.all(order == order.astype(int)):\n        raise ValueError('Invalid %s. Non-integer order (%s) given.' % (\n            title, order))\n    order = order.astype(int)\n    if np.any(order < 0):\n        raise ValueError('Terms in the %s cannot be negative.' % title)\n    if order.ndim == 2 and order.shape[1] == 1:\n        order = order[:, 0]\n    elif order.ndim > 1:\n        raise ValueError(\n            'Invalid %s. Must be an integer or 1-dimensional array-like object (e.g. list, ndarray, etc.). Got %s.'\n             % (title, order))\n    if order.ndim == 0:\n        order = order.item()\n    elif len(order) == 0:\n        order = 0\n    else:\n        has_zeros = 0 in order\n        has_multiple_ones = np.sum(order == 1) > 1\n        has_gt_one = np.any(order > 1)\n        if has_zeros or has_multiple_ones:\n            if has_gt_one:\n                raise ValueError(\n                    'Invalid %s. Appears to be a boolean list (since it contains a 0 element and/or multiple elements) but also contains elements greater than 1 like a list of lag orders.'\n                     % title)\n            order = np.where(order == 1)[0] + 1\n        else:\n            order = np.sort(order)\n        if len(order) == 0:\n            order = 0\n        elif np.all(order == np.arange(1, len(order) + 1)):\n            order = order[-1]\n        else:\n            order = order.tolist()\n    has_duplicate = isinstance(order, list) and np.any(np.diff(order) == 0)\n    if has_duplicate:\n        raise ValueError('Invalid %s. Cannot have duplicate elements.' % title)\n    return order", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_int():\n    assert_equal(standardize_lag_order(0, title='test'), 0)\n    assert_equal(standardize_lag_order(3), 3)\n\ntest_standardize_lag_order_int()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_list_int():\n    assert_equal(standardize_lag_order([]), 0)\n    assert_equal(standardize_lag_order([1, 2]), 2)\n    assert_equal(standardize_lag_order([1, 3]), [1, 3])\n\ntest_standardize_lag_order_list_int()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_tuple_int():\n    assert_equal(standardize_lag_order((1, 2)), 2)\n    assert_equal(standardize_lag_order((1, 3)), [1, 3])\n\ntest_standardize_lag_order_tuple_int()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_ndarray_int():\n    assert_equal(standardize_lag_order(np.array([1, 2])), 2)\n    assert_equal(standardize_lag_order(np.array([1, 3])), [1, 3])\n\ntest_standardize_lag_order_ndarray_int()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_list_bool():\n    assert_equal(standardize_lag_order([0]), 0)\n    assert_equal(standardize_lag_order([1]), 1)\n    assert_equal(standardize_lag_order([0, 1]), [2])\n    assert_equal(standardize_lag_order([0, 1, 0, 1]), [2, 4])\n\ntest_standardize_lag_order_list_bool()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_tuple_bool():\n    assert_equal(standardize_lag_order(0), 0)\n    assert_equal(standardize_lag_order(1), 1)\n    assert_equal(standardize_lag_order((0, 1)), [2])\n    assert_equal(standardize_lag_order((0, 1, 0, 1)), [2, 4])\n\ntest_standardize_lag_order_tuple_bool()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_ndarray_bool():\n    assert_equal(standardize_lag_order(np.array([0])), 0)\n    assert_equal(standardize_lag_order(np.array([1])), 1)\n    assert_equal(standardize_lag_order(np.array([0, 1])), [2])\n    assert_equal(standardize_lag_order(np.array([0, 1, 0, 1])), [2, 4])\n\ntest_standardize_lag_order_ndarray_bool()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_standardize_lag_order_misc():\n    assert_equal(standardize_lag_order(np.array([[1], [3]])), [1, 3])\n\ntest_standardize_lag_order_misc()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}], "instruction": "Functionality: The function standardize_lag_order is designed to process and validate lag order inputs for time series analysis. It ensures that the input is correctly interpreted and formatted as either a maximum lag order or a list of specific lag orders.\n\nInputs: \n- order : int or array_like\n  - Maximum lag order specified as an integer, or an iterable of specific lag orders.\n- title : str, optional\n  - A description of the order (e.g., \"autoregressive\") to be used in error messages.\n\nOutputs:\n- order : int or list of int\n  - Returns a maximum lag order if consecutive lag orders were specified, otherwise a list of integer lag orders. The function also checks for invalid inputs, such as non-integer values, negative values, duplicate elements, and ambiguous boolean lists when specific lag orders are intended. If any of these conditions are met, the function will raise a ValueError with an appropriate error message.", "method_code_mask": "import numpy as np\n\n\ndef standardize_lag_order(order, title=None): [MASK]\n"}
{"method_name": "validate_basic", "full_method_name": "validate_basic", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tools.py", "method_code": "import numpy as np\ndef validate_basic(params, length, allow_infnan=False, title=None):\n    \"\"\"\n    Validate parameter vector for basic correctness.\n\n    Parameters\n    ----------\n    params : array_like\n        Array of parameters to validate.\n    length : int\n        Expected length of the parameter vector.\n    allow_infnan : bool, optional\n            Whether or not to allow `params` to contain -np.inf, np.inf, and\n            np.nan. Default is False.\n    title : str, optional\n        Description of the parameters (e.g. \"autoregressive\") to use in error\n        messages.\n\n    Returns\n    -------\n    params : ndarray\n        Array of validated parameters.\n\n    Notes\n    -----\n    Basic check that the parameters are numeric and that they are the right\n    shape. Optionally checks for NaN / infinite values.\n    \"\"\"\n    title = '' if title is None else ' for %s' % title\n    try:\n        params = np.array(params, dtype=object)\n        is_complex = [isinstance(p, complex) for p in params.ravel()]\n        dtype = complex if any(is_complex) else float\n        params = np.array(params, dtype=dtype)\n    except TypeError:\n        raise ValueError('Parameters vector%s includes invalid values.' % title\n            )\n    if not allow_infnan and (np.any(np.isnan(params)) or np.any(np.isinf(\n        params))):\n        raise ValueError('Parameters vector%s includes NaN or Inf values.' %\n            title)\n    params = np.atleast_1d(np.squeeze(params))\n    if params.shape != (length,):\n        plural = '' if length == 1 else 's'\n        raise ValueError(\n            'Specification%s implies %d parameter%s, but values with shape %s were provided.'\n             % (title, length, plural, params.shape))\n    return params", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom statsmodels.tsa.arima.tools import standardize_lag_order\nfrom statsmodels.tsa.arima.tools import validate_basic\ndef test_validate_basic():\n    assert_equal(validate_basic([], 0, title='test'), [])\n    assert_equal(validate_basic(0, 1), [0])\n    assert_equal(validate_basic([0], 1), [0])\n    assert_equal(validate_basic(np.array([1.2, 0.5 + 1.0j]), 2), np.array([\n        1.2, 0.5 + 1.0j]))\n    assert_equal(validate_basic([np.nan, -np.inf, np.inf], 3, allow_infnan=\n        True), [np.nan, -np.inf, np.inf])\n    assert_raises(ValueError, validate_basic, [], 1, title='test')\n    assert_raises(ValueError, validate_basic, 0, 0)\n    assert_raises(ValueError, validate_basic, 'a', 1)\n    assert_raises(ValueError, validate_basic, None, 1)\n    assert_raises(ValueError, validate_basic, np.nan, 1)\n    assert_raises(ValueError, validate_basic, np.inf, 1)\n    assert_raises(ValueError, validate_basic, -np.inf, 1)\n    assert_raises(ValueError, validate_basic, [1, 2], 1)\n\ntest_validate_basic()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima/tests/test_tools.py"}], "instruction": "Functionality: The validate_basic function ensures that the input parameter vector is valid based on specific criteria. It checks that the parameters are numeric, have the correct length, and optionally verifies the absence of NaN or infinite values.\n\nInputs: \n- params: An array-like structure containing the parameters to be validated.\n- length: An integer representing the expected length of the parameter vector.\n- allow_infnan: A boolean flag indicating whether the function should allow the presence of -np.inf, np.inf, or np.nan in the parameter vector. Defaults to False.\n- title: An optional string description of the parameters, which is used in error messages for better clarity. Defaults to None.\n\nOutputs:\n- params: An ndarray containing the validated parameters, with a data type of either float or complex, depending on the input values.\n\nNotes: The function performs essential checks to ensure the parameters meet the specified criteria. It supports conversion to a numeric data type and raises ValueErrors for invalid values, incorrect lengths, or disallowed NaN/Inf values.", "method_code_mask": "import numpy as np\n\n\ndef validate_basic(params, length, allow_infnan=False, title=None): [MASK]\n"}
{"method_name": "date_parser", "full_method_name": "date_parser", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/base/datetools.py", "method_code": "from statsmodels.compat.python import asstr\nfrom statsmodels.compat.python import lmap\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport datetime\nimport re\nimport numpy as np\nfrom pandas import to_datetime\ndef date_parser(timestr, parserinfo=None, **kwargs):\n    \"\"\"\n    Uses dateutil.parser.parse, but also handles monthly dates of the form\n    1999m4, 1999:m4, 1999:mIV, 1999mIV and the same for quarterly data\n    with q instead of m. It is not case sensitive. The default for annual\n    data is the end of the year, which also differs from dateutil.\n    \"\"\"\n    flags = re.IGNORECASE | re.VERBOSE\n    if re.search(_q_pattern, timestr, flags):\n        y, q = timestr.replace(':', '').lower().split('q')\n        month, day = _quarter_to_day[q.upper()]\n        year = int(y)\n    elif re.search(_m_pattern, timestr, flags):\n        y, m = timestr.replace(':', '').lower().split('m')\n        month, day = _month_to_day[m.upper()]\n        year = int(y)\n        if _is_leap(y) and month == 2:\n            day += 1\n    elif re.search(_y_pattern, timestr, flags):\n        month, day = 12, 31\n        year = int(timestr)\n    else:\n        return to_datetime(timestr, **kwargs)\n    return datetime.datetime(year, month, day)", "test_code_list": [{"test_code": "from datetime import datetime\nimport numpy.testing as npt\nfrom statsmodels.tsa.base.datetools import date_parser\nfrom statsmodels.tsa.base.datetools import dates_from_range\ndef test_regex_matching_month():\n    t1 = '1999m4'\n    t2 = '1999:m4'\n    t3 = '1999:mIV'\n    t4 = '1999mIV'\n    result = datetime(1999, 4, 30)\n    npt.assert_equal(date_parser(t1), result)\n    npt.assert_equal(date_parser(t2), result)\n    npt.assert_equal(date_parser(t3), result)\n    npt.assert_equal(date_parser(t4), result)\n\ntest_regex_matching_month()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/base/tests/test_datetools.py"}, {"test_code": "from datetime import datetime\nimport numpy.testing as npt\nfrom statsmodels.tsa.base.datetools import date_parser\nfrom statsmodels.tsa.base.datetools import dates_from_range\ndef test_regex_matching_quarter():\n    t1 = '1999q4'\n    t2 = '1999:q4'\n    t3 = '1999:qIV'\n    t4 = '1999qIV'\n    result = datetime(1999, 12, 31)\n    npt.assert_equal(date_parser(t1), result)\n    npt.assert_equal(date_parser(t2), result)\n    npt.assert_equal(date_parser(t3), result)\n    npt.assert_equal(date_parser(t4), result)\n\ntest_regex_matching_quarter()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/base/tests/test_datetools.py"}], "instruction": "Functionality: The date_parser function is designed to parse and convert date strings into datetime objects. It specifically handles date strings formatted for monthly and quarterly data, such as '1999m4', '1999:m4', '1999:mIV', '1999q4', '1999:q4', '1999:qIV', and also supports annual data formats. The function is not case sensitive and by default assumes the end of the year for annual data.\n\nInputs: \n- timestr: A string representing the date in various formats (e.g., '1999m4', '1999q4', '1999').\n- parserinfo: An optional parameter that is not utilized in this function (default is None).\n- **kwargs: Additional keyword arguments that can be passed to pandas.to_datetime if the function cannot parse the date string in the special formats.\n\nOutputs:\n- A datetime.datetime object representing the parsed date. If the function cannot parse the date string in the special formats, it returns the output of pandas.to_datetime using the provided timestr and any additional keyword arguments.", "method_code_mask": "from statsmodels.compat.python import asstr\nfrom statsmodels.compat.python import lmap\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport datetime\nimport re\nimport numpy as np\nfrom pandas import to_datetime\n\n\ndef date_parser(timestr, parserinfo=None, **kwargs): [MASK]\n"}
{"method_name": "dates_from_range", "full_method_name": "dates_from_range", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/base/datetools.py", "method_code": "from statsmodels.compat.python import asstr\nfrom statsmodels.compat.python import lmap\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport datetime\nimport re\nimport numpy as np\nfrom pandas import to_datetime\ndef dates_from_range(start, end=None, length=None):\n    \"\"\"\n    Turns a sequence of date strings and returns a list of datetime.\n\n    Parameters\n    ----------\n    start : str\n        The first abbreviated date, for instance, '1965q1' or '1965m1'\n    end : str, optional\n        The last abbreviated date if length is None.\n    length : int, optional\n        The length of the returned array of end is None.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> import pandas as pd\n    >>> nobs = 50\n    >>> dates = pd.date_range('1960m1', length=nobs)\n\n\n    Returns\n    -------\n    date_list : ndarray\n        A list of datetime types.\n    \"\"\"\n    dates = date_range_str(start, end, length)\n    return dates_from_str(dates)", "test_code_list": [{"test_code": "from datetime import datetime\nimport numpy.testing as npt\nfrom statsmodels.tsa.base.datetools import date_parser\nfrom statsmodels.tsa.base.datetools import dates_from_range\ndef test_dates_from_range():\n    results = [datetime(1959, 3, 31, 0, 0), datetime(1959, 6, 30, 0, 0),\n        datetime(1959, 9, 30, 0, 0), datetime(1959, 12, 31, 0, 0), datetime\n        (1960, 3, 31, 0, 0), datetime(1960, 6, 30, 0, 0), datetime(1960, 9,\n        30, 0, 0), datetime(1960, 12, 31, 0, 0), datetime(1961, 3, 31, 0, 0\n        ), datetime(1961, 6, 30, 0, 0), datetime(1961, 9, 30, 0, 0),\n        datetime(1961, 12, 31, 0, 0), datetime(1962, 3, 31, 0, 0), datetime\n        (1962, 6, 30, 0, 0)]\n    dt_range = dates_from_range('1959q1', '1962q2')\n    npt.assert_(results == dt_range)\n    results = results[2:]\n    dt_range = dates_from_range('1959q3', length=len(results))\n    npt.assert_(results == dt_range)\n    results = [datetime(1959, 3, 31, 0, 0), datetime(1959, 4, 30, 0, 0),\n        datetime(1959, 5, 31, 0, 0), datetime(1959, 6, 30, 0, 0), datetime(\n        1959, 7, 31, 0, 0), datetime(1959, 8, 31, 0, 0), datetime(1959, 9, \n        30, 0, 0), datetime(1959, 10, 31, 0, 0), datetime(1959, 11, 30, 0, \n        0), datetime(1959, 12, 31, 0, 0), datetime(1960, 1, 31, 0, 0),\n        datetime(1960, 2, 28, 0, 0), datetime(1960, 3, 31, 0, 0), datetime(\n        1960, 4, 30, 0, 0), datetime(1960, 5, 31, 0, 0), datetime(1960, 6, \n        30, 0, 0), datetime(1960, 7, 31, 0, 0), datetime(1960, 8, 31, 0, 0),\n        datetime(1960, 9, 30, 0, 0), datetime(1960, 10, 31, 0, 0), datetime\n        (1960, 12, 31, 0, 0), datetime(1961, 1, 31, 0, 0), datetime(1961, 2,\n        28, 0, 0), datetime(1961, 3, 31, 0, 0), datetime(1961, 4, 30, 0, 0),\n        datetime(1961, 5, 31, 0, 0), datetime(1961, 6, 30, 0, 0), datetime(\n        1961, 7, 31, 0, 0), datetime(1961, 8, 31, 0, 0), datetime(1961, 9, \n        30, 0, 0), datetime(1961, 10, 31, 0, 0)]\n    dt_range = dates_from_range('1959m3', length=len(results))\n\ntest_dates_from_range()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/base/tests/test_datetools.py"}], "instruction": "Functionality: The dates_from_range function is designed to convert a range of abbreviated date strings into a list of datetime objects. It can either generate dates up to a specified end date or generate a fixed number of dates based on a given length.\n\nInputs: \n1. start: A string representing the first date in the range. The date format can be abbreviated (e.g., '1965q1' for the first quarter of 1965 or '1965m1' for January 1965).\n2. end: An optional string representing the last date in the range. This parameter is only used when the length parameter is not provided.\n3. length: An optional integer specifying the total number of dates to generate. This parameter is only used when the end parameter is not provided.\n\nOutputs:\nThe function returns a list of datetime objects representing the date range specified by the input parameters.\n\nNote: The function internally calls date_range_str and dates_from_str functions which are not defined here. These functions are assumed to be part of the underlying implementation and are responsible for generating a string-based date range and converting these strings to datetime objects, respectively.", "method_code_mask": "from statsmodels.compat.python import asstr\nfrom statsmodels.compat.python import lmap\nfrom statsmodels.compat.python import lrange\nfrom statsmodels.compat.python import lzip\nimport datetime\nimport re\nimport numpy as np\nfrom pandas import to_datetime\n\n\ndef dates_from_range(start, end=None, length=None): [MASK]\n"}
{"method_name": "bkfilter", "full_method_name": "bkfilter", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/bk_filter.py", "method_code": "import numpy as np\nfrom scipy.signal import fftconvolve\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\ndef bkfilter(x, low=6, high=32, K=12):\n    \"\"\"\n    Filter a time series using the Baxter-King bandpass filter.\n\n    Parameters\n    ----------\n    x : array_like\n        A 1 or 2d ndarray. If 2d, variables are assumed to be in columns.\n    low : float\n        Minimum period for oscillations, ie., Baxter and King suggest that\n        the Burns-Mitchell U.S. business cycle has 6 for quarterly data and\n        1.5 for annual data.\n    high : float\n        Maximum period for oscillations BK suggest that the U.S.\n        business cycle has 32 for quarterly data and 8 for annual data.\n    K : int\n        Lead-lag length of the filter. Baxter and King propose a truncation\n        length of 12 for quarterly data and 3 for annual data.\n\n    Returns\n    -------\n    ndarray\n        The cyclical component of x.\n\n    See Also\n    --------\n    statsmodels.tsa.filters.cf_filter.cffilter\n        The Christiano Fitzgerald asymmetric, random walk filter.\n    statsmodels.tsa.filters.bk_filter.hpfilter\n        Hodrick-Prescott filter.\n    statsmodels.tsa.seasonal.seasonal_decompose\n        Decompose a time series using moving averages.\n    statsmodels.tsa.seasonal.STL\n        Season-Trend decomposition using LOESS.\n\n    Notes\n    -----\n    Returns a centered weighted moving average of the original series. Where\n    the weights a[j] are computed ::\n\n      a[j] = b[j] + theta, for j = 0, +/-1, +/-2, ... +/- K\n      b[0] = (omega_2 - omega_1)/pi\n      b[j] = 1/(pi*j)(sin(omega_2*j)-sin(omega_1*j), for j = +/-1, +/-2,...\n\n    and theta is a normalizing constant ::\n\n      theta = -sum(b)/(2K+1)\n\n    See the notebook `Time Series Filters\n    <../examples/notebooks/generated/tsa_filters.html>`__ for an overview.\n\n    References\n    ----------\n    Baxter, M. and R. G. King. \"Measuring Business Cycles: Approximate\n        Band-Pass Filters for Economic Time Series.\" *Review of Economics and\n        Statistics*, 1999, 81(4), 575-593.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> import pandas as pd\n    >>> dta = sm.datasets.macrodata.load_pandas().data\n    >>> index = pd.DatetimeIndex(start='1959Q1', end='2009Q4', freq='Q')\n    >>> dta.set_index(index, inplace=True)\n\n    >>> cycles = sm.tsa.filters.bkfilter(dta[['realinv']], 6, 24, 12)\n\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots()\n    >>> cycles.plot(ax=ax, style=['r--', 'b-'])\n    >>> plt.show()\n\n    .. plot:: plots/bkf_plot.py\n    \"\"\"\n    pw = PandasWrapper(x)\n    x = array_like(x, 'x', maxdim=2)\n    omega_1 = 2.0 * np.pi / high\n    omega_2 = 2.0 * np.pi / low\n    bweights = np.zeros(2 * K + 1)\n    bweights[K] = (omega_2 - omega_1) / np.pi\n    j = np.arange(1, int(K) + 1)\n    weights = 1 / (np.pi * j) * (np.sin(omega_2 * j) - np.sin(omega_1 * j))\n    bweights[K + j] = weights\n    bweights[:K] = weights[::-1]\n    bweights -= bweights.mean()\n    if x.ndim == 2:\n        bweights = bweights[:, None]\n    x = fftconvolve(x, bweights, mode='valid')\n    return pw.wrap(x, append='cycle', trim_start=K, trim_end=K)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nfrom datetime import datetime\nimport numpy as np\nfrom numpy import array\nfrom numpy import column_stack\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom pandas import date_range\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa.filters._utils import pandas_wrapper\nfrom statsmodels.tsa.filters.bk_filter import bkfilter\nfrom statsmodels.tsa.filters.cf_filter import cffilter\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.filters.filtertools import recursive_filter\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\ndef test_bking1d():\n    bking_results = array([7.320813, 2.886914, -6.818976, -13.49436, -\n        13.27936, -9.405913, -5.691091, -5.133076, -7.273468, -9.243364, -\n        8.482916, -4.447764, 2.406559, 10.68433, 19.46414, 28.09749, \n        34.11066, 33.48468, 24.64598, 9.952399, -4.265528, -12.59471, -\n        13.46714, -9.049501, -3.011248, 0.5655082, 2.897976, 7.406077, \n        14.67959, 18.651, 13.05891, -2.945415, -24.08659, -41.86147, -\n        48.68383, -43.32689, -31.66654, -20.38356, -13.76411, -9.978693, -\n        3.7704, 10.27108, 31.02847, 51.87613, 66.93117, 73.51951, 73.4053, \n        69.17468, 59.8543, 38.23899, -0.2604809, -49.0107, -91.1128, -\n        112.1574, -108.3227, -86.51453, -59.91258, -40.01185, -29.70265, -\n        22.76396, -13.08037, 1.913622, 20.44045, 37.32873, 46.79802, \n        51.95937, 59.67393, 70.50803, 81.27311, 83.53191, 67.72536, \n        33.78039, -6.509092, -37.31579, -46.05207, -29.81496, 1.416417, \n        28.31503, 32.90134, 8.949259, -35.41895, -84.65775, -124.4288, -\n        144.6036, -140.2204, -109.2624, -53.6901, 15.07415, 74.44268, \n        104.0403, 101.0725, 76.58291, 49.27925, 36.15751, 36.48799, \n        37.60897, 27.75998, 4.216643, -23.20579, -39.33292, -36.6134, -\n        20.90161, -4.143123, 5.48432, 9.270075, 13.69573, 22.16675, \n        33.01987, 41.93186, 47.12222, 48.62164, 47.30701, 40.20537, \n        22.37898, -7.133002, -43.3339, -78.51229, -101.3684, -105.2179, -\n        90.97147, -68.30824, -48.10113, -35.60709, -31.15775, -31.82346, -\n        32.49278, -28.22499, -14.42852, 10.1827, 36.64189, 49.43468, \n        38.75517, 6.447761, -33.15883, -62.60446, -72.87829, -66.54629, -\n        52.61205, -38.06676, -26.19963, -16.51492, -7.007577, 0.6125674, \n        7.866972, 14.8123, 22.52388, 30.65265, 39.47801, 49.05027, 59.02925,\n        72.88999, 95.08865, 125.8983, 154.4283, 160.7638, 130.6092, \n        67.84406, -7.070272, -68.08128, -99.39944, -104.911, -100.2372, -\n        98.11596, -104.2051, -114.0125, -113.3475, -92.98669, -51.91707, -\n        0.7313812, 43.22938, 64.62762, 64.07226, 59.35707, 67.06026, \n        91.87247, 124.4591, 151.2402, 163.0648, 154.6432])\n    X = macrodata.load_pandas().data['realinv'].values\n    Y = bkfilter(X, 6, 32, 12)\n    assert_almost_equal(Y, bking_results, 4)\n\ntest_bking1d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/tests/test_filters.py"}, {"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nfrom datetime import datetime\nimport numpy as np\nfrom numpy import array\nfrom numpy import column_stack\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom pandas import date_range\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa.filters._utils import pandas_wrapper\nfrom statsmodels.tsa.filters.bk_filter import bkfilter\nfrom statsmodels.tsa.filters.cf_filter import cffilter\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.filters.filtertools import recursive_filter\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\ndef test_bking2d():\n    bking_results = array([[7.320813, -0.0374475], [2.886914, -0.0430094],\n        [-6.818976, -0.053456], [-13.49436, -0.0620739], [-13.27936, -\n        0.0626929], [-9.405913, -0.0603022], [-5.691091, -0.0630016], [-\n        5.133076, -0.0832268], [-7.273468, -0.1186448], [-9.243364, -\n        0.1619868], [-8.482916, -0.2116604], [-4.447764, -0.2670747], [\n        2.406559, -0.3209931], [10.68433, -0.3583075], [19.46414, -\n        0.3626742], [28.09749, -0.3294618], [34.11066, -0.2773388], [\n        33.48468, -0.2436127], [24.64598, -0.2605531], [9.952399, -\n        0.3305166], [-4.265528, -0.4275561], [-12.59471, -0.5076068], [-\n        13.46714, -0.537573], [-9.049501, -0.5205845], [-3.011248, -\n        0.481673], [0.5655082, -0.4403994], [2.897976, -0.4039957], [\n        7.406077, -0.3537394], [14.67959, -0.2687359], [18.651, -0.1459743],\n        [13.05891, 0.0014926], [-2.945415, 0.1424277], [-24.08659, \n        0.2451936], [-41.86147, 0.288541], [-48.68383, 0.2727282], [-\n        43.32689, 0.1959127], [-31.66654, 0.0644874], [-20.38356, -\n        0.1158372], [-13.76411, -0.3518627], [-9.978693, -0.6557535], [-\n        3.7704, -1.003754], [10.27108, -1.341632], [31.02847, -1.614486], [\n        51.87613, -1.779089], [66.93117, -1.807459], [73.51951, -1.679688],\n        [73.4053, -1.401012], [69.17468, -0.9954996], [59.8543, -0.511261],\n        [38.23899, -0.0146745], [-0.2604809, 0.4261311], [-49.0107, \n        0.7452514], [-91.1128, 0.8879492], [-112.1574, 0.8282748], [-\n        108.3227, 0.5851508], [-86.51453, 0.2351699], [-59.91258, -\n        0.1208998], [-40.01185, -0.4297895], [-29.70265, -0.6821963], [-\n        22.76396, -0.9234254], [-13.08037, -1.217539], [1.913622, -1.57367],\n        [20.44045, -1.927008], [37.32873, -2.229565], [46.79802, -2.463154],\n        [51.95937, -2.614697], [59.67393, -2.681357], [70.50803, -2.609654],\n        [81.27311, -2.301618], [83.53191, -1.720974], [67.72536, -0.9837123\n        ], [33.78039, -0.2261613], [-6.509092, 0.4546985], [-37.31579, \n        1.005751], [-46.05207, 1.457224], [-29.81496, 1.870815], [1.416417,\n        2.263313], [28.31503, 2.599906], [32.90134, 2.812282], [8.949259, \n        2.83358], [-35.41895, 2.632667], [-84.65775, 2.201077], [-124.4288,\n        1.598951], [-144.6036, 0.9504762], [-140.2204, 0.4187932], [-\n        109.2624, 0.1646726], [-53.6901, 0.2034265], [15.07415, 0.398165],\n        [74.44268, 0.5427476], [104.0403, 0.5454975], [101.0725, 0.4723354],\n        [76.58291, 0.4626823], [49.27925, 0.5840143], [36.15751, 0.7187981],\n        [36.48799, 0.6058422], [37.60897, 0.1221227], [27.75998, -0.5891272\n        ], [4.216643, -1.249841], [-23.20579, -1.594972], [-39.33292, -\n        1.545968], [-36.6134, -1.275494], [-20.90161, -1.035783], [-\n        4.143123, -0.9971732], [5.48432, -1.154264], [9.270075, -1.29987],\n        [13.69573, -1.240559], [22.16675, -0.9662656], [33.01987, -\n        0.6420301], [41.93186, -0.4698712], [47.12222, -0.4527797], [\n        48.62164, -0.4407153], [47.30701, -0.2416076], [40.20537, 0.2317583\n        ], [22.37898, 0.8710276], [-7.133002, 1.426177], [-43.3339, \n        1.652785], [-78.51229, 1.488021], [-101.3684, 1.072096], [-105.2179,\n        0.6496446], [-90.97147, 0.4193682], [-68.30824, 0.41847], [-\n        48.10113, 0.5253419], [-35.60709, 0.595076], [-31.15775, 0.5509905],\n        [-31.82346, 0.3755519], [-32.49278, 0.1297979], [-28.22499, -\n        0.0916165], [-14.42852, -0.2531037], [10.1827, -0.3220784], [\n        36.64189, -0.2660561], [49.43468, -0.1358522], [38.75517, -\n        0.0279508], [6.447761, 0.0168735], [-33.15883, 0.0315687], [-\n        62.60446, 0.0819507], [-72.87829, 0.2274033], [-66.54629, 0.4641401\n        ], [-52.61205, 0.7211093], [-38.06676, 0.907773], [-26.19963, \n        0.9387103], [-16.51492, 0.7940786], [-7.007577, 0.5026631], [\n        0.6125674, 0.1224996], [7.866972, -0.2714422], [14.8123, -0.6273921\n        ], [22.52388, -0.9124271], [30.65265, -1.108861], [39.47801, -\n        1.199206], [49.05027, -1.19908], [59.02925, -1.139046], [72.88999, \n        -0.9775021], [95.08865, -0.6592603], [125.8983, -0.1609712], [\n        154.4283, 0.4796201], [160.7638, 1.100565], [130.6092, 1.447148], [\n        67.84406, 1.359608], [-7.070272, 0.8931825], [-68.08128, 0.2619787],\n        [-99.39944, -0.252208], [-104.911, -0.4703874], [-100.2372, -\n        0.4430657], [-98.11596, -0.390683], [-104.2051, -0.5647846], [-\n        114.0125, -0.9397582], [-113.3475, -1.341633], [-92.98669, -\n        1.567337], [-51.91707, -1.504943], [-0.7313812, -1.30576], [\n        43.22938, -1.17151], [64.62762, -1.136151], [64.07226, -1.050555],\n        [59.35707, -0.7308369], [67.06026, -0.1766731], [91.87247, \n        0.3898467], [124.4591, 0.8135461], [151.2402, 0.9644226], [163.0648,\n        0.6865934], [154.6432, 0.0115685]])\n    mdata = macrodata.load_pandas()\n    X = mdata.data[['realinv', 'cpi']].values.astype(float)\n    Y = bkfilter(X, 6, 32, 12)\n    assert_almost_equal(Y, bking_results, 4)\n\ntest_bking2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/tests/test_filters.py"}], "instruction": "Functionality: The function implements the Baxter-King bandpass filter to filter a time series, isolating the cyclical component.\n\nInputs: \n- x: A 1 or 2d ndarray. If 2d, variables are assumed to be in columns.\n- low: Minimum period for oscillations (default=6).\n- high: Maximum period for oscillations (default=32).\n- K: Lead-lag length of the filter (default=12).\n\nOutputs:\n- An ndarray representing the cyclical component of the input time series 'x'.", "method_code_mask": "import numpy as np\nfrom scipy.signal import fftconvolve\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\n\n\ndef bkfilter(x, low=6, high=32, K=12): [MASK]\n"}
{"method_name": "hpfilter", "full_method_name": "hpfilter", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/hp_filter.py", "method_code": "import numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\ndef hpfilter(x, lamb=1600):\n    \"\"\"\n    Hodrick-Prescott filter.\n\n    Parameters\n    ----------\n    x : array_like\n        The time series to filter, 1-d.\n    lamb : float\n        The Hodrick-Prescott smoothing parameter. A value of 1600 is\n        suggested for quarterly data. Ravn and Uhlig suggest using a value\n        of 6.25 (1600/4**4) for annual data and 129600 (1600*3**4) for monthly\n        data.\n\n    Returns\n    -------\n    cycle : ndarray\n        The estimated cycle in the data given lamb.\n    trend : ndarray\n        The estimated trend in the data given lamb.\n\n    See Also\n    --------\n    statsmodels.tsa.filters.bk_filter.bkfilter\n        Baxter-King filter.\n    statsmodels.tsa.filters.cf_filter.cffilter\n        The Christiano Fitzgerald asymmetric, random walk filter.\n    statsmodels.tsa.seasonal.seasonal_decompose\n        Decompose a time series using moving averages.\n    statsmodels.tsa.seasonal.STL\n        Season-Trend decomposition using LOESS.\n\n    Notes\n    -----\n    The HP filter removes a smooth trend, `T`, from the data `x`. by solving\n\n    min sum((x[t] - T[t])**2 + lamb*((T[t+1] - T[t]) - (T[t] - T[t-1]))**2)\n     T   t\n\n    Here we implemented the HP filter as a ridge-regression rule using\n    scipy.sparse. In this sense, the solution can be written as\n\n    T = inv(I + lamb*K'K)x\n\n    where I is a nobs x nobs identity matrix, and K is a (nobs-2) x nobs matrix\n    such that\n\n    K[i,j] = 1 if i == j or i == j + 2\n    K[i,j] = -2 if i == j + 1\n    K[i,j] = 0 otherwise\n\n    See the notebook `Time Series Filters\n    <../examples/notebooks/generated/tsa_filters.html>`__ for an overview.\n\n    References\n    ----------\n    Hodrick, R.J, and E. C. Prescott. 1980. \"Postwar U.S. Business Cycles: An\n        Empirical Investigation.\" `Carnegie Mellon University discussion\n        paper no. 451`.\n    Ravn, M.O and H. Uhlig. 2002. \"Notes On Adjusted the Hodrick-Prescott\n        Filter for the Frequency of Observations.\" `The Review of Economics and\n        Statistics`, 84(2), 371-80.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> import pandas as pd\n    >>> dta = sm.datasets.macrodata.load_pandas().data\n    >>> index = pd.period_range('1959Q1', '2009Q3', freq='Q')\n    >>> dta.set_index(index, inplace=True)\n\n    >>> cycle, trend = sm.tsa.filters.hpfilter(dta.realgdp, 1600)\n    >>> gdp_decomp = dta[['realgdp']]\n    >>> gdp_decomp[\"cycle\"] = cycle\n    >>> gdp_decomp[\"trend\"] = trend\n\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots()\n    >>> gdp_decomp[[\"realgdp\", \"trend\"]][\"2000-03-31\":].plot(ax=ax,\n    ...                                                      fontsize=16)\n    >>> plt.show()\n\n    .. plot:: plots/hpf_plot.py\n    \"\"\"\n    pw = PandasWrapper(x)\n    x = array_like(x, 'x', ndim=1)\n    nobs = len(x)\n    I = sparse.eye(nobs, nobs)\n    offsets = np.array([0, 1, 2])\n    data = np.repeat([[1.0], [-2.0], [1.0]], nobs, axis=1)\n    K = sparse.dia_matrix((data, offsets), shape=(nobs - 2, nobs))\n    use_umfpack = True\n    trend = spsolve(I + lamb * K.T.dot(K), x, use_umfpack=use_umfpack)\n    cycle = x - trend\n    return pw.wrap(cycle, append='cycle'), pw.wrap(trend, append='trend')", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nfrom datetime import datetime\nimport numpy as np\nfrom numpy import array\nfrom numpy import column_stack\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom pandas import date_range\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa.filters._utils import pandas_wrapper\nfrom statsmodels.tsa.filters.bk_filter import bkfilter\nfrom statsmodels.tsa.filters.cf_filter import cffilter\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.filters.filtertools import recursive_filter\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\ndef test_hpfilter():\n    hpfilt_res = array([[39.51191484487845, 2670.8370851551217], [\n        80.08853245681075, 2698.712467543189], [48.87545512195402, \n        2726.612544878046], [30.59193256079834, 2754.612067439202], [\n        64.8826673342196, 2782.8163326657805], [23.04024204546704, \n        2811.349757954533], [-1.3553123694873648, 2840.3773123694873], [-\n        67.46236512580754, 2870.0783651258075], [-81.3674383685343, \n        2900.6314383685344], [-60.16789026443257, 2932.1728902644327], [-\n        46.369224331382156, 2964.788224331382], [-20.695339155704005, \n        2998.525339155704], [-2.162152558595608, 3033.4031525585956], [-\n        4.718647774311648, 3069.4276477743115], [-13.556456691690073, \n        3106.60345669169], [-44.3692620447564, 3144.9322620447565], [-\n        43.3202737821166, 3184.4072737821166], [-44.54697106352069, \n        3224.993971063521], [-26.29875787765286, 3266.6307578776527], [-\n        44.26119635629266, 3309.2281963562928], [-14.434411907624963, \n        3352.680411907625], [-20.26686669186438, 3396.8538666918644], [-\n        19.137001362088995, 3441.606001362089], [-54.82458977940951, \n        3486.7815897794094], [-15.962445179377937, 3532.213445179378], [-\n        13.740115428745412, 3577.7001154287454], [13.254828134039144, \n        3623.0301718659607], [56.03040174253829, 3667.983598257462], [\n        103.0743373627106, 3712.348662637289], [72.17534795943993, \n        3755.94865204056], [54.629725036932086, 3798.671274963068], [\n        44.07065050666142, 3840.4493494933386], [37.49016270204993, \n        3881.24983729795], [-1.5112441999231123, 3921.067244199923], [-\n        9.093507374079763, 3959.91950737408], [-16.853619467602584, \n        3997.8236194676024], [28.2221103143429, 4034.790889685657], [\n        61.17590627896425, 4070.8220937210353], [54.33135391434371, \n        4105.935646085656], [38.10480376716623, 4140.188196232833], [\n        70.42964928802849, 4173.670350711972], [49.96346842507592, \n        4206.496531574924], [44.55282059571255, 4238.825179404287], [-\n        7.584961950576144, 4270.845961950577], [-46.2033924769712, \n        4302.7763924769715], [-70.5402436455297, 4334.8292436455295], [-\n        64.92941099801465, 4367.188410998015], [-143.35670242395554, \n        4399.993702423955], [-59.328344930890125, 4433.34434493089], [-\n        68.42096758743628, 4467.249967587436], [-67.7401192465486, \n        4501.683119246549], [-90.30958565658057, 4536.573585656581], [-\n        46.039814991368075, 4571.808814991368], [25.88118806672992, \n        4607.21981193327], [34.894193719122995, 4642.608806280877], [\n        76.75179642495095, 4677.794203575049], [163.5497817724172, \n        4712.616218227583], [185.60796547656173, 4746.963034523438], [\n        125.42694463927182, 4780.825055360729], [138.7413113837174, \n        4814.308688616283], [62.01826599282231, 4847.598734007178], [\n        41.22129542972198, 4880.966704570278], [-41.202874758423604, \n        4914.722874758424], [-94.86328233441964, 4949.20328233442], [-\n        189.4232132641573, 4984.718213264157], [-189.57666396200875, \n        5021.518663962009], [-146.40924133426506, 5059.7372413342655], [-\n        121.87706687212176, 5099.388066872122], [-49.730756290781756, \n        5140.393756290781], [-53.65375213897278, 5182.600752138973], [-\n        71.75241524251214, 5225.824415242512], [-78.34757283225463, \n        5269.846572832254], [-62.64220687943907, 5314.404206879439], [-\n        3.054332122210326, 5359.185332122211], [48.08218808024685, \n        5403.838811919753], [2.7813993267363912, 5448.011600673263], [-\n        21.975704151732316, 5491.380704151732], [150.9441335012807, \n        5533.62486649872], [165.8909029574852, 5574.409097042515], [\n        202.72925480499816, 5613.492745195002], [175.21015781760616, \n        5650.7388421823935], [145.2808749847536, 5686.137125015246], [\n        153.54816294750253, 5719.7868370524975], [137.61697779988754, \n        5751.878022200112], [125.77030803407706, 5782.696691965923], [-\n        25.241868468956454, 5812.614868468956], [-65.46618027042405, \n        5842.083180270424], [11.923520235803153, 5871.536479764197], [\n        104.34829701887429, 5901.368702981125], [25.813761847683963, \n        5931.981238152316], [66.34330880534071, 5963.8406911946595], [-\n        42.36780162594641, 5997.429801625946], [-175.9397735321818, \n        6033.272773532181], [-182.7933311233055, 6071.867331123305], [-\n        247.2312362505918, 6113.601236250592], [-287.7470049336489, \n        6158.748004933649], [-263.40663366935405, 6207.4266336693545], [-\n        181.95727707636252, 6259.576277076362], [-117.50346062746212, \n        6314.971460627462], [-47.698986497183796, 6373.272986497183], [\n        14.195782802878966, 6434.068217197121], [62.67929662760798, \n        6496.914703372392], [61.96413196753747, 6561.378868032462], [\n        50.19769125317907, 6627.066308746821], [46.65364933213823, \n        6693.621350667861], [36.62430749527266, 6760.719692504727], [\n        75.45680850246481, 6828.066191497535], [60.52940492147536, \n        6895.388595078524], [60.29518881462354, 6962.461811185376], [\n        21.870421366526898, 7029.098578633473], [23.800679268247222, \n        7095.149320731753], [-7.119129802169482, 7160.47812980217], [-\n        31.94497359120851, 7224.963973591209], [-18.971370389341246, \n        7288.4813703893415], [-18.326872878451468, 7350.8848728784515], [\n        46.004823365975426, 7412.0171766340245], [24.890477064030165, \n        7471.70952293597], [63.059093921272506, 7529.821906078728], [\n        45.852123094981835, 7586.2298769050185], [93.14260180878318, \n        7640.848398191217], [112.98190970953692, 7693.621090290463], [\n        120.4662123176704, 7744.549787682329], [133.68606146012462, \n        7793.706938539875], [103.4567175813736, 7841.2402824186265], [\n        140.311887337205, 7887.381112662795], [127.17261693510045, \n        7932.4253830648995], [82.7192576528214, 7976.756742347178], [-\n        31.974322117525844, 8020.838322117525], [-115.02095351940625, \n        8065.184953519406], [-106.46948374567728, 8110.291483745677], [-\n        119.04287189253682, 8156.580871892536], [-135.36353362929913, \n        8204.4095336293], [-96.44348283027102, 8254.059482830271], [-\n        61.43413116116608, 8305.728131161166], [-30.191613110979233, \n        8359.55261311098], [1.3843331635525828, 8415.631666836447], [-\n        41.56016073666615, 8474.045160736667], [-48.43882841860977, \n        8534.87382841861], [-67.06442838867042, 8598.17242838867], [-\n        20.196444885799792, 8663.9654448858], [-4.31644688108463, \n        8732.235446881084], [44.35061943264736, 8802.952380567353], [\n        28.205505641555646, 8876.083494358445], [51.55624419490778, \n        8951.623755805093], [-4.318760899315748, 9029.585760899316], [-\n        65.34632828542271, 9110.014328285422], [-72.26757738268498, \n        9192.951577382684], [-94.12378615444868, 9278.398786154448], [-\n        119.12406532883688, 9366.312065328837], [-49.53669826751866, \n        9456.588698267518], [-60.17251579067488, 9549.051515790676], [-\n        51.03438828313483, 9643.492388283135], [-73.43057830678117, \n        9739.665578306782], [-27.742451930549578, 9837.293451930549], [-\n        3.380481112519192, 9936.05248111252], [-26.727798777943462, \n        10035.601798777943], [-32.17342505148372, 10135.598425051483], [-\n        41.40567518359967, 10235.6826751836], [-6.687756033938058, \n        10335.474756033938], [73.00600408459468, 10434.568995915406], [\n        68.62345670680043, 10532.5555432932], [54.97882461487461, \n        10629.070175385126], [96.1224409305596, 10723.791559069441], [\n        197.82127701038917, 10816.432722989612], [136.27722768487547, \n        10906.766772315124], [263.76354948672633, 10994.690450513273], [\n        187.68132568151668, 11080.185674318484], [171.1447873158413, \n        11163.399212684159], [52.575864608266784, 11244.595135391733], [\n        47.106522285317624, 11324.144477714683], [-62.376134842410465, \n        11402.451134842411], [-99.82044354035315, 11479.948443540354], [-\n        79.1627554899751, 11557.030755489975], [-95.26003459472304, \n        11634.030034594723], [-114.79876803691695, 11711.228768036917], [-\n        190.0259054765902, 11788.84990547659], [-221.22564734395564, \n        11867.044647343955], [-207.1394278781845, 11945.845427878185], [-\n        89.68541528904825, 12025.146415289048], [-61.89531564415665, \n        12104.712315644156], [-56.62878162551715, 12184.251781625517], [-\n        49.61678134413705, 12263.434781344136], [-38.36288992144182, \n        12341.895889921441], [-8.95667199145646, 12419.238671991456], [\n        39.070284618668666, 12495.04271538133], [18.652990001844955, \n        12568.882009998155], [42.79803532226833, 12640.354964677732], [\n        39.62735362631611, 12709.071646373684], [141.26912918778544, \n        12774.668870812215], [125.65377918443664, 12836.808220815563], [\n        70.67642758858892, 12895.23957241141], [110.88766476031924, \n        12949.79133523968], [99.56490829291761, 13000.336091707082], [\n        157.16127098809375, 13046.815729011907], [231.8746375812716, \n        13089.234362418729], [263.5546670125277, 13127.694332987472], [\n        204.42209657392596, 13162.442903426074], [221.3739418903715, \n        13193.892058109628], [102.01845477671122, 13222.58154522329], [-\n        107.26947166633909, 13249.18947166634], [-349.0477058718843, \n        13274.457705871884], [-397.557072853353, 13299.061072853354], [-\n        333.11524280806225, 13323.456242808063]])\n    dta = macrodata.load_pandas().data['realgdp'].values\n    res = column_stack(hpfilter(dta, 1600))\n    assert_almost_equal(res, hpfilt_res, 6)\n\ntest_hpfilter()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/tests/test_filters.py"}], "instruction": "Functionality: The hpfilter function implements the Hodrick-Prescott filter, a method for decomposing a time series into a trend and a cyclical component. It minimizes a criterion that balances the fit of the trend to the data and the smoothness of the trend.\n\nInputs: \n1. x : array_like\n   - The time series data to be filtered. It should be one-dimensional.\n2. lamb : float, optional (default=1600)\n   - The smoothing parameter for the Hodrick-Prescott filter. A value of 1600 is suggested for quarterly data. Other values are suggested for annual (6.25) and monthly (129600) data.\n\nOutputs: \n1. cycle : ndarray\n   - The estimated cyclical component in the data, which represents the fluctuations around the trend, given the smoothing parameter lamb.\n2. trend : ndarray\n   - The estimated trend component in the data, which represents the smooth long-term pattern, given the smoothing parameter lamb.", "method_code_mask": "import numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import PandasWrapper\n\n\ndef hpfilter(x, lamb=1600): [MASK]\n"}
{"method_name": "cffilter", "full_method_name": "cffilter", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/cf_filter.py", "method_code": "import numpy as np\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import array_like\nimport statsmodels as sm\ndef cffilter(x, low=6, high=32, drift=True):\n    \"\"\"\n    Christiano Fitzgerald asymmetric, random walk filter.\n\n    Parameters\n    ----------\n    x : array_like\n        The 1 or 2d array to filter. If 2d, variables are assumed to be in\n        columns.\n    low : float\n        Minimum period of oscillations. Features below low periodicity are\n        filtered out. Default is 6 for quarterly data, giving a 1.5 year\n        periodicity.\n    high : float\n        Maximum period of oscillations. Features above high periodicity are\n        filtered out. Default is 32 for quarterly data, giving an 8 year\n        periodicity.\n    drift : bool\n        Whether or not to remove a trend from the data. The trend is estimated\n        as np.arange(nobs)*(x[-1] - x[0])/(len(x)-1).\n\n    Returns\n    -------\n    cycle : array_like\n        The features of x between the periodicities low and high.\n    trend : array_like\n        The trend in the data with the cycles removed.\n\n    See Also\n    --------\n    statsmodels.tsa.filters.bk_filter.bkfilter\n        Baxter-King filter.\n    statsmodels.tsa.filters.bk_filter.hpfilter\n        Hodrick-Prescott filter.\n    statsmodels.tsa.seasonal.seasonal_decompose\n        Decompose a time series using moving averages.\n    statsmodels.tsa.seasonal.STL\n        Season-Trend decomposition using LOESS.\n\n    Notes\n    -----\n    See the notebook `Time Series Filters\n    <../examples/notebooks/generated/tsa_filters.html>`__ for an overview.\n\n    Examples\n    --------\n    >>> import statsmodels.api as sm\n    >>> import pandas as pd\n    >>> dta = sm.datasets.macrodata.load_pandas().data\n    >>> index = pd.DatetimeIndex(start='1959Q1', end='2009Q4', freq='Q')\n    >>> dta.set_index(index, inplace=True)\n\n    >>> cf_cycles, cf_trend = sm.tsa.filters.cffilter(dta[[\"infl\", \"unemp\"]])\n\n    >>> import matplotlib.pyplot as plt\n    >>> fig, ax = plt.subplots()\n    >>> cf_cycles.plot(ax=ax, style=['r--', 'b-'])\n    >>> plt.show()\n\n    .. plot:: plots/cff_plot.py\n    \"\"\"\n    if low < 2:\n        raise ValueError('low must be >= 2')\n    pw = PandasWrapper(x)\n    x = array_like(x, 'x', ndim=2)\n    nobs, nseries = x.shape\n    a = 2 * np.pi / high\n    b = 2 * np.pi / low\n    if drift:\n        x = x - np.arange(nobs)[:, None] * (x[-1] - x[0]) / (nobs - 1)\n    J = np.arange(1, nobs + 1)\n    Bj = (np.sin(b * J) - np.sin(a * J)) / (np.pi * J)\n    B0 = (b - a) / np.pi\n    Bj = np.r_[B0, Bj][:, None]\n    y = np.zeros((nobs, nseries))\n    for i in range(nobs):\n        B = -0.5 * Bj[0] - np.sum(Bj[1:-i - 2])\n        A = -Bj[0] - np.sum(Bj[1:-i - 2]) - np.sum(Bj[1:i]) - B\n        y[i] = Bj[0] * x[i] + np.dot(Bj[1:-i - 2].T, x[i + 1:-1]) + B * x[-1\n            ] + np.dot(Bj[1:i].T, x[1:i][::-1]) + A * x[0]\n    y = y.squeeze()\n    cycle, trend = y.squeeze(), x.squeeze() - y\n    return pw.wrap(cycle, append='cycle'), pw.wrap(trend, append='trend')", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import make_dataframe\nfrom datetime import datetime\nimport numpy as np\nfrom numpy import array\nfrom numpy import column_stack\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom pandas import date_range\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa.filters._utils import pandas_wrapper\nfrom statsmodels.tsa.filters.bk_filter import bkfilter\nfrom statsmodels.tsa.filters.cf_filter import cffilter\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.filters.filtertools import recursive_filter\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\ndef test_cfitz_filter():\n    cfilt_res = array([[0.712599537179426, 0.439563468233128], [\n        1.06824041304411, 0.352886666575907], [1.19422467791128, \n        0.257297004260607], [0.970845473140327, 0.114504692143872], [\n        0.467026976628563, -0.070734782329146], [-0.089153511514031, -\n        0.238609685132605], [-0.452339254128573, -0.32376584042956], [-\n        0.513231214461187, -0.314288554228112], [-0.352372578720063, -\n        0.258815055101336], [-0.160282602521333, -0.215076844089567], [-\n        0.0918782593827686, -0.194120745417214], [-0.168083823205437, -\n        0.158327420072693], [-0.291595204965808, -0.0742727139742986], [-\n        0.348638756841307, 0.037008291163602], [-0.304328040874631, \n        0.108196527328748], [-0.215933150969686, 0.0869231107437175], [-\n        0.165632621390694, -0.0130556619786275], [-0.182326839507151, -\n        0.126570926191824], [-0.223737786804725, -0.205535321806185], [-\n        0.228939291453403, -0.269110078201836], [-0.185518327227038, -\n        0.375976507132174], [-0.143900152461529, -0.53760115656157], [-\n        0.162749541550174, -0.660065018626038], [-0.236263634756884, -\n        0.588542352053736], [-0.275785854309211, -0.236867929421996], [-\n        0.173666515108109, 0.303436335579219], [0.0963135720251639, \n        0.779772338801993], [0.427070069032285, 0.929108075350647], [\n        0.629034743259998, 0.658330841002647], [0.557941248993624, \n        0.118500049361018], [0.227866624051603, -0.385048321099911], [-\n        0.179878859883227, -0.582223992561493], [-0.428263000051965, -\n        0.394053702908091], [-0.381640684645912, 0.0445437406977307], [-\n        0.0942745548364887, 0.493997792757968], [0.238132391504895, \n        0.764519811304315], [0.431293754256291, 0.814755206427316], [\n        0.455010435813661, 0.745567043101108], [0.452800768971269, \n        0.709401694610443], [0.615754619329312, 0.798293251119636], [\n        1.00256335412457, 0.975856845059388], [1.44841039351691, \n        1.09097252730799], [1.6465197112037, 0.967823457118036], [\n        1.35534532901802, 0.522397724737059], [0.580492790312048, -\n        0.16941343361609], [-0.410746188031773, -0.90760401289056], [-\n        1.26148406066881, -1.49592867122591], [-1.75784179124566, -\n        1.87404167409849], [-1.94478553960064, -2.14586210891112], [-\n        2.03751202708559, -2.465855239868], [-2.20376059354166, -\n        2.86294187189049], [-2.39722338315852, -3.15004697654831], [-\n        2.38032366161537, -3.01390466643222], [-1.91798022532025, -\n        2.23395210271226], [-0.982318490353716, -0.861346053067472], [\n        0.199047030343412, 0.790266582335616], [1.28582776574786, \n        2.33731327460104], [2.0356590537643, 3.54085486821911], [\n        2.41201557412526, 4.36519456268955], [2.52011070482927, \n        4.84810517685452], [2.45618479815452, 4.92906708807477], [\n        2.22272146945388, 4.42591058990048], [1.78307567169034, \n        3.20962906108388], [1.18234431860844, 1.42568060336985], [\n        0.590069172333348, -0.461896808688991], [0.19662302949837, -\n        1.89020992539465], [0.048307034171166, -2.53490571941987], [-\n        0.0141956981899, -2.50020338531674], [-0.230505187108187, -\n        2.20625973569823], [-0.700947410386801, -2.06643697511048], [-\n        1.2708512316306, -2.21536883679783], [-1.64082547897928, -\n        2.49016921117735], [-1.62286182971254, -2.63948740221362], [-\n        1.31609762181362, -2.54685250637904], [-1.03085567704873, -\n        2.27157435428923], [-1.01100120380112, -1.90404507430561], [-\n        1.19823958399826, -1.4123209792214], [-1.26398933608383, -\n        0.654000086153317], [-0.904710628949692, 0.447960016248203], [-\n        0.151340093679588, 1.73970411237156], [0.592926881165989, \n        2.85741581650685], [0.851660587507523, 3.4410446351716], [\n        0.480324393352127, 3.36870271362297], [-0.165153230782417, \n        2.82003806696544], [-0.459235919375844, 2.12858991660866], [\n        0.0271158842479935, 1.55840980891556], [1.18759188180671, \n        1.17980298478623], [2.43238266962309, 0.904011534980672], [\n        3.08277213720132, 0.595286911949837], [2.79953663720953, \n        0.148014782859571], [1.73694442845833, -0.496297332023011], [\n        0.357638079951977, -1.3310814987757], [-0.891418825216945, -\n        2.22650083183366], [-1.77646467793627, -2.89359299718574], [-\n        2.24614790863088, -2.97921619243347], [-2.29048879096607, -\n        2.3000309277928], [-1.87929656465888, -1.05298381273274], [-\n        1.04510101454788, 0.215837488618531], [0.00413338508394524, \n        0.937866257924888], [0.906870625251025, 0.92664365343019], [\n        1.33869057593416, 0.518564571494679], [1.2265967845444, \n        0.28809686965289], [0.79380139656044, 0.541053084632774], [\n        0.38029431865832, 1.01905199983437], [0.183929413600038, \n        1.10529586616777], [0.140045425897033, 0.393618564826736], [\n        0.0337313182352219, -0.86431819007665], [-0.269208622829813, -\n        1.85638085246792], [-0.687276639992166, -1.82275359004533], [-\n        1.00161592325614, -0.692695765071617], [-1.06320089194036, \n        0.803577361347341], [-0.927152307196776, 1.67366338751788], [-\n        0.786802101366614, 1.42564362251793], [-0.772970884572502, \n        0.426446388877964], [-0.81275662801789, -0.437721213831647], [-\n        0.686831250382476, -0.504255468075149], [-0.237936463020255, \n        0.148656301898438], [0.459631879129522, 0.832925905720478], [\n        1.12717379822508, 0.889455302576383], [1.48640453200855, \n        0.268042676202216], [1.46515245776211, -0.446505038539178], [\n        1.22993484959115, -0.563868578181134], [1.0272100765927, \n        0.0996849952196907], [0.979191212438404, 1.05053652824665], [\n        1.00733490030391, 1.51658415000556], [0.932192535457706, \n        1.06262774912638], [0.643374300839414, -0.0865180803476065], [\n        0.186885168954461, -1.24799408923277], [-0.290842337365465, -\n        1.80035611156538], [-0.669446735516495, -1.5884733356151], [-\n        0.928915624595538, -0.932116966867929], [-1.11758635926997, -\n        0.30787939680785], [-1.26832454569756, -0.00856199983957032], [-\n        1.35755577149251, -0.0303537516690989], [-1.34244112665546, -\n        0.196807620887435], [-1.22227976023299, -0.342062643495923], [-\n        1.04601473486818, -0.390474392372016], [-0.85158508717846, -\n        0.322164402093596], [-0.605033439160543, -0.126930141915954], [-\n        0.218304303942818, 0.179551077808122], [0.352173017779006, \n        0.512327303000081], [1.01389600097229, 0.733397490572755], [\n        1.55149778750607, 0.748740387440165], [1.75499674757591, \n        0.601759717901009], [1.56636057468633, 0.457705308377562], [\n        1.12239792537274, 0.470849913286519], [0.655802600286141, \n        0.646142040378738], [0.33528511534018, 0.824103600255079], [\n        0.173454596506888, 0.808068498175582], [0.0666753011315252, \n        0.521488214487996], [-0.0842367474816212, 0.0583493276173476], [-\n        0.285604762631464, -0.405958418332253], [-0.465735422869919, -\n        0.747800086512926], [-0.563586691231348, -0.94982272350799], [-\n        0.598110322024572, -1.04736894794361], [-0.65216025756061, -\n        1.04858365218822], [-0.789663117801624, -0.924145633093637], [-\n        0.984704045337959, -0.670740724179446], [-1.12449565589348, -\n        0.359476803003931], [-1.07878318723543, -0.092290938944355], [-\n        0.775555435407062, 0.102132527529259], [-0.231610677329856, \n        0.314409560305622], [0.463192794235131, 0.663523546243286], [\n        1.17416973448423, 1.13156902460931], [1.74112278814906, \n        1.48967153067024], [2.00320855757084, 1.42571085941843], [\n        1.8529912317336, 0.802460519079555], [1.30747261947211, -\n        0.169219078629572], [0.540237070403222, -1.01621539672694], [-\n        0.177136817092375, -1.3130784867977], [-0.611981468823591, -\n        0.982477824460773], [-0.700240028737747, -0.344919609255406], [-\n        0.572396497740112, 0.12508353503539], [-0.450934466600975, \n        0.14255311273228], [-0.494020014254326, -0.211429053871656], [-\n        0.701707589094918, -0.599602868825992], [-0.94721339346157, -\n        0.710669870591623], [-1.09297139748946, -0.47846194092245], [-\n        1.08850658866583, -0.082258450179988], [-0.976082880696692, \n        0.235758921309309], [-0.81885695346771, 0.365298185204303], [-\n        0.63165529525553, 0.384725179378064], [-0.37983149226421, \n        0.460240196164378], [-0.0375551354277652, 0.68580913832794], [\n        0.361996927427804, 0.984470835955107], [0.739920615366072, \n        1.13195975020298], [1.03583478061534, 0.88812510421667], [\n        1.2561493896216, 0.172561520611839], [1.45295030231799, -\n        0.804979390544485], [1.64887158748426, -1.55662011197859], [\n        1.78022721495313, -1.52921975346218], [1.71945683859668, -\n        0.462240366424548], [1.3672888023919, 1.31213774341268], [\n        0.740173894315912, 2.88362740582926], [-0.0205364331835904, \n        3.20319080963167], [-0.725643970956428, 1.75222466531151], [-\n        1.23900506689782, -0.998432917440275], [-1.52651897508678, -\n        3.72752870885448], [-1.62857516631435, -5.00551707196292], [-\n        1.59657420180451, -4.18499132634584], [-1.45489013276495, -\n        1.81759097305637], [-1.21309542313047, 0.722029457352468]])\n    dta = macrodata.load_pandas().data[['tbilrate', 'infl']].values[1:]\n    cyc, trend = cffilter(dta)\n    assert_almost_equal(cyc, cfilt_res, 8)\n    cyc, trend = cffilter(dta[:, 1])\n    assert_almost_equal(cyc, cfilt_res[:, 1], 8)\n\ntest_cfitz_filter()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/filters/tests/test_filters.py"}], "instruction": "Functionality: The cffilter function implements the Christiano-Fitzgerald asymmetric, random walk filter for extracting cycles from time series data within a specified periodicity range. It can handle both 1D and 2D arrays, treating columns as separate variables if a 2D array is provided. The function also has an option to remove a trend from the data.\n\nInputs: \n- x: An array-like object (1D or 2D) representing the time series data to be filtered. For 2D arrays, variables are assumed to be in columns.\n- low: A float (default is 6) representing the minimum period of oscillations. Features below this periodicity are filtered out.\n- high: A float (default is 32) representing the maximum period of oscillations. Features above this periodicity are filtered out.\n- drift: A boolean (default is True) indicating whether or not to remove a trend from the data. The trend is estimated as a linear function of the data endpoints.\n\nOutputs: \n- cycle: An array-like object containing the features of x between the periodicities specified by 'low' and 'high'.\n- trend: An array-like object representing the trend in the data with the cycles removed.", "method_code_mask": "import numpy as np\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import array_like\nimport statsmodels as sm\n\n\ndef cffilter(x, low=6, high=32, drift=True): [MASK]\n"}
{"method_name": "get_trendorder", "full_method_name": "get_trendorder", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/util.py", "method_code": "from statsmodels.compat.pandas import frequencies\nfrom statsmodels.compat.python import asbytes\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import int_like\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy import linalg\nimport statsmodels.tsa.tsatools as tsa\nfrom collections import deque\nfrom datetime import datetime\nimport re\ndef get_trendorder(trend='c'):\n    if trend == 'c':\n        trendorder = 1\n    elif trend in ('n', 'nc'):\n        trendorder = 0\n    elif trend == 'ct':\n        trendorder = 2\n    elif trend == 'ctt':\n        trendorder = 3\n    else:\n        raise ValueError(f'Unkown trend: {trend}')\n    return trendorder", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom io import StringIO\nimport os\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import macrodata\nimport statsmodels.tools.data as data_util\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tsa.base.datetools import dates_from_str\nimport statsmodels.tsa.vector_ar.util as util\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import var_acf\nimport datetime\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\ndef test_get_trendorder():\n    results = {'c': 1, 'n': 0, 'ct': 2, 'ctt': 3}\n    for t, trendorder in results.items():\n        assert get_trendorder(t) == trendorder\n\ntest_get_trendorder()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/tests/test_var.py"}], "instruction": "Functionality: The get_trendorder function is designed to translate a trend string identifier into a numerical representation that signifies the order of the trend. This is particularly useful in time series analysis where different trends (e.g., constant, linear, quadratic) need to be distinguished and handled accordingly.\n\nInputs: \n- trend (str): A string representing the type of trend. The possible values are:\n    - 'c': constant trend (default).\n    - 'nc' or 'n': no trend.\n    - 'ct': trend with a constant and time (linear trend).\n    - 'ctt': trend with a constant, time, and time squared (quadratic trend).\n\nOutputs:\n- trendorder (int): An integer representing the order of the trend. The mapping is as follows:\n    - 'c' -> 1\n    - 'nc' or 'n' -> 0\n    - 'ct' -> 2\n    - 'ctt' -> 3\nIf the input trend is not one of the specified strings, the function raises a ValueError.", "method_code_mask": "from statsmodels.compat.pandas import frequencies\nfrom statsmodels.compat.python import asbytes\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import int_like\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy import linalg\nimport statsmodels.tsa.tsatools as tsa\nfrom collections import deque\nfrom datetime import datetime\nimport re\n\n\ndef get_trendorder(trend='c'): [MASK]\n"}
{"method_name": "var_acf", "full_method_name": "var_acf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/var_model.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.python import lrange\nfrom collections import defaultdict\nfrom io import StringIO\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.decorators import deprecated_alias\nfrom statsmodels.tools.linalg import logdet_symm\nfrom statsmodels.tools.sm_exceptions import OutputWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.base.tsa_model import TimeSeriesModel\nfrom statsmodels.tsa.base.tsa_model import TimeSeriesResultsWrapper\nimport statsmodels.tsa.tsatools as tsa\nfrom statsmodels.tsa.tsatools import duplication_matrix\nfrom statsmodels.tsa.tsatools import unvec\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.vector_ar import output\nfrom statsmodels.tsa.vector_ar import plotting\nfrom statsmodels.tsa.vector_ar import util\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import CausalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import NormalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import WhitenessTestResults\nfrom statsmodels.tsa.vector_ar.irf import IRAnalysis\nfrom statsmodels.tsa.vector_ar.output import VARSummary\nimport warnings\nimport matplotlib.pyplot as plt\ndef var_acf(coefs, sig_u, nlags=None):\n    \"\"\"\n    Compute autocovariance function ACF_y(h) up to nlags of stable VAR(p)\n    process\n\n    Parameters\n    ----------\n    coefs : ndarray (p x k x k)\n        Coefficient matrices A_i\n    sig_u : ndarray (k x k)\n        Covariance of white noise process u_t\n    nlags : int, optional\n        Defaults to order p of system\n\n    Notes\n    -----\n    Ref: L\u00fctkepohl p.28-29\n\n    Returns\n    -------\n    acf : ndarray, (p, k, k)\n    \"\"\"\n    p, k, _ = coefs.shape\n    if nlags is None:\n        nlags = p\n    result = np.zeros((nlags + 1, k, k))\n    result[:p] = _var_acf(coefs, sig_u)\n    for h in range(p, nlags + 1):\n        for j in range(p):\n            result[h] += np.dot(coefs[j], result[h - j - 1])\n    return result", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.python import lrange\nfrom io import BytesIO\nfrom io import StringIO\nimport os\nimport sys\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.datasets import macrodata\nimport statsmodels.tools.data as data_util\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tsa.base.datetools import dates_from_str\nimport statsmodels.tsa.vector_ar.util as util\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import var_acf\nimport datetime\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nclass CheckIRF:\n    ref = None\n    res = None\n    irf = None\n    k = None\n\n    def test_irf_coefs(self):\n        self._check_irfs(self.irf.irfs, self.ref.irf)\n        self._check_irfs(self.irf.orth_irfs, self.ref.orth_irf)\n\n    def _check_irfs(self, py_irfs, r_irfs):\n        for i, name in enumerate(self.res.names):\n            ref_irfs = r_irfs[name].view((float, self.k), type=np.ndarray)\n            res_irfs = py_irfs[:, :, i]\n            assert_almost_equal(ref_irfs, res_irfs)\n\n    @pytest.mark.matplotlib\n    def test_plot_irf(self, close_figures):\n        self.irf.plot()\n        self.irf.plot(plot_stderr=False)\n        self.irf.plot(impulse=0, response=1)\n        self.irf.plot(impulse=0)\n        self.irf.plot(response=0)\n        self.irf.plot(orth=True)\n        self.irf.plot(impulse=0, response=1, orth=True)\n\n    @pytest.mark.matplotlib\n    def test_plot_cum_effects(self, close_figures):\n        self.irf.plot_cum_effects()\n        self.irf.plot_cum_effects(plot_stderr=False)\n        self.irf.plot_cum_effects(impulse=0, response=1)\n        self.irf.plot_cum_effects(orth=True)\n        self.irf.plot_cum_effects(impulse=0, response=1, orth=True)\n\n    @pytest.mark.matplotlib\n    def test_plot_figsizes(self):\n        assert_equal(self.irf.plot().get_size_inches(), (10, 10))\n        assert_equal(self.irf.plot(figsize=(14, 10)).get_size_inches(), (14,\n            10))\n        assert_equal(self.irf.plot_cum_effects().get_size_inches(), (10, 10))\n        assert_equal(self.irf.plot_cum_effects(figsize=(14, 10)).\n            get_size_inches(), (14, 10))\n@pytest.mark.smoke\nclass CheckFEVD:\n    fevd = None\n\n    @pytest.mark.matplotlib\n    def test_fevd_plot(self, close_figures):\n        self.fevd.plot()\n\n    def test_fevd_repr(self):\n        self.fevd\n\n    def test_fevd_summary(self):\n        self.fevd.summary()\n\n    @pytest.mark.xfail(reason='FEVD.cov() is not implemented', raises=\n        NotImplementedError, strict=True)\n    def test_fevd_cov(self):\n        covs = self.fevd.cov()\n        raise NotImplementedError\n\nclass TestVARResults(CheckIRF, CheckFEVD):\n\tdef test_acf_2_lags(self):\n\t    c = np.zeros((2, 2, 2))\n\t    c[0] = np.array([[0.2, 0.1], [0.15, 0.15]])\n\t    c[1] = np.array([[0.1, 0.9], [0, 0.1]])\n\t    acf = var_acf(c, np.eye(2), 3)\n\t    gamma = np.zeros((6, 6))\n\t    gamma[:2, :2] = acf[0]\n\t    gamma[2:4, 2:4] = acf[0]\n\t    gamma[4:6, 4:6] = acf[0]\n\t    gamma[2:4, :2] = acf[1].T\n\t    gamma[4:, :2] = acf[2].T\n\t    gamma[:2, 2:4] = acf[1]\n\t    gamma[:2, 4:] = acf[2]\n\t    recovered = np.dot(gamma[:2, 2:], np.linalg.inv(gamma[:4, :4]))\n\t    recovered = [recovered[:, 2 * i:2 * (i + 1)] for i in range(2)]\n\t    recovered = np.array(recovered)\n\t    assert_allclose(recovered, c, atol=1e-07)\n\t\nTestVARResults().test_acf_2_lags()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/tests/test_var.py"}], "instruction": "Functionality: Compute the autocovariance function ACF_y(h) up to nlags for a stable Vector Autoregressive (VAR) process of order p.\n\nInputs:\n- coefs (ndarray, shape (p x k x k)): Coefficient matrices A_i of the VAR(p) process, where p is the order of the process, and k is the number of endogenous variables.\n- sig_u (ndarray, shape (k x k)): Covariance matrix of the white noise process u_t driving the VAR(p) process.\n- nlags (int, optional): Number of lags for which to compute the autocovariance function. Defaults to the order p of the system.\n\nOutputs:\n- acf (ndarray, shape (nlags + 1, k, k)): Autocovariance function ACF_y(h) up to nlags. Each element acf[h] gives the autocovariance at lag h.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.python import lrange\nfrom collections import defaultdict\nfrom io import StringIO\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.base.wrapper as wrap\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.decorators import deprecated_alias\nfrom statsmodels.tools.linalg import logdet_symm\nfrom statsmodels.tools.sm_exceptions import OutputWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.base.tsa_model import TimeSeriesModel\nfrom statsmodels.tsa.base.tsa_model import TimeSeriesResultsWrapper\nimport statsmodels.tsa.tsatools as tsa\nfrom statsmodels.tsa.tsatools import duplication_matrix\nfrom statsmodels.tsa.tsatools import unvec\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.vector_ar import output\nfrom statsmodels.tsa.vector_ar import plotting\nfrom statsmodels.tsa.vector_ar import util\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import CausalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import NormalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import WhitenessTestResults\nfrom statsmodels.tsa.vector_ar.irf import IRAnalysis\nfrom statsmodels.tsa.vector_ar.output import VARSummary\nimport warnings\nimport matplotlib.pyplot as plt\n\n\ndef var_acf(coefs, sig_u, nlags=None): [MASK]\n"}
{"method_name": "coint_johansen", "full_method_name": "coint_johansen", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/vecm.py", "method_code": "from collections import defaultdict\nimport numpy as np\nfrom numpy import hstack\nfrom numpy import vstack\nfrom numpy.linalg import inv\nfrom numpy.linalg import svd\nimport scipy\nimport scipy.stats\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.validation import string_like\nimport statsmodels.tsa.base.tsa_model as tsbase\nfrom statsmodels.tsa.coint_tables import c_sja\nfrom statsmodels.tsa.coint_tables import c_sjt\nfrom statsmodels.tsa.tsatools import duplication_matrix\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import CausalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import WhitenessTestResults\nimport statsmodels.tsa.vector_ar.irf as irf\nimport statsmodels.tsa.vector_ar.plotting as plot\nfrom statsmodels.tsa.vector_ar.util import get_index\nfrom statsmodels.tsa.vector_ar.util import seasonal_dummies\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import LagOrderResults\nfrom statsmodels.tsa.vector_ar.var_model import _compute_acov\nfrom statsmodels.tsa.vector_ar.var_model import forecast\nfrom statsmodels.tsa.vector_ar.var_model import forecast_interval\nfrom statsmodels.tsa.vector_ar.var_model import ma_rep\nfrom statsmodels.tsa.vector_ar.var_model import orth_ma_rep\nfrom statsmodels.tsa.vector_ar.var_model import test_normality\nimport warnings\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.iolib.summary import summary_params\ndef coint_johansen(endog, det_order, k_ar_diff):\n    \"\"\"\n    Johansen cointegration test of the cointegration rank of a VECM\n\n    Parameters\n    ----------\n    endog : array_like (nobs_tot x neqs)\n        Data to test\n    det_order : int\n        * -1 - no deterministic terms\n        * 0 - constant term\n        * 1 - linear trend\n    k_ar_diff : int, nonnegative\n        Number of lagged differences in the model.\n\n    Returns\n    -------\n    result : JohansenTestResult\n        An object containing the test's results. The most important attributes\n        of the result class are:\n\n        * trace_stat and trace_stat_crit_vals\n        * max_eig_stat and max_eig_stat_crit_vals\n\n    Notes\n    -----\n    The implementation might change to make more use of the existing VECM\n    framework.\n\n    See Also\n    --------\n    statsmodels.tsa.vector_ar.vecm.select_coint_rank\n\n    References\n    ----------\n    .. [1] L\u00fctkepohl, H. 2005. New Introduction to Multiple Time Series\n        Analysis. Springer.\n    \"\"\"\n    import warnings\n    if det_order not in [-1, 0, 1]:\n        warnings.warn(\n            'Critical values are only available for a det_order of -1, 0, or 1.'\n            , category=HypothesisTestWarning, stacklevel=2)\n    if endog.shape[1] > 12:\n        warnings.warn(\n            'Critical values are only available for time series with 12 variables at most.'\n            , category=HypothesisTestWarning, stacklevel=2)\n    from statsmodels.regression.linear_model import OLS\n\n    def detrend(y, order):\n        if order == -1:\n            return y\n        return OLS(y, np.vander(np.linspace(-1, 1, len(y)), order + 1)).fit(\n            ).resid\n\n    def resid(y, x):\n        if x.size == 0:\n            return y\n        r = y - np.dot(x, np.dot(np.linalg.pinv(x), y))\n        return r\n    endog = np.asarray(endog)\n    nobs, neqs = endog.shape\n    if det_order > -1:\n        f = 0\n    else:\n        f = det_order\n    endog = detrend(endog, det_order)\n    dx = np.diff(endog, 1, axis=0)\n    z = lagmat(dx, k_ar_diff)\n    z = z[k_ar_diff:]\n    z = detrend(z, f)\n    dx = dx[k_ar_diff:]\n    dx = detrend(dx, f)\n    r0t = resid(dx, z)\n    lx = endog[:endog.shape[0] - k_ar_diff]\n    lx = lx[1:]\n    dx = detrend(lx, f)\n    rkt = resid(dx, z)\n    skk = np.dot(rkt.T, rkt) / rkt.shape[0]\n    sk0 = np.dot(rkt.T, r0t) / rkt.shape[0]\n    s00 = np.dot(r0t.T, r0t) / r0t.shape[0]\n    sig = np.dot(sk0, np.dot(inv(s00), sk0.T))\n    tmp = inv(skk)\n    au, du = np.linalg.eig(np.dot(tmp, sig))\n    temp = inv(np.linalg.cholesky(np.dot(du.T, np.dot(skk, du))))\n    dt = np.dot(du, temp)\n    auind = np.argsort(au)\n    aind = np.flipud(auind)\n    a = au[aind]\n    d = dt[:, aind]\n    non_zero_d = d.flat != 0\n    if np.any(non_zero_d):\n        d *= np.sign(d.flat[non_zero_d][0])\n    lr1 = np.zeros(neqs)\n    lr2 = np.zeros(neqs)\n    cvm = np.zeros((neqs, 3))\n    cvt = np.zeros((neqs, 3))\n    iota = np.ones(neqs)\n    t, junk = rkt.shape\n    for i in range(0, neqs):\n        tmp = np.log(iota - a)[i:]\n        lr1[i] = -t * np.sum(tmp, 0)\n        lr2[i] = -t * np.log(1 - a[i])\n        cvm[i, :] = c_sja(neqs - i, det_order)\n        cvt[i, :] = c_sjt(neqs - i, det_order)\n        aind[i] = i\n    return JohansenTestResult(rkt, r0t, a, d, lr1, lr2, cvt, cvm, aind)", "test_code_list": [{"test_code": "import os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nimport pandas as pd\nimport pytest\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen\n@pytest.mark.smoke\ndef test_coint_johansen_0lag():\n    x_diff = np.random.normal(0, 1, 1000)\n    x = pd.Series(np.cumsum(x_diff))\n    e1 = np.random.normal(0, 1, 1000)\n    y = x + 5 + e1\n    data = pd.concat([x, y], axis=1)\n    result = coint_johansen(data, det_order=-1, k_ar_diff=0)\n    assert result.eig.shape == (2,)\n\ntest_coint_johansen_0lag()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/vector_ar/tests/test_coint.py"}], "instruction": "Functionality: The coint_johansen function performs a Johansen cointegration test to determine the cointegration rank of a Vector Error Correction Model (VECM). This test is crucial for understanding the long-run equilibrium relationship between multiple time series.\n\nInputs:\n    - endog: array_like (nobs_tot x neqs) - The data to be tested. It should be an array where each column represents a time series variable.\n    - det_order: int - Determines the deterministic terms in the model. It can be -1 for no deterministic terms, 0 for a constant term, or 1 for a linear trend.\n    - k_ar_diff: int, nonnegative - The number of lagged differences to include in the model.\n\nOutputs:\n    - result: JohansenTestResult - An object that contains the test's results. The most important attributes of the result class are:\n        * trace_stat: The trace statistic for the hypothesis of cointegration rank.\n        * trace_stat_crit_vals: Critical values for the trace statistic.\n        * max_eig_stat: The statistic for the hypothesis of cointegration rank based on the maximum eigenvalue.\n        * max_eig_stat_crit_vals: Critical values for the maximum eigenvalue statistic.", "method_code_mask": "from collections import defaultdict\nimport numpy as np\nfrom numpy import hstack\nfrom numpy import vstack\nfrom numpy.linalg import inv\nfrom numpy.linalg import svd\nimport scipy\nimport scipy.stats\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.iolib.table import SimpleTable\nfrom statsmodels.tools.decorators import cache_readonly\nfrom statsmodels.tools.sm_exceptions import HypothesisTestWarning\nfrom statsmodels.tools.validation import string_like\nimport statsmodels.tsa.base.tsa_model as tsbase\nfrom statsmodels.tsa.coint_tables import c_sja\nfrom statsmodels.tsa.coint_tables import c_sjt\nfrom statsmodels.tsa.tsatools import duplication_matrix\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import CausalityTestResults\nfrom statsmodels.tsa.vector_ar.hypothesis_test_results import WhitenessTestResults\nimport statsmodels.tsa.vector_ar.irf as irf\nimport statsmodels.tsa.vector_ar.plotting as plot\nfrom statsmodels.tsa.vector_ar.util import get_index\nfrom statsmodels.tsa.vector_ar.util import seasonal_dummies\nfrom statsmodels.tsa.vector_ar.var_model import VAR\nfrom statsmodels.tsa.vector_ar.var_model import LagOrderResults\nfrom statsmodels.tsa.vector_ar.var_model import _compute_acov\nfrom statsmodels.tsa.vector_ar.var_model import forecast\nfrom statsmodels.tsa.vector_ar.var_model import forecast_interval\nfrom statsmodels.tsa.vector_ar.var_model import ma_rep\nfrom statsmodels.tsa.vector_ar.var_model import orth_ma_rep\nfrom statsmodels.tsa.vector_ar.var_model import test_normality\nimport warnings\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.iolib.summary import summary_params\n\n\ndef coint_johansen(endog, det_order, k_ar_diff): [MASK]\n"}
{"method_name": "dentonm", "full_method_name": "dentonm", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/interp/denton.py", "method_code": "import numpy as np\nfrom numpy import dot\nfrom numpy import eye\nfrom numpy import diag_indices\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import diag\nfrom numpy import asarray\nfrom numpy import r_\nfrom numpy.linalg import solve\ndef dentonm(indicator, benchmark, freq='aq', **kwargs):\n    \"\"\"\n    Modified Denton's method to convert low-frequency to high-frequency data.\n\n    Uses proportionate first-differences as the penalty function.  See notes.\n\n    Parameters\n    ----------\n    indicator : array_like\n        A low-frequency indicator series.  It is assumed that there are no\n        pre-sample indicators.  Ie., the first indicators line up with\n        the first benchmark.\n    benchmark : array_like\n        The higher frequency benchmark.  A 1d or 2d data series in columns.\n        If 2d, then M series are assumed.\n    freq : str {\"aq\",\"qm\", \"other\"}\n        The frequency to use in the conversion.\n\n        * \"aq\" - Benchmarking an annual series to quarterly.\n        * \"mq\" - Benchmarking a quarterly series to monthly.\n        * \"other\" - Custom stride.  A kwarg, k, must be supplied.\n    **kwargs\n        Additional keyword argument. For example:\n\n        * k, an int, the number of high-frequency observations that sum to make\n          an aggregate low-frequency observation. `k` is used with\n          `freq` == \"other\".\n\n    Returns\n    -------\n    transformed : ndarray\n        The transformed series.\n\n    Examples\n    --------\n    >>> indicator = [50,100,150,100] * 5\n    >>> benchmark = [500,400,300,400,500]\n    >>> benchmarked = dentonm(indicator, benchmark, freq=\"aq\")\n\n    Notes\n    -----\n    Denton's method minimizes the distance given by the penalty function, in\n    a least squares sense, between the unknown benchmarked series and the\n    indicator series subject to the condition that the sum of the benchmarked\n    series is equal to the benchmark. The modification allows that the first\n    value not be pre-determined as is the case with Denton's original method.\n    If the there is no benchmark provided for the last few indicator\n    observations, then extrapolation is performed using the last\n    benchmark-indicator ratio of the previous period.\n\n    Minimizes sum((X[t]/I[t] - X[t-1]/I[t-1])**2)\n\n    s.t.\n\n    sum(X) = A, for each period.  Where X is the benchmarked series, I is\n    the indicator, and A is the benchmark.\n\n    References\n    ----------\n    Bloem, A.M, Dippelsman, R.J. and Maehle, N.O.  2001 Quarterly National\n        Accounts Manual--Concepts, Data Sources, and Compilation. IMF.\n        http://www.imf.org/external/pubs/ft/qna/2000/Textbook/index.htm\n    Cholette, P. 1988. \"Benchmarking systems of socio-economic time series.\"\n        Statistics Canada, Time Series Research and Analysis Division,\n        Working Paper No TSRA-88-017E.\n    Denton, F.T. 1971. \"Adjustment of monthly or quarterly series to annual\n        totals: an approach based on quadratic minimization.\" Journal of the\n        American Statistical Association. 99-102.\n    \"\"\"\n    indicator = asarray(indicator)\n    if indicator.ndim == 1:\n        indicator = indicator[:, None]\n    benchmark = asarray(benchmark)\n    if benchmark.ndim == 1:\n        benchmark = benchmark[:, None]\n    N = len(indicator)\n    m = len(benchmark)\n    if freq == 'aq':\n        k = 4\n    elif freq == 'qm':\n        k = 3\n    elif freq == 'other':\n        k = kwargs.get('k')\n        if not k:\n            raise ValueError('k must be supplied with freq=\"other\"')\n    else:\n        raise ValueError('freq %s not understood' % freq)\n    n = k * m\n    if N > n:\n        q = N - n\n    else:\n        q = 0\n    B = np.kron(np.eye(m), ones((k, 1)))\n    Zinv = diag(1.0 / indicator.squeeze()[:n])\n    HTH = eye(n)\n    diag_idx0, diag_idx1 = diag_indices(n)\n    HTH[diag_idx0[1:-1], diag_idx1[1:-1]] += 1\n    HTH[diag_idx0[:-1] + 1, diag_idx1[:-1]] = -1\n    HTH[diag_idx0[:-1], diag_idx1[:-1] + 1] = -1\n    W = dot(dot(Zinv, HTH), Zinv)\n    I = zeros((n + m, n + m))\n    I[:n, :n] = W\n    I[:n, n:] = B\n    I[n:, :n] = B.T\n    A = zeros((m + n, 1))\n    A[-m:] = benchmark\n    X = solve(I, A)\n    X = X[:-m]\n    if q > 0:\n        bi = X[n - 1] / indicator[n - 1]\n        extrapolated = bi * indicator[n:]\n        X = r_[X, extrapolated]\n    return X.squeeze()", "test_code_list": [{"test_code": "import numpy as np\nfrom statsmodels.tsa.interp import dentonm\nimport pytest\ndef test_denton_quarterly():\n    indicator = np.array([98.2, 100.8, 102.2, 100.8, 99.0, 101.6, 102.7, \n        101.5, 100.5, 103.0, 103.5, 101.5])\n    benchmark = np.array([4000.0, 4161.4])\n    x_imf = dentonm(indicator, benchmark, freq='aq')\n    imf_stata = np.array([969.8, 998.4, 1018.3, 1013.4, 1007.2, 1042.9, \n        1060.3, 1051.0, 1040.6, 1066.5, 1071.7, 1051.0])\n    np.testing.assert_almost_equal(imf_stata, x_imf, 1)\n\ntest_denton_quarterly()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/interp/tests/test_denton.py"}, {"test_code": "import numpy as np\nfrom statsmodels.tsa.interp import dentonm\nimport pytest\ndef test_denton_quarterly2():\n    zQ = np.array([50, 100, 150, 100] * 5)\n    Y = np.array([500, 400, 300, 400, 500])\n    x_denton = dentonm(zQ, Y, freq='aq')\n    x_stata = np.array([64.334796, 127.80616, 187.82379, 120.03526, \n        56.563894, 105.97568, 147.50144, 89.958987, 40.547201, 74.445963, \n        108.34473, 76.66211, 42.763347, 94.14664, 153.41596, 109.67405, \n        58.290761, 122.62556, 190.41409, 128.66959])\n    np.testing.assert_almost_equal(x_denton, x_stata, 5)\n\ntest_denton_quarterly2()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/interp/tests/test_denton.py"}], "instruction": "Functionality: The dentonm function benchmarks (converts) low-frequency data to high-frequency data using Denton's modified method. This method minimizes the difference between the unknown benchmarked series and the indicator series, subject to the condition that the sum of the benchmarked series equals the benchmark. The method is optimized for adjusting data such as economic indicators from annual to quarterly or quarterly to monthly frequencies, or custom frequencies if provided.\n\nInputs:\n- indicator: A 1D or 2D array representing a low-frequency indicator series. It's assumed that there are no pre-sample indicators, meaning the first indicator lines up with the first benchmark.\n- benchmark: A 1D or 2D array representing the higher frequency benchmark. If 2D, it's assumed to contain M series.\n- freq: A string that specifies the frequency conversion to be applied. It can be 'aq' for annual to quarterly, 'qm' for quarterly to monthly, or 'other' for custom frequencies.\n- **kwargs: Additional keyword arguments, specifically 'k' for custom frequencies, which is an integer indicating the number of high-frequency observations that sum to make an aggregate low-frequency observation.\n\nOutputs:\n- transformed: A NumPy ndarray representing the transformed series, which is the benchmarked high-frequency data derived from the low-frequency indicator series.", "method_code_mask": "import numpy as np\nfrom numpy import dot\nfrom numpy import eye\nfrom numpy import diag_indices\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import diag\nfrom numpy import asarray\nfrom numpy import r_\nfrom numpy.linalg import solve\n\n\ndef dentonm(indicator, benchmark, freq='aq', **kwargs): [MASK]\n"}
{"method_name": "pacf_yw", "full_method_name": "pacf_yw", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/stattools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\ndef pacf_yw(x: ArrayLike1D, nlags: (int | None)=None, method: Literal[\n    'adjusted', 'mle']='adjusted') ->np.ndarray:\n    \"\"\"\n    Partial autocorrelation estimated with non-recursive yule_walker.\n\n    Parameters\n    ----------\n    x : array_like\n        The observations of time series for which pacf is calculated.\n    nlags : int, optional\n        Number of lags to return autocorrelation for. If not provided,\n        uses min(10 * np.log10(nobs), nobs - 1).\n    method : {\"adjusted\", \"mle\"}, default \"adjusted\"\n        The method for the autocovariance calculations in yule walker.\n\n    Returns\n    -------\n    ndarray\n        The partial autocorrelations, maxlag+1 elements.\n\n    See Also\n    --------\n    statsmodels.tsa.stattools.pacf\n        Partial autocorrelation estimation.\n    statsmodels.tsa.stattools.pacf_ols\n        Partial autocorrelation estimation using OLS.\n    statsmodels.tsa.stattools.pacf_burg\n        Partial autocorrelation estimation using Burg\"s method.\n\n    Notes\n    -----\n    This solves yule_walker for each desired lag and contains\n    currently duplicate calculations.\n    \"\"\"\n    x = array_like(x, 'x')\n    nlags = int_like(nlags, 'nlags', optional=True)\n    nobs = x.shape[0]\n    if nlags is None:\n        nlags = max(min(int(10 * np.log10(nobs)), nobs - 1), 1)\n    method = string_like(method, 'method', options=('adjusted', 'mle'))\n    pacf = [1.0]\n    with warnings.catch_warnings():\n        warnings.simplefilter('once', ValueWarning)\n        for k in range(1, nlags + 1):\n            pacf.append(yule_walker(x, k, method=method)[0][-1])\n    return np.array(pacf)", "test_code_list": [{"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_pacf_burg():\n    rnd = np.random.RandomState(12345)\n    e = rnd.randn(10001)\n    y = e[1:] + 0.5 * e[:-1]\n    pacf, sigma2 = pacf_burg(y, 10)\n    yw_pacf = pacf_yw(y, 10)\n    assert_allclose(pacf, yw_pacf, atol=0.0005)\n    ye = y - y.mean()\n    s2y = ye.dot(ye) / 10000\n    pacf[0] = 0\n    sigma2_direct = s2y * np.cumprod(1 - pacf ** 2)\n    assert_allclose(sigma2, sigma2_direct, atol=0.001)\n\ntest_pacf_burg()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}], "instruction": "Functionality: Estimate the partial autocorrelation function (PACF) of a time series using the non-recursive Yule-Walker method. This function calculates the PACF by solving the Yule-Walker equations for each desired lag, potentially involving duplicate calculations for efficiency.\n\nInputs: \n- x: An array-like object representing the observations of the time series for which the PACF is to be calculated.\n- nlags: An optional integer specifying the number of lags for which to return the PACF. If not provided, it defaults to the minimum of 10 multiplied by the base-10 logarithm of the number of observations, or the number of observations minus one.\n- method: A string literal specifying the method for the autocovariance calculations in the Yule-Walker equation, which can be either 'adjusted' or 'mle' (maximum likelihood estimation). The default is 'adjusted'.\n\nOutputs:\n- A one-dimensional numpy array containing the estimated partial autocorrelations, with the number of elements equal to nlags + 1.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\n\n\ndef pacf_yw(x: ArrayLike1D, nlags: (int | None)=None, method: Literal[\n    'adjusted', 'mle']='adjusted') ->np.ndarray: [MASK]\n"}
{"method_name": "unvech", "full_method_name": "unvech", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tsatools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\ndef unvech(v):\n    rows = 0.5 * (-1 + np.sqrt(1 + 8 * len(v)))\n    rows = int(np.round(rows))\n    result = np.zeros((rows, rows))\n    result[np.triu_indices(rows)] = v\n    result = result + result.T\n    result[np.diag_indices(rows)] /= 2\n    return result", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.tseries.frequencies import to_offset\nimport pytest\nfrom statsmodels import regression\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa import stattools\nfrom statsmodels.tsa.tests.results import savedrvs\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlccf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlpacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlywar\nimport statsmodels.tsa.tsatools as tools\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.tsatools import vech\ndef test_duplication_matrix():\n    for k in range(2, 10):\n        m = unvech(np.random.randn(k * (k + 1) // 2))\n        Dk = tools.duplication_matrix(k)\n        assert np.array_equal(vec(m), np.dot(Dk, vech(m)))\n\ntest_duplication_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_tsa_tools.py"}], "instruction": "Functionality: The unvech function takes a vector as an input and converts it into a symmetric matrix using the vech representation. The vech representation is a method to convert a symmetric matrix into a vector by stacking the lower or upper triangular elements of the matrix. The function calculates the size of the original symmetric matrix, fills the upper triangular part with the input vector, creates the symmetric part, and ensures that the diagonal elements are divided by 2 to maintain the symmetry.\nInputs: \n- v: A numpy array or vector of length m(m+1)/2 where m is the size of the resulting symmetric matrix.\nOutputs: \n- result: A numpy array representing the symmetric matrix of size m x m.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\n\n\ndef unvech(v): [MASK]\n"}
{"method_name": "elimination_matrix", "full_method_name": "elimination_matrix", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tsatools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\ndef elimination_matrix(n):\n    \"\"\"\n    Create the elimination matrix L_n which satisfies vech(M) = L_n vec(M) for\n    any matrix M\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n    \"\"\"\n    n = int_like(n, 'n')\n    vech_indices = vec(np.tril(np.ones((n, n))))\n    return np.eye(n * n)[vech_indices != 0]", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.tseries.frequencies import to_offset\nimport pytest\nfrom statsmodels import regression\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa import stattools\nfrom statsmodels.tsa.tests.results import savedrvs\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlccf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlpacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlywar\nimport statsmodels.tsa.tsatools as tools\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.tsatools import vech\ndef test_elimination_matrix():\n    for k in range(2, 10):\n        m = np.random.randn(k, k)\n        Lk = elimination_matrix(k)\n        assert np.array_equal(vech(m), np.dot(Lk, vec(m)))\n\ntest_elimination_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_tsa_tools.py"}], "instruction": "Functionality: The function 'elimination_matrix' is designed to construct an elimination matrix, denoted as L_n. This matrix is special in that it can be used to transform any given square matrix M into its vectorized lower triangular part (vech(M)) when applied to the vectorized form of M (vec(M)). This operation is critical in various applications of linear algebra and statistics, particularly in dealing with symmetric matrices.\n\nInputs:\n- n: An integer representing the dimension of the square matrix M. This parameter specifies the size of the matrix upon which the elimination matrix L_n will operate. It is essential that n is a positive integer.\n\nOutputs:\n- A NumPy array representing the elimination matrix L_n. This matrix, when multiplied with the vectorized form of any n x n matrix (vec(M)), yields the vectorized form of the lower triangular part of that matrix (vech(M)). The output is a 2D array where rows correspond to the elements of vech(M), and columns correspond to the elements of vec(M).", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\n\n\ndef elimination_matrix(n): [MASK]\n"}
{"method_name": "commutation_matrix", "full_method_name": "commutation_matrix", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tsatools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\ndef commutation_matrix(p, q):\n    \"\"\"\n    Create the commutation matrix K_{p,q} satisfying vec(A') = K_{p,q} vec(A)\n\n    Parameters\n    ----------\n    p : int\n    q : int\n\n    Returns\n    -------\n    K : ndarray (pq x pq)\n    \"\"\"\n    p = int_like(p, 'p')\n    q = int_like(q, 'q')\n    K = np.eye(p * q)\n    indices = np.arange(p * q).reshape((p, q), order='F')\n    return K.take(indices.ravel(), axis=0)", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.tseries.frequencies import to_offset\nimport pytest\nfrom statsmodels import regression\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa import stattools\nfrom statsmodels.tsa.tests.results import savedrvs\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlccf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlpacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlywar\nimport statsmodels.tsa.tsatools as tools\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.tsatools import vech\ndef test_commutation_matrix():\n    m = np.random.randn(4, 3)\n    K = commutation_matrix(4, 3)\n    assert np.array_equal(vec(m.T), np.dot(K, vec(m)))\n\ntest_commutation_matrix()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_tsa_tools.py"}], "instruction": "Functionality: The function commutation_matrix is designed to generate a commutation matrix K_{p,q}, which is a special matrix that satisfies the equation vec(A') = K_{p,q} vec(A). Here, A is any p x q matrix, A' is the transpose of A, and vec() is the vectorization operator, which stacks all columns of a matrix into a single column vector.\n\nInputs: \n- p : int - The number of rows in the matrix A.\n- q : int - The number of columns in the matrix A.\n\nOutputs: \n- K : ndarray (pq x pq) - The commutation matrix of size pq x pq, where p and q are the dimensions provided as input. This matrix can be used to transpose a matrix via vectorization, by multiplying the vectorized form of a matrix by the commutation matrix.\n", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\n\n\ndef commutation_matrix(p, q): [MASK]\n"}
{"method_name": "_ar_transparams", "full_method_name": "_ar_transparams", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tsatools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\ndef _ar_transparams(params):\n    \"\"\"\n    Transforms params to induce stationarity/invertability.\n\n    Parameters\n    ----------\n    params : array_like\n        The AR coefficients\n\n    Reference\n    ---------\n    Jones(1980)\n    \"\"\"\n    newparams = np.tanh(params / 2)\n    tmp = np.tanh(params / 2)\n    for j in range(1, len(params)):\n        a = newparams[j]\n        for kiter in range(j):\n            tmp[kiter] -= a * newparams[j - kiter - 1]\n        newparams[:j] = tmp[:j]\n    return newparams", "test_code_list": [{"test_code": "from statsmodels.compat.pandas import assert_frame_equal\nfrom statsmodels.compat.pandas import assert_series_equal\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_array_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas.tseries.frequencies import to_offset\nimport pytest\nfrom statsmodels import regression\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.tsa import stattools\nfrom statsmodels.tsa.tests.results import savedrvs\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlccf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlpacf\nfrom statsmodels.tsa.tests.results.datamlw_tls import mlywar\nimport statsmodels.tsa.tsatools as tools\nfrom statsmodels.tsa.tsatools import vec\nfrom statsmodels.tsa.tsatools import vech\ndef test_ar_transparams():\n    arr = np.array([-1000.0, -100.0, -10.0, 1.0, 0.0, 1.0, 10.0, 100.0, 1000.0]\n        )\n    assert not np.isnan(_ar_transparams(arr)).any()\n\ntest_ar_transparams()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_tsa_tools.py"}], "instruction": "Functionality: The _ar_transparams function is designed to transform an array of Autoregressive (AR) coefficients to induce stationarity and invertibility in time series analysis. This transformation is based on a method referenced from Jones(1980), which is crucial for ensuring that the time series model is stable and can be accurately estimated.\n\nInputs: \n- params: array_like - This input represents the AR coefficients that need to be transformed. These coefficients are typically estimated from a time series data set and are used to predict future values in the series based on past values.\n\nOutputs:\n- newparams: A transformed array of AR coefficients. After applying the transformation method, the output array should represent coefficients that are more suitable for use in a stable time series model. This output can then be used in further statistical analyses or model fitting processes to ensure that the model is stationary and invertible.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lrange\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas.tseries import offsets\nfrom pandas.tseries.frequencies import to_offset\nfrom statsmodels.tools.data import _is_recarray\nfrom statsmodels.tools.data import _is_using_pandas\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.typing import NDArray\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tools.sm_exceptions import recarray_exception\n\n\ndef _ar_transparams(params): [MASK]\n"}
{"method_name": "gen_data", "full_method_name": "gen_data", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_ar.py", "method_code": "from statsmodels.compat.pytest import pytest_warns\nimport datetime as dt\nfrom itertools import product\nfrom typing import NamedTuple\nfrom typing import Union\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.ar_model import AutoRegResultsWrapper\nfrom statsmodels.tsa.ar_model import ar_select_order\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom statsmodels.tsa.deterministic import Seasonality\nfrom statsmodels.tsa.deterministic import TimeTrend\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.tests.results import results_ar\nfrom io import BytesIO\nfrom matplotlib.figure import Figure\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.ar_model import ARResults\ndef gen_data(nobs, nexog, pandas, seed=92874765):\n    rs = np.random.RandomState(seed)\n    endog = rs.standard_normal(nobs)\n    exog = rs.standard_normal((nobs, nexog)) if nexog else None\n    if pandas:\n        index = pd.date_range(dt.datetime(1999, 12, 31), periods=nobs, freq\n            =MONTH_END)\n        endog = pd.Series(endog, name='endog', index=index)\n        if nexog:\n            cols = [f'exog.{i}' for i in range(exog.shape[1])]\n            exog = pd.DataFrame(exog, columns=cols, index=index)\n\n\n    class DataSet(NamedTuple):\n        endog: Union[np.ndarray, pd.Series]\n        exog: Union[np.ndarray, pd.DataFrame]\n    return DataSet(endog=endog, exog=exog)", "test_code_list": [{"test_code": "from statsmodels.compat.pytest import pytest_warns\nimport datetime as dt\nfrom itertools import product\nfrom typing import NamedTuple\nfrom typing import Union\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.ar_model import AutoRegResultsWrapper\nfrom statsmodels.tsa.ar_model import ar_select_order\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom statsmodels.tsa.deterministic import Seasonality\nfrom statsmodels.tsa.deterministic import TimeTrend\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.tests.results import results_ar\nfrom io import BytesIO\nfrom matplotlib.figure import Figure\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.ar_model import ARResults\n@pytest.mark.matplotlib\ndef test_parameterless_autoreg():\n    data = gen_data(250, 0, False)\n    mod = AutoReg(data.endog, 0, trend='n', seasonal=False, exog=None)\n    res = mod.fit()\n    for attr in dir(res):\n        if attr.startswith('_'):\n            continue\n        if attr in ('predict', 'f_test', 't_test', 'initialize', 'load',\n            'remove_data', 'save', 't_test', 't_test_pairwise', 'wald_test',\n            'wald_test_terms', 'apply', 'append'):\n            continue\n        attr = getattr(res, attr)\n        if callable(attr):\n            attr()\n        else:\n            assert isinstance(attr, object)\n\ntest_parameterless_autoreg()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_ar.py"}], "instruction": "Functionality: The gen_data function generates synthetic data for use in statistical models, particularly for time series analysis. It creates a random endogenous variable (endog) and, optionally, a set of random exogenous variables (exog). The data can be returned in either a NumPy array format or a pandas DataFrame/Series format.\n\nInputs: \n- nobs: An integer representing the number of observations to generate.\n- nexog: An integer specifying the number of exogenous variables to include. If nexog is set to 0, no exogenous variables will be generated.\n- pandas: A boolean value that determines the format of the output. If True, the data will be returned as pandas DataFrame/Series. If False, the data will be returned as NumPy arrays.\n- seed: An optional integer representing the seed for the random number generator to ensure reproducibility. The default value is 92874765.\n\nOutputs: \n- A NamedTuple named DataSet which contains two fields:\n    - endog: A NumPy array or pandas Series representing the endogenous variable (the variable being modeled).\n    - exog: A NumPy array or pandas DataFrame representing the exogenous variables (predictors). If nexog is 0, exog will be None.", "method_code_mask": "from statsmodels.compat.pytest import pytest_warns\nimport datetime as dt\nfrom itertools import product\nfrom typing import NamedTuple\nfrom typing import Union\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas.testing import assert_series_equal\nimport pytest\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.iolib.summary import Summary\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools.sm_exceptions import SpecificationWarning\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.ar_model import AutoRegResultsWrapper\nfrom statsmodels.tsa.ar_model import ar_select_order\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom statsmodels.tsa.deterministic import Seasonality\nfrom statsmodels.tsa.deterministic import TimeTrend\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.tests.results import results_ar\nfrom io import BytesIO\nfrom matplotlib.figure import Figure\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.ar_model import ARResults\n\n\ndef gen_data(nobs, nexog, pandas, seed=92874765): [MASK]\n"}
{"method_name": "seasonal_decompose", "full_method_name": "seasonal_decompose", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/seasonal.py", "method_code": "import numpy as np\nimport pandas as pd\nfrom pandas.core.nanops import nanmean as pd_nanmean\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stl._stl import STL\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.stl.mstl import MSTL\nfrom statsmodels.tsa.tsatools import freq_to_period\nfrom pandas.plotting import register_matplotlib_converters\nfrom statsmodels.graphics.utils import _import_mpl\ndef seasonal_decompose(x, model='additive', filt=None, period=None,\n    two_sided=True, extrapolate_trend=0):\n    \"\"\"\n    Seasonal decomposition using moving averages.\n\n    Parameters\n    ----------\n    x : array_like\n        Time series. If 2d, individual series are in columns. x must contain 2\n        complete cycles.\n    model : {\"additive\", \"multiplicative\"}, optional\n        Type of seasonal component. Abbreviations are accepted.\n    filt : array_like, optional\n        The filter coefficients for filtering out the seasonal component.\n        The concrete moving average method used in filtering is determined by\n        two_sided.\n    period : int, optional\n        Period of the series (eg, 1 for annual, 4 for quarterly, etc). Must be\n        used if x is not a pandas object or if the index of x does not have a\n        frequency. Overrides default periodicity of x if x is a pandas object\n        with a timeseries index.\n    two_sided : bool, optional\n        The moving average method used in filtering.\n        If True (default), a centered moving average is computed using the\n        filt. If False, the filter coefficients are for past values only.\n    extrapolate_trend : int or 'freq', optional\n        If set to > 0, the trend resulting from the convolution is\n        linear least-squares extrapolated on both ends (or the single one\n        if two_sided is False) considering this many (+1) closest points.\n        If set to 'freq', use `freq` closest points. Setting this parameter\n        results in no NaN values in trend or resid components.\n\n    Returns\n    -------\n    DecomposeResult\n        A object with seasonal, trend, and resid attributes.\n\n    See Also\n    --------\n    statsmodels.tsa.filters.bk_filter.bkfilter\n        Baxter-King filter.\n    statsmodels.tsa.filters.cf_filter.cffilter\n        Christiano-Fitzgerald asymmetric, random walk filter.\n    statsmodels.tsa.filters.hp_filter.hpfilter\n        Hodrick-Prescott filter.\n    statsmodels.tsa.filters.convolution_filter\n        Linear filtering via convolution.\n    statsmodels.tsa.seasonal.STL\n        Season-Trend decomposition using LOESS.\n\n    Notes\n    -----\n    This is a naive decomposition. More sophisticated methods should\n    be preferred.\n\n    The additive model is Y[t] = T[t] + S[t] + e[t]\n\n    The multiplicative model is Y[t] = T[t] * S[t] * e[t]\n\n    The results are obtained by first estimating the trend by applying\n    a convolution filter to the data. The trend is then removed from the\n    series and the average of this de-trended series for each period is\n    the returned seasonal component.\n    \"\"\"\n    pfreq = period\n    pw = PandasWrapper(x)\n    if period is None:\n        pfreq = getattr(getattr(x, 'index', None), 'inferred_freq', None)\n    x = array_like(x, 'x', maxdim=2)\n    nobs = len(x)\n    if not np.all(np.isfinite(x)):\n        raise ValueError('This function does not handle missing values')\n    if model.startswith('m'):\n        if np.any(x <= 0):\n            raise ValueError(\n                'Multiplicative seasonality is not appropriate for zero and negative values'\n                )\n    if period is None:\n        if pfreq is not None:\n            pfreq = freq_to_period(pfreq)\n            period = pfreq\n        else:\n            raise ValueError(\n                'You must specify a period or x must be a pandas object with a PeriodIndex or a DatetimeIndex with a freq not set to None'\n                )\n    if x.shape[0] < 2 * pfreq:\n        raise ValueError(\n            f'x must have 2 complete cycles requires {2 * pfreq} observations. x only has {x.shape[0]} observation(s)'\n            )\n    if filt is None:\n        if period % 2 == 0:\n            filt = np.array([0.5] + [1] * (period - 1) + [0.5]) / period\n        else:\n            filt = np.repeat(1.0 / period, period)\n    nsides = int(two_sided) + 1\n    trend = convolution_filter(x, filt, nsides)\n    if extrapolate_trend == 'freq':\n        extrapolate_trend = period - 1\n    if extrapolate_trend > 0:\n        trend = _extrapolate_trend(trend, extrapolate_trend + 1)\n    if model.startswith('m'):\n        detrended = x / trend\n    else:\n        detrended = x - trend\n    period_averages = seasonal_mean(detrended, period)\n    if model.startswith('m'):\n        period_averages /= np.mean(period_averages, axis=0)\n    else:\n        period_averages -= np.mean(period_averages, axis=0)\n    seasonal = np.tile(period_averages.T, nobs // period + 1).T[:nobs]\n    if model.startswith('m'):\n        resid = x / seasonal / trend\n    else:\n        resid = detrended - seasonal\n    results = []\n    for s, name in zip((seasonal, trend, resid, x), ('seasonal', 'trend',\n        'resid', None)):\n        results.append(pw.wrap(s.squeeze(), columns=name))\n    return DecomposeResult(seasonal=results[0], trend=results[1], resid=\n        results[2], observed=results[3])", "test_code_list": [{"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\ndef test_seasonal_decompose_multiple():\n    x = np.array([-50, 175, 149, 214, 247, 237, 225, 329, 729, 809, 530, \n        489, 540, 457, 195, 176, 337, 239, 128, 102, 232, 429, 3, 98, 43, -\n        141, -77, -13, 125, 361, -45, 184])\n    x = np.c_[x, x]\n    res = seasonal_decompose(x, period=4)\n    assert_allclose(res.trend[:, 0], res.trend[:, 1])\n    assert_allclose(res.seasonal[:, 0], res.seasonal[:, 1])\n    assert_allclose(res.resid[:, 0], res.resid[:, 1])\n\ntest_seasonal_decompose_multiple()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_seasonal.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\n\nclass TestDecompose():\n\tdef test_pandas_nofreq(self):\n\t    nobs = 100\n\t    dta = pd.Series([(x % 3) for x in range(nobs)] + np.random.randn(nobs))\n\t    res_np = seasonal_decompose(dta.values, period=3)\n\t    res = seasonal_decompose(dta, period=3)\n\t    atol = 1e-08\n\t    rtol = 1e-10\n\t    assert_allclose(res.seasonal.values.squeeze(), res_np.seasonal, atol=\n\t        atol, rtol=rtol)\n\t    assert_allclose(res.trend.values.squeeze(), res_np.trend, atol=atol,\n\t        rtol=rtol)\n\t    assert_allclose(res.resid.values.squeeze(), res_np.resid, atol=atol,\n\t        rtol=rtol)\n\t\nTestDecompose().test_pandas_nofreq()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_seasonal.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\n\nclass TestDecompose():\n\tdef test_2d(self):\n\t    x = np.tile(np.arange(6), (2, 1)).T\n\t    trend = seasonal_decompose(x, period=2).trend\n\t    expected = np.tile(np.arange(6, dtype=float), (2, 1)).T\n\t    expected[0] = expected[-1] = np.nan\n\t    assert_equal(trend, expected)\n\t\nTestDecompose().test_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_seasonal.py"}, {"test_code": "import numpy as np\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\n\nclass TestDecompose():\n\tdef test_interpolate_trend(self):\n\t    x = np.arange(12)\n\t    freq = 4\n\t    trend = seasonal_decompose(x, period=freq).trend\n\t    assert_equal(trend[0], np.nan)\n\t    trend = seasonal_decompose(x, period=freq, extrapolate_trend=5).trend\n\t    assert_almost_equal(trend, x)\n\t    trend = seasonal_decompose(x, period=freq, extrapolate_trend='freq').trend\n\t    assert_almost_equal(trend, x)\n\t    trend = seasonal_decompose(x[:, None], period=freq, extrapolate_trend=5\n\t        ).trend\n\t    assert_almost_equal(trend, x)\n\t    x = np.tile(np.arange(12), (2, 1)).T\n\t    trend = seasonal_decompose(x, period=freq, extrapolate_trend=1).trend\n\t    assert_almost_equal(trend, x)\n\t    trend = seasonal_decompose(x, period=freq, extrapolate_trend='freq').trend\n\t    assert_almost_equal(trend, x)\n\t\nTestDecompose().test_interpolate_trend()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_seasonal.py"}], "instruction": "Functionality: Decomposes time series data into seasonal, trend, and residual components using moving averages. This function implements a naive decomposition method suitable for series with an additive or multiplicative seasonal component.\n\nInputs:\n- x: array_like\n  Time series data. If 2D, individual series are in columns. x must contain at least 2 complete cycles.\n- model: {\"additive\", \"multiplicative\"} (optional)\n  Type of seasonal component. Default is 'additive'. Abbreviations are accepted.\n- filt: array_like (optional)\n  Filter coefficients for filtering out the seasonal component. Used in the moving average method determined by the 'two_sided' parameter.\n- period: int (optional)\n  Period of the series (e.g., 1 for annual, 4 for quarterly, etc). Required if x is not a pandas object or if the index of x does not have a frequency.\n- two_sided: bool (optional)\n  Determines the moving average method used in filtering. True for a centered moving average, False for filtering using past values only. Default is True.\n- extrapolate_trend: int or 'freq' (optional)\n  If > 0, linear least-squares extrapolation of the trend is performed on both ends (or one end if 'two_sided' is False) using this many (+1) closest points. If set to 'freq', uses 'freq' closest points. Removes NaN values in trend or resid components.\n\nOutputs:\n- DecomposeResult\n  An object with attributes 'seasonal', 'trend', and 'resid', representing the seasonal component, trend component, and residual component of the time series data, respectively.", "method_code_mask": "import numpy as np\nimport pandas as pd\nfrom pandas.core.nanops import nanmean as pd_nanmean\nfrom statsmodels.tools.validation import PandasWrapper\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tsa.stl._stl import STL\nfrom statsmodels.tsa.filters.filtertools import convolution_filter\nfrom statsmodels.tsa.stl.mstl import MSTL\nfrom statsmodels.tsa.tsatools import freq_to_period\nfrom pandas.plotting import register_matplotlib_converters\nfrom statsmodels.graphics.utils import _import_mpl\n\n\ndef seasonal_decompose(x, model='additive', filt=None, period=None,\n    two_sided=True, extrapolate_trend=0): [MASK]\n"}
{"method_name": "levinson_durbin", "full_method_name": "levinson_durbin", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/stattools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\ndef levinson_durbin(s, nlags=10, isacov=False):\n    \"\"\"\n    Levinson-Durbin recursion for autoregressive processes.\n\n    Parameters\n    ----------\n    s : array_like\n        If isacov is False, then this is the time series. If iasacov is true\n        then this is interpreted as autocovariance starting with lag 0.\n    nlags : int, optional\n        The largest lag to include in recursion or order of the autoregressive\n        process.\n    isacov : bool, optional\n        Flag indicating whether the first argument, s, contains the\n        autocovariances or the data series.\n\n    Returns\n    -------\n    sigma_v : float\n        The estimate of the error variance.\n    arcoefs : ndarray\n        The estimate of the autoregressive coefficients for a model including\n        nlags.\n    pacf : ndarray\n        The partial autocorrelation function.\n    sigma : ndarray\n        The entire sigma array from intermediate result, last value is sigma_v.\n    phi : ndarray\n        The entire phi array from intermediate result, last column contains\n        autoregressive coefficients for AR(nlags).\n\n    Notes\n    -----\n    This function returns currently all results, but maybe we drop sigma and\n    phi from the returns.\n\n    If this function is called with the time series (isacov=False), then the\n    sample autocovariance function is calculated with the default options\n    (biased, no fft).\n    \"\"\"\n    s = array_like(s, 's')\n    nlags = int_like(nlags, 'nlags')\n    isacov = bool_like(isacov, 'isacov')\n    order = nlags\n    if isacov:\n        sxx_m = s\n    else:\n        sxx_m = acovf(s, fft=False)[:order + 1]\n    phi = np.zeros((order + 1, order + 1), 'd')\n    sig = np.zeros(order + 1)\n    phi[1, 1] = sxx_m[1] / sxx_m[0]\n    sig[1] = sxx_m[0] - phi[1, 1] * sxx_m[1]\n    for k in range(2, order + 1):\n        phi[k, k] = (sxx_m[k] - np.dot(phi[1:k, k - 1], sxx_m[1:k][::-1])\n            ) / sig[k - 1]\n        for j in range(1, k):\n            phi[j, k] = phi[j, k - 1] - phi[k, k] * phi[k - j, k - 1]\n        sig[k] = sig[k - 1] * (1 - phi[k, k] ** 2)\n    sigma_v = sig[-1]\n    arcoefs = phi[1:, -1]\n    pacf_ = np.diag(phi).copy()\n    pacf_[0] = 1.0\n    return sigma_v, arcoefs, pacf_, sig, phi", "test_code_list": [{"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_levinson_durbin_acov():\n    rho = 0.9\n    m = 20\n    acov = rho ** np.arange(200)\n    sigma2_eps, ar, pacf, _, _ = levinson_durbin(acov, m, isacov=True)\n    assert_allclose(sigma2_eps, 1 - rho ** 2)\n    assert_allclose(ar, np.array([rho] + [0] * (m - 1)), atol=1e-08)\n    assert_allclose(pacf, np.array([1, rho] + [0] * (m - 1)), atol=1e-08)\n\ntest_levinson_durbin_acov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}, {"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_pacf2acf_levinson_durbin():\n    pacf = -0.9 ** np.arange(11.0)\n    pacf[0] = 1\n    ar, acf = levinson_durbin_pacf(pacf)\n    _, ar_ld, pacf_ld, _, _ = levinson_durbin(acf, 10, isacov=True)\n    assert_allclose(ar, ar_ld, atol=1e-08)\n    assert_allclose(pacf, pacf_ld, atol=1e-08)\n    ar_from_r = [-4.1609, -9.2549, -14.4826, -17.6505, -17.5012, -14.2969, \n        -9.502, -4.9184, -1.7911, -0.3486]\n    assert_allclose(ar, ar_from_r, atol=0.0001)\n\ntest_pacf2acf_levinson_durbin()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}], "instruction": "Functionality: The levinson_durbin function implements the Levinson-Durbin recursion algorithm which is used for estimating parameters of an autoregressive (AR) process. This function is particularly useful in time series analysis for calculating the error variance, autoregressive coefficients, partial autocorrelation function, and intermediate results of the recursion.\n\nInputs: \n- s: Array-like input. If isacov is False, this represents the time series data. If isacov is True, this is interpreted as the autocovariance sequence starting with lag 0.\n- nlags: Integer, optional. This specifies the largest lag to include in the recursion or the order of the autoregressive process. Default is 10.\n- isacov: Boolean, optional. This flag indicates whether the first argument, s, contains the autocovariances (True) or the data series (False). Default is False.\n\nOutputs:\n- sigma_v: A float representing the estimate of the error variance.\n- arcoefs: A 1D ndarray containing the estimate of the autoregressive coefficients for a model that includes nlags.\n- pacf: A 1D ndarray representing the partial autocorrelation function.\n- sigma: A 1D ndarray containing the entire sigma array from intermediate results, where the last value is sigma_v.\n- phi: A 2D ndarray containing the entire phi array from intermediate results, where the last column contains the autoregressive coefficients for AR(nlags).\n  \nNotes: When called with a time series (isacov=False), the function calculates the sample autocovariance function with default options (biased, no fft). The function currently returns all results, but it might be simplified to drop sigma and phi from the returns in future implementations.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\n\n\ndef levinson_durbin(s, nlags=10, isacov=False): [MASK]\n"}
{"method_name": "levinson_durbin_pacf", "full_method_name": "levinson_durbin_pacf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/stattools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\ndef levinson_durbin_pacf(pacf, nlags=None):\n    \"\"\"\n    Levinson-Durbin algorithm that returns the acf and ar coefficients.\n\n    Parameters\n    ----------\n    pacf : array_like\n        Partial autocorrelation array for lags 0, 1, ... p.\n    nlags : int, optional\n        Number of lags in the AR model.  If omitted, returns coefficients from\n        an AR(p) and the first p autocorrelations.\n\n    Returns\n    -------\n    arcoefs : ndarray\n        AR coefficients computed from the partial autocorrelations.\n    acf : ndarray\n        The acf computed from the partial autocorrelations. Array returned\n        contains the autocorrelations corresponding to lags 0, 1, ..., p.\n\n    References\n    ----------\n    .. [1] Brockwell, P.J. and Davis, R.A., 2016. Introduction to time series\n        and forecasting. Springer.\n    \"\"\"\n    pacf = array_like(pacf, 'pacf')\n    nlags = int_like(nlags, 'nlags', optional=True)\n    pacf = np.squeeze(np.asarray(pacf))\n    if pacf[0] != 1:\n        raise ValueError(\n            'The first entry of the pacf corresponds to lags 0 and so must be 1.'\n            )\n    pacf = pacf[1:]\n    n = pacf.shape[0]\n    if nlags is not None:\n        if nlags > n:\n            raise ValueError(\n                'Must provide at least as many values from the pacf as the number of lags.'\n                )\n        pacf = pacf[:nlags]\n        n = pacf.shape[0]\n    acf = np.zeros(n + 1)\n    acf[1] = pacf[0]\n    nu = np.cumprod(1 - pacf ** 2)\n    arcoefs = pacf.copy()\n    for i in range(1, n):\n        prev = arcoefs[:-(n - i)].copy()\n        arcoefs[:-(n - i)] = prev - arcoefs[i] * prev[::-1]\n        acf[i + 1] = arcoefs[i] * nu[i - 1] + prev.dot(acf[1:-(n - i)][::-1])\n    acf[0] = 1\n    return arcoefs, acf", "test_code_list": [{"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_pacf2acf_ar():\n    pacf = np.zeros(10)\n    pacf[0] = 1\n    pacf[1] = 0.9\n    ar, acf = levinson_durbin_pacf(pacf)\n    assert_allclose(acf, 0.9 ** np.arange(10.0))\n    assert_allclose(ar, pacf[1:], atol=1e-08)\n    ar, acf = levinson_durbin_pacf(pacf, nlags=5)\n    assert_allclose(acf, 0.9 ** np.arange(6.0))\n    assert_allclose(ar, pacf[1:6], atol=1e-08)\n\ntest_pacf2acf_ar()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}, {"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_pacf2acf_levinson_durbin():\n    pacf = -0.9 ** np.arange(11.0)\n    pacf[0] = 1\n    ar, acf = levinson_durbin_pacf(pacf)\n    _, ar_ld, pacf_ld, _, _ = levinson_durbin(acf, 10, isacov=True)\n    assert_allclose(ar, ar_ld, atol=1e-08)\n    assert_allclose(pacf, pacf_ld, atol=1e-08)\n    ar_from_r = [-4.1609, -9.2549, -14.4826, -17.6505, -17.5012, -14.2969, \n        -9.502, -4.9184, -1.7911, -0.3486]\n    assert_allclose(ar, ar_from_r, atol=0.0001)\n\ntest_pacf2acf_levinson_durbin()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}], "instruction": "Functionality: The levinson_durbin_pacf function implements the Levinson-Durbin algorithm to compute the autocorrelation function (ACF) and autoregressive (AR) coefficients from the given partial autocorrelation function (PACF) values. This is particularly useful in time series analysis for identifying the order of an AR model and estimating its coefficients.\n\nInputs:\npacf : array_like\n    An array representing the partial autocorrelation function for lags 0, 1, ..., p. The first element must correspond to lag 0 and should be 1.\n\nnlags : int, optional (default is None)\n    The number of lags in the AR model. If not provided, the function will return coefficients for an AR(p) model corresponding to the length of the pacf array minus one, and the autocorrelations for these lags.\n\nOutputs:\narcoefs : ndarray\n    An array of autoregressive coefficients computed from the partial autocorrelations. These coefficients can be used to define an AR model.\n\nacf : ndarray\n    An array containing the autocorrelation function. The autocorrelations are computed for lags 0, 1, ..., p, where p is determined by the nlags parameter or the length of the pacf array minus one.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\n\n\ndef levinson_durbin_pacf(pacf, nlags=None): [MASK]\n"}
{"method_name": "pacf_burg", "full_method_name": "pacf_burg", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/stattools.py", "method_code": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\ndef pacf_burg(x: ArrayLike1D, nlags: (int | None)=None, demean: bool=True\n    ) ->tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate Burg\"s partial autocorrelation estimator.\n\n    Parameters\n    ----------\n    x : array_like\n        Observations of time series for which pacf is calculated.\n    nlags : int, optional\n        Number of lags to return autocorrelation for. If not provided,\n        uses min(10 * np.log10(nobs), nobs - 1).\n    demean : bool, optional\n        Flag indicating to demean that data. Set to False if x has been\n        previously demeaned.\n\n    Returns\n    -------\n    pacf : ndarray\n        Partial autocorrelations for lags 0, 1, ..., nlag.\n    sigma2 : ndarray\n        Residual variance estimates where the value in position m is the\n        residual variance in an AR model that includes m lags.\n\n    See Also\n    --------\n    statsmodels.tsa.stattools.pacf\n        Partial autocorrelation estimation.\n    statsmodels.tsa.stattools.pacf_yw\n         Partial autocorrelation estimation using Yule-Walker.\n    statsmodels.tsa.stattools.pacf_ols\n        Partial autocorrelation estimation using OLS.\n\n    References\n    ----------\n    .. [1] Brockwell, P.J. and Davis, R.A., 2016. Introduction to time series\n        and forecasting. Springer.\n    \"\"\"\n    x = array_like(x, 'x')\n    if demean:\n        x = x - x.mean()\n    nobs = x.shape[0]\n    p = nlags if nlags is not None else min(int(10 * np.log10(nobs)), nobs - 1)\n    p = max(p, 1)\n    if p > nobs - 1:\n        raise ValueError('nlags must be smaller than nobs - 1')\n    d = np.zeros(p + 1)\n    d[0] = 2 * x.dot(x)\n    pacf = np.zeros(p + 1)\n    u = x[::-1].copy()\n    v = x[::-1].copy()\n    d[1] = u[:-1].dot(u[:-1]) + v[1:].dot(v[1:])\n    pacf[1] = 2 / d[1] * v[1:].dot(u[:-1])\n    last_u = np.empty_like(u)\n    last_v = np.empty_like(v)\n    for i in range(1, p):\n        last_u[:] = u\n        last_v[:] = v\n        u[1:] = last_u[:-1] - pacf[i] * last_v[1:]\n        v[1:] = last_v[1:] - pacf[i] * last_u[:-1]\n        d[i + 1] = (1 - pacf[i] ** 2) * d[i] - v[i] ** 2 - u[-1] ** 2\n        pacf[i + 1] = 2 / d[i + 1] * v[i + 1:].dot(u[i:-1])\n    sigma2 = (1 - pacf ** 2) * d / (2.0 * (nobs - np.arange(0, p + 1)))\n    pacf[0] = 1\n    return pacf, sigma2", "test_code_list": [{"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_pacf_burg():\n    rnd = np.random.RandomState(12345)\n    e = rnd.randn(10001)\n    y = e[1:] + 0.5 * e[:-1]\n    pacf, sigma2 = pacf_burg(y, 10)\n    yw_pacf = pacf_yw(y, 10)\n    assert_allclose(pacf, yw_pacf, atol=0.0005)\n    ye = y - y.mean()\n    s2y = ye.dot(ye) / 10000\n    pacf[0] = 0\n    sigma2_direct = s2y * np.cumprod(1 - pacf ** 2)\n    assert_allclose(sigma2, sigma2_direct, atol=0.001)\n\ntest_pacf_burg()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}], "instruction": "Functionality: The pacf_burg function calculates Burg's partial autocorrelation estimator for a given time series. It is used to estimate the partial autocorrelations for a specified number of lags and also computes the residual variance estimates for an autoregressive (AR) model that includes those lags.\n\nInputs:\n1. x: An array-like object containing observations of the time series for which the partial autocorrelation function is calculated.\n2. nlags: An optional integer argument specifying the number of lags to return autocorrelation for. If not provided, it defaults to the minimum of 10 times the logarithm (base 10) of the number of observations or the number of observations minus one.\n3. demean: An optional boolean argument indicating whether the data should be demeaned (centered) before calculating the partial autocorrelations. Set to False if x has already been demeaned.\n\nOutputs:\n1. pacf: A numpy array containing the partial autocorrelations for lags 0 through nlags.\n2. sigma2: A numpy array containing residual variance estimates, where the value in position m is the residual variance in an AR model that includes m lags.", "method_code_mask": "from __future__ import annotations\nfrom statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import deprecate_kwarg\nfrom statsmodels.compat.python import Literal\nfrom statsmodels.compat.python import lzip\nfrom statsmodels.compat.scipy import _next_regular\nfrom typing import Union\nimport warnings\nimport numpy as np\nfrom numpy.linalg import LinAlgError\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import correlate\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.regression.linear_model import yule_walker\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.tools import Bunch\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tools.validation import dict_like\nfrom statsmodels.tools.validation import float_like\nfrom statsmodels.tools.validation import int_like\nfrom statsmodels.tools.validation import string_like\nfrom statsmodels.tsa._bds import bds\nfrom statsmodels.tsa._innovations import innovations_algo\nfrom statsmodels.tsa._innovations import innovations_filter\nfrom statsmodels.tsa.adfvalues import mackinnoncrit\nfrom statsmodels.tsa.adfvalues import mackinnonp\nfrom statsmodels.tsa.tsatools import add_trend\nfrom statsmodels.tsa.tsatools import lagmat\nfrom statsmodels.tsa.tsatools import lagmat2ds\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom scipy.stats import f\nfrom scipy.stats import chi2\nfrom statsmodels.tsa.arima.model import ARIMA\n\n\ndef pacf_burg(x: ArrayLike1D, nlags: (int | None)=None, demean: bool=True\n    ) ->tuple[np.ndarray, np.ndarray]: [MASK]\n"}
{"method_name": "arma_acovf", "full_method_name": "arma_acovf", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima_process.py", "method_code": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\ndef arma_acovf(ar, ma, nobs=10, sigma2=1, dtype=None):\n    \"\"\"\n    Theoretical autocovariances of stationary ARMA processes\n\n    Parameters\n    ----------\n    ar : array_like, 1d\n        The coefficients for autoregressive lag polynomial, including zero lag.\n    ma : array_like, 1d\n        The coefficients for moving-average lag polynomial, including zero lag.\n    nobs : int\n        The number of terms (lags plus zero lag) to include in returned acovf.\n    sigma2 : float\n        Variance of the innovation term.\n\n    Returns\n    -------\n    ndarray\n        The autocovariance of ARMA process given by ar, ma.\n\n    See Also\n    --------\n    arma_acf : Autocorrelation function for ARMA processes.\n    acovf : Sample autocovariance estimation.\n\n    References\n    ----------\n    .. [*] Brockwell, Peter J., and Richard A. Davis. 2009. Time Series:\n        Theory and Methods. 2nd ed. 1991. New York, NY: Springer.\n    \"\"\"\n    if dtype is None:\n        dtype = np.common_type(np.array(ar), np.array(ma), np.array(sigma2))\n    p = len(ar) - 1\n    q = len(ma) - 1\n    m = max(p, q) + 1\n    if sigma2.real < 0:\n        raise ValueError('Must have positive innovation variance.')\n    if p == q == 0:\n        out = np.zeros(nobs, dtype=dtype)\n        out[0] = sigma2\n        return out\n    elif p > 0 and np.max(np.abs(np.roots(ar))) >= 1:\n        raise ValueError(NONSTATIONARY_ERROR)\n    ma_coeffs = arma2ma(ar, ma, lags=m)\n    A = np.zeros((m, m), dtype=dtype)\n    b = np.zeros((m, 1), dtype=dtype)\n    tmp_ar = np.zeros(m, dtype=dtype)\n    tmp_ar[:p + 1] = ar\n    for k in range(m):\n        A[k, :k + 1] = tmp_ar[:k + 1][::-1]\n        A[k, 1:m - k] += tmp_ar[k + 1:m]\n        b[k] = sigma2 * np.dot(ma[k:q + 1], ma_coeffs[:max(q + 1 - k, 0)])\n    acovf = np.zeros(max(nobs, m), dtype=dtype)\n    try:\n        acovf[:m] = np.linalg.solve(A, b)[:, 0]\n    except np.linalg.LinAlgError:\n        raise ValueError(NONSTATIONARY_ERROR)\n    if nobs > m:\n        zi = signal.lfiltic([1], ar, acovf[:m][::-1])\n        acovf[m:] = signal.lfilter([1], ar, np.zeros(nobs - m, dtype=dtype),\n            zi=zi)[0]\n    return acovf[:nobs]", "test_code_list": [{"test_code": "from statsmodels.compat.numpy import lstsq\nfrom statsmodels.compat.pandas import assert_index_equal\nfrom statsmodels.compat.platform import PLATFORM_WIN\nfrom statsmodels.compat.python import lrange\nimport os\nimport warnings\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nimport pytest\nfrom scipy import stats\nfrom scipy.interpolate import interp1d\nfrom statsmodels.datasets import macrodata\nfrom statsmodels.datasets import modechoice\nfrom statsmodels.datasets import nile\nfrom statsmodels.datasets import randhie\nfrom statsmodels.datasets import sunspots\nfrom statsmodels.tools.sm_exceptions import CollinearityWarning\nfrom statsmodels.tools.sm_exceptions import InfeasibleTestError\nfrom statsmodels.tools.sm_exceptions import InterpolationWarning\nfrom statsmodels.tools.sm_exceptions import MissingDataError\nfrom statsmodels.tools.sm_exceptions import ValueWarning\nfrom statsmodels.tools.validation import array_like\nfrom statsmodels.tools.validation import bool_like\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.stattools import acf\nfrom statsmodels.tsa.stattools import acovf\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import arma_order_select_ic\nfrom statsmodels.tsa.stattools import breakvar_heteroskedasticity_test\nfrom statsmodels.tsa.stattools import ccf\nfrom statsmodels.tsa.stattools import ccovf\nfrom statsmodels.tsa.stattools import coint\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.stattools import innovations_algo\nfrom statsmodels.tsa.stattools import innovations_filter\nfrom statsmodels.tsa.stattools import kpss\nfrom statsmodels.tsa.stattools import levinson_durbin\nfrom statsmodels.tsa.stattools import levinson_durbin_pacf\nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.stattools import pacf_burg\nfrom statsmodels.tsa.stattools import pacf_ols\nfrom statsmodels.tsa.stattools import pacf_yw\nfrom statsmodels.tsa.stattools import range_unit_root_test\nfrom statsmodels.tsa.stattools import zivot_andrews\nfrom scipy.stats import chi2\nfrom scipy.stats import f\nfrom statsmodels.stats.diagnostic import ResultsStore\nfrom statsmodels.tsa.arima_process import arma_generate_sample\ndef test_innovations_algo_filter_kalman_filter():\n    ar_params = np.array([0.5])\n    ma_params = np.array([0.2])\n    sigma2 = 1\n    endog = np.random.normal(size=10)\n    acovf = arma_acovf(np.r_[1, -ar_params], np.r_[1, ma_params], nobs=len(\n        endog))\n    theta, v = innovations_algo(acovf)\n    u = innovations_filter(endog, theta)\n    llf_obs = -0.5 * u ** 2 / (sigma2 * v) - 0.5 * np.log(2 * np.pi * v)\n    mod = SARIMAX(endog, order=(len(ar_params), 0, len(ma_params)))\n    res = mod.filter(np.r_[ar_params, ma_params, sigma2])\n    atol = 1e-06 if PLATFORM_WIN else 0.0\n    assert_allclose(u, res.forecasts_error[0], rtol=1e-06, atol=atol)\n    assert_allclose(theta[1:, 0], res.filter_results.kalman_gain[0, 0, :-1],\n        atol=atol)\n    assert_allclose(llf_obs, res.llf_obs, atol=atol)\n\ntest_innovations_algo_filter_kalman_filter()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_stattools.py"}, {"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_arma_acovf():\n    N = 20\n    phi = 0.9\n    sigma = 1\n    rep1 = arma_acovf([1, -phi], [1], N)\n    rep2 = [(1.0 * sigma * phi ** i / (1 - phi ** 2)) for i in range(N)]\n    assert_allclose(rep1, rep2)\n\ntest_arma_acovf()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}, {"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_arma_acov_compare_theoretical_arma_acov():\n\n    def arma_acovf_historical(ar, ma, nobs=10):\n        if np.abs(np.sum(ar) - 1) > 0.9:\n            nobs_ir = max(1000, 2 * nobs)\n        else:\n            nobs_ir = max(100, 2 * nobs)\n        ir = arma_impulse_response(ar, ma, leads=nobs_ir)\n        while ir[-1] > 5 * 1e-05:\n            nobs_ir *= 10\n            ir = arma_impulse_response(ar, ma, leads=nobs_ir)\n        if nobs_ir > 50000 and nobs < 1001:\n            end = len(ir)\n            acovf = np.array([np.dot(ir[:end - nobs - t], ir[t:end - nobs]) for\n                t in range(nobs)])\n        else:\n            acovf = np.correlate(ir, ir, 'full')[len(ir) - 1:]\n        return acovf[:nobs]\n    assert_allclose(arma_acovf([1, -0.5], [1, 0.2]), arma_acovf_historical(\n        [1, -0.5], [1, 0.2]))\n    assert_allclose(arma_acovf([1, -0.99], [1, 0.2]), arma_acovf_historical\n        ([1, -0.99], [1, 0.2]))\n\ntest_arma_acov_compare_theoretical_arma_acov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.innovations import _arma_innovations\nfrom statsmodels.tsa.innovations import arma_innovations\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_brockwell_davis_ex533():\n    nobs = 10\n    ar_params = np.array([0.2])\n    ma_params = np.array([0.4])\n    sigma2 = 8.92\n    p = len(ar_params)\n    q = len(ma_params)\n    m = max(p, q)\n    ar = np.r_[1, -ar_params]\n    ma = np.r_[1, ma_params]\n    arma_process_acovf = arma_acovf(ar, ma, nobs=nobs, sigma2=sigma2)\n    unconditional_variance = sigma2 * (1 + 2 * ar_params[0] * ma_params[0] +\n        ma_params[0] ** 2) / (1 - ar_params[0] ** 2)\n    assert_allclose(arma_process_acovf[0], unconditional_variance)\n    arma_process_acovf /= sigma2\n    unconditional_variance /= sigma2\n    transformed_acovf = _arma_innovations.darma_transformed_acovf_fast(ar,\n        ma, arma_process_acovf)\n    acovf, acovf2 = (np.array(arr) for arr in transformed_acovf)\n    assert_equal(acovf2.shape, (nobs - m,))\n    assert_allclose(acovf2[0], 1 + ma_params[0] ** 2)\n    assert_allclose(acovf2[1], ma_params[0])\n    assert_allclose(acovf2[2:], 0)\n    assert_equal(acovf.shape, (m * 2, m * 2))\n    ix = np.diag_indices_from(acovf)\n    ix_lower = ix[0][:-1] + 1, ix[1][:-1]\n    assert_allclose(acovf[ix][:m], unconditional_variance)\n    assert_allclose(acovf[ix_lower][:m], ma_params[0])\n    out = _arma_innovations.darma_innovations_algo_fast(nobs, ar_params,\n        ma_params, acovf, acovf2)\n    theta = np.array(out[0])\n    v = np.array(out[1])\n    desired_v = np.zeros(nobs)\n    desired_v[0] = unconditional_variance\n    for i in range(1, nobs):\n        desired_v[i] = 1 + (1 - 1 / desired_v[i - 1]) * ma_params[0] ** 2\n    assert_allclose(v, desired_v)\n    assert_equal(theta.shape, (nobs, m + 1))\n    desired_theta = np.zeros(nobs)\n    for i in range(1, nobs):\n        desired_theta[i] = ma_params[0] / desired_v[i - 1]\n    assert_allclose(theta[:, 0], desired_theta)\n    assert_allclose(theta[:, 1:], 0)\n    endog = np.array([-1.1, 0.514, 0.116, -0.845, 0.872, -0.467, -0.977, -\n        1.699, -1.228, -1.093])\n    u = _arma_innovations.darma_innovations_filter(endog, ar_params,\n        ma_params, theta)\n    desired_hat = np.array([0, -0.54, 0.5068, -0.1321, -0.4539, 0.7046, -\n        0.562, -0.3614, -0.8748, -0.3869])\n    desired_u = endog - desired_hat\n    assert_allclose(u, desired_u, atol=0.0001)\n\ntest_brockwell_davis_ex533()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/innovations/tests/test_cython_arma_innovations_fast.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_allclose\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.innovations import _arma_innovations\nfrom statsmodels.tsa.innovations import arma_innovations\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\ndef test_brockwell_davis_ex534():\n    nobs = 10\n    ar_params = np.array([1, -0.24])\n    ma_params = np.array([0.4, 0.2, 0.1])\n    sigma2 = 1\n    p = len(ar_params)\n    q = len(ma_params)\n    m = max(p, q)\n    ar = np.r_[1, -ar_params]\n    ma = np.r_[1, ma_params]\n    arma_process_acovf = arma_acovf(ar, ma, nobs=nobs, sigma2=sigma2)\n    assert_allclose(arma_process_acovf[:3], [7.17133, 6.44139, 5.06027],\n        atol=1e-05)\n    transformed_acovf = _arma_innovations.darma_transformed_acovf_fast(ar,\n        ma, arma_process_acovf)\n    acovf, acovf2 = (np.array(arr) for arr in transformed_acovf)\n    assert_equal(acovf.shape, (m * 2, m * 2))\n    ix = np.diag_indices_from(acovf)\n    ix_lower1 = ix[0][:-1] + 1, ix[1][:-1]\n    ix_lower2 = ix[0][:-2] + 2, ix[1][:-2]\n    ix_lower3 = ix[0][:-3] + 3, ix[1][:-3]\n    ix_lower4 = ix[0][:-4] + 4, ix[1][:-4]\n    assert_allclose(acovf[ix][:m], 7.17133, atol=1e-05)\n    desired = [6.44139, 6.44139, 0.816]\n    assert_allclose(acovf[ix_lower1][:m], desired, atol=1e-05)\n    assert_allclose(acovf[ix_lower2][0], 5.06027, atol=1e-05)\n    assert_allclose(acovf[ix_lower2][1:m], 0.34, atol=1e-05)\n    assert_allclose(acovf[ix_lower3][:m], 0.1, atol=1e-05)\n    assert_allclose(acovf[ix_lower4][:m], 0, atol=1e-05)\n    assert_equal(acovf2.shape, (nobs - m,))\n    assert_allclose(acovf2[:4], [1.21, 0.5, 0.24, 0.1])\n    assert_allclose(acovf2[4:], 0)\n    out = _arma_innovations.darma_innovations_algo_fast(nobs, ar_params,\n        ma_params, acovf, acovf2)\n    theta = np.array(out[0])\n    v = np.array(out[1])\n    desired_v = [7.1713, 1.3856, 1.0057, 1.0019, 1.0016, 1.0005, 1.0, 1.0, \n        1.0, 1.0]\n    assert_allclose(v, desired_v, atol=0.0001)\n    assert_equal(theta.shape, (nobs, m + 1))\n    desired_theta = np.array([[0, 0.8982, 1.3685, 0.4008, 0.3998, 0.3992, \n        0.4, 0.4, 0.4, 0.4], [0, 0, 0.7056, 0.1806, 0.202, 0.1995, 0.1997, \n        0.2, 0.2, 0.2], [0, 0, 0, 0.0139, 0.0722, 0.0994, 0.0998, 0.0998, \n        0.0999, 0.1]]).T\n    assert_allclose(theta[:, :m], desired_theta, atol=0.0001)\n    assert_allclose(theta[:, m:], 0)\n    endog = np.array([1.704, 0.527, 1.041, 0.942, 0.555, -1.002, -0.585, \n        0.01, -0.638, 0.525])\n    u = _arma_innovations.darma_innovations_filter(endog, ar_params,\n        ma_params, theta)\n    desired_hat = np.array([0, 1.5305, -0.171, 1.2428, 0.7443, 0.3138, -\n        1.7293, -0.1688, 0.3193, -0.8731])\n    desired_u = endog - desired_hat\n    assert_allclose(u, desired_u, atol=0.0001)\n\ntest_brockwell_davis_ex534()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/innovations/tests/test_cython_arma_innovations_fast.py"}], "instruction": "Functionality: The arma_acovf function calculates the theoretical autocovariances of a stationary ARMA (Autoregressive Moving Average) process for a given number of terms. It solves the Yule-Walker equations to determine the autocovariance function, which is essential for understanding the dynamics of time series data.\n\nInputs: \n- ar: array_like, 1d - The coefficients for the autoregressive lag polynomial, including the zero lag coefficient.\n- ma: array_like, 1d - The coefficients for the moving-average lag polynomial, including the zero lag coefficient.\n- nobs: int (default: 10) - The number of terms (lags plus zero lag) to include in the returned autocovariance function.\n- sigma2: float (default: 1) - The variance of the innovation term (white noise).\n\nOutputs: \n- ndarray - The autocovariance function of the ARMA process specified by the input parameters. This array contains nobs elements, representing the autocovariance at lags 0 to nobs-1.\n\nNote: The function checks for the stationarity of the ARMA process and raises an error if the process is determined to be non-stationary or if the innovation variance is negative. If the ARMA process is trivial (neither AR nor MA components), it returns an array with the variance of the innovation term at the zero lag position and zeros elsewhere.", "method_code_mask": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\n\n\ndef arma_acovf(ar, ma, nobs=10, sigma2=1, dtype=None): [MASK]\n"}
{"method_name": "arma_impulse_response", "full_method_name": "arma_impulse_response", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima_process.py", "method_code": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\ndef arma_impulse_response(ar, ma, leads=100):\n    \"\"\"\n    Compute the impulse response function (MA representation) for ARMA process.\n\n    Parameters\n    ----------\n    ar : array_like, 1d\n        The auto regressive lag polynomial.\n    ma : array_like, 1d\n        The moving average lag polynomial.\n    leads : int\n        The number of observations to calculate.\n\n    Returns\n    -------\n    ndarray\n        The impulse response function with nobs elements.\n\n    Notes\n    -----\n    This is the same as finding the MA representation of an ARMA(p,q).\n    By reversing the role of ar and ma in the function arguments, the\n    returned result is the AR representation of an ARMA(p,q), i.e\n\n    ma_representation = arma_impulse_response(ar, ma, leads=100)\n    ar_representation = arma_impulse_response(ma, ar, leads=100)\n\n    Fully tested against matlab\n\n    Examples\n    --------\n    AR(1)\n\n    >>> arma_impulse_response([1.0, -0.8], [1.], leads=10)\n    array([ 1.        ,  0.8       ,  0.64      ,  0.512     ,  0.4096    ,\n            0.32768   ,  0.262144  ,  0.2097152 ,  0.16777216,  0.13421773])\n\n    this is the same as\n\n    >>> 0.8**np.arange(10)\n    array([ 1.        ,  0.8       ,  0.64      ,  0.512     ,  0.4096    ,\n            0.32768   ,  0.262144  ,  0.2097152 ,  0.16777216,  0.13421773])\n\n    MA(2)\n\n    >>> arma_impulse_response([1.0], [1., 0.5, 0.2], leads=10)\n    array([ 1. ,  0.5,  0.2,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ])\n\n    ARMA(1,2)\n\n    >>> arma_impulse_response([1.0, -0.8], [1., 0.5, 0.2], leads=10)\n    array([ 1.        ,  1.3       ,  1.24      ,  0.992     ,  0.7936    ,\n            0.63488   ,  0.507904  ,  0.4063232 ,  0.32505856,  0.26004685])\n    \"\"\"\n    impulse = np.zeros(leads)\n    impulse[0] = 1.0\n    return signal.lfilter(ma, ar, impulse)", "test_code_list": [{"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_arma_acov_compare_theoretical_arma_acov():\n\n    def arma_acovf_historical(ar, ma, nobs=10):\n        if np.abs(np.sum(ar) - 1) > 0.9:\n            nobs_ir = max(1000, 2 * nobs)\n        else:\n            nobs_ir = max(100, 2 * nobs)\n        ir = arma_impulse_response(ar, ma, leads=nobs_ir)\n        while ir[-1] > 5 * 1e-05:\n            nobs_ir *= 10\n            ir = arma_impulse_response(ar, ma, leads=nobs_ir)\n        if nobs_ir > 50000 and nobs < 1001:\n            end = len(ir)\n            acovf = np.array([np.dot(ir[:end - nobs - t], ir[t:end - nobs]) for\n                t in range(nobs)])\n        else:\n            acovf = np.correlate(ir, ir, 'full')[len(ir) - 1:]\n        return acovf[:nobs]\n    assert_allclose(arma_acovf([1, -0.5], [1, 0.2]), arma_acovf_historical(\n        [1, -0.5], [1, 0.2]))\n    assert_allclose(arma_acovf([1, -0.99], [1, 0.2]), arma_acovf_historical\n        ([1, -0.99], [1, 0.2]))\n\ntest_arma_acov_compare_theoretical_arma_acov()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}, {"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_fi():\n    n = 100\n    mafromar = arma_impulse_response(lpol_fiar(0.4, n=n), [1], n)\n    assert_array_almost_equal(mafromar, lpol_fima(0.4, n=n), 13)\n\ntest_fi()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}, {"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_arma_impulse_response():\n    arrep = arma_impulse_response(armarep.ma, armarep.ar, leads=21)[1:]\n    marep = arma_impulse_response(armarep.ar, armarep.ma, leads=21)[1:]\n    assert_array_almost_equal(armarep.marep.ravel(), marep, 14)\n    assert_array_almost_equal(-armarep.arrep.ravel(), arrep, 14)\n\ntest_arma_impulse_response()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}], "instruction": "Functionality: Compute the impulse response function (MA representation) for an ARMA process. This function calculates the response of the system to an impulse, which is equivalent to finding the MA representation of an ARMA(p,q) process or the AR representation when reversing the role of AR and MA components.\n\nInputs:\n- ar: array_like, 1d - The auto regressive lag polynomial coefficients.\n- ma: array_like, 1d - The moving average lag polynomial coefficients.\n- leads: int - The number of observations to calculate for the impulse response function.\n\nOutputs:\n- ndarray: The impulse response function with 'leads' elements, representing the system's response over time to an initial impulse.", "method_code_mask": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\n\n\ndef arma_impulse_response(ar, ma, leads=100): [MASK]\n"}
{"method_name": "lpol_fima", "full_method_name": "lpol_fima", "method_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/arima_process.py", "method_code": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\ndef lpol_fima(d, n=20):\n    \"\"\"MA representation of fractional integration\n\n    .. math:: (1-L)^{-d} for |d|<0.5  or |d|<1 (?)\n\n    Parameters\n    ----------\n    d : float\n        fractional power\n    n : int\n        number of terms to calculate, including lag zero\n\n    Returns\n    -------\n    ma : ndarray\n        coefficients of lag polynomial\n    \"\"\"\n    from scipy.special import gammaln\n    j = np.arange(n)\n    return np.exp(gammaln(d + j) - gammaln(j + 1) - gammaln(d))", "test_code_list": [{"test_code": "import datetime as dt\nimport numpy as np\nfrom numpy.testing import assert_\nfrom numpy.testing import assert_allclose\nfrom numpy.testing import assert_almost_equal\nfrom numpy.testing import assert_array_almost_equal\nfrom numpy.testing import assert_equal\nfrom numpy.testing import assert_raises\nimport pandas as pd\nimport pytest\nfrom statsmodels.sandbox.tsa.fftarma import ArmaFft\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_process import arma_acf\nfrom statsmodels.tsa.arima_process import arma_acovf\nfrom statsmodels.tsa.arima_process import arma_generate_sample\nfrom statsmodels.tsa.arima_process import arma_impulse_response\nfrom statsmodels.tsa.arima_process import index2lpol\nfrom statsmodels.tsa.arima_process import lpol2index\nfrom statsmodels.tsa.arima_process import lpol_fiar\nfrom statsmodels.tsa.arima_process import lpol_fima\nfrom statsmodels.tsa.tests.results import results_arma_acf\nfrom statsmodels.tsa.tests.results.results_process import armarep\ndef test_fi():\n    n = 100\n    mafromar = arma_impulse_response(lpol_fiar(0.4, n=n), [1], n)\n    assert_array_almost_equal(mafromar, lpol_fima(0.4, n=n), 13)\n\ntest_fi()\n", "code_start": "", "test_path": "../srcdata/Computation/statsmodels/statsmodels/tsa/tests/test_arima_process.py"}], "instruction": "Functionality: The lpol_fima function computes the coefficients of the lag polynomial for the moving average (MA) representation of fractional integration. It calculates the coefficients for the expression (1-L)^{-d} for a given fractional power d and a specified number of terms n, including the lag zero term.\n\nInputs: \n- d: float - The fractional power for the integration. The absolute value of d should be less than 0.5 or 1, depending on the context.\n- n: int (optional) - The number of terms to calculate in the lag polynomial, including the lag zero term. The default value is 20.\n\nOutputs: \n- ma: ndarray - An array of coefficients for the lag polynomial, representing the MA representation of fractional integration for the given parameters.", "method_code_mask": "from statsmodels.compat.pandas import Appender\nimport warnings\nimport numpy as np\nfrom scipy import linalg\nfrom scipy import optimize\nfrom scipy import signal\nfrom statsmodels.tools.docstring import Docstring\nfrom statsmodels.tools.docstring import remove_parameters\nfrom statsmodels.tools.validation import array_like\nfrom scipy.special import gammaln\n\n\ndef lpol_fima(d, n=20): [MASK]\n"}
