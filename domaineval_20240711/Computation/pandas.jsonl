{"method_name": "maybe_mangle_lambdas", "full_method_name": "maybe_mangle_lambdas", "method_path": "../srcdata/Computation/pandas/pandas/core/apply.py", "method_code": "from __future__ import annotations\nimport abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nimport functools\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs.internals import BlockValuesRefs\nfrom pandas._typing import AggFuncType\nfrom pandas._typing import AggFuncTypeBase\nfrom pandas._typing import AggFuncTypeDict\nfrom pandas._typing import AggObjType\nfrom pandas._typing import Axis\nfrom pandas._typing import AxisInt\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import npt\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import SpecificationError\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.core.dtypes.cast import is_nested_object\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_sequence\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCNDFrame\nfrom pandas.core.dtypes.generic import ABCSeries\nimport pandas.core.common as com\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.util.numba_ import get_jit_arguments\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.groupby import GroupBy\nfrom pandas.core.resample import Resampler\nfrom pandas.core.window.rolling import BaseWindow\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.groupby.generic import DataFrameGroupBy\nfrom pandas.core.groupby.generic import SeriesGroupBy\nfrom pandas.core.indexes.base import Index\ndef maybe_mangle_lambdas(agg_spec: Any) ->Any:\n    \"\"\"\n    Make new lambdas with unique names.\n\n    Parameters\n    ----------\n    agg_spec : Any\n        An argument to GroupBy.agg.\n        Non-dict-like `agg_spec` are pass through as is.\n        For dict-like `agg_spec` a new spec is returned\n        with name-mangled lambdas.\n\n    Returns\n    -------\n    mangled : Any\n        Same type as the input.\n\n    Examples\n    --------\n    >>> maybe_mangle_lambdas(\"sum\")\n    'sum'\n    >>> maybe_mangle_lambdas([lambda: 1, lambda: 2])  # doctest: +SKIP\n    [<function __main__.<lambda_0>,\n     <function pandas...._make_lambda.<locals>.f(*args, **kwargs)>]\n    \"\"\"\n    is_dict = is_dict_like(agg_spec)\n    if not (is_dict or is_list_like(agg_spec)):\n        return agg_spec\n    mangled_aggspec = type(agg_spec)()\n    if is_dict:\n        for key, aggfuncs in agg_spec.items():\n            if is_list_like(aggfuncs) and not is_dict_like(aggfuncs):\n                mangled_aggfuncs = _managle_lambda_list(aggfuncs)\n            else:\n                mangled_aggfuncs = aggfuncs\n            mangled_aggspec[key] = mangled_aggfuncs\n    else:\n        mangled_aggspec = _managle_lambda_list(agg_spec)\n    return mangled_aggspec", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.apply import _make_unique_kwarg_list\nfrom pandas.core.apply import maybe_mangle_lambdas\ndef test_maybe_mangle_lambdas_passthrough():\n    assert maybe_mangle_lambdas('mean') == 'mean'\n    assert maybe_mangle_lambdas(lambda x: x).__name__ == '<lambda>'\n    assert maybe_mangle_lambdas([lambda x: x])[0].__name__ == '<lambda>'\n\ntest_maybe_mangle_lambdas_passthrough()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_aggregation.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.apply import _make_unique_kwarg_list\nfrom pandas.core.apply import maybe_mangle_lambdas\ndef test_maybe_mangle_lambdas_listlike():\n    aggfuncs = [lambda x: 1, lambda x: 2]\n    result = maybe_mangle_lambdas(aggfuncs)\n    assert result[0].__name__ == '<lambda_0>'\n    assert result[1].__name__ == '<lambda_1>'\n    assert aggfuncs[0](None) == result[0](None)\n    assert aggfuncs[1](None) == result[1](None)\n\ntest_maybe_mangle_lambdas_listlike()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_aggregation.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.apply import _make_unique_kwarg_list\nfrom pandas.core.apply import maybe_mangle_lambdas\ndef test_maybe_mangle_lambdas():\n    func = {'A': [lambda x: 0, lambda x: 1]}\n    result = maybe_mangle_lambdas(func)\n    assert result['A'][0].__name__ == '<lambda_0>'\n    assert result['A'][1].__name__ == '<lambda_1>'\n\ntest_maybe_mangle_lambdas()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_aggregation.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.apply import _make_unique_kwarg_list\nfrom pandas.core.apply import maybe_mangle_lambdas\ndef test_maybe_mangle_lambdas_args():\n    func = {'A': [lambda x, a, b=1: (0, a, b), lambda x: 1]}\n    result = maybe_mangle_lambdas(func)\n    assert result['A'][0].__name__ == '<lambda_0>'\n    assert result['A'][1].__name__ == '<lambda_1>'\n    assert func['A'][0](0, 1) == (0, 1, 1)\n    assert func['A'][0](0, 1, 2) == (0, 1, 2)\n    assert func['A'][0](0, 2, b=3) == (0, 2, 3)\n\ntest_maybe_mangle_lambdas_args()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_aggregation.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.apply import _make_unique_kwarg_list\nfrom pandas.core.apply import maybe_mangle_lambdas\ndef test_maybe_mangle_lambdas_named():\n    func = {'C': np.mean, 'D': {'foo': np.mean, 'bar': np.mean}}\n    result = maybe_mangle_lambdas(func)\n    assert result == func\n\ntest_maybe_mangle_lambdas_named()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_aggregation.py"}], "instruction": "Functionality: The maybe_mangle_lambdas function is designed to modify lambda functions within an agg_spec argument that is meant to be passed to the GroupBy.agg function. It ensures that each lambda function has a unique name, which is essential for pandas to process them correctly. The function supports both list-like and dict-like agg_spec inputs, where each element or value can be a lambda function. Non-dict-like agg_spec inputs are returned as is.\n\nInputs: \n- agg_spec: Any\n    This is the input argument that could be a list-like or dict-like object meant to be passed to the GroupBy.agg function. Elements in a list-like agg_spec or values in a dict-like agg_spec can be lambda functions, strings representing aggregation functions (e.g., 'sum'), or other callable objects.\n\nOutputs:\n- mangled: Any\n    This is the output of the function, which is the modified agg_spec input. If the input is not list-like or dict-like, it is returned unchanged. If the input is dict-like, the output is a new dict-like object with mangled (or uniquely-named) lambdas. If the input is list-like, the output is a new list-like object with mangled lambdas. The type of the output is the same as the type of the input.", "method_code_mask": "from __future__ import annotations\nimport abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nimport functools\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs.internals import BlockValuesRefs\nfrom pandas._typing import AggFuncType\nfrom pandas._typing import AggFuncTypeBase\nfrom pandas._typing import AggFuncTypeDict\nfrom pandas._typing import AggObjType\nfrom pandas._typing import Axis\nfrom pandas._typing import AxisInt\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import npt\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import SpecificationError\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.core.dtypes.cast import is_nested_object\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_sequence\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCNDFrame\nfrom pandas.core.dtypes.generic import ABCSeries\nimport pandas.core.common as com\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.util.numba_ import get_jit_arguments\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import MutableMapping\nfrom collections.abc import Sequence\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.groupby import GroupBy\nfrom pandas.core.resample import Resampler\nfrom pandas.core.window.rolling import BaseWindow\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.groupby.generic import DataFrameGroupBy\nfrom pandas.core.groupby.generic import SeriesGroupBy\nfrom pandas.core.indexes.base import Index\n\n\ndef maybe_mangle_lambdas(agg_spec: Any) ->Any: [MASK]\n"}
{"method_name": "option_context", "full_method_name": "option_context", "method_path": "../srcdata/Computation/pandas/pandas/_config/config.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\n@contextmanager\ndef option_context(*args) ->Generator[None, None, None]:\n    \"\"\"\n    Context manager to temporarily set options in a ``with`` statement.\n\n    Parameters\n    ----------\n    *args : str | object\n        An even amount of arguments provided in pairs which will be\n        interpreted as (pattern, value) pairs.\n\n    Returns\n    -------\n    None\n        No return value.\n\n    See Also\n    --------\n    get_option : Retrieve the value of the specified option.\n    set_option : Set the value of the specified option.\n    reset_option : Reset one or more options to their default value.\n    describe_option : Print the description for one or more registered options.\n\n    Notes\n    -----\n    For all available options, please view the :ref:`User Guide <options.available>`\n    or use ``pandas.describe_option()``.\n\n    Examples\n    --------\n    >>> from pandas import option_context\n    >>> with option_context(\"display.max_rows\", 10, \"display.max_columns\", 5):\n    ...     pass\n    \"\"\"\n    if len(args) % 2 != 0 or len(args) < 2:\n        raise ValueError(\n            'Provide an even amount of arguments as option_context(pat, val, pat, val...).'\n            )\n    ops = tuple(zip(args[::2], args[1::2]))\n    try:\n        undo = tuple((pat, get_option(pat)) for pat, val in ops)\n        for pat, val in ops:\n            set_option(pat, val)\n        yield\n    finally:\n        for pat, val in undo:\n            set_option(pat, val)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.errors import NumbaUtilError\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nimport numba\ndef test_use_global_config():\n    pytest.importorskip('numba')\n\n    def func_1(values, index):\n        return values + 1\n    data = DataFrame({(0): ['a', 'a', 'b', 'b', 'a'], (1): [1.0, 2.0, 3.0, \n        4.0, 5.0]}, columns=[0, 1])\n    grouped = data.groupby(0)\n    expected = grouped.transform(func_1, engine='numba')\n    with option_context('compute.use_numba', True):\n        result = grouped.transform(func_1, engine=None)\n    tm.assert_frame_equal(expected, result)\n\ntest_use_global_config()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/groupby/transform/test_numba.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.errors import NumbaUtilError\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import NamedAgg\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nimport numba\ndef test_use_global_config():\n    pytest.importorskip('numba')\n\n    def func_1(values, index):\n        return np.mean(values) - 3.4\n    data = DataFrame({(0): ['a', 'a', 'b', 'b', 'a'], (1): [1.0, 2.0, 3.0, \n        4.0, 5.0]}, columns=[0, 1])\n    grouped = data.groupby(0)\n    expected = grouped.agg(func_1, engine='numba')\n    with option_context('compute.use_numba', True):\n        result = grouped.agg(func_1, engine=None)\n    tm.assert_frame_equal(expected, result)\n\ntest_use_global_config()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/groupby/aggregate/test_numba.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.errors import NumbaUtilError\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas import to_datetime\nimport pandas._testing as tm\nimport numba\n@td.skip_if_no('numba')\ndef test_use_global_config():\n\n    def f(x):\n        return np.mean(x) + 2\n    s = Series(range(10))\n    with option_context('compute.use_numba', True):\n        result = s.rolling(2).apply(f, engine=None, raw=True)\n    expected = s.rolling(2).apply(f, engine='numba', raw=True)\n    tm.assert_series_equal(expected, result)\n\ntest_use_global_config()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/window/test_numba.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nfrom io import StringIO\nimport numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import option_context\nfrom pandas import period_range\nimport pandas._testing as tm\n\nclass TestDataFrameRepr():\n\tdef test_repr_dimensions(self):\n\t    df = DataFrame([[1, 2], [3, 4]])\n\t    with option_context('display.show_dimensions', True):\n\t        assert '2 rows x 2 columns' in repr(df)\n\t    with option_context('display.show_dimensions', False):\n\t        assert '2 rows x 2 columns' not in repr(df)\n\t    with option_context('display.show_dimensions', 'truncate'):\n\t        assert '2 rows x 2 columns' not in repr(df)\n\t\nTestDataFrameRepr().test_repr_dimensions()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/test_repr.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nfrom io import StringIO\nimport numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import option_context\nfrom pandas import period_range\nimport pandas._testing as tm\n\nclass TestDataFrameRepr():\n\tdef test_repr_column_name_unicode_truncation_bug(self):\n\t    df = DataFrame({'Id': [7117434], 'StringCol':\n\t        'Is it possible to modify drop plot codeso that the output graph is displayed in iphone simulator, Is it possible to modify drop plot code so that the output graph is \u00e2\\x80\u00a8displayed in iphone simulator.Now we are adding the CSV file externally. I want to Call the File through the code..'\n\t        })\n\t    with option_context('display.max_columns', 20):\n\t        assert 'StringCol' in repr(df)\n\t\nTestDataFrameRepr().test_repr_column_name_unicode_truncation_bug()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/test_repr.py"}, {"test_code": "from copy import deepcopy\nimport inspect\nimport pydoc\nimport numpy as np\nimport pytest\nfrom pandas._config.config import option_context\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import timedelta_range\nimport pandas._testing as tm\nfrom IPython.core.completer import provisionalcompleter\n\nclass TestDataFrameMisc():\n\tdef test_display_max_dir_items(self):\n\t    columns = [('a' + str(i)) for i in range(420)]\n\t    values = [range(420), range(420)]\n\t    df = DataFrame(values, columns=columns)\n\t    assert 'a99' in dir(df)\n\t    assert 'a100' not in dir(df)\n\t    with option_context('display.max_dir_items', 300):\n\t        df = DataFrame(values, columns=columns)\n\t        assert 'a299' in dir(df)\n\t        assert 'a300' not in dir(df)\n\t    with option_context('display.max_dir_items', None):\n\t        df = DataFrame(values, columns=columns)\n\t        assert 'a419' in dir(df)\n\t\nTestDataFrameMisc().test_display_max_dir_items()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/test_api.py"}, {"test_code": "from io import StringIO\nimport re\nfrom string import ascii_uppercase\nimport sys\nimport textwrap\nimport numpy as np\nimport pytest\nfrom pandas.compat import IS64\nfrom pandas.compat import PYPY\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import option_context\nimport pandas._testing as tm\ndef test_info_wide():\n    io = StringIO()\n    df = DataFrame(np.random.default_rng(2).standard_normal((5, 101)))\n    df.info(buf=io)\n    io = StringIO()\n    df.info(buf=io, max_cols=101)\n    result = io.getvalue()\n    assert len(result.splitlines()) > 100\n    expected = result\n    with option_context('display.max_info_columns', 101):\n        io = StringIO()\n        df.info(buf=io)\n        result = io.getvalue()\n        assert result == expected\n\ntest_info_wide()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/methods/test_info.py"}, {"test_code": "from io import StringIO\nimport re\nfrom string import ascii_uppercase\nimport sys\nimport textwrap\nimport numpy as np\nimport pytest\nfrom pandas.compat import IS64\nfrom pandas.compat import PYPY\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import option_context\nimport pandas._testing as tm\ndef test_info_max_cols():\n    df = DataFrame(np.random.default_rng(2).standard_normal((10, 5)))\n    for len_, verbose in [(5, None), (5, False), (12, True)]:\n        with option_context('max_info_columns', 4):\n            buf = StringIO()\n            df.info(buf=buf, verbose=verbose)\n            res = buf.getvalue()\n            assert len(res.strip().split('\\n')) == len_\n    for len_, verbose in [(12, None), (5, False), (12, True)]:\n        with option_context('max_info_columns', 5):\n            buf = StringIO()\n            df.info(buf=buf, verbose=verbose)\n            res = buf.getvalue()\n            assert len(res.strip().split('\\n')) == len_\n    for len_, max_cols in [(12, 5), (5, 4)]:\n        with option_context('max_info_columns', 4):\n            buf = StringIO()\n            df.info(buf=buf, max_cols=max_cols)\n            res = buf.getvalue()\n            assert len(res.strip().split('\\n')) == len_\n        with option_context('max_info_columns', 5):\n            buf = StringIO()\n            df.info(buf=buf, max_cols=max_cols)\n            res = buf.getvalue()\n            assert len(res.strip().split('\\n')) == len_\n\ntest_info_max_cols()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/methods/test_info.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import Categorical\nfrom pandas import CategoricalDtype\nfrom pandas import CategoricalIndex\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import option_context\nfrom pandas import period_range\nfrom pandas import timedelta_range\n\nclass TestCategoricalRepr():\n\tdef test_print_none_width(self):\n\t    a = Series(Categorical([1, 2, 3, 4]))\n\t    exp = (\n\t        '0    1\\n1    2\\n2    3\\n3    4\\ndtype: category\\nCategories (4, int64): [1, 2, 3, 4]'\n\t        )\n\t    with option_context('display.width', None):\n\t        assert exp == repr(a)\n\t\nTestCategoricalRepr().test_print_none_width()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/categorical/test_repr.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\ndef test_to_html_round_column_headers():\n    df = DataFrame([1], columns=[0.55555])\n    with option_context('display.precision', 3):\n        html = df.to_html(notebook=False)\n        notebook = df.to_html(notebook=True)\n    assert '0.55555' in html\n    assert '0.556' in notebook\n\ntest_to_html_round_column_headers()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_info_repr_html(self):\n\t    max_rows = 60\n\t    max_cols = 20\n\t    h, w = max_rows + 1, max_cols - 1\n\t    df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})\n\t    assert '&lt;class' not in df._repr_html_()\n\t    with option_context('display.large_repr', 'info'):\n\t        assert '&lt;class' in df._repr_html_()\n\t    h, w = max_rows - 1, max_cols + 1\n\t    df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})\n\t    assert '<class' not in df._repr_html_()\n\t    with option_context('display.large_repr', 'info', 'display.max_columns',\n\t        max_cols):\n\t        assert '&lt;class' in df._repr_html_()\n\t\nTestReprHTML().test_info_repr_html()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_mathjax(self):\n\t    df = DataFrame([[1, 2], [3, 4]])\n\t    assert 'tex2jax_ignore' not in df._repr_html_()\n\t    with option_context('display.html.use_mathjax', False):\n\t        assert 'tex2jax_ignore' in df._repr_html_()\n\t\nTestReprHTML().test_repr_html_mathjax()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_wide(self):\n\t    max_cols = 20\n\t    df = DataFrame([['a' * 25] * (max_cols - 1)] * 10)\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        assert '...' not in df._repr_html_()\n\t    wide_df = DataFrame([['a' * 25] * (max_cols + 1)] * 10)\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        assert '...' in wide_df._repr_html_()\n\t\nTestReprHTML().test_repr_html_wide()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_wide_multiindex_cols(self):\n\t    max_cols = 20\n\t    mcols = MultiIndex.from_product([np.arange(max_cols // 2), ['foo',\n\t        'bar']], names=['first', 'second'])\n\t    df = DataFrame([['a' * 25] * len(mcols)] * 10, columns=mcols)\n\t    reg_repr = df._repr_html_()\n\t    assert '...' not in reg_repr\n\t    mcols = MultiIndex.from_product((np.arange(1 + max_cols // 2), ['foo',\n\t        'bar']), names=['first', 'second'])\n\t    df = DataFrame([['a' * 25] * len(mcols)] * 10, columns=mcols)\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        assert '...' in df._repr_html_()\n\t\nTestReprHTML().test_repr_html_wide_multiindex_cols()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_long(self):\n\t    with option_context('display.max_rows', 60):\n\t        max_rows = get_option('display.max_rows')\n\t        h = max_rows - 1\n\t        df = DataFrame({'A': np.arange(1, 1 + h), 'B': np.arange(41, 41 + h)})\n\t        reg_repr = df._repr_html_()\n\t        assert '..' not in reg_repr\n\t        assert str(41 + max_rows // 2) in reg_repr\n\t        h = max_rows + 1\n\t        df = DataFrame({'A': np.arange(1, 1 + h), 'B': np.arange(41, 41 + h)})\n\t        long_repr = df._repr_html_()\n\t        assert '..' in long_repr\n\t        assert str(41 + max_rows // 2) not in long_repr\n\t        assert f'{h} rows ' in long_repr\n\t        assert '2 columns' in long_repr\n\t\nTestReprHTML().test_repr_html_long()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_float(self):\n\t    with option_context('display.max_rows', 60):\n\t        max_rows = get_option('display.max_rows')\n\t        h = max_rows - 1\n\t        df = DataFrame({'idx': np.linspace(-10, 10, h), 'A': np.arange(1, 1 +\n\t            h), 'B': np.arange(41, 41 + h)}).set_index('idx')\n\t        reg_repr = df._repr_html_()\n\t        assert '..' not in reg_repr\n\t        assert f'<td>{40 + h}</td>' in reg_repr\n\t        h = max_rows + 1\n\t        df = DataFrame({'idx': np.linspace(-10, 10, h), 'A': np.arange(1, 1 +\n\t            h), 'B': np.arange(41, 41 + h)}).set_index('idx')\n\t        long_repr = df._repr_html_()\n\t        assert '..' in long_repr\n\t        assert '<td>31</td>' not in long_repr\n\t        assert f'{h} rows ' in long_repr\n\t        assert '2 columns' in long_repr\n\t\nTestReprHTML().test_repr_html_float()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_long_multiindex(self):\n\t    max_rows = 60\n\t    max_L1 = max_rows // 2\n\t    tuples = list(itertools.product(np.arange(max_L1), ['foo', 'bar']))\n\t    idx = MultiIndex.from_tuples(tuples, names=['first', 'second'])\n\t    df = DataFrame(np.random.default_rng(2).standard_normal((max_L1 * 2, 2)\n\t        ), index=idx, columns=['A', 'B'])\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        reg_repr = df._repr_html_()\n\t    assert '...' not in reg_repr\n\t    tuples = list(itertools.product(np.arange(max_L1 + 1), ['foo', 'bar']))\n\t    idx = MultiIndex.from_tuples(tuples, names=['first', 'second'])\n\t    df = DataFrame(np.random.default_rng(2).standard_normal(((max_L1 + 1) *\n\t        2, 2)), index=idx, columns=['A', 'B'])\n\t    long_repr = df._repr_html_()\n\t    assert '...' in long_repr\n\t\nTestReprHTML().test_repr_html_long_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_long_and_wide(self):\n\t    max_cols = 20\n\t    max_rows = 60\n\t    h, w = max_rows - 1, max_cols - 1\n\t    df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        assert '...' not in df._repr_html_()\n\t    h, w = max_rows + 1, max_cols + 1\n\t    df = DataFrame({k: np.arange(1, 1 + h) for k in np.arange(w)})\n\t    with option_context('display.max_rows', 60, 'display.max_columns', 20):\n\t        assert '...' in df._repr_html_()\n\t\nTestReprHTML().test_repr_html_long_and_wide()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_repr_chop_threshold(self):\n\t    df = DataFrame([[0.1, 0.5], [0.5, -0.1]])\n\t    reset_option('display.chop_threshold')\n\t    assert repr(df) == '     0    1\\n0  0.1  0.5\\n1  0.5 -0.1'\n\t    with option_context('display.chop_threshold', 0.2):\n\t        assert repr(df) == '     0    1\\n0  0.0  0.5\\n1  0.5  0.0'\n\t    with option_context('display.chop_threshold', 0.6):\n\t        assert repr(df) == '     0    1\\n0  0.0  0.0\\n1  0.0  0.0'\n\t    with option_context('display.chop_threshold', None):\n\t        assert repr(df) == '     0    1\\n0  0.1  0.5\\n1  0.5 -0.1'\n\t\nTestDataFrameFormatting().test_repr_chop_threshold()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_repr_no_backslash(self):\n\t    with option_context('mode.sim_interactive', True):\n\t        df = DataFrame(np.random.default_rng(2).standard_normal((10, 4)))\n\t        assert '\\\\' not in repr(df)\n\t\nTestDataFrameFormatting().test_repr_no_backslash()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_repr_min_rows(self):\n\t    df = DataFrame({'a': range(20)})\n\t    assert '..' not in repr(df)\n\t    assert '..' not in df._repr_html_()\n\t    df = DataFrame({'a': range(61)})\n\t    assert '..' in repr(df)\n\t    assert '..' in df._repr_html_()\n\t    with option_context('display.max_rows', 10, 'display.min_rows', 4):\n\t        assert '..' in repr(df)\n\t        assert '2  ' not in repr(df)\n\t        assert '...' in df._repr_html_()\n\t        assert '<td>2</td>' not in df._repr_html_()\n\t    with option_context('display.max_rows', 12, 'display.min_rows', None):\n\t        assert '5    5' in repr(df)\n\t        assert '<td>5</td>' in df._repr_html_()\n\t    with option_context('display.max_rows', 10, 'display.min_rows', 12):\n\t        assert '5    5' not in repr(df)\n\t        assert '<td>5</td>' not in df._repr_html_()\n\t    with option_context('display.max_rows', None, 'display.min_rows', 12):\n\t        assert '..' not in repr(df)\n\t        assert '..' not in df._repr_html_()\n\t\nTestDataFrameFormatting().test_repr_min_rows()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_truncate_with_different_dtypes2(self):\n\t    df = DataFrame({'text': ['some words'] + [None] * 9}, dtype=object)\n\t    with option_context('display.max_rows', 8, 'display.max_columns', 3):\n\t        result = str(df)\n\t        assert 'None' in result\n\t        assert 'NaN' not in result\n\t\nTestDataFrameFormatting().test_truncate_with_different_dtypes2()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr(self):\n\t    with option_context('mode.sim_interactive', True,\n\t        'display.show_dimensions', True, 'display.max_columns', 20):\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10)\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        assert f'10 rows x {max_cols - 1} columns' in rep_str\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 120):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t\nTestDataFrameFormatting().test_wide_repr()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_wide_columns(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        df = DataFrame(np.random.default_rng(2).standard_normal((5, 3)),\n\t            columns=['a' * 90, 'b' * 90, 'c' * 90])\n\t        rep_str = repr(df)\n\t        assert len(rep_str.splitlines()) == 20\n\t\nTestDataFrameFormatting().test_wide_repr_wide_columns()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_named(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10)\n\t        df.index.name = 'DataFrame Index'\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 150):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t        for line in wide_repr.splitlines()[1::13]:\n\t            assert 'DataFrame Index' in line\n\t\nTestDataFrameFormatting().test_wide_repr_named()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_multiindex(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        midx = MultiIndex.from_arrays([['a' * 5] * 10] * 2)\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10, index=midx)\n\t        df.index.names = ['Level 0', 'Level 1']\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 150):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t        for line in wide_repr.splitlines()[1::13]:\n\t            assert 'Level 0 Level 1' in line\n\t\nTestDataFrameFormatting().test_wide_repr_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_multiindex_cols(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        max_cols = get_option('display.max_columns')\n\t        midx = MultiIndex.from_arrays([['a' * 5] * 10] * 2)\n\t        mcols = MultiIndex.from_arrays([['b' * 3] * (max_cols - 1)] * 2)\n\t        df = DataFrame([['c' * 25] * (max_cols - 1)] * 10, index=midx,\n\t            columns=mcols)\n\t        df.index.names = ['Level 0', 'Level 1']\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t    with option_context('display.width', 150, 'display.max_columns', 20):\n\t        wider_repr = repr(df)\n\t        assert len(wider_repr) < len(wide_repr)\n\t\nTestDataFrameFormatting().test_wide_repr_multiindex_cols()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_unicode(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        max_cols = 20\n\t        df = DataFrame([['a' * 25] * 10] * (max_cols - 1))\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 150):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t\nTestDataFrameFormatting().test_wide_repr_unicode()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_wide_long_columns(self):\n\t    with option_context('mode.sim_interactive', True):\n\t        df = DataFrame({'a': ['a' * 30, 'b' * 30], 'b': ['c' * 70, 'd' * 80]})\n\t        result = repr(df)\n\t        assert 'ccccc' in result\n\t        assert 'ddddd' in result\n\t\nTestDataFrameFormatting().test_wide_repr_wide_long_columns()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_show_dimensions(self):\n\t    df = DataFrame(123, index=range(10, 15), columns=range(30))\n\t    with option_context('display.max_rows', 10, 'display.max_columns', 40,\n\t        'display.width', 500, 'display.expand_frame_repr', 'info',\n\t        'display.show_dimensions', True):\n\t        assert '5 rows' in str(df)\n\t        assert '5 rows' in df._repr_html_()\n\t    with option_context('display.max_rows', 10, 'display.max_columns', 40,\n\t        'display.width', 500, 'display.expand_frame_repr', 'info',\n\t        'display.show_dimensions', False):\n\t        assert '5 rows' not in str(df)\n\t        assert '5 rows' not in df._repr_html_()\n\t    with option_context('display.max_rows', 2, 'display.max_columns', 2,\n\t        'display.width', 500, 'display.expand_frame_repr', 'info',\n\t        'display.show_dimensions', 'truncate'):\n\t        assert '5 rows' in str(df)\n\t        assert '5 rows' in df._repr_html_()\n\t    with option_context('display.max_rows', 10, 'display.max_columns', 40,\n\t        'display.width', 500, 'display.expand_frame_repr', 'info',\n\t        'display.show_dimensions', 'truncate'):\n\t        assert '5 rows' not in str(df)\n\t        assert '5 rows' not in df._repr_html_()\n\t\nTestDataFrameFormatting().test_show_dimensions()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestSeriesFormatting():\n\tdef test_max_multi_index_display(self):\n\t    arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], [\n\t        'one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n\t    tuples = list(zip(*arrays))\n\t    index = MultiIndex.from_tuples(tuples, names=['first', 'second'])\n\t    s = Series(np.random.default_rng(2).standard_normal(8), index=index)\n\t    with option_context('display.max_rows', 10):\n\t        assert len(str(s).split('\\n')) == 10\n\t    with option_context('display.max_rows', 3):\n\t        assert len(str(s).split('\\n')) == 5\n\t    with option_context('display.max_rows', 2):\n\t        assert len(str(s).split('\\n')) == 5\n\t    with option_context('display.max_rows', 1):\n\t        assert len(str(s).split('\\n')) == 4\n\t    with option_context('display.max_rows', 0):\n\t        assert len(str(s).split('\\n')) == 10\n\t    s = Series(np.random.default_rng(2).standard_normal(8), None)\n\t    with option_context('display.max_rows', 10):\n\t        assert len(str(s).split('\\n')) == 9\n\t    with option_context('display.max_rows', 3):\n\t        assert len(str(s).split('\\n')) == 4\n\t    with option_context('display.max_rows', 2):\n\t        assert len(str(s).split('\\n')) == 4\n\t    with option_context('display.max_rows', 1):\n\t        assert len(str(s).split('\\n')) == 3\n\t    with option_context('display.max_rows', 0):\n\t        assert len(str(s).split('\\n')) == 9\n\t\nTestSeriesFormatting().test_max_multi_index_display()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestSeriesFormatting():\n\tdef test_max_rows_eq_one(self):\n\t    s = Series(range(10), dtype='int64')\n\t    with option_context('display.max_rows', 1):\n\t        strrepr = repr(s).split('\\n')\n\t    exp1 = ['0', '0']\n\t    res1 = strrepr[0].split()\n\t    assert exp1 == res1\n\t    exp2 = ['..']\n\t    res2 = strrepr[1].split()\n\t    assert exp2 == res2\n\t\nTestSeriesFormatting().test_max_rows_eq_one()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestSeriesFormatting():\n\tdef test_truncate_ndots(self):\n\t\n\t    def getndots(s):\n\t        return len(re.match('[^\\\\.]*(\\\\.*)', s).groups()[0])\n\t    s = Series([0, 2, 3, 6])\n\t    with option_context('display.max_rows', 2):\n\t        strrepr = repr(s).replace('\\n', '')\n\t    assert getndots(strrepr) == 2\n\t    s = Series([0, 100, 200, 400])\n\t    with option_context('display.max_rows', 2):\n\t        strrepr = repr(s).replace('\\n', '')\n\t    assert getndots(strrepr) == 3\n\t\nTestSeriesFormatting().test_truncate_ndots()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestSeriesFormatting():\n\tdef test_show_dimensions(self):\n\t    s = Series(range(5))\n\t    assert 'Length' not in repr(s)\n\t    with option_context('display.max_rows', 4):\n\t        assert 'Length' in repr(s)\n\t    with option_context('display.show_dimensions', True):\n\t        assert 'Length' in repr(s)\n\t    with option_context('display.max_rows', 4, 'display.show_dimensions', False\n\t        ):\n\t        assert 'Length' not in repr(s)\n\t\nTestSeriesFormatting().test_show_dimensions()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestSeriesFormatting():\n\tdef test_repr_min_rows(self):\n\t    s = Series(range(20))\n\t    assert '..' not in repr(s)\n\t    s = Series(range(61))\n\t    assert '..' in repr(s)\n\t    with option_context('display.max_rows', 10, 'display.min_rows', 4):\n\t        assert '..' in repr(s)\n\t        assert '2  ' not in repr(s)\n\t    with option_context('display.max_rows', 12, 'display.min_rows', None):\n\t        assert '5      5' in repr(s)\n\t    with option_context('display.max_rows', 10, 'display.min_rows', 12):\n\t        assert '5      5' not in repr(s)\n\t    with option_context('display.max_rows', None, 'display.min_rows', 12):\n\t        assert '..' not in repr(s)\n\t\nTestSeriesFormatting().test_repr_min_rows()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestFloatArrayFormatter():\n\tdef test_output_display_precision_trailing_zeroes(self):\n\t    with option_context('display.precision', 0):\n\t        s = Series([840.0, 4200.0])\n\t        expected_output = '0     840\\n1    4200\\ndtype: float64'\n\t        assert str(s) == expected_output\n\t\nTestFloatArrayFormatter().test_output_display_precision_trailing_zeroes()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestFloatArrayFormatter():\n\tdef test_too_long(self):\n\t    with option_context('display.precision', 4):\n\t        df = DataFrame({'x': [12345.6789]})\n\t        assert str(df) == '            x\\n0  12345.6789'\n\t        df = DataFrame({'x': [2000000.0]})\n\t        assert str(df) == '           x\\n0  2000000.0'\n\t        df = DataFrame({'x': [12345.6789, 2000000.0]})\n\t        assert str(df) == '            x\\n0  1.2346e+04\\n1  2.0000e+06'\n\t\nTestFloatArrayFormatter().test_too_long()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_render_trimming_mi():\n    midx = MultiIndex.from_product([[1, 2], [1, 2, 3]])\n    df = DataFrame(np.arange(36).reshape(6, 6), columns=midx, index=midx)\n    with option_context('styler.render.max_elements', 4):\n        ctx = df.style._translate(True, True)\n    assert len(ctx['body'][0]) == 5\n    assert {'attributes': 'rowspan=\"2\"'}.items() <= ctx['body'][0][0].items()\n    assert {'class': 'data row0 col_trim'}.items() <= ctx['body'][0][4].items()\n    assert {'class': 'data row_trim col_trim'}.items() <= ctx['body'][2][4\n        ].items()\n    assert len(ctx['body']) == 3\n\ntest_render_trimming_mi()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_row_trimming_hide_index():\n    df = DataFrame([[1], [2], [3], [4], [5]])\n    with option_context('styler.render.max_rows', 2):\n        ctx = df.style.hide([0, 1], axis='index')._translate(True, True)\n    assert len(ctx['body']) == 3\n    for r, val in enumerate(['3', '4', '...']):\n        assert ctx['body'][r][1]['display_value'] == val\n\ntest_row_trimming_hide_index()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "from textwrap import dedent\nfrom textwrap import indent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\ndef test_hiding_index_columns_multiindex_trimming():\n    df = DataFrame(np.arange(64).reshape(8, 8))\n    df.columns = MultiIndex.from_product([[0, 1, 2, 3], [0, 1]])\n    df.index = MultiIndex.from_product([[0, 1, 2, 3], [0, 1]])\n    df.index.names, df.columns.names = ['a', 'b'], ['c', 'd']\n    styler = Styler(df, cell_ids=False, uuid_len=0)\n    styler.hide([(0, 0), (0, 1), (1, 0)], axis=1).hide([(0, 0), (0, 1), (1,\n        0)], axis=0)\n    with option_context('styler.render.max_rows', 4,\n        'styler.render.max_columns', 4):\n        result = styler.to_html()\n    expected = dedent(\n        \"\"\"    <style type=\"text/css\">\n    </style>\n    <table id=\"T_\">\n      <thead>\n        <tr>\n          <th class=\"blank\" >&nbsp;</th>\n          <th class=\"index_name level0\" >c</th>\n          <th class=\"col_heading level0 col3\" >1</th>\n          <th class=\"col_heading level0 col4\" colspan=\"2\">2</th>\n          <th class=\"col_heading level0 col6\" >3</th>\n        </tr>\n        <tr>\n          <th class=\"blank\" >&nbsp;</th>\n          <th class=\"index_name level1\" >d</th>\n          <th class=\"col_heading level1 col3\" >1</th>\n          <th class=\"col_heading level1 col4\" >0</th>\n          <th class=\"col_heading level1 col5\" >1</th>\n          <th class=\"col_heading level1 col6\" >0</th>\n          <th class=\"col_heading level1 col_trim\" >...</th>\n        </tr>\n        <tr>\n          <th class=\"index_name level0\" >a</th>\n          <th class=\"index_name level1\" >b</th>\n          <th class=\"blank col3\" >&nbsp;</th>\n          <th class=\"blank col4\" >&nbsp;</th>\n          <th class=\"blank col5\" >&nbsp;</th>\n          <th class=\"blank col6\" >&nbsp;</th>\n          <th class=\"blank col7 col_trim\" >&nbsp;</th>\n        </tr>\n      </thead>\n      <tbody>\n        <tr>\n          <th class=\"row_heading level0 row3\" >1</th>\n          <th class=\"row_heading level1 row3\" >1</th>\n          <td class=\"data row3 col3\" >27</td>\n          <td class=\"data row3 col4\" >28</td>\n          <td class=\"data row3 col5\" >29</td>\n          <td class=\"data row3 col6\" >30</td>\n          <td class=\"data row3 col_trim\" >...</td>\n        </tr>\n        <tr>\n          <th class=\"row_heading level0 row4\" rowspan=\"2\">2</th>\n          <th class=\"row_heading level1 row4\" >0</th>\n          <td class=\"data row4 col3\" >35</td>\n          <td class=\"data row4 col4\" >36</td>\n          <td class=\"data row4 col5\" >37</td>\n          <td class=\"data row4 col6\" >38</td>\n          <td class=\"data row4 col_trim\" >...</td>\n        </tr>\n        <tr>\n          <th class=\"row_heading level1 row5\" >1</th>\n          <td class=\"data row5 col3\" >43</td>\n          <td class=\"data row5 col4\" >44</td>\n          <td class=\"data row5 col5\" >45</td>\n          <td class=\"data row5 col6\" >46</td>\n          <td class=\"data row5 col_trim\" >...</td>\n        </tr>\n        <tr>\n          <th class=\"row_heading level0 row6\" >3</th>\n          <th class=\"row_heading level1 row6\" >0</th>\n          <td class=\"data row6 col3\" >51</td>\n          <td class=\"data row6 col4\" >52</td>\n          <td class=\"data row6 col5\" >53</td>\n          <td class=\"data row6 col6\" >54</td>\n          <td class=\"data row6 col_trim\" >...</td>\n        </tr>\n        <tr>\n          <th class=\"row_heading level0 row_trim\" >...</th>\n          <th class=\"row_heading level1 row_trim\" >...</th>\n          <td class=\"data col3 row_trim\" >...</td>\n          <td class=\"data col4 row_trim\" >...</td>\n          <td class=\"data col5 row_trim\" >...</td>\n          <td class=\"data col6 row_trim\" >...</td>\n          <td class=\"data row_trim col_trim\" >...</td>\n        </tr>\n      </tbody>\n    </table>\n    \"\"\"\n        )\n    assert result == expected\n\ntest_hiding_index_columns_multiindex_trimming()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_html.py"}], "instruction": "Functionality: Context manager to temporarily set options within a with statement, which allows the modification of pandas options without permanently changing the global settings.\n\nInputs: \n    *args: A variable number of arguments provided in pairs, interpreted as (pattern, value) pairs. The patterns represent the option names to be set, and the values are the new settings for those options. An even number of arguments must be provided.\n\nOutputs:\n    None: The function yields control back to the with statement and no value is returned. After the with statement is exited, the options are reset to their original values.\n\nExample usage:\n>>> with option_context(\"display.max_rows\", 10, \"display.max_columns\", 5):\n...     # code block where the options are in effect\n...", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\n\n\n@contextmanager\ndef option_context(*args) ->Generator[None, None, None]: [MASK]\n"}
{"method_name": "get_option", "full_method_name": "get_option", "method_path": "../srcdata/Computation/pandas/pandas/_config/config.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\ndef get_option(pat: str) ->Any:\n    \"\"\"\n    Retrieve the value of the specified option.\n\n    Parameters\n    ----------\n    pat : str\n        Regexp which should match a single option.\n\n        .. warning::\n\n            Partial matches are supported for convenience, but unless you use the\n            full option name (e.g. x.y.z.option_name), your code may break in future\n            versions if new options with similar names are introduced.\n\n    Returns\n    -------\n    Any\n        The value of the option.\n\n    Raises\n    ------\n    OptionError : if no such option exists\n\n    See Also\n    --------\n    set_option : Set the value of the specified option or options.\n    reset_option : Reset one or more options to their default value.\n    describe_option : Print the description for one or more registered options.\n\n    Notes\n    -----\n    For all available options, please view the :ref:`User Guide <options.available>`\n    or use ``pandas.describe_option()``.\n\n    Examples\n    --------\n    >>> pd.get_option(\"display.max_columns\")  # doctest: +SKIP\n    4\n    \"\"\"\n    key = _get_single_key(pat)\n    root, k = _get_root(key)\n    return root[k]", "test_code_list": [{"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_long(self):\n\t    with option_context('display.max_rows', 60):\n\t        max_rows = get_option('display.max_rows')\n\t        h = max_rows - 1\n\t        df = DataFrame({'A': np.arange(1, 1 + h), 'B': np.arange(41, 41 + h)})\n\t        reg_repr = df._repr_html_()\n\t        assert '..' not in reg_repr\n\t        assert str(41 + max_rows // 2) in reg_repr\n\t        h = max_rows + 1\n\t        df = DataFrame({'A': np.arange(1, 1 + h), 'B': np.arange(41, 41 + h)})\n\t        long_repr = df._repr_html_()\n\t        assert '..' in long_repr\n\t        assert str(41 + max_rows // 2) not in long_repr\n\t        assert f'{h} rows ' in long_repr\n\t        assert '2 columns' in long_repr\n\t\nTestReprHTML().test_repr_html_long()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport itertools\nimport re\nimport textwrap\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import get_option\nfrom pandas import option_context\nimport pandas.io.formats.format as fmt\n\nclass TestReprHTML():\n\tdef test_repr_html_float(self):\n\t    with option_context('display.max_rows', 60):\n\t        max_rows = get_option('display.max_rows')\n\t        h = max_rows - 1\n\t        df = DataFrame({'idx': np.linspace(-10, 10, h), 'A': np.arange(1, 1 +\n\t            h), 'B': np.arange(41, 41 + h)}).set_index('idx')\n\t        reg_repr = df._repr_html_()\n\t        assert '..' not in reg_repr\n\t        assert f'<td>{40 + h}</td>' in reg_repr\n\t        h = max_rows + 1\n\t        df = DataFrame({'idx': np.linspace(-10, 10, h), 'A': np.arange(1, 1 +\n\t            h), 'B': np.arange(41, 41 + h)}).set_index('idx')\n\t        long_repr = df._repr_html_()\n\t        assert '..' in long_repr\n\t        assert '<td>31</td>' not in long_repr\n\t        assert f'{h} rows ' in long_repr\n\t        assert '2 columns' in long_repr\n\t\nTestReprHTML().test_repr_html_float()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_to_html.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_to_string_repr_unicode2(self):\n\t    idx = Index(['abc', '\u03c3a', 'aegdvg'])\n\t    ser = Series(np.random.default_rng(2).standard_normal(len(idx)), idx)\n\t    rs = repr(ser).split('\\n')\n\t    line_len = len(rs[0])\n\t    for line in rs[1:]:\n\t        try:\n\t            line = line.decode(get_option('display.encoding'))\n\t        except AttributeError:\n\t            pass\n\t        if not line.startswith('dtype:'):\n\t            assert len(line) == line_len\n\t\nTestDataFrameFormatting().test_to_string_repr_unicode2()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr(self):\n\t    with option_context('mode.sim_interactive', True,\n\t        'display.show_dimensions', True, 'display.max_columns', 20):\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10)\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        assert f'10 rows x {max_cols - 1} columns' in rep_str\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 120):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t\nTestDataFrameFormatting().test_wide_repr()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_named(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10)\n\t        df.index.name = 'DataFrame Index'\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 150):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t        for line in wide_repr.splitlines()[1::13]:\n\t            assert 'DataFrame Index' in line\n\t\nTestDataFrameFormatting().test_wide_repr_named()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_multiindex(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        midx = MultiIndex.from_arrays([['a' * 5] * 10] * 2)\n\t        max_cols = get_option('display.max_columns')\n\t        df = DataFrame([['a' * 25] * (max_cols - 1)] * 10, index=midx)\n\t        df.index.names = ['Level 0', 'Level 1']\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t        with option_context('display.width', 150):\n\t            wider_repr = repr(df)\n\t            assert len(wider_repr) < len(wide_repr)\n\t        for line in wide_repr.splitlines()[1::13]:\n\t            assert 'Level 0 Level 1' in line\n\t\nTestDataFrameFormatting().test_wide_repr_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}, {"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_wide_repr_multiindex_cols(self):\n\t    with option_context('mode.sim_interactive', True, 'display.max_columns', 20\n\t        ):\n\t        max_cols = get_option('display.max_columns')\n\t        midx = MultiIndex.from_arrays([['a' * 5] * 10] * 2)\n\t        mcols = MultiIndex.from_arrays([['b' * 3] * (max_cols - 1)] * 2)\n\t        df = DataFrame([['c' * 25] * (max_cols - 1)] * 10, index=midx,\n\t            columns=mcols)\n\t        df.index.names = ['Level 0', 'Level 1']\n\t        with option_context('display.expand_frame_repr', False):\n\t            rep_str = repr(df)\n\t        with option_context('display.expand_frame_repr', True):\n\t            wide_repr = repr(df)\n\t        assert rep_str != wide_repr\n\t    with option_context('display.width', 150, 'display.max_columns', 20):\n\t        wider_repr = repr(df)\n\t        assert len(wider_repr) < len(wide_repr)\n\t\nTestDataFrameFormatting().test_wide_repr_multiindex_cols()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}], "instruction": "Functionality: Retrieve the value of a specified option from the configuration.\n\nInputs: \n- pat: A string representing a regular expression that should match a single option. Partial matches are supported, but using the full option name is recommended to avoid potential issues with future versions introducing new options with similar names.\n\nOutputs:\n- Any: The value of the option is returned. The type of the value can vary depending on the option.\n\nRaises:\n- OptionError: If no such option exists, an OptionError is raised.\n\nAdditional Information:\n- The function supports convenience partial matches, but full option names are recommended.\n- For all available options, refer to the User Guide or use `pandas.describe_option()` to view descriptions of registered options.\n- The function is part of a larger configuration system for pandas, and allows users to access specific configuration settings.", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\n\n\ndef get_option(pat: str) ->Any: [MASK]\n"}
{"method_name": "is_integer_dtype", "full_method_name": "is_integer_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_integer_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether the provided array or dtype is of an integer dtype.\n\n    Unlike in `is_any_int_dtype`, timedelta64 instances will return False.\n\n    The nullable Integer dtypes (e.g. pandas.Int64Dtype) are also considered\n    as integer by this function.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of an integer dtype and\n        not an instance of timedelta64.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_integer_dtype\n    >>> is_integer_dtype(str)\n    False\n    >>> is_integer_dtype(int)\n    True\n    >>> is_integer_dtype(float)\n    False\n    >>> is_integer_dtype(np.uint64)\n    True\n    >>> is_integer_dtype(\"int8\")\n    True\n    >>> is_integer_dtype(\"Int8\")\n    True\n    >>> is_integer_dtype(pd.Int8Dtype)\n    True\n    >>> is_integer_dtype(np.datetime64)\n    False\n    >>> is_integer_dtype(np.timedelta64)\n    False\n    >>> is_integer_dtype(np.array([\"a\", \"b\"]))\n    False\n    >>> is_integer_dtype(pd.Series([1, 2]))\n    True\n    >>> is_integer_dtype(np.array([], dtype=np.timedelta64))\n    False\n    >>> is_integer_dtype(pd.Index([1, 2.0]))  # float\n    False\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, _classes_and_not_datetimelike(np.\n        integer)) or _is_dtype(arr_or_dtype, lambda typ: isinstance(typ,\n        ExtensionDtype) and typ.kind in 'iu')", "test_code_list": [{"test_code": "from datetime import datetime\nfrom itertools import product\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import cut\nfrom pandas import date_range\nimport pandas._testing as tm\n\nclass TestResetIndex():\n\tdef test_reset_index_delevel_infer_dtype(self):\n\t    tuples = list(product(['foo', 'bar'], [10, 20], [1.0, 1.1]))\n\t    index = MultiIndex.from_tuples(tuples, names=['prm0', 'prm1', 'prm2'])\n\t    df = DataFrame(np.random.default_rng(2).standard_normal((8, 3)),\n\t        columns=['A', 'B', 'C'], index=index)\n\t    deleveled = df.reset_index()\n\t    assert is_integer_dtype(deleveled['prm1'])\n\t    assert is_float_dtype(deleveled['prm2'])\n\t\nTestResetIndex().test_reset_index_delevel_infer_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/methods/test_reset_index.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas import timedelta_range\nimport pandas._testing as tm\n\nclass TestCategoricalConstructors():\n\tdef test_constructor(self):\n\t    exp_arr = np.array(['a', 'b', 'c', 'a', 'b', 'c'], dtype=np.object_)\n\t    c1 = Categorical(exp_arr)\n\t    tm.assert_numpy_array_equal(c1.__array__(), exp_arr)\n\t    c2 = Categorical(exp_arr, categories=['a', 'b', 'c'])\n\t    tm.assert_numpy_array_equal(c2.__array__(), exp_arr)\n\t    c2 = Categorical(exp_arr, categories=['c', 'b', 'a'])\n\t    tm.assert_numpy_array_equal(c2.__array__(), exp_arr)\n\t    msg = 'Categorical categories must be unique'\n\t    with pytest.raises(ValueError, match=msg):\n\t        Categorical([1, 2], [1, 2, 2])\n\t    with pytest.raises(ValueError, match=msg):\n\t        Categorical(['a', 'b'], ['a', 'b', 'b'])\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    assert not c1.ordered\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(c1, categories=['a', 'b', 'c'])\n\t    tm.assert_numpy_array_equal(c1.__array__(), c2.__array__())\n\t    tm.assert_index_equal(c2.categories, Index(['a', 'b', 'c']))\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(Series(c1))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(Series(c1))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    c2 = Categorical(Series(['a', 'b', 'c', 'a']))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(Series(['a', 'b', 'c', 'a']), categories=['a', 'b',\n\t        'c', 'd'])\n\t    tm.assert_categorical_equal(c1, c2)\n\t    cat = Categorical([1, 2, 3, np.nan], categories=[1, 2, 3])\n\t    assert is_integer_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1, 2, 3])\n\t    assert is_integer_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1, 2.0, 3])\n\t    assert is_float_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1.0, 2.0, 3.0])\n\t    assert is_float_dtype(cat.categories)\n\t    cat = Categorical([1])\n\t    assert len(cat.categories) == 1\n\t    assert cat.categories[0] == 1\n\t    assert len(cat.codes) == 1\n\t    assert cat.codes[0] == 0\n\t    cat = Categorical(['a'])\n\t    assert len(cat.categories) == 1\n\t    assert cat.categories[0] == 'a'\n\t    assert len(cat.codes) == 1\n\t    assert cat.codes[0] == 0\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], categories=['a', 'b', 'c'])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], categories=[3, 4, 5])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], [1, 2, 3])\n\t        cat = Categorical([1, 2], categories=[1, 2, 3])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical(np.array([], dtype='int64'), categories=[3, 2, 1],\n\t            ordered=True)\n\t\nTestCategoricalConstructors().test_constructor()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/categorical/test_constructors.py"}], "instruction": "Functionality: The function 'is_integer_dtype' is designed to determine whether the provided array or dtype is of an integer data type. This includes checking for standard integer types, nullable Integer dtypes (like pandas.Int64Dtype), and integer-like dtypes. However, it specifically excludes timedelta64 instances from being classified as integers.\n\nInputs: \n- arr_or_dtype: This can be either an array-like object or a data type (dtype). The function will check this input to determine if it is of an integer dtype.\n\nOutputs: \n- A boolean value indicating whether the input 'arr_or_dtype' is of an integer dtype. The function returns 'True' if the input is an integer dtype and 'False' otherwise.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_integer_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "_ensure_numeric", "full_method_name": "_ensure_numeric", "method_path": "../srcdata/Computation/pandas/pandas/core/nanops.py", "method_code": "from __future__ import annotations\nimport functools\nimport itertools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import NaT\nfrom pandas._libs import NaTType\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import CorrelationMethod\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import F\nfrom pandas._typing import Scalar\nfrom pandas._typing import Shape\nfrom pandas._typing import npt\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom collections.abc import Callable\nfrom scipy.stats import kendalltau\nfrom scipy.stats import spearmanr\ndef _ensure_numeric(x):\n    if isinstance(x, np.ndarray):\n        if x.dtype.kind in 'biu':\n            x = x.astype(np.float64)\n        elif x.dtype == object:\n            inferred = lib.infer_dtype(x)\n            if inferred in ['string', 'mixed']:\n                raise TypeError(f'Could not convert {x} to numeric')\n            try:\n                x = x.astype(np.complex128)\n            except (TypeError, ValueError):\n                try:\n                    x = x.astype(np.float64)\n                except ValueError as err:\n                    raise TypeError(f'Could not convert {x} to numeric'\n                        ) from err\n            else:\n                if not np.any(np.imag(x)):\n                    x = x.real\n    elif not (is_float(x) or is_integer(x) or is_complex(x)):\n        if isinstance(x, str):\n            raise TypeError(f\"Could not convert string '{x}' to numeric\")\n        try:\n            x = float(x)\n        except (TypeError, ValueError):\n            try:\n                x = complex(x)\n            except ValueError as err:\n                raise TypeError(f'Could not convert {x} to numeric') from err\n    return x", "test_code_list": [{"test_code": "from functools import partial\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.common import is_integer_dtype\nimport pandas as pd\nfrom pandas import Series\nfrom pandas import isna\nimport pandas._testing as tm\nfrom pandas.core import nanops\n\nclass TestEnsureNumeric():\n\tdef test_numeric_values(self):\n\t    assert _ensure_numeric(1) == 1\n\t    assert _ensure_numeric(1.1) == 1.1\n\t    assert _ensure_numeric(1 + 2.0j) == 1 + 2.0j\n\t\nTestEnsureNumeric().test_numeric_values()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_nanops.py"}, {"test_code": "from functools import partial\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.common import is_integer_dtype\nimport pandas as pd\nfrom pandas import Series\nfrom pandas import isna\nimport pandas._testing as tm\nfrom pandas.core import nanops\n\nclass TestEnsureNumeric():\n\tdef test_ndarray(self):\n\t    values = np.array([1, 2, 3])\n\t    assert np.allclose(_ensure_numeric(values), values)\n\t    o_values = values.astype(object)\n\t    assert np.allclose(_ensure_numeric(o_values), values)\n\t    s_values = np.array(['1', '2', '3'], dtype=object)\n\t    msg = \"Could not convert \\\\['1' '2' '3'\\\\] to numeric\"\n\t    with pytest.raises(TypeError, match=msg):\n\t        _ensure_numeric(s_values)\n\t    s_values = np.array(['foo', 'bar', 'baz'], dtype=object)\n\t    msg = 'Could not convert .* to numeric'\n\t    with pytest.raises(TypeError, match=msg):\n\t        _ensure_numeric(s_values)\n\t\nTestEnsureNumeric().test_ndarray()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_nanops.py"}], "instruction": "Functionality: The _ensure_numeric function is designed to ensure that the input, x, is converted to a numeric type if it is not already in a numeric format. This function handles various types of inputs, including numpy arrays and scalar values. It supports conversion to float or complex numbers, as well as handling cases where the input is not directly convertible to numeric types, by raising appropriate TypeError exceptions.\n\nInputs: \n- x: The input that needs to be ensured as numeric. This could be a numpy array, an integer, a float, a complex number, or a string that can potentially be converted to a numeric type.\n\nOutputs:\n- The function returns the numeric representation of the input x. If x is a numpy array with integer types ('biu' for boolean, signed, and unsigned integers), it is converted to float64. If x is a numpy array with object dtype, and the inferred type is 'string' or 'mixed', a TypeError is raised. If x is a scalar value and not inherently numeric, it attempts to convert to float or complex, raising a TypeError if the conversion is not possible.", "method_code_mask": "from __future__ import annotations\nimport functools\nimport itertools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import NaT\nfrom pandas._libs import NaTType\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import CorrelationMethod\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import F\nfrom pandas._typing import Scalar\nfrom pandas._typing import Shape\nfrom pandas._typing import npt\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom collections.abc import Callable\nfrom scipy.stats import kendalltau\nfrom scipy.stats import spearmanr\n\n\ndef _ensure_numeric(x): [MASK]\n"}
{"method_name": "is_bool_dtype", "full_method_name": "is_bool_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_bool_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a boolean dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a boolean dtype.\n\n    Notes\n    -----\n    An ExtensionArray is considered boolean when the ``_is_boolean``\n    attribute is set to True.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_bool_dtype\n    >>> is_bool_dtype(str)\n    False\n    >>> is_bool_dtype(int)\n    False\n    >>> is_bool_dtype(bool)\n    True\n    >>> is_bool_dtype(np.bool_)\n    True\n    >>> is_bool_dtype(np.array([\"a\", \"b\"]))\n    False\n    >>> is_bool_dtype(pd.Series([1, 2]))\n    False\n    >>> is_bool_dtype(np.array([True, False]))\n    True\n    >>> is_bool_dtype(pd.Categorical([True, False]))\n    True\n    >>> is_bool_dtype(pd.arrays.SparseArray([True, False]))\n    True\n    \"\"\"\n    if arr_or_dtype is None:\n        return False\n    try:\n        dtype = _get_dtype(arr_or_dtype)\n    except (TypeError, ValueError):\n        return False\n    if isinstance(dtype, CategoricalDtype):\n        arr_or_dtype = dtype.categories\n    if isinstance(arr_or_dtype, ABCIndex):\n        if arr_or_dtype.inferred_type == 'boolean':\n            if not is_bool_dtype(arr_or_dtype.dtype):\n                warnings.warn(\n                    'The behavior of is_bool_dtype with an object-dtype Index of bool objects is deprecated. In a future version, this will return False. Cast the Index to a bool dtype instead.'\n                    , DeprecationWarning, stacklevel=2)\n            return True\n        return False\n    elif isinstance(dtype, ExtensionDtype):\n        return getattr(dtype, '_is_boolean', False)\n    return issubclass(dtype.type, np.bool_)", "test_code_list": [{"test_code": "import re\nimport weakref\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_categorical_dtype\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_dtype_equal\nfrom pandas.core.dtypes.common import is_interval_dtype\nfrom pandas.core.dtypes.common import is_period_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import SparseDtype\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import SparseArray\ndef test_is_bool_dtype_sparse():\n    result = is_bool_dtype(Series(SparseArray([True, False])))\n    assert result is True\n\ntest_is_bool_dtype_sparse()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_dtypes.py"}], "instruction": "Functionality: Check whether the provided array or dtype is of a boolean dtype.\nInputs: \n    arr_or_dtype : array-like or dtype\n        The array or dtype to check.\nOutputs: \n    boolean\n        Whether or not the array or dtype is of a boolean dtype.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_bool_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "is_float_dtype", "full_method_name": "is_float_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_float_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether the provided array or dtype is of a float dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of a float dtype.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_float_dtype\n    >>> is_float_dtype(str)\n    False\n    >>> is_float_dtype(int)\n    False\n    >>> is_float_dtype(float)\n    True\n    >>> is_float_dtype(np.array([\"a\", \"b\"]))\n    False\n    >>> is_float_dtype(pd.Series([1, 2]))\n    False\n    >>> is_float_dtype(pd.Index([1, 2.0]))\n    True\n    \"\"\"\n    return _is_dtype_type(arr_or_dtype, classes(np.floating)) or _is_dtype(\n        arr_or_dtype, lambda typ: isinstance(typ, ExtensionDtype) and typ.\n        kind in 'f')", "test_code_list": [{"test_code": "from datetime import datetime\nfrom itertools import product\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import cut\nfrom pandas import date_range\nimport pandas._testing as tm\n\nclass TestResetIndex():\n\tdef test_reset_index_delevel_infer_dtype(self):\n\t    tuples = list(product(['foo', 'bar'], [10, 20], [1.0, 1.1]))\n\t    index = MultiIndex.from_tuples(tuples, names=['prm0', 'prm1', 'prm2'])\n\t    df = DataFrame(np.random.default_rng(2).standard_normal((8, 3)),\n\t        columns=['A', 'B', 'C'], index=index)\n\t    deleveled = df.reset_index()\n\t    assert is_integer_dtype(deleveled['prm1'])\n\t    assert is_float_dtype(deleveled['prm2'])\n\t\nTestResetIndex().test_reset_index_delevel_infer_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/methods/test_reset_index.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas import timedelta_range\nimport pandas._testing as tm\n\nclass TestCategoricalConstructors():\n\tdef test_constructor(self):\n\t    exp_arr = np.array(['a', 'b', 'c', 'a', 'b', 'c'], dtype=np.object_)\n\t    c1 = Categorical(exp_arr)\n\t    tm.assert_numpy_array_equal(c1.__array__(), exp_arr)\n\t    c2 = Categorical(exp_arr, categories=['a', 'b', 'c'])\n\t    tm.assert_numpy_array_equal(c2.__array__(), exp_arr)\n\t    c2 = Categorical(exp_arr, categories=['c', 'b', 'a'])\n\t    tm.assert_numpy_array_equal(c2.__array__(), exp_arr)\n\t    msg = 'Categorical categories must be unique'\n\t    with pytest.raises(ValueError, match=msg):\n\t        Categorical([1, 2], [1, 2, 2])\n\t    with pytest.raises(ValueError, match=msg):\n\t        Categorical(['a', 'b'], ['a', 'b', 'b'])\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    assert not c1.ordered\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(c1)\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(c1, categories=['a', 'b', 'c'])\n\t    tm.assert_numpy_array_equal(c1.__array__(), c2.__array__())\n\t    tm.assert_index_equal(c2.categories, Index(['a', 'b', 'c']))\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(Series(c1))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'c', 'b'])\n\t    c2 = Categorical(Series(c1))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'])\n\t    c2 = Categorical(Series(['a', 'b', 'c', 'a']))\n\t    tm.assert_categorical_equal(c1, c2)\n\t    c1 = Categorical(['a', 'b', 'c', 'a'], categories=['a', 'b', 'c', 'd'])\n\t    c2 = Categorical(Series(['a', 'b', 'c', 'a']), categories=['a', 'b',\n\t        'c', 'd'])\n\t    tm.assert_categorical_equal(c1, c2)\n\t    cat = Categorical([1, 2, 3, np.nan], categories=[1, 2, 3])\n\t    assert is_integer_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1, 2, 3])\n\t    assert is_integer_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1, 2.0, 3])\n\t    assert is_float_dtype(cat.categories)\n\t    cat = Categorical([np.nan, 1.0, 2.0, 3.0])\n\t    assert is_float_dtype(cat.categories)\n\t    cat = Categorical([1])\n\t    assert len(cat.categories) == 1\n\t    assert cat.categories[0] == 1\n\t    assert len(cat.codes) == 1\n\t    assert cat.codes[0] == 0\n\t    cat = Categorical(['a'])\n\t    assert len(cat.categories) == 1\n\t    assert cat.categories[0] == 'a'\n\t    assert len(cat.codes) == 1\n\t    assert cat.codes[0] == 0\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], categories=['a', 'b', 'c'])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], categories=[3, 4, 5])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical([0, 1, 2, 0, 1, 2], [1, 2, 3])\n\t        cat = Categorical([1, 2], categories=[1, 2, 3])\n\t    with tm.assert_produces_warning(None):\n\t        Categorical(np.array([], dtype='int64'), categories=[3, 2, 1],\n\t            ordered=True)\n\t\nTestCategoricalConstructors().test_constructor()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/categorical/test_constructors.py"}], "instruction": "Functionality: Determine if the given array or dtype is of a floating-point data type.\n\nInputs: \n- arr_or_dtype: array-like or dtype. The array or data type to be checked. This can be any object that can be interpreted as a data type or an array-like object.\n\nOutputs:\n- A boolean value indicating whether the input array or dtype is of a floating-point data type. True is returned if the input is a float type, False otherwise.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_float_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "isin", "full_method_name": "isin", "method_path": "../srcdata/Computation/pandas/pandas/core/algorithms.py", "method_code": "from __future__ import annotations\nimport decimal\nimport operator\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos\nfrom pandas._libs import hashtable as htable\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import TakeIndexer\nfrom pandas._typing import npt\nfrom pandas.util._decorators import doc\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.common import ensure_float64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDatetimeArray\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.array_algos.take import take_nd\nfrom pandas.core.construction import array as pd_array\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import validate_indices\nfrom pandas import Categorical\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.reshape.tile import cut\nfrom pandas.core.internals.construction import to_arrays\nfrom pandas.core.sorting import lexsort_indexer\ndef isin(comps: ListLike, values: ListLike) ->npt.NDArray[np.bool_]:\n    \"\"\"\n    Compute the isin boolean array.\n\n    Parameters\n    ----------\n    comps : list-like\n    values : list-like\n\n    Returns\n    -------\n    ndarray[bool]\n        Same length as `comps`.\n    \"\"\"\n    if not is_list_like(comps):\n        raise TypeError(\n            f'only list-like objects are allowed to be passed to isin(), you passed a `{type(comps).__name__}`'\n            )\n    if not is_list_like(values):\n        raise TypeError(\n            f'only list-like objects are allowed to be passed to isin(), you passed a `{type(values).__name__}`'\n            )\n    if not isinstance(values, (ABCIndex, ABCSeries, ABCExtensionArray, np.\n        ndarray)):\n        orig_values = list(values)\n        values = _ensure_arraylike(orig_values, func_name='isin-targets')\n        if len(values\n            ) > 0 and values.dtype.kind in 'iufcb' and not is_signed_integer_dtype(\n            comps):\n            values = construct_1d_object_array_from_listlike(orig_values)\n    elif isinstance(values, ABCMultiIndex):\n        values = np.array(values)\n    else:\n        values = extract_array(values, extract_numpy=True, extract_range=True)\n    comps_array = _ensure_arraylike(comps, func_name='isin')\n    comps_array = extract_array(comps_array, extract_numpy=True)\n    if not isinstance(comps_array, np.ndarray):\n        return comps_array.isin(values)\n    elif needs_i8_conversion(comps_array.dtype):\n        return pd_array(comps_array).isin(values)\n    elif needs_i8_conversion(values.dtype) and not is_object_dtype(comps_array\n        .dtype):\n        return np.zeros(comps_array.shape, dtype=bool)\n    elif needs_i8_conversion(values.dtype):\n        return isin(comps_array, values.astype(object))\n    elif isinstance(values.dtype, ExtensionDtype):\n        return isin(np.asarray(comps_array), np.asarray(values))\n    if len(comps_array) > _MINIMUM_COMP_ARR_LEN and len(values\n        ) <= 26 and comps_array.dtype != object:\n        if isna(values).any():\n\n            def f(c, v):\n                return np.logical_or(np.isin(c, v).ravel(), np.isnan(c))\n        else:\n            f = lambda a, b: np.isin(a, b).ravel()\n    else:\n        common = np_find_common_type(values.dtype, comps_array.dtype)\n        values = values.astype(common, copy=False)\n        comps_array = comps_array.astype(common, copy=False)\n        f = htable.ismember\n    return f(comps_array, values)", "test_code_list": [{"test_code": "from collections.abc import Generator\nfrom contextlib import contextmanager\nimport re\nimport struct\nimport tracemalloc\nimport numpy as np\nimport pytest\nfrom pandas._libs import hashtable as ht\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.algorithms import isin\ndef test_ismember_tuple_with_nans():\n    values = np.empty(2, dtype=object)\n    values[:] = [('a', float('nan')), ('b', 1)]\n    comps = [('a', float('nan'))]\n    result = isin(values, comps)\n    expected = np.array([True, False], dtype=np.bool_)\n    tm.assert_numpy_array_equal(result, expected)\n\ntest_ismember_tuple_with_nans()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/libs/test_hashtable.py"}, {"test_code": "from collections.abc import Generator\nfrom contextlib import contextmanager\nimport re\nimport struct\nimport tracemalloc\nimport numpy as np\nimport pytest\nfrom pandas._libs import hashtable as ht\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.algorithms import isin\ndef test_float_complex_int_are_equal_as_objects():\n    values = ['a', 5, 5.0, 5.0 + 0.0j]\n    comps = list(range(129))\n    result = isin(np.array(values, dtype=object), np.asarray(comps))\n    expected = np.array([False, True, True, True], dtype=np.bool_)\n    tm.assert_numpy_array_equal(result, expected)\n\ntest_float_complex_int_are_equal_as_objects()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/libs/test_hashtable.py"}], "instruction": "Functionality: The isin function computes a boolean array indicating whether each element in the input array 'comps' is found within the 'values' array.\n\nInputs:\n- comps: A list-like object whose elements will be checked against the 'values' array.\n- values: A list-like object that contains the values to check against the 'comps' array.\n\nOutputs:\n- An ndarray of booleans with the same length as 'comps', where each element indicates whether the corresponding element in 'comps' is found in 'values'.", "method_code_mask": "from __future__ import annotations\nimport decimal\nimport operator\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos\nfrom pandas._libs import hashtable as htable\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import TakeIndexer\nfrom pandas._typing import npt\nfrom pandas.util._decorators import doc\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.common import ensure_float64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDatetimeArray\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.array_algos.take import take_nd\nfrom pandas.core.construction import array as pd_array\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import validate_indices\nfrom pandas import Categorical\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.reshape.tile import cut\nfrom pandas.core.internals.construction import to_arrays\nfrom pandas.core.sorting import lexsort_indexer\n\n\ndef isin(comps: ListLike, values: ListLike) ->npt.NDArray[np.bool_]: [MASK]\n"}
{"method_name": "value_counts_internal", "full_method_name": "value_counts_internal", "method_path": "../srcdata/Computation/pandas/pandas/core/algorithms.py", "method_code": "from __future__ import annotations\nimport decimal\nimport operator\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos\nfrom pandas._libs import hashtable as htable\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import TakeIndexer\nfrom pandas._typing import npt\nfrom pandas.util._decorators import doc\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.common import ensure_float64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDatetimeArray\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.array_algos.take import take_nd\nfrom pandas.core.construction import array as pd_array\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import validate_indices\nfrom pandas import Categorical\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.reshape.tile import cut\nfrom pandas.core.internals.construction import to_arrays\nfrom pandas.core.sorting import lexsort_indexer\ndef value_counts_internal(values, sort: bool=True, ascending: bool=False,\n    normalize: bool=False, bins=None, dropna: bool=True) ->Series:\n    from pandas import Index, Series\n    index_name = getattr(values, 'name', None)\n    name = 'proportion' if normalize else 'count'\n    if bins is not None:\n        from pandas.core.reshape.tile import cut\n        if isinstance(values, Series):\n            values = values._values\n        try:\n            ii = cut(values, bins, include_lowest=True)\n        except TypeError as err:\n            raise TypeError('bins argument only works with numeric data.'\n                ) from err\n        result = ii.value_counts(dropna=dropna)\n        result.name = name\n        result = result[result.index.notna()]\n        result.index = result.index.astype('interval')\n        result = result.sort_index()\n        if dropna and (result._values == 0).all():\n            result = result.iloc[0:0]\n        counts = np.array([len(ii)])\n    elif is_extension_array_dtype(values):\n        result = Series(values, copy=False)._values.value_counts(dropna=dropna)\n        result.name = name\n        result.index.name = index_name\n        counts = result._values\n        if not isinstance(counts, np.ndarray):\n            counts = np.asarray(counts)\n    elif isinstance(values, ABCMultiIndex):\n        levels = list(range(values.nlevels))\n        result = Series(index=values, name=name).groupby(level=levels,\n            dropna=dropna).size()\n        result.index.names = values.names\n        counts = result._values\n    else:\n        values = _ensure_arraylike(values, func_name='value_counts')\n        keys, counts, _ = value_counts_arraylike(values, dropna)\n        if keys.dtype == np.float16:\n            keys = keys.astype(np.float32)\n        idx = Index(keys, dtype=keys.dtype, name=index_name)\n        result = Series(counts, index=idx, name=name, copy=False)\n    if sort:\n        result = result.sort_values(ascending=ascending)\n    if normalize:\n        result = result / counts.sum()\n    return result", "test_code_list": [{"test_code": "from datetime import datetime\nimport struct\nimport numpy as np\nimport pytest\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import hashtable as ht\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Period\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import cut\nfrom pandas import date_range\nfrom pandas import timedelta_range\nfrom pandas import to_datetime\nfrom pandas import to_timedelta\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\nimport pandas.core.common as com\n\nclass TestValueCounts():\n\tdef test_value_counts(self):\n\t    arr = np.random.default_rng(1234).standard_normal(4)\n\t    factor = cut(arr, 4)\n\t    result = value_counts_internal(factor)\n\t    breaks = [-1.606, -1.018, -0.431, 0.155, 0.741]\n\t    index = IntervalIndex.from_breaks(breaks).astype(CategoricalDtype(\n\t        ordered=True))\n\t    expected = Series([1, 0, 2, 1], index=index, name='count')\n\t    tm.assert_series_equal(result.sort_index(), expected.sort_index())\n\t\nTestValueCounts().test_value_counts()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_algos.py"}, {"test_code": "from datetime import datetime\nimport struct\nimport numpy as np\nimport pytest\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import hashtable as ht\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Period\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import cut\nfrom pandas import date_range\nfrom pandas import timedelta_range\nfrom pandas import to_datetime\nfrom pandas import to_timedelta\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\nimport pandas.core.common as com\n\nclass TestValueCounts():\n\tdef test_value_counts_bins(self):\n\t    s = [1, 2, 3, 4]\n\t    result = value_counts_internal(s, bins=1)\n\t    expected = Series([4], index=IntervalIndex.from_tuples([(0.996, 4.0)]),\n\t        name='count')\n\t    tm.assert_series_equal(result, expected)\n\t    result = value_counts_internal(s, bins=2, sort=False)\n\t    expected = Series([2, 2], index=IntervalIndex.from_tuples([(0.996, 2.5),\n\t        (2.5, 4.0)]), name='count')\n\t    tm.assert_series_equal(result, expected)\n\t\nTestValueCounts().test_value_counts_bins()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_algos.py"}], "instruction": "Functionality: The value_counts_internal function is designed to count the frequency of each unique value in a given input (values). It can sort the frequencies, adjust the order of the results, normalize the frequencies to proportions, and optionally handle binning for numeric data. It is capable of working with various data types including Series, ExtensionArray, and MultiIndex.\n\nInputs: \n- values: This is the input data from which unique values and their frequencies are to be counted. It could be a pandas Series, ExtensionArray, MultiIndex, or any array-like object.\n- sort (bool, optional): Determines whether the result should be sorted by frequency. Default is True.\n- ascending (bool, optional): Determines the sorting order if sort is True. If False, the result is sorted in descending order. Default is False.\n- normalize (bool, optional): If True, the frequencies are normalized to proportions. Default is False.\n- bins (optional): If provided, the input values are binned into intervals before counting. This is typically used for numeric data. Default is None.\n- dropna (bool, optional): Determines if NaN values should be dropped before counting. Default is True.\n\nOutputs: \n- Series: A pandas Series object containing the unique values as the index and their frequencies or proportions as the values. The Series name is 'proportion' if normalize is True, otherwise it is 'count'. The index name is carried over from the input 'values' if available.", "method_code_mask": "from __future__ import annotations\nimport decimal\nimport operator\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos\nfrom pandas._libs import hashtable as htable\nfrom pandas._libs import iNaT\nfrom pandas._libs import lib\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import TakeIndexer\nfrom pandas._typing import npt\nfrom pandas.util._decorators import doc\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.common import ensure_float64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_complex_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_extension_array_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCDatetimeArray\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.array_algos.take import take_nd\nfrom pandas.core.construction import array as pd_array\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import validate_indices\nfrom pandas import Categorical\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.reshape.tile import cut\nfrom pandas.core.internals.construction import to_arrays\nfrom pandas.core.sorting import lexsort_indexer\n\n\ndef value_counts_internal(values, sort: bool=True, ascending: bool=False,\n    normalize: bool=False, bins=None, dropna: bool=True) ->Series: [MASK]\n"}
{"method_name": "standardize_mapping", "full_method_name": "standardize_mapping", "method_path": "../srcdata/Computation/pandas/pandas/core/common.py", "method_code": "from __future__ import annotations\nimport builtins\nfrom collections import abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Collection\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat.numpy import np_version_gte1p24\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import iterable_not_string\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import NpDtype\nfrom pandas._typing import RandomState\nfrom pandas._typing import T\nfrom pandas import Index\ndef standardize_mapping(into):\n    \"\"\"\n    Helper function to standardize a supplied mapping.\n\n    Parameters\n    ----------\n    into : instance or subclass of collections.abc.Mapping\n        Must be a class, an initialized collections.defaultdict,\n        or an instance of a collections.abc.Mapping subclass.\n\n    Returns\n    -------\n    mapping : a collections.abc.Mapping subclass or other constructor\n        a callable object that can accept an iterator to create\n        the desired Mapping.\n\n    See Also\n    --------\n    DataFrame.to_dict\n    Series.to_dict\n    \"\"\"\n    if not inspect.isclass(into):\n        if isinstance(into, defaultdict):\n            return partial(defaultdict, into.default_factory)\n        into = type(into)\n    if not issubclass(into, abc.Mapping):\n        raise TypeError(f'unsupported type: {into}')\n    if into == defaultdict:\n        raise TypeError('to_dict() only accepts initialized defaultdicts')\n    return into", "test_code_list": [{"test_code": "import collections\nfrom functools import partial\nimport string\nimport subprocess\nimport sys\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.util.version import Version\ndef test_standardize_mapping():\n    msg = 'to_dict\\\\(\\\\) only accepts initialized defaultdicts'\n    with pytest.raises(TypeError, match=msg):\n        standardize_mapping(collections.defaultdict)\n    msg = \"unsupported type: <class 'list'>\"\n    with pytest.raises(TypeError, match=msg):\n        standardize_mapping([])\n    with pytest.raises(TypeError, match=msg):\n        standardize_mapping(list)\n    fill = {'bad': 'data'}\n    assert standardize_mapping(fill) == dict\n    assert standardize_mapping({}) == dict\n    dd = collections.defaultdict(list)\n    assert isinstance(standardize_mapping(dd), partial)\n\ntest_standardize_mapping()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_common.py"}], "instruction": "Functionality: The standardize_mapping function is designed to ensure that a given mapping object conforms to a standardized collections.abc.Mapping subclass or constructor. This function is particularly useful for handling various types of mappings in a uniform way, making it easier to work with dictionaries or similar structures in data processing tasks.\n\nInputs: \n- into: This parameter accepts an instance or a subclass of collections.abc.Mapping. It could be a class definition, an initialized collections.defaultdict, or any instance of a collections.abc.Mapping subclass.\n\nOutputs: \n- mapping: A callable object that can take an iterator as an argument to create a standardized Mapping. This output is either a subclass of collections.abc.Mapping or a constructor that adheres to the Mapping protocol. If the input was a collections.defaultdict, the output will be a partially initialized defaultdict, preserving the default factory function.", "method_code_mask": "from __future__ import annotations\nimport builtins\nfrom collections import abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Collection\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat.numpy import np_version_gte1p24\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import iterable_not_string\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import NpDtype\nfrom pandas._typing import RandomState\nfrom pandas._typing import T\nfrom pandas import Index\n\n\ndef standardize_mapping(into): [MASK]\n"}
{"method_name": "round_trip_pickle", "full_method_name": "round_trip_pickle", "method_path": "../srcdata/Computation/pandas/pandas/_testing/_io.py", "method_code": "from __future__ import annotations\nimport gzip\nimport io\nimport pathlib\nimport tarfile\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport uuid\nimport zipfile\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas._testing.contexts import ensure_clean\nfrom collections.abc import Callable\nfrom pandas._typing import FilePath\nfrom pandas._typing import ReadPickleBuffer\nfrom pandas import DataFrame\nfrom pandas import Series\nimport bz2\nimport lzma\ndef round_trip_pickle(obj: Any, path: (FilePath | ReadPickleBuffer | None)=None\n    ) ->(DataFrame | Series):\n    \"\"\"\n    Pickle an object and then read it again.\n\n    Parameters\n    ----------\n    obj : any object\n        The object to pickle and then re-read.\n    path : str, path object or file-like object, default None\n        The path where the pickled object is written and then read.\n\n    Returns\n    -------\n    pandas object\n        The original object that was pickled and then re-read.\n    \"\"\"\n    _path = path\n    if _path is None:\n        _path = f'__{uuid.uuid4()}__.pickle'\n    with ensure_clean(_path) as temp_path:\n        pd.to_pickle(obj, temp_path)\n        return pd.read_pickle(temp_path)", "test_code_list": [{"test_code": "import re\nimport weakref\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_categorical_dtype\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_dtype_equal\nfrom pandas.core.dtypes.common import is_interval_dtype\nfrom pandas.core.dtypes.common import is_period_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import SparseDtype\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import SparseArray\nclass Base:\n\n    def test_hash(self, dtype):\n        hash(dtype)\n\n    def test_equality_invalid(self, dtype):\n        assert not dtype == 'foo'\n        assert not is_dtype_equal(dtype, np.int64)\n\n    def test_numpy_informed(self, dtype):\n        msg = '|'.join(['data type not understood',\n            \"Cannot interpret '.*' as a data type\"])\n        with pytest.raises(TypeError, match=msg):\n            np.dtype(dtype)\n        assert not dtype == np.str_\n        assert not np.str_ == dtype\n\n    def test_pickle(self, dtype):\n        type(dtype).reset_cache()\n        assert not len(dtype._cache_dtypes)\n        result = round_trip_pickle(dtype)\n        if not isinstance(dtype, PeriodDtype):\n            assert not len(dtype._cache_dtypes)\n        assert result == dtype\n\nclass TestIntervalDtype(Base):\n\tdef test_unpickling_without_closed(self):\n\t    dtype = IntervalDtype('interval')\n\t    assert dtype._closed is None\n\t    round_trip_pickle(dtype)\n\t\nTestIntervalDtype().test_unpickling_without_closed()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_dtypes.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import conversion\nfrom pandas._libs.tslibs import timezones\nimport pandas._libs.tslibs.offsets as liboffsets\nfrom pandas._libs.tslibs.offsets import _get_offset\nfrom pandas._libs.tslibs.offsets import _offset_map\nfrom pandas._libs.tslibs.offsets import to_offset\nfrom pandas._libs.tslibs.period import INVALID_FREQ_ERR_MSG\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Series\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.tests.tseries.offsets.common import WeekDay\nfrom pandas.tseries import offsets\nfrom pandas.tseries.offsets import FY5253\nfrom pandas.tseries.offsets import BDay\nfrom pandas.tseries.offsets import BMonthEnd\nfrom pandas.tseries.offsets import BusinessHour\nfrom pandas.tseries.offsets import CustomBusinessDay\nfrom pandas.tseries.offsets import CustomBusinessHour\nfrom pandas.tseries.offsets import CustomBusinessMonthBegin\nfrom pandas.tseries.offsets import CustomBusinessMonthEnd\nfrom pandas.tseries.offsets import DateOffset\nfrom pandas.tseries.offsets import Easter\nfrom pandas.tseries.offsets import FY5253Quarter\nfrom pandas.tseries.offsets import LastWeekOfMonth\nfrom pandas.tseries.offsets import MonthBegin\nfrom pandas.tseries.offsets import Nano\nfrom pandas.tseries.offsets import Tick\nfrom pandas.tseries.offsets import Week\nfrom pandas.tseries.offsets import WeekOfMonth\n\nclass TestCommon():\n\tdef test_pickle_dateoffset_odd_inputs(self):\n\t    off = DateOffset(months=12)\n\t    res = round_trip_pickle(off)\n\t    assert off == res\n\t    base_dt = datetime(2020, 1, 1)\n\t    assert base_dt + off == base_dt + res\n\t\nTestCommon().test_pickle_dateoffset_odd_inputs()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/tseries/offsets/test_offsets.py"}, {"test_code": "import operator\nimport numpy as np\nimport pytest\nimport pandas as pd\nimport pandas._testing as tm\ndef test_pickle():\n    a = pd.Series([1, 2]).set_flags(allows_duplicate_labels=False)\n    b = round_trip_pickle(a)\n    tm.assert_series_equal(a, b)\n    a = pd.DataFrame({'A': []}).set_flags(allows_duplicate_labels=False)\n    b = round_trip_pickle(a)\n    tm.assert_frame_equal(a, b)\n\ntest_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/generic/test_duplicate_labels.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas._libs import Timedelta\nfrom pandas._libs import lib\nfrom pandas._libs import writers as libwriters\nfrom pandas.compat import IS64\nfrom pandas import Index\nimport pandas._testing as tm\ndef test_no_default_pickle():\n    obj = round_trip_pickle(lib.no_default)\n    assert obj is lib.no_default\n\ntest_no_default_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/libs/test_lib.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nimport pandas._testing as tm\n\nclass TestDataFrameSubclassing():\n\tdef test_dataframe_metadata(self):\n\t    df = tm.SubclassedDataFrame({'X': [1, 2, 3], 'Y': [1, 2, 3]}, index=[\n\t        'a', 'b', 'c'])\n\t    df.testattr = 'XXX'\n\t    assert df.testattr == 'XXX'\n\t    assert df[['X']].testattr == 'XXX'\n\t    assert df.loc[['a', 'b'], :].testattr == 'XXX'\n\t    assert df.iloc[[0, 1], :].testattr == 'XXX'\n\t    assert df.iloc[0:1, :].testattr == 'XXX'\n\t    unpickled = round_trip_pickle(df)\n\t    tm.assert_frame_equal(df, unpickled)\n\t    assert df._metadata == unpickled._metadata\n\t    assert df.testattr == unpickled.testattr\n\t\nTestDataFrameSubclassing().test_dataframe_metadata()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/frame/test_subclass.py"}, {"test_code": "import bz2\nimport datetime\nimport functools\nfrom functools import partial\nimport gzip\nimport io\nimport os\nfrom pathlib import Path\nimport pickle\nimport shutil\nimport tarfile\nfrom typing import Any\nimport uuid\nimport zipfile\nimport numpy as np\nimport pytest\nfrom pandas.compat import is_platform_little_endian\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import period_range\nimport pandas._testing as tm\nfrom pandas.tests.io.generate_legacy_storage_files import create_pickle_data\nimport pandas.io.common as icom\nfrom pandas.tseries.offsets import Day\nfrom pandas.tseries.offsets import MonthEnd\nimport lzma\ndef test_pickle_timeseries_periodindex():\n    prng = period_range('1/1/2011', '1/1/2012', freq='M')\n    ts = Series(np.random.default_rng(2).standard_normal(len(prng)), prng)\n    new_ts = round_trip_pickle(ts)\n    assert new_ts.index.freqstr == 'M'\n\ntest_pickle_timeseries_periodindex()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_pickle.py"}, {"test_code": "import bz2\nimport datetime\nimport functools\nfrom functools import partial\nimport gzip\nimport io\nimport os\nfrom pathlib import Path\nimport pickle\nimport shutil\nimport tarfile\nfrom typing import Any\nimport uuid\nimport zipfile\nimport numpy as np\nimport pytest\nfrom pandas.compat import is_platform_little_endian\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import period_range\nimport pandas._testing as tm\nfrom pandas.tests.io.generate_legacy_storage_files import create_pickle_data\nimport pandas.io.common as icom\nfrom pandas.tseries.offsets import Day\nfrom pandas.tseries.offsets import MonthEnd\nimport lzma\ndef test_pickle_preserves_block_ndim():\n    ser = Series(list('abc')).astype('category').iloc[[0]]\n    res = round_trip_pickle(ser)\n    assert res._mgr.blocks[0].ndim == 1\n    assert res._mgr.blocks[0].shape == (1,)\n    tm.assert_series_equal(res[[True]], ser)\n\ntest_pickle_preserves_block_ndim()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_pickle.py"}, {"test_code": "from datetime import date\nfrom datetime import time\nfrom datetime import timedelta\nimport pickle\nimport numpy as np\nimport pytest\nfrom pandas._libs.missing import NA\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nimport pandas._testing as tm\ndef test_pickle_roundtrip_pandas():\n    result = round_trip_pickle(NA)\n    assert result is NA\n\ntest_pickle_roundtrip_pandas()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/scalar/test_na_scalar.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nimport operator\nimport zoneinfo\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p24p3\nfrom pandas import DatetimeIndex\nfrom pandas import DatetimeTZDtype\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Period\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import TimedeltaIndex\nfrom pandas import Timestamp\nfrom pandas import isna\nfrom pandas import offsets\nimport pandas._testing as tm\nfrom pandas.core import roperator\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\ndef test_pickle():\n    p = round_trip_pickle(NaT)\n    assert p is NaT\n\ntest_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/scalar/test_nat.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs.ccalendar import DAYS\nfrom pandas._libs.tslibs.ccalendar import MONTHS\nfrom pandas._libs.tslibs.np_datetime import OutOfBoundsDatetime\nfrom pandas._libs.tslibs.parsing import DateParseError\nfrom pandas._libs.tslibs.period import INVALID_FREQ_ERR_MSG\nfrom pandas import NaT\nfrom pandas import Period\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import offsets\nimport pandas._testing as tm\n\nclass TestPeriodMethods():\n\tdef test_round_trip(self):\n\t    p = Period('2000Q1')\n\t    new_p = round_trip_pickle(p)\n\t    assert new_p == p\n\t\nTestPeriodMethods().test_round_trip()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/scalar/period/test_period.py"}, {"test_code": "from datetime import timedelta\nimport sys\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.errors import OutOfBoundsTimedelta\nfrom pandas import Timedelta\nfrom pandas import to_timedelta\nimport pandas._testing as tm\n\nclass TestTimedeltas():\n\tdef test_pickle(self):\n\t    v = Timedelta('1 days 10:11:12.0123456')\n\t    v_p = round_trip_pickle(v)\n\t    assert v == v_p\n\t\nTestTimedeltas().test_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/scalar/timedelta/test_timedelta.py"}, {"test_code": "from pandas import Index\nimport pandas._testing as tm\ndef test_pickle_preserves_object_dtype():\n    index = Index([1, 2, 3], dtype=object)\n    result = round_trip_pickle(index)\n    assert result.dtype == object\n    tm.assert_index_equal(index, result)\n\ntest_pickle_preserves_object_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/base_class/test_pickle.py"}, {"test_code": "import pytest\nfrom pandas import NaT\nfrom pandas import date_range\nfrom pandas import to_datetime\nimport pandas._testing as tm\n\nclass TestPickle():\n\tdef test_pickle(self):\n\t    idx = to_datetime(['2013-01-01', NaT, '2014-01-06'])\n\t    idx_p = round_trip_pickle(idx)\n\t    assert idx_p[0] == idx[0]\n\t    assert idx_p[1] is NaT\n\t    assert idx_p[2] == idx[2]\n\t\nTestPickle().test_pickle()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/datetimes/test_pickle.py"}, {"test_code": "import pytest\nfrom pandas import NaT\nfrom pandas import date_range\nfrom pandas import to_datetime\nimport pandas._testing as tm\n\nclass TestPickle():\n\tdef test_pickle_dont_infer_freq(self):\n\t    idx = date_range('1750-1-1', '2050-1-1', freq='7D')\n\t    idx_p = round_trip_pickle(idx)\n\t    tm.assert_index_equal(idx, idx_p)\n\t\nTestPickle().test_pickle_dont_infer_freq()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/datetimes/test_pickle.py"}, {"test_code": "import pytest\nfrom pandas import NaT\nfrom pandas import date_range\nfrom pandas import to_datetime\nimport pandas._testing as tm\n\nclass TestPickle():\n\tdef test_pickle_after_set_freq(self):\n\t    dti = date_range('20130101', periods=3, tz='US/Eastern', name='foo')\n\t    dti = dti._with_freq(None)\n\t    res = round_trip_pickle(dti)\n\t    tm.assert_index_equal(res, dti)\n\t\nTestPickle().test_pickle_after_set_freq()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/datetimes/test_pickle.py"}, {"test_code": "import pytest\nfrom pandas import NaT\nfrom pandas import date_range\nfrom pandas import to_datetime\nimport pandas._testing as tm\n\nclass TestPickle():\n\tdef test_roundtrip_pickle_with_tz(self):\n\t    index = date_range('20130101', periods=3, tz='US/Eastern', name='foo')\n\t    unpickled = round_trip_pickle(index)\n\t    tm.assert_index_equal(index, unpickled)\n\t\nTestPickle().test_roundtrip_pickle_with_tz()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/datetimes/test_pickle.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NaT\nfrom pandas import PeriodIndex\nfrom pandas import period_range\nimport pandas._testing as tm\nfrom pandas.tseries import offsets\n\nclass TestPickle():\n\tdef test_pickle_freq(self):\n\t    prng = period_range('1/1/2011', '1/1/2012', freq='M')\n\t    new_prng = round_trip_pickle(prng)\n\t    assert new_prng.freq == offsets.MonthEnd()\n\t    assert new_prng.freqstr == 'M'\n\t\nTestPickle().test_pickle_freq()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/period/test_pickle.py"}, {"test_code": "from pandas import timedelta_range\nimport pandas._testing as tm\n\nclass TestPickle():\n\tdef test_pickle_after_set_freq(self):\n\t    tdi = timedelta_range('1 day', periods=4, freq='s')\n\t    tdi = tdi._with_freq(None)\n\t    res = round_trip_pickle(tdi)\n\t    tm.assert_index_equal(res, tdi)\n\t\nTestPickle().test_pickle_after_set_freq()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/timedeltas/test_pickle.py"}], "instruction": "Functionality: The round_trip_pickle function is designed to serialize an object using pandas' pickle functionality and then deserialize it back to its original form. This is useful for testing the preservation of an object's integrity through the serialization and deserialization process.\n\nInputs:\n- obj: Any object that is to be pickled and then re-read. This can be any object that is compatible with pandas' pickle routines, such as a DataFrame or Series.\n- path: Optional. A string, path object, or file-like object that specifies the location where the pickled object is to be written and then read. If not provided (None), a temporary path is automatically generated for the operation.\n\nOutputs:\n- pandas object: The function returns the original object that was pickled and then re-read. This allows for verification that the object has been successfully pickled and unpickled without any loss of information or change in its structure.", "method_code_mask": "from __future__ import annotations\nimport gzip\nimport io\nimport pathlib\nimport tarfile\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport uuid\nimport zipfile\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas._testing.contexts import ensure_clean\nfrom collections.abc import Callable\nfrom pandas._typing import FilePath\nfrom pandas._typing import ReadPickleBuffer\nfrom pandas import DataFrame\nfrom pandas import Series\nimport bz2\nimport lzma\n\n\ndef round_trip_pickle(obj: Any, path: (FilePath | ReadPickleBuffer | None)=None\n    ) ->(DataFrame | Series): [MASK]\n"}
{"method_name": "is_bool_indexer", "full_method_name": "is_bool_indexer", "method_path": "../srcdata/Computation/pandas/pandas/core/common.py", "method_code": "from __future__ import annotations\nimport builtins\nfrom collections import abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Collection\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat.numpy import np_version_gte1p24\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import iterable_not_string\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import NpDtype\nfrom pandas._typing import RandomState\nfrom pandas._typing import T\nfrom pandas import Index\ndef is_bool_indexer(key: Any) ->bool:\n    \"\"\"\n    Check whether `key` is a valid boolean indexer.\n\n    Parameters\n    ----------\n    key : Any\n        Only list-likes may be considered boolean indexers.\n        All other types are not considered a boolean indexer.\n        For array-like input, boolean ndarrays or ExtensionArrays\n        with ``_is_boolean`` set are considered boolean indexers.\n\n    Returns\n    -------\n    bool\n        Whether `key` is a valid boolean indexer.\n\n    Raises\n    ------\n    ValueError\n        When the array is an object-dtype ndarray or ExtensionArray\n        and contains missing values.\n\n    See Also\n    --------\n    check_array_indexer : Check that `key` is a valid array to index,\n        and convert to an ndarray.\n    \"\"\"\n    if isinstance(key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\n        ) and not isinstance(key, ABCMultiIndex):\n        if key.dtype == np.object_:\n            key_array = np.asarray(key)\n            if not lib.is_bool_array(key_array):\n                na_msg = (\n                    'Cannot mask with non-boolean array containing NA / NaN values'\n                    )\n                if lib.is_bool_array(key_array, skipna=True):\n                    raise ValueError(na_msg)\n                return False\n            return True\n        elif is_bool_dtype(key.dtype):\n            return True\n    elif isinstance(key, list):\n        if len(key) > 0:\n            if type(key) is not list:\n                key = list(key)\n            return lib.is_bool_list(key)\n    return False", "test_code_list": [{"test_code": "import collections\nfrom functools import partial\nimport string\nimport subprocess\nimport sys\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.util.version import Version\n\nclass TestIsBoolIndexer():\n\tdef test_non_bool_array_with_na(self):\n\t    arr = np.array(['A', 'B', np.nan], dtype=object)\n\t    assert not is_bool_indexer(arr)\n\t\nTestIsBoolIndexer().test_non_bool_array_with_na()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_common.py"}, {"test_code": "import collections\nfrom functools import partial\nimport string\nimport subprocess\nimport sys\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.util.version import Version\n\nclass TestIsBoolIndexer():\n\tdef test_list_subclass(self):\n\t\n\t\n\t    class MyList(list):\n\t        pass\n\t    val = MyList(['a'])\n\t    assert not is_bool_indexer(val)\n\t    val = MyList([True])\n\t    assert is_bool_indexer(val)\n\t\nTestIsBoolIndexer().test_list_subclass()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_common.py"}, {"test_code": "import collections\nfrom functools import partial\nimport string\nimport subprocess\nimport sys\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.util.version import Version\n\nclass TestIsBoolIndexer():\n\tdef test_frozenlist(self):\n\t    data = {'col1': [1, 2], 'col2': [3, 4]}\n\t    df = pd.DataFrame(data=data)\n\t    frozen = df.index.names[1:]\n\t    assert not is_bool_indexer(frozen)\n\t    result = df[frozen]\n\t    expected = df[[]]\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestIsBoolIndexer().test_frozenlist()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/test_common.py"}], "instruction": "Functionality: Check if the given input is a valid boolean indexer for an array or list-like structure. This involves determining if the input is a list-like object (excluding multi-indexes) with boolean values or an array-like object with a boolean dtype, considering special cases for object-dtype arrays and ExtensionArrays with missing values.\n\nInputs: \n- key: Any\n  - The input to be checked for being a valid boolean indexer. It can be any data type or structure, but the function will primarily focus on list-like structures and arrays.\n\nOutputs:\n- bool\n  - Returns True if `key` is determined to be a valid boolean indexer according to the criteria mentioned in the functionality. Returns False otherwise.\n\nNote: The function does not return any test cases and relies on internal logic to determine if the input is a boolean indexer. It also raises a ValueError if the input is an object-dtype array or ExtensionArray containing missing values.", "method_code_mask": "from __future__ import annotations\nimport builtins\nfrom collections import abc\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Collection\nfrom collections.abc import Generator\nfrom collections.abc import Hashable\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nimport contextlib\nfrom functools import partial\nimport inspect\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat.numpy import np_version_gte1p24\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import iterable_not_string\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import NpDtype\nfrom pandas._typing import RandomState\nfrom pandas._typing import T\nfrom pandas import Index\n\n\ndef is_bool_indexer(key: Any) ->bool: [MASK]\n"}
{"method_name": "pandas_dtype", "full_method_name": "pandas_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef pandas_dtype(dtype) ->DtypeObj:\n    \"\"\"\n    Convert input into a pandas only dtype object or a numpy dtype object.\n\n    Parameters\n    ----------\n    dtype : object to be converted\n\n    Returns\n    -------\n    np.dtype or a pandas dtype\n\n    Raises\n    ------\n    TypeError if not a dtype\n\n    Examples\n    --------\n    >>> pd.api.types.pandas_dtype(int)\n    dtype('int64')\n    \"\"\"\n    if isinstance(dtype, np.ndarray):\n        return dtype.dtype\n    elif isinstance(dtype, (np.dtype, ExtensionDtype)):\n        return dtype\n    result = registry.find(dtype)\n    if result is not None:\n        if isinstance(result, type):\n            warnings.warn(\n                f'Instantiating {result.__name__} without any arguments.Pass a {result.__name__} instance to silence this warning.'\n                , UserWarning, stacklevel=find_stack_level())\n            result = result()\n        return result\n    try:\n        with warnings.catch_warnings():\n            warnings.simplefilter('always', DeprecationWarning)\n            npdtype = np.dtype(dtype)\n    except SyntaxError as err:\n        raise TypeError(f\"data type '{dtype}' not understood\") from err\n    if is_hashable(dtype) and dtype in [object, np.object_, 'object', 'O',\n        'object_']:\n        return npdtype\n    elif npdtype.kind == 'O':\n        raise TypeError(f\"dtype '{dtype}' not understood\")\n    return npdtype", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\n\nclass TestNumpyEADtype():\n\tdef test_numpy_string_dtype(self):\n\t    assert pandas_dtype('U') == np.dtype('U')\n\t    assert pandas_dtype('S') == np.dtype('S')\n\t\nTestNumpyEADtype().test_numpy_string_dtype()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\n\nclass TestNumpyEADtype():\n\tdef test_categorical_dtype(self):\n\t    assert pandas_dtype('category') == CategoricalDtype()\n\t\nTestNumpyEADtype().test_categorical_dtype()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: The pandas_dtype function converts the given input into a pandas-specific dtype object or a numpy dtype object. It supports various types of inputs, including numpy arrays, numpy dtypes, pandas ExtensionDtypes, strings representing dtypes, and more. The function aims to ensure that the input is recognized as a proper data type for pandas data structures.\n\nInputs: \n- dtype: An object that needs to be converted into a pandas or numpy dtype. This can be a numpy array, a numpy dtype, a pandas ExtensionDtype, a string representation of a dtype, or other data types that can be interpreted as dtypes.\n\nOutputs: \n- Returns either a numpy dtype object or a pandas dtype object depending on the input. If the input is recognized as a dtype, it will be returned directly. If the input is a string or other object that can be interpreted as a dtype, the function will attempt to convert it into the appropriate dtype object.\n- If the input is not a valid dtype or cannot be converted to a dtype, the function will raise a TypeError with a message indicating that the data type is not understood.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef pandas_dtype(dtype) ->DtypeObj: [MASK]\n"}
{"method_name": "skip_if_no", "full_method_name": "skip_if_no", "method_path": "../srcdata/Computation/pandas/pandas/util/_test_decorators.py", "method_code": "from __future__ import annotations\nimport locale\nfrom typing import TYPE_CHECKING\nimport pytest\nfrom collections.abc import Callable\nfrom pandas._typing import F\nfrom pandas.compat import IS64\nfrom pandas.compat import is_platform_windows\nfrom pandas.compat._optional import import_optional_dependency\ndef skip_if_no(package: str, min_version: (str | None)=None\n    ) ->pytest.MarkDecorator:\n    \"\"\"\n    Generic function to help skip tests when required packages are not\n    present on the testing system.\n\n    This function returns a pytest mark with a skip condition that will be\n    evaluated during test collection. An attempt will be made to import the\n    specified ``package`` and optionally ensure it meets the ``min_version``\n\n    The mark can be used as either a decorator for a test class or to be\n    applied to parameters in pytest.mark.parametrize calls or parametrized\n    fixtures. Use pytest.importorskip if an imported moduled is later needed\n    or for test functions.\n\n    If the import and version check are unsuccessful, then the test function\n    (or test case when used in conjunction with parametrization) will be\n    skipped.\n\n    Parameters\n    ----------\n    package: str\n        The name of the required package.\n    min_version: str or None, default None\n        Optional minimum version of the package.\n\n    Returns\n    -------\n    pytest.MarkDecorator\n        a pytest.mark.skipif to use as either a test decorator or a\n        parametrization mark.\n    \"\"\"\n    msg = f\"Could not import '{package}'\"\n    if min_version:\n        msg += f' satisfying a min_version of {min_version}'\n    return pytest.mark.skipif(not bool(import_optional_dependency(package,\n        errors='ignore', min_version=min_version)), reason=msg)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.errors import NumbaUtilError\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas import to_datetime\nimport pandas._testing as tm\nimport numba\n@skip_if_no('numba')\ndef test_use_global_config():\n\n    def f(x):\n        return np.mean(x) + 2\n    s = Series(range(10))\n    with option_context('compute.use_numba', True):\n        result = s.rolling(2).apply(f, engine=None, raw=True)\n    expected = s.rolling(2).apply(f, engine='numba', raw=True)\n    tm.assert_series_equal(expected, result)\n\ntest_use_global_config()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/window/test_numba.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.errors import NumbaUtilError\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas import to_datetime\nimport pandas._testing as tm\nimport numba\n@skip_if_no('numba')\ndef test_npfunc_no_warnings():\n    df = DataFrame({'col1': [1, 2, 3, 4, 5]})\n    with tm.assert_produces_warning(False):\n        df.col1.rolling(2).apply(np.prod, raw=True, engine='numba')\n\ntest_npfunc_no_warnings()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/window/test_numba.py"}, {"test_code": "from functools import reduce\nfrom itertools import product\nimport operator\nimport numpy as np\nimport pytest\nfrom pandas.errors import NumExprClobberingError\nfrom pandas.errors import PerformanceWarning\nfrom pandas.errors import UndefinedVariableError\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import date_range\nfrom pandas import period_range\nfrom pandas import timedelta_range\nimport pandas._testing as tm\nfrom pandas.core.computation import expr\nfrom pandas.core.computation import pytables\nfrom pandas.core.computation.engines import ENGINES\nfrom pandas.core.computation.expr import BaseExprVisitor\nfrom pandas.core.computation.expr import PandasExprVisitor\nfrom pandas.core.computation.expr import PythonExprVisitor\nfrom pandas.core.computation.expressions import NUMEXPR_INSTALLED\nfrom pandas.core.computation.expressions import USE_NUMEXPR\nfrom pandas.core.computation.ops import ARITH_OPS_SYMS\nfrom pandas.core.computation.ops import _binary_math_ops\nfrom pandas.core.computation.ops import _binary_ops_dict\nfrom pandas.core.computation.ops import _unary_math_ops\nfrom pandas.core.computation.scope import DEFAULT_GLOBALS\nimport numexpr as ne\nfrom pandas.core.computation.eval import _check_engine\n@skip_if_no('numexpr')\ndef test_numexpr_option_incompatible_op():\n    with pd.option_context('compute.use_numexpr', False):\n        df = DataFrame({'A': [True, False, True, False, None, None], 'B': [\n            1, 2, 3, 4, 5, 6]})\n        result = df.query('A.isnull()')\n        expected = DataFrame({'A': [None, None], 'B': [5, 6]}, index=[4, 5])\n        tm.assert_frame_equal(result, expected)\n\ntest_numexpr_option_incompatible_op()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/computation/test_eval.py"}, {"test_code": "import pickle\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.tests.copy_view.util import get_array\n@skip_if_no('pyarrow')\ndef test_astype_string_read_only_on_pickle_roundrip():\n    base = Series(np.array([(1, 2), None, 1], dtype='object'))\n    base_copy = pickle.loads(pickle.dumps(base))\n    base_copy._values.flags.writeable = False\n    base_copy.astype('string[pyarrow]')\n    tm.assert_series_equal(base, base_copy)\n\ntest_astype_string_read_only_on_pickle_roundrip()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/copy_view/test_astype.py"}, {"test_code": "import datetime\nfrom datetime import timedelta\nfrom decimal import Decimal\nfrom io import StringIO\nimport json\nimport os\nimport sys\nimport time\nimport numpy as np\nimport pytest\nfrom pandas.compat import IS64\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays import ArrowStringArray\nfrom pandas.core.arrays import StringArray\nfrom pandas.arrays import ArrowExtensionArray\n@skip_if_no('pyarrow')\ndef test_to_json_ea_null():\n    df = DataFrame({'a': Series([1, NA], dtype='int64[pyarrow]'), 'b':\n        Series([2, NA], dtype='Int64')})\n    result = df.to_json(orient='records', lines=True)\n    expected = '{\"a\":1,\"b\":2}\\n{\"a\":null,\"b\":null}\\n'\n    assert result == expected\n\ntest_to_json_ea_null()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_pandas.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nfrom importlib import reload\nimport string\nimport sys\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nimport pandas.util._test_decorators as td\nfrom pandas import NA\nfrom pandas import Categorical\nfrom pandas import CategoricalDtype\nfrom pandas import DatetimeTZDtype\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import cut\nfrom pandas import date_range\nfrom pandas import to_datetime\nimport pandas._testing as tm\n\nclass TestAstypeCategorical():\n\t@skip_if_no('pyarrow')\n\tdef test_astype_int_na_string(self):\n\t    ser = Series([12, NA], dtype='Int64[pyarrow]')\n\t    result = ser.astype('string[pyarrow]')\n\t    expected = Series(['12', NA], dtype='string[pyarrow]')\n\t    tm.assert_series_equal(result, expected)\n\t\nTestAstypeCategorical().test_astype_int_na_string()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/series/methods/test_astype.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas import NA\nfrom pandas import Series\nfrom pandas import Timedelta\nimport pandas._testing as tm\n@skip_if_no('pyarrow')\ndef test_to_numpy_arrow_dtype_given():\n    ser = Series([1, NA], dtype='int64[pyarrow]')\n    result = ser.to_numpy(dtype='float64')\n    expected = np.array([1.0, np.nan])\n    tm.assert_numpy_array_equal(result, expected)\n\ntest_to_numpy_arrow_dtype_given()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/series/methods/test_to_numpy.py"}], "instruction": "Functionality: The skip_if_no function is designed to facilitate skipping tests when specific packages are not available or do not meet a minimum version requirement on the testing system. This function is essential for test automation, ensuring that tests are only run when the necessary prerequisites are met, thus avoiding potential import errors and test failures.\n\nInputs: \n- package: str\n    The name of the required package that needs to be tested for availability.\n- min_version: str | None (default None)\n    The minimum version of the package that is required. If specified, the function will check if the installed version of the package meets or exceeds this version.\n\nOutputs:\n- pytest.MarkDecorator\n    The function returns a pytest.mark.skipif decorator. This decorator can be applied to test classes or used in conjunction with pytest.mark.parametrize calls or parametrized fixtures. The decorator conditionally skips test functions or test cases based on the availability and version of the specified package.\n\nUsage:\n1. Decorate a test class or function to skip the test if the package is not available or does not meet the minimum version.\n2. Apply the mark in pytest.mark.parametrize calls or parametrized fixtures to skip certain test cases based on the package's availability or version.", "method_code_mask": "from __future__ import annotations\nimport locale\nfrom typing import TYPE_CHECKING\nimport pytest\nfrom collections.abc import Callable\nfrom pandas._typing import F\nfrom pandas.compat import IS64\nfrom pandas.compat import is_platform_windows\nfrom pandas.compat._optional import import_optional_dependency\n\n\ndef skip_if_no(package: str, min_version: (str | None)=None\n    ) ->pytest.MarkDecorator: [MASK]\n"}
{"method_name": "is_string_dtype", "full_method_name": "is_string_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_string_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    If an array is passed with an object dtype, the elements must be\n    inferred as strings.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_string_dtype\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>> is_string_dtype(np.array([\"a\", \"b\"]))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    >>> is_string_dtype(pd.Series([1, 2], dtype=object))\n    False\n    \"\"\"\n    if hasattr(arr_or_dtype, 'dtype') and _get_dtype(arr_or_dtype).kind == 'O':\n        return is_all_strings(arr_or_dtype)\n\n    def condition(dtype) ->bool:\n        if is_string_or_object_np_dtype(dtype):\n            return True\n        try:\n            return dtype == 'string'\n        except TypeError:\n            return False\n    return _is_dtype(arr_or_dtype, condition)", "test_code_list": [{"test_code": "import re\nimport weakref\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_categorical_dtype\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_dtype_equal\nfrom pandas.core.dtypes.common import is_interval_dtype\nfrom pandas.core.dtypes.common import is_period_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import SparseDtype\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import SparseArray\nclass Base:\n\n    def test_hash(self, dtype):\n        hash(dtype)\n\n    def test_equality_invalid(self, dtype):\n        assert not dtype == 'foo'\n        assert not is_dtype_equal(dtype, np.int64)\n\n    def test_numpy_informed(self, dtype):\n        msg = '|'.join(['data type not understood',\n            \"Cannot interpret '.*' as a data type\"])\n        with pytest.raises(TypeError, match=msg):\n            np.dtype(dtype)\n        assert not dtype == np.str_\n        assert not np.str_ == dtype\n\n    def test_pickle(self, dtype):\n        type(dtype).reset_cache()\n        assert not len(dtype._cache_dtypes)\n        result = tm.round_trip_pickle(dtype)\n        if not isinstance(dtype, PeriodDtype):\n            assert not len(dtype._cache_dtypes)\n        assert result == dtype\n\nclass TestCategoricalDtype(Base):\n\tdef test_not_string(self):\n\t    assert not is_string_dtype(CategoricalDtype())\n\t\nTestCategoricalDtype().test_not_string()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_dtypes.py"}, {"test_code": "import re\nimport weakref\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_categorical_dtype\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_dtype_equal\nfrom pandas.core.dtypes.common import is_interval_dtype\nfrom pandas.core.dtypes.common import is_period_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import SparseDtype\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import SparseArray\nclass Base:\n\n    def test_hash(self, dtype):\n        hash(dtype)\n\n    def test_equality_invalid(self, dtype):\n        assert not dtype == 'foo'\n        assert not is_dtype_equal(dtype, np.int64)\n\n    def test_numpy_informed(self, dtype):\n        msg = '|'.join(['data type not understood',\n            \"Cannot interpret '.*' as a data type\"])\n        with pytest.raises(TypeError, match=msg):\n            np.dtype(dtype)\n        assert not dtype == np.str_\n        assert not np.str_ == dtype\n\n    def test_pickle(self, dtype):\n        type(dtype).reset_cache()\n        assert not len(dtype._cache_dtypes)\n        result = tm.round_trip_pickle(dtype)\n        if not isinstance(dtype, PeriodDtype):\n            assert not len(dtype._cache_dtypes)\n        assert result == dtype\n\nclass TestPeriodDtype(Base):\n\tdef test_not_string(self):\n\t    assert not is_string_dtype(PeriodDtype('D'))\n\t\nTestPeriodDtype().test_not_string()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_dtypes.py"}, {"test_code": "import re\nimport weakref\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_categorical_dtype\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_dtype_equal\nfrom pandas.core.dtypes.common import is_interval_dtype\nfrom pandas.core.dtypes.common import is_period_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import SparseDtype\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.arrays.sparse import SparseArray\nclass Base:\n\n    def test_hash(self, dtype):\n        hash(dtype)\n\n    def test_equality_invalid(self, dtype):\n        assert not dtype == 'foo'\n        assert not is_dtype_equal(dtype, np.int64)\n\n    def test_numpy_informed(self, dtype):\n        msg = '|'.join(['data type not understood',\n            \"Cannot interpret '.*' as a data type\"])\n        with pytest.raises(TypeError, match=msg):\n            np.dtype(dtype)\n        assert not dtype == np.str_\n        assert not np.str_ == dtype\n\n    def test_pickle(self, dtype):\n        type(dtype).reset_cache()\n        assert not len(dtype._cache_dtypes)\n        result = tm.round_trip_pickle(dtype)\n        if not isinstance(dtype, PeriodDtype):\n            assert not len(dtype._cache_dtypes)\n        assert result == dtype\n\nclass TestIntervalDtype(Base):\n\tdef test_not_string(self):\n\t    assert not is_string_dtype(IntervalDtype())\n\t\nTestIntervalDtype().test_not_string()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_dtypes.py"}], "instruction": "Functionality: The is_string_dtype function checks whether the provided array or dtype is of the string dtype. If an array with an object dtype is passed, the function infers whether the elements are strings.\n\nInputs: \n- arr_or_dtype: array-like or dtype\n  The array or dtype to check. This can be any array-like object (e.g., list, np.array, pd.Series) or a dtype object.\n\nOutputs:\n- boolean: \n  A boolean value indicating whether the array or dtype is of the string dtype. Returns True if the array or dtype is of string type, and False otherwise.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_string_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "to_time", "full_method_name": "to_time", "method_path": "../srcdata/Computation/pandas/pandas/core/tools/times.py", "method_code": "from __future__ import annotations\nfrom datetime import datetime\nfrom datetime import time\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs.lib import is_list_like\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import notna\nfrom pandas._typing import DateTimeErrorChoices\ndef to_time(arg, format: (str | None)=None, infer_time_format: bool=False,\n    errors: DateTimeErrorChoices='raise'):\n    \"\"\"\n    Parse time strings to time objects using fixed strptime formats (\"%H:%M\",\n    \"%H%M\", \"%I:%M%p\", \"%I%M%p\", \"%H:%M:%S\", \"%H%M%S\", \"%I:%M:%S%p\",\n    \"%I%M%S%p\")\n\n    Use infer_time_format if all the strings are in the same format to speed\n    up conversion.\n\n    Parameters\n    ----------\n    arg : string in time format, datetime.time, list, tuple, 1-d array,  Series\n    format : str, default None\n        Format used to convert arg into a time object.  If None, fixed formats\n        are used.\n    infer_time_format: bool, default False\n        Infer the time format based on the first non-NaN element.  If all\n        strings are in the same format, this will speed up conversion.\n    errors : {'raise', 'coerce'}, default 'raise'\n        - If 'raise', then invalid parsing will raise an exception\n        - If 'coerce', then invalid parsing will be set as None\n\n    Returns\n    -------\n    datetime.time\n    \"\"\"\n    if errors not in ('raise', 'coerce'):\n        raise ValueError(\"errors must be one of 'raise', or 'coerce'.\")\n\n    def _convert_listlike(arg, format):\n        if isinstance(arg, (list, tuple)):\n            arg = np.array(arg, dtype='O')\n        elif getattr(arg, 'ndim', 1) > 1:\n            raise TypeError(\n                'arg must be a string, datetime, list, tuple, 1-d array, or Series'\n                )\n        arg = np.asarray(arg, dtype='O')\n        if infer_time_format and format is None:\n            format = _guess_time_format_for_array(arg)\n        times: list[time | None] = []\n        if format is not None:\n            for element in arg:\n                try:\n                    times.append(datetime.strptime(element, format).time())\n                except (ValueError, TypeError) as err:\n                    if errors == 'raise':\n                        msg = (\n                            f'Cannot convert {element} to a time with given format {format}'\n                            )\n                        raise ValueError(msg) from err\n                    times.append(None)\n        else:\n            formats = _time_formats[:]\n            format_found = False\n            for element in arg:\n                time_object = None\n                try:\n                    time_object = time.fromisoformat(element)\n                except (ValueError, TypeError):\n                    for time_format in formats:\n                        try:\n                            time_object = datetime.strptime(element,\n                                time_format).time()\n                            if not format_found:\n                                fmt = formats.pop(formats.index(time_format))\n                                formats.insert(0, fmt)\n                                format_found = True\n                            break\n                        except (ValueError, TypeError):\n                            continue\n                if time_object is not None:\n                    times.append(time_object)\n                elif errors == 'raise':\n                    raise ValueError(f'Cannot convert arg {arg} to a time')\n                else:\n                    times.append(None)\n        return times\n    if arg is None:\n        return arg\n    elif isinstance(arg, time):\n        return arg\n    elif isinstance(arg, ABCSeries):\n        values = _convert_listlike(arg._values, format)\n        return arg._constructor(values, index=arg.index, name=arg.name)\n    elif isinstance(arg, ABCIndex):\n        return _convert_listlike(arg, format)\n    elif is_list_like(arg):\n        return _convert_listlike(arg, format)\n    return _convert_listlike(np.array([arg]), format)[0]", "test_code_list": [{"test_code": "from datetime import time\nimport locale\nimport numpy as np\nimport pytest\nfrom pandas.compat import PY311\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.tools.times import to_time\n\nclass TestToTime():\n\tdef test_odd_format(self):\n\t    new_string = '14.15'\n\t    msg = \"Cannot convert arg \\\\['14\\\\.15'\\\\] to a time\"\n\t    if not PY311:\n\t        with pytest.raises(ValueError, match=msg):\n\t            to_time(new_string)\n\t    assert to_time(new_string, format='%H.%M') == time(14, 15)\n\t\nTestToTime().test_odd_format()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/tools/test_to_time.py"}], "instruction": "Functionality: Parses time strings to time objects using fixed strptime formats or a custom format if provided. It can handle various input types including strings, datetime.time objects, lists, tuples, 1-d arrays, and Series. The function also supports inferring the time format from the data if all strings are in the same format, and it can handle errors gracefully by either raising an exception or coercing invalid data to None.\n\nInputs:\narg: A time representation in various formats (string in time format, datetime.time, list, tuple, 1-d array, Series).\nformat: Optional string specifying the format used to convert arg into a time object. If None, fixed formats are used.\ninfer_time_format: Optional boolean indicating whether to infer the time format based on the first non-NaN element. This can speed up conversion if all strings are in the same format.\nerrors: Optional parameter specifying how to handle invalid parsing. It can be 'raise' to raise an exception or 'coerce' to set invalid parsing as None.\n\nOutputs:\nReturns a datetime.time object for single inputs or a list of datetime.time objects for list-like inputs. If errors='coerce' and invalid parsing occurs, None is returned for that particular input.", "method_code_mask": "from __future__ import annotations\nfrom datetime import datetime\nfrom datetime import time\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs.lib import is_list_like\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import notna\nfrom pandas._typing import DateTimeErrorChoices\n\n\ndef to_time(arg, format: (str | None)=None, infer_time_format: bool=False,\n    errors: DateTimeErrorChoices='raise'): [MASK]\n"}
{"method_name": "_guess_datetime_format_for_array", "full_method_name": "_guess_datetime_format_for_array", "method_path": "../srcdata/Computation/pandas/pandas/core/tools/datetimes.py", "method_code": "from __future__ import annotations\nfrom collections import abc\nfrom datetime import date\nfrom functools import partial\nfrom itertools import islice\nfrom typing import TYPE_CHECKING\nfrom typing import TypedDict\nfrom typing import Union\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import tslib\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import astype_overflowsafe\nfrom pandas._libs.tslibs import timezones as libtimezones\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas._libs.tslibs.parsing import DateParseError\nfrom pandas._libs.tslibs.parsing import guess_datetime_format\nfrom pandas._libs.tslibs.strptime import array_strptime\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DateTimeErrorChoices\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.arrays import DatetimeArray\nfrom pandas.arrays import IntegerArray\nfrom pandas.core.algorithms import unique\nfrom pandas.core.arrays import ArrowExtensionArray\nfrom pandas.core.arrays.base import ExtensionArray\nfrom pandas.core.arrays.datetimes import maybe_convert_dtype\nfrom pandas.core.arrays.datetimes import tz_to_dtype\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom pandas._libs.tslibs.nattype import NaTType\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import to_numeric\nfrom pandas import to_timedelta\ndef _guess_datetime_format_for_array(arr, dayfirst: (bool | None)=False) ->(str\n     | None):\n    if (first_non_null := tslib.first_non_null(arr)) != -1:\n        if type((first_non_nan_element := arr[first_non_null])) is str:\n            guessed_format = guess_datetime_format(first_non_nan_element,\n                dayfirst=dayfirst)\n            if guessed_format is not None:\n                return guessed_format\n            if tslib.first_non_null(arr[first_non_null + 1:]) != -1:\n                warnings.warn(\n                    'Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.'\n                    , UserWarning, stacklevel=find_stack_level())\n    return None", "test_code_list": [{"test_code": "import calendar\nfrom collections import deque\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nimport locale\nimport zoneinfo\nfrom dateutil.parser import parse\nimport numpy as np\nimport pytest\nfrom pandas._libs import tslib\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs import parsing\nfrom pandas.errors import OutOfBoundsDatetime\nfrom pandas.errors import OutOfBoundsTimedelta\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import isna\nfrom pandas import to_datetime\nimport pandas._testing as tm\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.tools import datetimes as tools\nfrom pandas.core.tools.datetimes import start_caching_at\nfrom pandas.tests.indexes.datetimes.test_timezones import FixedOffset\n\nclass TestGuessDatetimeFormat():\n\t@td.skip_if_not_us_locale\n\tdef test_guess_datetime_format_for_array_all_nans(self):\n\t    format_for_string_of_nans = _guess_datetime_format_for_array(np.\n\t        array([np.nan, np.nan, np.nan], dtype='O'))\n\t    assert format_for_string_of_nans is None\n\t\nTestGuessDatetimeFormat().test_guess_datetime_format_for_array_all_nans()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/tools/test_to_datetime.py"}], "instruction": "Functionality: \nThe _guess_datetime_format_for_array function attempts to guess the datetime format of the strings in an array. It specifically looks at the first non-null element and tries to determine the format using the guess_datetime_format function from pandas' time series library. If the format can be guessed, it returns this format as a string. If the format cannot be determined, it issues a warning and returns None, indicating that each datetime string will be parsed individually using the dateutil parser.\n\nInputs: \n1. arr: An array-like structure containing datetime strings, which might be nested or contain null values.\n2. dayfirst: An optional boolean parameter that, if provided, specifies whether dates in the array are formatted with the day before the month (True) or the month before the day (False or None). The default is None.\n\nOutputs: \n1. str | None: The guessed datetime format as a string if it can be determined. If the format cannot be guessed, the function returns None.", "method_code_mask": "from __future__ import annotations\nfrom collections import abc\nfrom datetime import date\nfrom functools import partial\nfrom itertools import islice\nfrom typing import TYPE_CHECKING\nfrom typing import TypedDict\nfrom typing import Union\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import tslib\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import astype_overflowsafe\nfrom pandas._libs.tslibs import timezones as libtimezones\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\nfrom pandas._libs.tslibs.parsing import DateParseError\nfrom pandas._libs.tslibs.parsing import guess_datetime_format\nfrom pandas._libs.tslibs.strptime import array_strptime\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DateTimeErrorChoices\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.arrays import DatetimeArray\nfrom pandas.arrays import IntegerArray\nfrom pandas.core.algorithms import unique\nfrom pandas.core.arrays import ArrowExtensionArray\nfrom pandas.core.arrays.base import ExtensionArray\nfrom pandas.core.arrays.datetimes import maybe_convert_dtype\nfrom pandas.core.arrays.datetimes import tz_to_dtype\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom pandas._libs.tslibs.nattype import NaTType\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import to_numeric\nfrom pandas import to_timedelta\n\n\ndef _guess_datetime_format_for_array(arr, dayfirst: (bool | None)=False) ->(str\n     | None): [MASK]\n"}
{"method_name": "is_hashable", "full_method_name": "is_hashable", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/inference.py", "method_code": "from __future__ import annotations\nfrom collections import abc\nfrom numbers import Number\nimport re\nfrom re import Pattern\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs import lib\nfrom collections.abc import Hashable\nimport dataclasses\ndef is_hashable(obj: object) ->TypeGuard[Hashable]:\n    \"\"\"\n    Return True if hash(obj) will succeed, False otherwise.\n\n    Some types will pass a test against collections.abc.Hashable but fail when\n    they are actually hashed with hash().\n\n    Distinguish between these and other types by trying the call to hash() and\n    seeing if they raise TypeError.\n\n    Returns\n    -------\n    bool\n\n    Examples\n    --------\n    >>> import collections\n    >>> from pandas.api.types import is_hashable\n    >>> a = ([],)\n    >>> isinstance(a, collections.abc.Hashable)\n    True\n    >>> is_hashable(a)\n    False\n    \"\"\"\n    try:\n        hash(obj)\n    except TypeError:\n        return False\n    else:\n        return True", "test_code_list": [{"test_code": "import collections\nfrom collections import namedtuple\nfrom collections.abc import Iterator\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom fractions import Fraction\nfrom io import StringIO\nimport itertools\nfrom numbers import Number\nimport re\nimport sys\nfrom typing import Generic\nfrom typing import TypeVar\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs import ops as libops\nfrom pandas.core.dtypes import inference\nfrom pandas.core.dtypes.cast import find_result_type\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_number\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_scipy_sparse\nfrom pandas.core.dtypes.common import is_timedelta64_dtype\nfrom pandas.core.dtypes.common import is_timedelta64_ns_dtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DateOffset\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import Period\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import TimedeltaIndex\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.arrays import BooleanArray\nfrom pandas.core.arrays import FloatingArray\nfrom pandas.core.arrays import IntegerArray\ndef test_is_hashable():\n\n\n    class HashableClass:\n        pass\n\n\n    class UnhashableClass1:\n        __hash__ = None\n\n\n    class UnhashableClass2:\n\n        def __hash__(self):\n            raise TypeError('Not hashable')\n    hashable = 1, 3.14, np.float64(3.14), 'a', (), (1,), HashableClass()\n    not_hashable = [], UnhashableClass1()\n    abc_hashable_not_really_hashable = ([],), UnhashableClass2()\n    for i in hashable:\n        assert is_hashable(i)\n    for i in not_hashable:\n        assert not is_hashable(i)\n    for i in abc_hashable_not_really_hashable:\n        assert not is_hashable(i)\n    assert not is_hashable(np.array([]))\n\ntest_is_hashable()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_inference.py"}], "instruction": "Functionality: Determine if a given object can be hashed successfully.\nInputs: An object `obj` of any type.\nOutputs: A boolean value indicating whether the object can be hashed (`True`) or not (`False`).", "method_code_mask": "from __future__ import annotations\nfrom collections import abc\nfrom numbers import Number\nimport re\nfrom re import Pattern\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs import lib\nfrom collections.abc import Hashable\nimport dataclasses\n\n\ndef is_hashable(obj: object) ->TypeGuard[Hashable]: [MASK]\n"}
{"method_name": "is_datetime64tz_dtype", "full_method_name": "is_datetime64tz_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_datetime64tz_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\n\n    .. deprecated:: 2.1.0\n        Use isinstance(dtype, pd.DatetimeTZDtype) instead.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_datetime64tz_dtype\n    >>> is_datetime64tz_dtype(object)\n    False\n    >>> is_datetime64tz_dtype([1, 2, 3])\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))  # tz-naive\n    False\n    >>> is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    True\n\n    >>> from pandas.core.dtypes.dtypes import DatetimeTZDtype\n    >>> dtype = DatetimeTZDtype(\"ns\", tz=\"US/Eastern\")\n    >>> s = pd.Series([], dtype=dtype)\n    >>> is_datetime64tz_dtype(dtype)\n    True\n    >>> is_datetime64tz_dtype(s)\n    True\n    \"\"\"\n    warnings.warn(\n        'is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.'\n        , DeprecationWarning, stacklevel=2)\n    if isinstance(arr_or_dtype, DatetimeTZDtype):\n        return True\n    if arr_or_dtype is None:\n        return False\n    return DatetimeTZDtype.is_dtype(arr_or_dtype)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_is_datetime64tz_dtype():\n    msg = 'is_datetime64tz_dtype is deprecated'\n    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n        assert not is_datetime64tz_dtype(object)\n        assert not is_datetime64tz_dtype([1, 2, 3])\n        assert not is_datetime64tz_dtype(pd.DatetimeIndex([1, 2, 3]))\n        assert is_datetime64tz_dtype(pd.DatetimeIndex(['2000'], tz=\n            'US/Eastern'))\n\ntest_is_datetime64tz_dtype()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_custom_ea_kind_M_not_datetime64tz():\n\n\n    class NotTZDtype(ExtensionDtype):\n\n        @property\n        def kind(self) ->str:\n            return 'M'\n    not_tz_dtype = NotTZDtype()\n    msg = 'is_datetime64tz_dtype is deprecated'\n    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n        assert not is_datetime64tz_dtype(not_tz_dtype)\n        assert not com.needs_i8_conversion(not_tz_dtype)\n\ntest_custom_ea_kind_M_not_datetime64tz()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: Check whether an array-like or dtype is of a DatetimeTZDtype dtype.\nInputs: \n- arr_or_dtype : array-like or dtype\n    The array-like or dtype to check.\n\nOutputs:\n- boolean\n    Whether or not the array-like or dtype is of a DatetimeTZDtype dtype.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_datetime64tz_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "is_timedelta64_dtype", "full_method_name": "is_timedelta64_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_timedelta64_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the timedelta64 dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the timedelta64 dtype.\n\n    See Also\n    --------\n    api.types.is_timedelta64_ns_dtype : Check whether the provided array or dtype is\n        of the timedelta64[ns] dtype.\n    api.types.is_period_dtype : Check whether an array-like or dtype is of the\n        Period dtype.\n\n    Examples\n    --------\n    >>> from pandas.core.dtypes.common import is_timedelta64_dtype\n    >>> is_timedelta64_dtype(object)\n    False\n    >>> is_timedelta64_dtype(np.timedelta64)\n    True\n    >>> is_timedelta64_dtype([1, 2, 3])\n    False\n    >>> is_timedelta64_dtype(pd.Series([], dtype=\"timedelta64[ns]\"))\n    True\n    >>> is_timedelta64_dtype(\"0 days\")\n    False\n    \"\"\"\n    if isinstance(arr_or_dtype, np.dtype):\n        return arr_or_dtype.kind == 'm'\n    return _is_dtype_type(arr_or_dtype, classes(np.timedelta64))", "test_code_list": [{"test_code": "import collections\nfrom collections import namedtuple\nfrom collections.abc import Iterator\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom decimal import Decimal\nfrom fractions import Fraction\nfrom io import StringIO\nimport itertools\nfrom numbers import Number\nimport re\nimport sys\nfrom typing import Generic\nfrom typing import TypeVar\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs import ops as libops\nfrom pandas.core.dtypes import inference\nfrom pandas.core.dtypes.cast import find_result_type\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_datetime64_any_dtype\nfrom pandas.core.dtypes.common import is_datetime64_dtype\nfrom pandas.core.dtypes.common import is_datetime64_ns_dtype\nfrom pandas.core.dtypes.common import is_datetime64tz_dtype\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_number\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_scipy_sparse\nfrom pandas.core.dtypes.common import is_timedelta64_dtype\nfrom pandas.core.dtypes.common import is_timedelta64_ns_dtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DateOffset\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import Period\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import TimedeltaIndex\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.arrays import BooleanArray\nfrom pandas.core.arrays import FloatingArray\nfrom pandas.core.arrays import IntegerArray\n\nclass TestNumberScalar():\n\tdef test_is_timedelta(self):\n\t    assert is_timedelta64_dtype('timedelta64')\n\t    assert is_timedelta64_dtype('timedelta64[ns]')\n\t    assert not is_timedelta64_ns_dtype('timedelta64')\n\t    assert is_timedelta64_ns_dtype('timedelta64[ns]')\n\t    tdi = TimedeltaIndex([100000000000000.0, 200000000000000.0], dtype=\n\t        'timedelta64[ns]')\n\t    assert is_timedelta64_dtype(tdi)\n\t    assert is_timedelta64_ns_dtype(tdi)\n\t    assert is_timedelta64_ns_dtype(tdi.astype('timedelta64[ns]'))\n\t    assert not is_timedelta64_ns_dtype(Index([], dtype=np.float64))\n\t    assert not is_timedelta64_ns_dtype(Index([], dtype=np.int64))\n\t\nTestNumberScalar().test_is_timedelta()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_inference.py"}], "instruction": "Functionality: The is_timedelta64_dtype function checks whether an array-like object or a data type is of the timedelta64 data type, which is used to represent time intervals.\n\nInputs: \n- arr_or_dtype: The input can be any array-like object or a data type (dtype). This includes objects like numpy arrays, pandas Series, or any dtype that can be checked against the timedelta64 type.\n\nOutputs: \n- boolean: The function returns a boolean value indicating whether the input is of the timedelta64 dtype. It returns True if the input is of the timedelta64 dtype, and False otherwise.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_timedelta64_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "is_categorical_dtype", "full_method_name": "is_categorical_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_categorical_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Categorical dtype.\n\n    .. deprecated:: 2.2.0\n        Use isinstance(dtype, pd.CategoricalDtype) instead.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Categorical dtype.\n\n    Examples\n    --------\n    >>> from pandas.api.types import is_categorical_dtype\n    >>> from pandas import CategoricalDtype\n    >>> is_categorical_dtype(object)\n    False\n    >>> is_categorical_dtype(CategoricalDtype())\n    True\n    >>> is_categorical_dtype([1, 2, 3])\n    False\n    >>> is_categorical_dtype(pd.Categorical([1, 2, 3]))\n    True\n    >>> is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n    True\n    \"\"\"\n    warnings.warn(\n        'is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead'\n        , DeprecationWarning, stacklevel=2)\n    if isinstance(arr_or_dtype, ExtensionDtype):\n        return arr_or_dtype.name == 'category'\n    if arr_or_dtype is None:\n        return False\n    return CategoricalDtype.is_dtype(arr_or_dtype)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_is_categorical_dtype():\n    msg = 'is_categorical_dtype is deprecated'\n    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n        assert not is_categorical_dtype(object)\n        assert not is_categorical_dtype([1, 2, 3])\n        assert is_categorical_dtype(CategoricalDtype())\n        assert is_categorical_dtype(pd.Categorical([1, 2, 3]))\n        assert is_categorical_dtype(pd.CategoricalIndex([1, 2, 3]))\n\ntest_is_categorical_dtype()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: The is_categorical_dtype function checks whether an array-like object or a data type is of the Categorical dtype.\n\nInputs: \n- arr_or_dtype: array-like or dtype\n    The array-like object or data type to be checked. This could be a numpy array, a pandas Categorical object, a pandas CategoricalIndex, or a data type.\n\nOutputs: \n- boolean: \n    Returns True if the input array-like or dtype is of the Categorical dtype, otherwise returns False.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_categorical_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "is_period_dtype", "full_method_name": "is_period_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_period_dtype(arr_or_dtype) ->bool:\n    \"\"\"\n    Check whether an array-like or dtype is of the Period dtype.\n\n    .. deprecated:: 2.2.0\n        Use isinstance(dtype, pd.Period) instead.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like or dtype\n        The array-like or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array-like or dtype is of the Period dtype.\n\n    Examples\n    --------\n    >>> from pandas.core.dtypes.common import is_period_dtype\n    >>> is_period_dtype(object)\n    False\n    >>> is_period_dtype(pd.PeriodDtype(freq=\"D\"))\n    True\n    >>> is_period_dtype([1, 2, 3])\n    False\n    >>> is_period_dtype(pd.Period(\"2017-01-01\"))\n    False\n    >>> is_period_dtype(pd.PeriodIndex([], freq=\"Y\"))\n    True\n    \"\"\"\n    warnings.warn(\n        'is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead'\n        , DeprecationWarning, stacklevel=2)\n    if isinstance(arr_or_dtype, ExtensionDtype):\n        return arr_or_dtype.type is Period\n    if arr_or_dtype is None:\n        return False\n    return PeriodDtype.is_dtype(arr_or_dtype)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_is_period_dtype():\n    msg = 'is_period_dtype is deprecated'\n    with tm.assert_produces_warning(DeprecationWarning, match=msg):\n        assert not is_period_dtype(object)\n        assert not is_period_dtype([1, 2, 3])\n        assert not is_period_dtype(pd.Period('2017-01-01'))\n        assert is_period_dtype(PeriodDtype(freq='D'))\n        assert is_period_dtype(pd.PeriodIndex([], freq='Y'))\n\ntest_is_period_dtype()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: Checks whether an array-like object or a dtype is of the Period dtype in pandas.\n\nInputs: \n    arr_or_dtype : object\n        The array-like object or dtype to be checked. This could be an array, a list, a scalar, or any object that can represent a data type in pandas.\n\nOutputs:\n    boolean : bool\n        Returns True if the provided object is of the Period dtype, otherwise returns False.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_period_dtype(arr_or_dtype) ->bool: [MASK]\n"}
{"method_name": "needs_i8_conversion", "full_method_name": "needs_i8_conversion", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef needs_i8_conversion(dtype: (DtypeObj | None)) ->bool:\n    \"\"\"\n    Check whether the dtype should be converted to int64.\n\n    Dtype \"needs\" such a conversion if the dtype is of a datetime-like dtype\n\n    Parameters\n    ----------\n    dtype : np.dtype, ExtensionDtype, or None\n\n    Returns\n    -------\n    boolean\n        Whether or not the dtype should be converted to int64.\n\n    Examples\n    --------\n    >>> needs_i8_conversion(str)\n    False\n    >>> needs_i8_conversion(np.int64)\n    False\n    >>> needs_i8_conversion(np.datetime64)\n    False\n    >>> needs_i8_conversion(np.dtype(np.datetime64))\n    True\n    >>> needs_i8_conversion(np.array([\"a\", \"b\"]))\n    False\n    >>> needs_i8_conversion(pd.Series([1, 2]))\n    False\n    >>> needs_i8_conversion(pd.Series([], dtype=\"timedelta64[ns]\"))\n    False\n    >>> needs_i8_conversion(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\"))\n    False\n    >>> needs_i8_conversion(pd.DatetimeIndex([1, 2, 3], tz=\"US/Eastern\").dtype)\n    True\n    \"\"\"\n    if isinstance(dtype, np.dtype):\n        return dtype.kind in 'mM'\n    return isinstance(dtype, (PeriodDtype, DatetimeTZDtype))", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_needs_i8_conversion():\n    assert not needs_i8_conversion(str)\n    assert not needs_i8_conversion(np.int64)\n    assert not needs_i8_conversion(pd.Series([1, 2]))\n    assert not needs_i8_conversion(np.array(['a', 'b']))\n    assert not needs_i8_conversion(np.datetime64)\n    assert needs_i8_conversion(np.dtype(np.datetime64))\n    assert not needs_i8_conversion(pd.Series([], dtype='timedelta64[ns]'))\n    assert needs_i8_conversion(pd.Series([], dtype='timedelta64[ns]').dtype\n        )\n    assert not needs_i8_conversion(pd.DatetimeIndex(['2000'], tz=\n        'US/Eastern'))\n    assert needs_i8_conversion(pd.DatetimeIndex(['2000'], tz=\n        'US/Eastern').dtype)\n\ntest_needs_i8_conversion()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: The function 'needs_i8_conversion' checks if a given data type should be converted to a 64-bit integer (int64). This is particularly useful for datetime-like data types which can internally be represented as int64 for computational efficiency.\n\nInputs: \n- dtype: A numpy data type object (np.dtype), an ExtensionDtype, or None. This parameter represents the data type of the data being checked. It can be a basic data type like int, float, string, or complex data types such as datetime64, timedelta64, or specialized pandas data types like PeriodDtype or DatetimeTZDtype.\n\nOutputs: \n- boolean: Returns True if the input data type should be converted to int64, which typically includes datetime-like data types that can benefit from int64 conversion for efficiency. Returns False for other data types that do not require such a conversion.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef needs_i8_conversion(dtype: (DtypeObj | None)) ->bool: [MASK]\n"}
{"method_name": "is_numeric_v_string_like", "full_method_name": "is_numeric_v_string_like", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef is_numeric_v_string_like(a: ArrayLike, b) ->bool:\n    \"\"\"\n    Check if we are comparing a string-like object to a numeric ndarray.\n    NumPy doesn't like to compare such objects, especially numeric arrays\n    and scalar string-likes.\n\n    Parameters\n    ----------\n    a : array-like, scalar\n        The first object to check.\n    b : array-like, scalar\n        The second object to check.\n\n    Returns\n    -------\n    boolean\n        Whether we return a comparing a string-like object to a numeric array.\n\n    Examples\n    --------\n    >>> is_numeric_v_string_like(np.array([1]), \"foo\")\n    True\n    >>> is_numeric_v_string_like(np.array([1, 2]), np.array([\"foo\"]))\n    True\n    >>> is_numeric_v_string_like(np.array([\"foo\"]), np.array([1, 2]))\n    True\n    >>> is_numeric_v_string_like(np.array([1]), np.array([2]))\n    False\n    >>> is_numeric_v_string_like(np.array([\"foo\"]), np.array([\"foo\"]))\n    False\n    \"\"\"\n    is_a_array = isinstance(a, np.ndarray)\n    is_b_array = isinstance(b, np.ndarray)\n    is_a_numeric_array = is_a_array and a.dtype.kind in ('u', 'i', 'f', 'c',\n        'b')\n    is_b_numeric_array = is_b_array and b.dtype.kind in ('u', 'i', 'f', 'c',\n        'b')\n    is_a_string_array = is_a_array and a.dtype.kind in ('S', 'U')\n    is_b_string_array = is_b_array and b.dtype.kind in ('S', 'U')\n    is_b_scalar_string_like = not is_b_array and isinstance(b, str)\n    return (is_a_numeric_array and is_b_scalar_string_like or \n        is_a_numeric_array and is_b_string_array or is_b_numeric_array and\n        is_a_string_array)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_is_numeric_v_string_like():\n    assert not is_numeric_v_string_like(np.array([1]), 1)\n    assert not is_numeric_v_string_like(np.array([1]), np.array([2]))\n    assert not is_numeric_v_string_like(np.array(['foo']), np.array([\n        'foo']))\n    assert is_numeric_v_string_like(np.array([1]), 'foo')\n    assert is_numeric_v_string_like(np.array([1, 2]), np.array(['foo']))\n    assert is_numeric_v_string_like(np.array(['foo']), np.array([1, 2]))\n\ntest_is_numeric_v_string_like()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: The is_numeric_v_string_like function checks if we are comparing a string-like object to a numeric ndarray. This is useful because NumPy often encounters issues when comparing such disparate types, especially numeric arrays and scalar string-likes.\n\nInputs: \na: ArrayLike, scalar - The first object to check. This can be an array-like object or a scalar value.\nb: Any - The second object to check. This can be an array-like object or a scalar value, and its type is not restricted.\n\nOutputs: \nboolean - Returns a boolean value indicating whether a string-like object is being compared to a numeric array. The function returns True if such a comparison is detected, and False otherwise.\n\nExamples are provided in the docstring to illustrate the function's behavior.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef is_numeric_v_string_like(a: ArrayLike, b) ->bool: [MASK]\n"}
{"method_name": "validate_all_hashable", "full_method_name": "validate_all_hashable", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/common.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\ndef validate_all_hashable(*args, error_name: (str | None)=None) ->None:\n    \"\"\"\n    Return None if all args are hashable, else raise a TypeError.\n\n    Parameters\n    ----------\n    *args\n        Arguments to validate.\n    error_name : str, optional\n        The name to use if error\n\n    Raises\n    ------\n    TypeError : If an argument is not hashable\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if not all(is_hashable(arg) for arg in args):\n        if error_name:\n            raise TypeError(f'{error_name} must be a hashable type')\n        raise TypeError('All elements must be hashable')", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.astype import astype_array\nimport pandas.core.dtypes.common as com\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import isna\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.api.types import pandas_dtype\nfrom pandas.arrays import SparseArray\nimport scipy.sparse\ndef test_validate_allhashable():\n    assert validate_all_hashable(1, 'a') is None\n    with pytest.raises(TypeError, match='All elements must be hashable'):\n        validate_all_hashable([])\n    with pytest.raises(TypeError, match='list must be a hashable type'):\n        validate_all_hashable([], error_name='list')\n\ntest_validate_allhashable()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_common.py"}], "instruction": "Functionality: This function checks if all provided arguments are hashable. If any of the arguments is not hashable, it raises a TypeError with an optional custom error message.\n\nInputs:\n    *args\n        Any number of arguments to validate for hashability.\n    error_name : str, optional\n        An optional string that will be included in the error message if any argument is not hashable. It is intended to specify the name of the entity that is expected to be hashable.\n\nOutputs:\n    None\n        The function returns None if all arguments are hashable. However, if any argument is not hashable, it does not return anything but raises a TypeError with a message indicating that all elements must be hashable, or with a custom message if error_name is provided.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import algos\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import conversion\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.inference import is_array_like\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_complex\nfrom pandas.core.dtypes.inference import is_dataclass\nfrom pandas.core.dtypes.inference import is_decimal\nfrom pandas.core.dtypes.inference import is_dict_like\nfrom pandas.core.dtypes.inference import is_file_like\nfrom pandas.core.dtypes.inference import is_float\nfrom pandas.core.dtypes.inference import is_hashable\nfrom pandas.core.dtypes.inference import is_integer\nfrom pandas.core.dtypes.inference import is_iterator\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.inference import is_named_tuple\nfrom pandas.core.dtypes.inference import is_nested_list_like\nfrom pandas.core.dtypes.inference import is_number\nfrom pandas.core.dtypes.inference import is_re\nfrom pandas.core.dtypes.inference import is_re_compilable\nfrom pandas.core.dtypes.inference import is_scalar\nfrom pandas.core.dtypes.inference import is_sequence\nfrom collections.abc import Callable\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom scipy.sparse import issparse as _is_scipy_sparse\n\n\ndef validate_all_hashable(*args, error_name: (str | None)=None) ->None: [MASK]\n"}
{"method_name": "array_equivalent", "full_method_name": "array_equivalent", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/missing.py", "method_code": "from __future__ import annotations\nfrom decimal import Decimal\nfrom typing import TYPE_CHECKING\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nimport pandas._libs.missing as libmissing\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.core.dtypes.common import DT64NS_DTYPE\nfrom pandas.core.dtypes.common import TD64NS_DTYPE\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_or_object_np_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom re import Pattern\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Series\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.construction import sanitize_array\ndef array_equivalent(left, right, strict_nan: bool=False, dtype_equal: bool\n    =False) ->bool:\n    \"\"\"\n    True if two arrays, left and right, have equal non-NaN elements, and NaNs\n    in corresponding locations.  False otherwise. It is assumed that left and\n    right are NumPy arrays of the same dtype. The behavior of this function\n    (particularly with respect to NaNs) is not defined if the dtypes are\n    different.\n\n    Parameters\n    ----------\n    left, right : ndarrays\n    strict_nan : bool, default False\n        If True, consider NaN and None to be different.\n    dtype_equal : bool, default False\n        Whether `left` and `right` are known to have the same dtype\n        according to `is_dtype_equal`. Some methods like `BlockManager.equals`.\n        require that the dtypes match. Setting this to ``True`` can improve\n        performance, but will give different results for arrays that are\n        equal but different dtypes.\n\n    Returns\n    -------\n    b : bool\n        Returns True if the arrays are equivalent.\n\n    Examples\n    --------\n    >>> array_equivalent(np.array([1, 2, np.nan]), np.array([1, 2, np.nan]))\n    True\n    >>> array_equivalent(np.array([1, np.nan, 2]), np.array([1, 2, np.nan]))\n    False\n    \"\"\"\n    left, right = np.asarray(left), np.asarray(right)\n    if left.shape != right.shape:\n        return False\n    if dtype_equal:\n        if left.dtype.kind in 'fc':\n            return _array_equivalent_float(left, right)\n        elif left.dtype.kind in 'mM':\n            return _array_equivalent_datetimelike(left, right)\n        elif is_string_or_object_np_dtype(left.dtype):\n            return _array_equivalent_object(left, right, strict_nan)\n        else:\n            return np.array_equal(left, right)\n    if left.dtype.kind in 'OSU' or right.dtype.kind in 'OSU':\n        return _array_equivalent_object(left, right, strict_nan)\n    if left.dtype.kind in 'fc':\n        if not (left.size and right.size):\n            return True\n        return ((left == right) | isna(left) & isna(right)).all()\n    elif left.dtype.kind in 'mM' or right.dtype.kind in 'mM':\n        if left.dtype != right.dtype:\n            return False\n        left = left.view('i8')\n        right = right.view('i8')\n    if (left.dtype.type is np.void or right.dtype.type is np.void\n        ) and left.dtype != right.dtype:\n        return False\n    return np.array_equal(left, right)", "test_code_list": [{"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\ndef test_array_equivalent_array_mismatched_shape():\n    first = np.array([1, 2, 3])\n    second = np.array([1, 2])\n    left = Series([first, 'a'], dtype=object)\n    right = Series([second, 'a'], dtype=object)\n    assert not array_equivalent(left, right)\n\ntest_array_equivalent_array_mismatched_shape()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}, {"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\ndef test_array_equivalent_array_mismatched_dtype():\n    first = np.array([1, 2], dtype=np.float64)\n    second = np.array([1, 2])\n    left = Series([first, 'a'], dtype=object)\n    right = Series([second, 'a'], dtype=object)\n    assert array_equivalent(left, right)\n\ntest_array_equivalent_array_mismatched_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}, {"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\ndef test_array_equivalent_different_dtype_but_equal():\n    assert array_equivalent(np.array([1, 2]), np.array([1.0, 2.0]))\n\ntest_array_equivalent_different_dtype_but_equal()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}, {"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\ndef test_array_equivalent_compat():\n    m = np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', float)])\n    n = np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', float)])\n    assert array_equivalent(m, n, strict_nan=True)\n    assert array_equivalent(m, n, strict_nan=False)\n    m = np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', float)])\n    n = np.array([(1, 2), (4, 3)], dtype=[('a', int), ('b', float)])\n    assert not array_equivalent(m, n, strict_nan=True)\n    assert not array_equivalent(m, n, strict_nan=False)\n    m = np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', float)])\n    n = np.array([(1, 2), (3, 4)], dtype=[('b', int), ('a', float)])\n    assert not array_equivalent(m, n, strict_nan=True)\n    assert not array_equivalent(m, n, strict_nan=False)\n\ntest_array_equivalent_compat()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}, {"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\ndef test_array_equivalent_index_with_tuples():\n    idx1 = Index(np.array([(pd.NA, 4), (1, 1)], dtype='object'))\n    idx2 = Index(np.array([(1, 1), (pd.NA, 4)], dtype='object'))\n    assert not array_equivalent(idx1, idx2)\n    assert not idx1.equals(idx2)\n    assert not array_equivalent(idx2, idx1)\n    assert not idx2.equals(idx1)\n    idx1 = Index(np.array([(4, pd.NA), (1, 1)], dtype='object'))\n    idx2 = Index(np.array([(1, 1), (4, pd.NA)], dtype='object'))\n    assert not array_equivalent(idx1, idx2)\n    assert not idx1.equals(idx2)\n    assert not array_equivalent(idx2, idx1)\n    assert not idx2.equals(idx1)\n\ntest_array_equivalent_index_with_tuples()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}], "instruction": "Functionality: The array_equivalent function checks if two arrays, left and right, have equal non-NaN elements and NaNs in corresponding locations. It assumes that the arrays are NumPy arrays of the same dtype. The behavior is not defined if the dtypes are different.\n\nInputs: \n- left: ndarray (The first array to compare)\n- right: ndarray (The second array to compare)\n- strict_nan: bool (default False) - If True, consider NaN and None to be different.\n- dtype_equal: bool (default False) - Whether left and right are known to have the same dtype according to is_dtype_equal. Setting this to True can improve performance, but will give different results for arrays that are equal but have different dtypes.\n\nOutputs: \n- b: bool (Returns True if the arrays are equivalent, False otherwise.)", "method_code_mask": "from __future__ import annotations\nfrom decimal import Decimal\nfrom typing import TYPE_CHECKING\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nimport pandas._libs.missing as libmissing\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.core.dtypes.common import DT64NS_DTYPE\nfrom pandas.core.dtypes.common import TD64NS_DTYPE\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_or_object_np_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom re import Pattern\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Series\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.construction import sanitize_array\n\n\ndef array_equivalent(left, right, strict_nan: bool=False, dtype_equal: bool\n    =False) ->bool: [MASK]\n"}
{"method_name": "is_valid_na_for_dtype", "full_method_name": "is_valid_na_for_dtype", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/missing.py", "method_code": "from __future__ import annotations\nfrom decimal import Decimal\nfrom typing import TYPE_CHECKING\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nimport pandas._libs.missing as libmissing\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.core.dtypes.common import DT64NS_DTYPE\nfrom pandas.core.dtypes.common import TD64NS_DTYPE\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_or_object_np_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom re import Pattern\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Series\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.construction import sanitize_array\ndef is_valid_na_for_dtype(obj, dtype: DtypeObj) ->bool:\n    \"\"\"\n    isna check that excludes incompatible dtypes\n\n    Parameters\n    ----------\n    obj : object\n    dtype : np.datetime64, np.timedelta64, DatetimeTZDtype, or PeriodDtype\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    if not lib.is_scalar(obj) or not isna(obj):\n        return False\n    elif dtype.kind == 'M':\n        if isinstance(dtype, np.dtype):\n            return not isinstance(obj, (np.timedelta64, Decimal))\n        return not isinstance(obj, (np.timedelta64, np.datetime64, Decimal))\n    elif dtype.kind == 'm':\n        return not isinstance(obj, (np.datetime64, Decimal))\n    elif dtype.kind in 'iufc':\n        return obj is not NaT and not isinstance(obj, (np.datetime64, np.\n            timedelta64))\n    elif dtype.kind == 'b':\n        return lib.is_float(obj) or obj is None or obj is libmissing.NA\n    elif dtype == _dtype_str:\n        return not isinstance(obj, (np.datetime64, np.timedelta64, Decimal,\n            float))\n    elif dtype == _dtype_object:\n        return True\n    elif isinstance(dtype, PeriodDtype):\n        return not isinstance(obj, (np.datetime64, np.timedelta64, Decimal))\n    elif isinstance(dtype, IntervalDtype):\n        return lib.is_float(obj) or obj is None or obj is libmissing.NA\n    elif isinstance(dtype, CategoricalDtype):\n        return is_valid_na_for_dtype(obj, dtype.categories.dtype)\n    return not isinstance(obj, (np.datetime64, np.timedelta64, Decimal))", "test_code_list": [{"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\n\nclass TestIsValidNAForDtype():\n\tdef test_is_valid_na_for_dtype_interval(self):\n\t    dtype = IntervalDtype('int64', 'left')\n\t    assert not is_valid_na_for_dtype(NaT, dtype)\n\t    dtype = IntervalDtype('datetime64[ns]', 'both')\n\t    assert not is_valid_na_for_dtype(NaT, dtype)\n\t\nTestIsValidNAForDtype().test_is_valid_na_for_dtype_interval()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}, {"test_code": "from contextlib import nullcontext\nfrom datetime import datetime\nfrom decimal import Decimal\nimport numpy as np\nimport pytest\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat.numpy import np_version_gte1p25\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.missing import array_equivalent\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import isnull\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core.dtypes.missing import notnull\nimport pandas as pd\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nfrom pandas import date_range\nfrom pandas import period_range\nimport pandas._testing as tm\n\nclass TestIsValidNAForDtype():\n\tdef test_is_valid_na_for_dtype_categorical(self):\n\t    dtype = CategoricalDtype(categories=[0, 1, 2])\n\t    assert is_valid_na_for_dtype(np.nan, dtype)\n\t    assert not is_valid_na_for_dtype(NaT, dtype)\n\t    assert not is_valid_na_for_dtype(np.datetime64('NaT', 'ns'), dtype)\n\t    assert not is_valid_na_for_dtype(np.timedelta64('NaT', 'ns'), dtype)\n\t\nTestIsValidNAForDtype().test_is_valid_na_for_dtype_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_missing.py"}], "instruction": "Functionality: Check if the given object is a valid NA (missing) value for the specified dtype, excluding values that are incompatible with the dtype.\nInputs: \n    obj: The object to be checked.\n    dtype: The data type (DtypeObj) against which the object is to be validated. Supported dtypes include np.datetime64, np.timedelta64, DatetimeTZDtype, PeriodDtype, and other numerical and categorical types.\nOutputs:\n    bool: Returns True if the object is a valid NA value for the specified dtype and False otherwise.", "method_code_mask": "from __future__ import annotations\nfrom decimal import Decimal\nfrom typing import TYPE_CHECKING\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nimport pandas._libs.missing as libmissing\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.core.dtypes.common import DT64NS_DTYPE\nfrom pandas.core.dtypes.common import TD64NS_DTYPE\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_or_object_np_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCMultiIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom re import Pattern\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NDFrameT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Series\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.construction import sanitize_array\n\n\ndef is_valid_na_for_dtype(obj, dtype: DtypeObj) ->bool: [MASK]\n"}
{"method_name": "concat_compat", "full_method_name": "concat_compat", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/concat.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.core.dtypes.astype import astype_array\nfrom pandas.core.dtypes.cast import common_dtype_categorical_compat\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.generic import ABCCategoricalIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom collections.abc import Sequence\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas import Categorical\nfrom pandas.core.arrays.categorical import recode_for_categories\nfrom pandas.core.algorithms import take_nd\ndef concat_compat(to_concat: Sequence[ArrayLike], axis: AxisInt=0,\n    ea_compat_axis: bool=False) ->ArrayLike:\n    \"\"\"\n    provide concatenation of an array of arrays each of which is a single\n    'normalized' dtypes (in that for example, if it's object, then it is a\n    non-datetimelike and provide a combined dtype for the resulting array that\n    preserves the overall dtype if possible)\n\n    Parameters\n    ----------\n    to_concat : sequence of arrays\n    axis : axis to provide concatenation\n    ea_compat_axis : bool, default False\n        For ExtensionArray compat, behave as if axis == 1 when determining\n        whether to drop empty arrays.\n\n    Returns\n    -------\n    a single array, preserving the combined dtypes\n    \"\"\"\n    if len(to_concat) and lib.dtypes_all_equal([obj.dtype for obj in to_concat]\n        ):\n        obj = to_concat[0]\n        if isinstance(obj, np.ndarray):\n            to_concat_arrs = cast('Sequence[np.ndarray]', to_concat)\n            return np.concatenate(to_concat_arrs, axis=axis)\n        to_concat_eas = cast('Sequence[ExtensionArray]', to_concat)\n        if ea_compat_axis:\n            return obj._concat_same_type(to_concat_eas)\n        elif axis == 0:\n            return obj._concat_same_type(to_concat_eas)\n        else:\n            return obj._concat_same_type(to_concat_eas, axis=axis)\n    non_empties = [x for x in to_concat if _is_nonempty(x, axis)]\n    any_ea, kinds, target_dtype = _get_result_dtype(to_concat, non_empties)\n    if target_dtype is not None:\n        to_concat = [astype_array(arr, target_dtype, copy=False) for arr in\n            to_concat]\n    if not isinstance(to_concat[0], np.ndarray):\n        to_concat_eas = cast('Sequence[ExtensionArray]', to_concat)\n        cls = type(to_concat[0])\n        if ea_compat_axis or axis == 0:\n            return cls._concat_same_type(to_concat_eas)\n        else:\n            return cls._concat_same_type(to_concat_eas, axis=axis)\n    else:\n        to_concat_arrs = cast('Sequence[np.ndarray]', to_concat)\n        result = np.concatenate(to_concat_arrs, axis=axis)\n        if not any_ea and 'b' in kinds and result.dtype.kind in 'iuf':\n            result = result.astype(object, copy=False)\n    return result", "test_code_list": [{"test_code": "import pytest\nimport pandas.core.dtypes.concat as _concat\nimport pandas as pd\nfrom pandas import Series\nimport pandas._testing as tm\ndef test_concat_periodarray_2d():\n    pi = pd.period_range('2016-01-01', periods=36, freq='D')\n    arr = pi._data.reshape(6, 6)\n    result = concat_compat([arr[:2], arr[2:]], axis=0)\n    tm.assert_period_array_equal(result, arr)\n    result = concat_compat([arr[:, :2], arr[:, 2:]], axis=1)\n    tm.assert_period_array_equal(result, arr)\n    msg = (\n        'all the input array dimensions.* for the concatenation axis must match exactly'\n        )\n    with pytest.raises(ValueError, match=msg):\n        concat_compat([arr[:, :2], arr[:, 2:]], axis=0)\n    with pytest.raises(ValueError, match=msg):\n        concat_compat([arr[:2], arr[2:]], axis=1)\n\ntest_concat_periodarray_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/test_concat.py"}], "instruction": "Functionality: The concat_compat function is designed to concatenate a sequence of array-like objects along a specified axis. It ensures that the resulting array preserves the combined data type of the input arrays, especially when dealing with categorical or extension arrays.\n\nInputs:\n- to_concat: A sequence of array-like objects (e.g., np.ndarray, ExtensionArray) to be concatenated.\n- axis: An integer specifying the axis along which to concatenate the arrays. Default is 0, which means concatenation occurs along the rows.\n- ea_compat_axis: A boolean indicating whether to behave as if the axis is 1 when determining whether to drop empty arrays for ExtensionArray compatibility. Default is False.\n\nOutputs:\n- A single array-like object resulting from the concatenation of the input arrays along the specified axis. The output array will preserve the combined data type of the input arrays, taking into consideration the compatibility of categorical and extension arrays.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.core.dtypes.astype import astype_array\nfrom pandas.core.dtypes.cast import common_dtype_categorical_compat\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.cast import np_find_common_type\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.generic import ABCCategoricalIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom collections.abc import Sequence\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeObj\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas import Categorical\nfrom pandas.core.arrays.categorical import recode_for_categories\nfrom pandas.core.algorithms import take_nd\n\n\ndef concat_compat(to_concat: Sequence[ArrayLike], axis: AxisInt=0,\n    ea_compat_axis: bool=False) ->ArrayLike: [MASK]\n"}
{"method_name": "can_hold_element", "full_method_name": "can_hold_element", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/cast.py", "method_code": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\ndef can_hold_element(arr: ArrayLike, element: Any) ->bool:\n    \"\"\"\n    Can we do an inplace setitem with this element in an array with this dtype?\n\n    Parameters\n    ----------\n    arr : np.ndarray or ExtensionArray\n    element : Any\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    dtype = arr.dtype\n    if not isinstance(dtype, np.dtype) or dtype.kind in 'mM':\n        if isinstance(dtype, (PeriodDtype, IntervalDtype, DatetimeTZDtype,\n            np.dtype)):\n            arr = cast(\n                'PeriodArray | DatetimeArray | TimedeltaArray | IntervalArray',\n                arr)\n            try:\n                arr._validate_setitem_value(element)\n                return True\n            except (ValueError, TypeError):\n                return False\n        return True\n    try:\n        np_can_hold_element(dtype, element)\n        return True\n    except (TypeError, LossySetitemError):\n        return False", "test_code_list": [{"test_code": "import numpy as np\nfrom pandas.core.dtypes.cast import can_hold_element\ndef test_can_hold_element_int_values_float_ndarray():\n    arr = np.array([], dtype=np.int64)\n    element = np.array([1.0, 2.0])\n    assert can_hold_element(arr, element)\n    assert not can_hold_element(arr, element + 0.5)\n    element = np.array([3, 2 ** 65], dtype=np.float64)\n    assert not can_hold_element(arr, element)\n\ntest_can_hold_element_int_values_float_ndarray()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/cast/test_can_hold_element.py"}, {"test_code": "import numpy as np\nfrom pandas.core.dtypes.cast import can_hold_element\ndef test_can_hold_element_int8_int():\n    arr = np.array([], dtype=np.int8)\n    element = 2\n    assert can_hold_element(arr, element)\n    assert can_hold_element(arr, np.int8(element))\n    assert can_hold_element(arr, np.uint8(element))\n    assert can_hold_element(arr, np.int16(element))\n    assert can_hold_element(arr, np.uint16(element))\n    assert can_hold_element(arr, np.int32(element))\n    assert can_hold_element(arr, np.uint32(element))\n    assert can_hold_element(arr, np.int64(element))\n    assert can_hold_element(arr, np.uint64(element))\n    element = 2 ** 9\n    assert not can_hold_element(arr, element)\n    assert not can_hold_element(arr, np.int16(element))\n    assert not can_hold_element(arr, np.uint16(element))\n    assert not can_hold_element(arr, np.int32(element))\n    assert not can_hold_element(arr, np.uint32(element))\n    assert not can_hold_element(arr, np.int64(element))\n    assert not can_hold_element(arr, np.uint64(element))\n\ntest_can_hold_element_int8_int()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/cast/test_can_hold_element.py"}], "instruction": "Functionality: Determines if an element can be assigned to an array with a specific dtype without causing an error or losing precision.\nInputs: \n- arr: An np.ndarray or ExtensionArray. This is the array whose dtype is to be checked.\n- element: Any. This is the element to be checked for compatibility with the array's dtype.\nOutputs: \n- bool: Returns True if the element can be assigned to the array without errors or loss of precision, False otherwise.", "method_code_mask": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\n\n\ndef can_hold_element(arr: ArrayLike, element: Any) ->bool: [MASK]\n"}
{"method_name": "construct_1d_object_array_from_listlike", "full_method_name": "construct_1d_object_array_from_listlike", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/cast.py", "method_code": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\ndef construct_1d_object_array_from_listlike(values: Sized) ->np.ndarray:\n    \"\"\"\n    Transform any list-like object in a 1-dimensional numpy array of object\n    dtype.\n\n    Parameters\n    ----------\n    values : any iterable which has a len()\n\n    Raises\n    ------\n    TypeError\n        * If `values` does not have a len()\n\n    Returns\n    -------\n    1-dimensional numpy array of dtype object\n    \"\"\"\n    result = np.empty(len(values), dtype='object')\n    result[:] = values\n    return result", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nimport pandas._testing as tm\ndef test_from_product_datetimeindex():\n    dt_index = date_range('2000-01-01', periods=2)\n    mi = MultiIndex.from_product([[1, 2], dt_index])\n    etalon = construct_1d_object_array_from_listlike([(1, Timestamp(\n        '2000-01-01')), (1, Timestamp('2000-01-02')), (2, Timestamp(\n        '2000-01-01')), (2, Timestamp('2000-01-02'))])\n    tm.assert_numpy_array_equal(mi.values, etalon)\n\ntest_from_product_datetimeindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/multi/test_constructors.py"}, {"test_code": "import re\nimport numpy as np\nimport pytest\nfrom pandas._libs import index as libindex\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nimport pandas._testing as tm\ndef test_values_boxed():\n    tuples = [(1, pd.Timestamp('2000-01-01')), (2, pd.NaT), (3, pd.\n        Timestamp('2000-01-03')), (1, pd.Timestamp('2000-01-04')), (2, pd.\n        Timestamp('2000-01-02')), (3, pd.Timestamp('2000-01-03'))]\n    result = MultiIndex.from_tuples(tuples)\n    expected = construct_1d_object_array_from_listlike(tuples)\n    tm.assert_numpy_array_equal(result.values, expected)\n    tm.assert_numpy_array_equal(result.values[:4], result[:4].values)\n\ntest_values_boxed()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/multi/test_integrity.py"}], "instruction": "Functionality: The construct_1d_object_array_from_listlike function is designed to convert any list-like object into a 1-dimensional numpy array with an object data type. It is capable of handling various iterable objects that have a defined length.\n\nInputs:\n- values: A list-like object (Sized) that has a defined length. This can be a list, tuple, array, or any other iterable that supports len(). The elements within this iterable can be of any data type.\n\nOutputs:\n- A 1-dimensional numpy array (np.ndarray) where the dtype is 'object'. The array will have the same number of elements as the input iterable, and each element of the input iterable will be copied into the array at the corresponding position.", "method_code_mask": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\n\n\ndef construct_1d_object_array_from_listlike(values: Sized) ->np.ndarray: [MASK]\n"}
{"method_name": "construct_1d_arraylike_from_scalar", "full_method_name": "construct_1d_arraylike_from_scalar", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/cast.py", "method_code": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\ndef construct_1d_arraylike_from_scalar(value: Scalar, length: int, dtype: (\n    DtypeObj | None)) ->ArrayLike:\n    \"\"\"\n    create a np.ndarray / pandas type of specified shape and dtype\n    filled with values\n\n    Parameters\n    ----------\n    value : scalar value\n    length : int\n    dtype : pandas_dtype or np.dtype\n\n    Returns\n    -------\n    np.ndarray / pandas type of length, filled with value\n\n    \"\"\"\n    if dtype is None:\n        try:\n            dtype, value = infer_dtype_from_scalar(value)\n        except OutOfBoundsDatetime:\n            dtype = _dtype_obj\n    if isinstance(dtype, ExtensionDtype):\n        cls = dtype.construct_array_type()\n        seq = [] if length == 0 else [value]\n        return cls._from_sequence(seq, dtype=dtype).repeat(length)\n    if length and dtype.kind in 'iu' and isna(value):\n        dtype = np.dtype('float64')\n    elif lib.is_np_dtype(dtype, 'US'):\n        dtype = np.dtype('object')\n        if not isna(value):\n            value = ensure_str(value)\n    elif dtype.kind in 'mM':\n        value = _maybe_box_and_unbox_datetimelike(value, dtype)\n    subarr = np.empty(length, dtype=dtype)\n    if length:\n        subarr.fill(value)\n    return subarr", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.cast import construct_1d_arraylike_from_scalar\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas import Categorical\nfrom pandas import Timedelta\nimport pandas._testing as tm\ndef test_cast_1d_array_like_from_scalar_categorical():\n    cats = ['a', 'b', 'c']\n    cat_type = CategoricalDtype(categories=cats, ordered=False)\n    expected = Categorical(['a', 'a'], categories=cats)\n    result = construct_1d_arraylike_from_scalar('a', len(expected), cat_type)\n    tm.assert_categorical_equal(result, expected)\n\ntest_cast_1d_array_like_from_scalar_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/cast/test_construct_from_scalar.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.cast import construct_1d_arraylike_from_scalar\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas import Categorical\nfrom pandas import Timedelta\nimport pandas._testing as tm\ndef test_cast_1d_array_like_from_timedelta():\n    td = Timedelta(1)\n    res = construct_1d_arraylike_from_scalar(td, 2, np.dtype('m8[ns]'))\n    assert res[0] == td\n\ntest_cast_1d_array_like_from_timedelta()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/dtypes/cast/test_construct_from_scalar.py"}], "instruction": "Functionality: The construct_1d_arraylike_from_scalar function is designed to create a one-dimensional array-like object filled with a specified scalar value. This function supports various data types, including those from NumPy and pandas, and can infer the data type from the provided scalar if none is specified. It handles special cases, such as when the value is NaN and the data type is an integer, converting the data type to float64 to accommodate the NaN value. It also supports constructing arrays from extension data types, using their respective array types.\n\nInputs: \n- value: A scalar value that will be used to fill the resulting array-like object.\n- length: An integer that specifies the length of the resulting array-like object.\n- dtype: An optional parameter representing the data type of the resulting array-like object. It can be a pandas_dtype or np.dtype. If None, the function will attempt to infer the data type from the provided scalar value.\n\nOutputs:\n- An array-like object of length `length`, filled with the `value`. The type of the array-like object will match the `dtype` parameter, or will be inferred if the `dtype` parameter is None. The array-like object will be a NumPy ndarray or a pandas array type, depending on the `dtype`.\n\nNote: This function is designed to handle various data types and edge cases, such as datetime and timedelta data types, string data types, and extension array data types. It ensures that the resulting array-like object is correctly constructed and filled with the specified value, taking into account the specified length and data type.", "method_code_mask": "from __future__ import annotations\nimport datetime as dt\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import Interval\nfrom pandas._libs import Period\nfrom pandas._libs import lib\nfrom pandas._libs.missing import NA\nfrom pandas._libs.missing import NAType\nfrom pandas._libs.missing import checknull\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import OutOfBoundsDatetime\nfrom pandas._libs.tslibs import OutOfBoundsTimedelta\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs.timedeltas import array_to_timedelta64\nfrom pandas.errors import IntCastingNaNError\nfrom pandas.errors import LossySetitemError\nfrom pandas.core.dtypes.common import ensure_int8\nfrom pandas.core.dtypes.common import ensure_int16\nfrom pandas.core.dtypes.common import ensure_int32\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import ensure_str\nfrom pandas.core.dtypes.common import is_bool\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype as pandas_dtype_func\nfrom pandas.core.dtypes.dtypes import BaseMaskedDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PandasExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.inference import is_list_like\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.io._util import _arrow_dtype_mapping\nfrom collections.abc import Sequence\nfrom collections.abc import Sized\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NumpyIndexT\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas import Index\nfrom pandas.core.arrays import Categorical\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.arrays.arrow.array import to_pyarrow_type\nimport pyarrow as pa\nfrom pandas.core.arrays.datetimes import DatetimeArray\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\n\n\ndef construct_1d_arraylike_from_scalar(value: Scalar, length: int, dtype: (\n    DtypeObj | None)) ->ArrayLike: [MASK]\n"}
{"method_name": "f", "full_method_name": "f", "method_path": "../srcdata/Computation/pandas/pandas/tests/util/test_assert_produces_warning.py", "method_code": "import warnings\nimport pytest\nfrom pandas.errors import DtypeWarning\nfrom pandas.errors import PerformanceWarning\nimport pandas._testing as tm\ndef f():\n    warnings.warn('f1', FutureWarning)\n    warnings.warn('f2', RuntimeWarning)", "test_code_list": [{"test_code": "import warnings\nimport pytest\nfrom pandas.errors import DtypeWarning\nfrom pandas.errors import PerformanceWarning\nimport pandas._testing as tm\ndef test_assert_produces_warning_honors_filter():\n    msg = 'Caused unexpected warning\\\\(s\\\\)'\n    with pytest.raises(AssertionError, match=msg):\n        with tm.assert_produces_warning(RuntimeWarning):\n            f()\n    with tm.assert_produces_warning(RuntimeWarning, raise_on_extra_warnings\n        =False):\n        f()\n\ntest_assert_produces_warning_honors_filter()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/util/test_assert_produces_warning.py"}], "instruction": "Functionality: The function f is designed to trigger specific warning messages using Python's warnings module. This is particularly useful for testing how a codebase handles warnings, ensuring that warning messages are properly displayed and logged. The function emits two warnings, one with a category of FutureWarning labeled 'f1', and another with a category of RuntimeWarning labeled 'f2'.\n\nInputs: \n    This function does not have any input parameters. It is intended to be called without any arguments.\n\nOutputs:\n    The function does not return any value (it returns None). However, its primary output is the generation of warning messages to the console or the logging system, depending on how warnings are handled in the environment where the function is executed. The two warnings emitted are:\n        1. A FutureWarning with the message 'f1'\n        2. A RuntimeWarning with the message 'f2'", "method_code_mask": "import warnings\nimport pytest\nfrom pandas.errors import DtypeWarning\nfrom pandas.errors import PerformanceWarning\nimport pandas._testing as tm\n\n\ndef f(): [MASK]\n"}
{"method_name": "period_array", "full_method_name": "period_array", "method_path": "../srcdata/Computation/pandas/pandas/core/arrays/period.py", "method_code": "from __future__ import annotations\nfrom datetime import timedelta\nimport operator\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import lib\nfrom pandas._libs.arrays import NDArrayBacked\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import astype_overflowsafe\nfrom pandas._libs.tslibs import dt64arr_to_periodarr as c_dt64arr_to_periodarr\nfrom pandas._libs.tslibs import get_unit_from_dtype\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs import parsing\nfrom pandas._libs.tslibs import period as libperiod\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs.dtypes import FreqGroup\nfrom pandas._libs.tslibs.dtypes import PeriodDtypeBase\nfrom pandas._libs.tslibs.fields import isleapyear_arr\nfrom pandas._libs.tslibs.offsets import Tick\nfrom pandas._libs.tslibs.offsets import delta_to_tick\nfrom pandas._libs.tslibs.period import DIFFERENT_FREQ\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas._libs.tslibs.period import Period\nfrom pandas._libs.tslibs.period import get_period_field_arr\nfrom pandas._libs.tslibs.period import period_asfreq_arr\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCPeriodIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.arrays import datetimelike as dtl\nimport pandas.core.common as com\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import FillnaOptions\nfrom pandas._typing import NpDtype\nfrom pandas._typing import npt\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.base import ExtensionArray\nimport pyarrow\nfrom pandas.core.arrays.arrow.extension_types import ArrowPeriodType\ndef period_array(data: (Sequence[Period | str | None] | AnyArrayLike), freq:\n    (str | Tick | BaseOffset | None)=None, copy: bool=False) ->PeriodArray:\n    \"\"\"\n    Construct a new PeriodArray from a sequence of Period scalars.\n\n    Parameters\n    ----------\n    data : Sequence of Period objects\n        A sequence of Period objects. These are required to all have\n        the same ``freq.`` Missing values can be indicated by ``None``\n        or ``pandas.NaT``.\n    freq : str, Tick, or Offset\n        The frequency of every element of the array. This can be specified\n        to avoid inferring the `freq` from `data`.\n    copy : bool, default False\n        Whether to ensure a copy of the data is made.\n\n    Returns\n    -------\n    PeriodArray\n\n    See Also\n    --------\n    PeriodArray\n    pandas.PeriodIndex\n\n    Examples\n    --------\n    >>> period_array([pd.Period(\"2017\", freq=\"Y\"), pd.Period(\"2018\", freq=\"Y\")])\n    <PeriodArray>\n    ['2017', '2018']\n    Length: 2, dtype: period[Y-DEC]\n\n    >>> period_array([pd.Period(\"2017\", freq=\"Y\"), pd.Period(\"2018\", freq=\"Y\"), pd.NaT])\n    <PeriodArray>\n    ['2017', '2018', 'NaT']\n    Length: 3, dtype: period[Y-DEC]\n\n    Integers that look like years are handled\n\n    >>> period_array([2000, 2001, 2002], freq=\"D\")\n    <PeriodArray>\n    ['2000-01-01', '2001-01-01', '2002-01-01']\n    Length: 3, dtype: period[D]\n\n    Datetime-like strings may also be passed\n\n    >>> period_array([\"2000-Q1\", \"2000-Q2\", \"2000-Q3\", \"2000-Q4\"], freq=\"Q\")\n    <PeriodArray>\n    ['2000Q1', '2000Q2', '2000Q3', '2000Q4']\n    Length: 4, dtype: period[Q-DEC]\n    \"\"\"\n    data_dtype = getattr(data, 'dtype', None)\n    if lib.is_np_dtype(data_dtype, 'M'):\n        return PeriodArray._from_datetime64(data, freq)\n    if isinstance(data_dtype, PeriodDtype):\n        out = PeriodArray(data)\n        if freq is not None:\n            if freq == data_dtype.freq:\n                return out\n            return out.asfreq(freq)\n        return out\n    if not isinstance(data, (np.ndarray, list, tuple, ABCSeries)):\n        data = list(data)\n    arrdata = np.asarray(data)\n    dtype: PeriodDtype | None\n    if freq:\n        dtype = PeriodDtype(freq)\n    else:\n        dtype = None\n    if arrdata.dtype.kind == 'f' and len(arrdata) > 0:\n        raise TypeError(\n            'PeriodIndex does not allow floating point in construction')\n    if arrdata.dtype.kind in 'iu':\n        arr = arrdata.astype(np.int64, copy=False)\n        ordinals = libperiod.from_ordinals(arr, freq)\n        return PeriodArray(ordinals, dtype=dtype)\n    data = ensure_object(arrdata)\n    if freq is None:\n        freq = libperiod.extract_freq(data)\n    dtype = PeriodDtype(freq)\n    return PeriodArray._from_sequence(data, dtype=dtype)", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import period_array\ndef test_astype_copies():\n    arr = period_array(['2000', '2001', None], freq='D')\n    result = arr.astype(np.int64, copy=False)\n    assert result.base is arr._ndarray\n    result = arr.astype(np.int64, copy=True)\n    assert result is not arr._ndarray\n    tm.assert_numpy_array_equal(result, arr._ndarray.view('i8'))\n\ntest_astype_copies()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_astype.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import period_array\ndef test_astype_categorical():\n    arr = period_array(['2000', '2001', '2001', None], freq='D')\n    result = arr.astype('category')\n    categories = pd.PeriodIndex(['2000', '2001'], freq='D')\n    expected = pd.Categorical.from_codes([0, 1, 1, -1], categories=categories)\n    tm.assert_categorical_equal(result, expected)\n\ntest_astype_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_astype.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import period_array\ndef test_astype_period():\n    arr = period_array(['2000', '2001', None], freq='D')\n    result = arr.astype(PeriodDtype('M'))\n    expected = period_array(['2000', '2001', None], freq='M')\n    tm.assert_period_array_equal(result, expected)\n\ntest_astype_period()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_astype.py"}, {"test_code": "import pandas as pd\nfrom pandas.core.arrays import period_array\n\nclass TestReductions():\n\tdef test_min_max(self):\n\t    arr = period_array(['2000-01-03', '2000-01-03', 'NaT', '2000-01-02',\n\t        '2000-01-05', '2000-01-04'], freq='D')\n\t    result = arr.min()\n\t    expected = pd.Period('2000-01-02', freq='D')\n\t    assert result == expected\n\t    result = arr.max()\n\t    expected = pd.Period('2000-01-05', freq='D')\n\t    assert result == expected\n\t    result = arr.min(skipna=False)\n\t    assert result is pd.NaT\n\t    result = arr.max(skipna=False)\n\t    assert result is pd.NaT\n\t\nTestReductions().test_min_max()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_reductions.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs.offsets import MonthEnd\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import period_array\ndef test_period_array_readonly_object():\n    pa = period_array([pd.Period('2019-01-01')])\n    arr = np.asarray(pa, dtype='object')\n    arr.setflags(write=False)\n    result = period_array(arr)\n    tm.assert_period_array_equal(result, pa)\n    result = pd.Series(arr)\n    tm.assert_series_equal(result, pd.Series(pa))\n    result = pd.DataFrame({'A': arr})\n    tm.assert_frame_equal(result, pd.DataFrame({'A': pa}))\n\ntest_period_array_readonly_object()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_constructors.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs.offsets import MonthEnd\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import period_array\ndef test_from_datetime64_freq_changes():\n    arr = pd.date_range('2017', periods=3, freq='D')\n    result = PeriodArray._from_datetime64(arr, freq='M')\n    expected = period_array(['2017-01-01', '2017-01-01', '2017-01-01'],\n        freq='M')\n    tm.assert_period_array_equal(result, expected)\n\ntest_from_datetime64_freq_changes()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_constructors.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs.offsets import MonthEnd\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import period_array\ndef test_period_array_from_datetime64():\n    arr = np.array(['2020-01-01T00:00:00', '2020-02-02T00:00:00'], dtype=\n        'datetime64[ns]')\n    result = PeriodArray._from_datetime64(arr, freq=MonthEnd(2))\n    expected = period_array(['2020-01-01', '2020-02-01'], freq=MonthEnd(2))\n    tm.assert_period_array_equal(result, expected)\n\ntest_period_array_from_datetime64()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/period/test_constructors.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timedelta\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import NaT\nfrom pandas import Period\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import isna\nfrom pandas import timedelta_range\nimport pandas._testing as tm\nfrom pandas.core.arrays import period_array\n\nclass TestFillnaPad():\n\tdef test_fillna_parr(self):\n\t    dti = date_range(Timestamp.max - Timedelta(nanoseconds=10), periods=5,\n\t        freq='ns')\n\t    ser = Series(dti.to_period('ns'))\n\t    ser[2] = NaT\n\t    arr = period_array([Timestamp('2262-04-11 23:47:16.854775797'),\n\t        Timestamp('2262-04-11 23:47:16.854775798'), Timestamp(\n\t        '2262-04-11 23:47:16.854775798'), Timestamp(\n\t        '2262-04-11 23:47:16.854775800'), Timestamp(\n\t        '2262-04-11 23:47:16.854775801')], freq='ns')\n\t    expected = Series(arr)\n\t    filled = ser.ffill()\n\t    tm.assert_series_equal(filled, expected)\n\t\nTestFillnaPad().test_fillna_parr()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/series/methods/test_fillna.py"}], "instruction": "Functionality: The period_array function is designed to construct a new PeriodArray from a sequence of Period scalars, strings, or integers representing dates and times. It ensures all elements have the same frequency and handles missing values.\n\nInputs: \n- data: A sequence (list, tuple, or array-like) of Period objects, strings, or integers representing dates and times.\n- freq: The frequency of every element in the array. It can be a string, Tick, or BaseOffset object. If not provided, the function will attempt to infer it from the data.\n- copy: A boolean indicating whether a copy of the data should be made. Default is False.\n\nOutputs: \n- PeriodArray: The output is a PeriodArray object, which is a pandas data structure for representing arrays of Period objects. It includes the processed data with the specified or inferred frequency, and it can handle missing values represented by None or pandas.NaT.", "method_code_mask": "from __future__ import annotations\nfrom datetime import timedelta\nimport operator\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import TypeVar\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import lib\nfrom pandas._libs.arrays import NDArrayBacked\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import astype_overflowsafe\nfrom pandas._libs.tslibs import dt64arr_to_periodarr as c_dt64arr_to_periodarr\nfrom pandas._libs.tslibs import get_unit_from_dtype\nfrom pandas._libs.tslibs import iNaT\nfrom pandas._libs.tslibs import parsing\nfrom pandas._libs.tslibs import period as libperiod\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs.dtypes import FreqGroup\nfrom pandas._libs.tslibs.dtypes import PeriodDtypeBase\nfrom pandas._libs.tslibs.fields import isleapyear_arr\nfrom pandas._libs.tslibs.offsets import Tick\nfrom pandas._libs.tslibs.offsets import delta_to_tick\nfrom pandas._libs.tslibs.period import DIFFERENT_FREQ\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas._libs.tslibs.period import Period\nfrom pandas._libs.tslibs.period import get_period_field_arr\nfrom pandas._libs.tslibs.period import period_asfreq_arr\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCPeriodIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.generic import ABCTimedeltaArray\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.arrays import datetimelike as dtl\nimport pandas.core.common as com\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import Dtype\nfrom pandas._typing import FillnaOptions\nfrom pandas._typing import NpDtype\nfrom pandas._typing import npt\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.arrays.base import ExtensionArray\nimport pyarrow\nfrom pandas.core.arrays.arrow.extension_types import ArrowPeriodType\n\n\ndef period_array(data: (Sequence[Period | str | None] | AnyArrayLike), freq:\n    (str | Tick | BaseOffset | None)=None, copy: bool=False) ->PeriodArray: [M\n    ASK]\n"}
{"method_name": "new_block", "full_method_name": "new_block", "method_path": "../srcdata/Computation/pandas/pandas/core/internals/blocks.py", "method_code": "from __future__ import annotations\nimport inspect\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import final\nimport warnings\nimport weakref\nimport numpy as np\nfrom pandas._libs import NaT\nfrom pandas._libs import internals as libinternals\nfrom pandas._libs import lib\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas._libs.internals import BlockValuesRefs\nfrom pandas._libs.missing import NA\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeBackend\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import FillnaOptions\nfrom pandas._typing import IgnoreRaise\nfrom pandas._typing import QuantileInterpolation\nfrom pandas._typing import Shape\nfrom pandas._typing import npt\nfrom pandas.errors import AbstractMethodError\nfrom pandas.errors import OutOfBoundsDatetime\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.util._validators import validate_bool_kwarg\nfrom pandas.core.dtypes.astype import astype_array_safe\nfrom pandas.core.dtypes.astype import astype_is_view\nfrom pandas.core.dtypes.cast import LossySetitemError\nfrom pandas.core.dtypes.cast import can_hold_element\nfrom pandas.core.dtypes.cast import convert_dtypes\nfrom pandas.core.dtypes.cast import find_result_type\nfrom pandas.core.dtypes.cast import np_can_hold_element\nfrom pandas.core.dtypes.common import is_1d_only_ea_dtype\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core import missing\nimport pandas.core.algorithms as algos\nfrom pandas.core.array_algos.putmask import extract_bool_array\nfrom pandas.core.array_algos.putmask import putmask_inplace\nfrom pandas.core.array_algos.putmask import putmask_without_repeat\nfrom pandas.core.array_algos.putmask import setitem_datetimelike_compat\nfrom pandas.core.array_algos.putmask import validate_putmask\nfrom pandas.core.array_algos.quantile import quantile_compat\nfrom pandas.core.array_algos.replace import compare_or_regex_search\nfrom pandas.core.array_algos.replace import replace_regex\nfrom pandas.core.array_algos.replace import should_use_regex\nfrom pandas.core.array_algos.transforms import shift\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.computation import expressions\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import check_setitem_lengths\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nfrom pandas.core.api import Index\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\ndef new_block(values, placement: BlockPlacement, *, ndim: int, refs: (\n    BlockValuesRefs | None)=None) ->Block:\n    klass = get_block_type(values.dtype)\n    return klass(values, ndim=ndim, placement=placement, refs=refs)", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas.compat import IS64\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import period_range\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.internals import BlockManager\nfrom pandas.core.internals import SingleBlockManager\nfrom pandas.core.internals import make_block\nfrom pandas.core.internals.blocks import ensure_block_shape\nfrom pandas.core.internals.blocks import maybe_coerce_values\nfrom pandas.core.internals.blocks import new_block\n\nclass TestBlockManager():\n\tdef test_iget(self):\n\t    cols = Index(list('abc'))\n\t    values = np.random.default_rng(2).random((3, 3))\n\t    block = new_block(values=values.copy(), placement=BlockPlacement(np.\n\t        arange(3, dtype=np.intp)), ndim=values.ndim)\n\t    mgr = BlockManager(blocks=(block,), axes=[cols, Index(np.arange(3))])\n\t    tm.assert_almost_equal(mgr.iget(0).internal_values(), values[0])\n\t    tm.assert_almost_equal(mgr.iget(1).internal_values(), values[1])\n\t    tm.assert_almost_equal(mgr.iget(2).internal_values(), values[2])\n\t\nTestBlockManager().test_iget()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/internals/test_internals.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas.compat import IS64\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import period_range\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.internals import BlockManager\nfrom pandas.core.internals import SingleBlockManager\nfrom pandas.core.internals import make_block\nfrom pandas.core.internals.blocks import ensure_block_shape\nfrom pandas.core.internals.blocks import maybe_coerce_values\nfrom pandas.core.internals.blocks import new_block\n\nclass TestCanHoldElement():\n\tdef test_period_can_hold_element_emptylist(self):\n\t    pi = period_range('2016', periods=3, freq='Y')\n\t    blk = new_block(pi._data.reshape(1, 3), BlockPlacement([1]), ndim=2)\n\t    assert blk._can_hold_element([])\n\t\nTestCanHoldElement().test_period_can_hold_element_emptylist()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/internals/test_internals.py"}], "instruction": "Functionality: The new_block function is responsible for creating a new Block instance, which is a fundamental component in Pandas for managing data in DataFrame and Series. This function determines the appropriate type of Block to create based on the data type of the 'values' input. The returned Block object will contain the 'values' data, information on its placement within a larger data structure ('placement'), the number of dimensions of the data ('ndim'), and optional reference information ('refs').\n\nInputs: \n- values: An array-like object containing the data to be stored in the Block.\n- placement: An object of type BlockPlacement that specifies where the Block will be placed within a larger data structure.\n- ndim: An integer indicating the number of dimensions of the data.\n- refs: An optional BlockValuesRefs object that holds references to the 'values' data. This is useful for tracking ownership and potential sharing of the data.\n\nOutputs:\n- A Block object of the appropriate type, containing the provided 'values', placed according to 'placement', with the specified number of dimensions ('ndim'), and potentially with references defined by 'refs'.", "method_code_mask": "from __future__ import annotations\nimport inspect\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import final\nimport warnings\nimport weakref\nimport numpy as np\nfrom pandas._libs import NaT\nfrom pandas._libs import internals as libinternals\nfrom pandas._libs import lib\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas._libs.internals import BlockValuesRefs\nfrom pandas._libs.missing import NA\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AxisInt\nfrom pandas._typing import DtypeBackend\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import FillnaOptions\nfrom pandas._typing import IgnoreRaise\nfrom pandas._typing import QuantileInterpolation\nfrom pandas._typing import Shape\nfrom pandas._typing import npt\nfrom pandas.errors import AbstractMethodError\nfrom pandas.errors import OutOfBoundsDatetime\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.util._validators import validate_bool_kwarg\nfrom pandas.core.dtypes.astype import astype_array_safe\nfrom pandas.core.dtypes.astype import astype_is_view\nfrom pandas.core.dtypes.cast import LossySetitemError\nfrom pandas.core.dtypes.cast import can_hold_element\nfrom pandas.core.dtypes.cast import convert_dtypes\nfrom pandas.core.dtypes.cast import find_result_type\nfrom pandas.core.dtypes.cast import np_can_hold_element\nfrom pandas.core.dtypes.common import is_1d_only_ea_dtype\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import IntervalDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCDataFrame\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core import missing\nimport pandas.core.algorithms as algos\nfrom pandas.core.array_algos.putmask import extract_bool_array\nfrom pandas.core.array_algos.putmask import putmask_inplace\nfrom pandas.core.array_algos.putmask import putmask_without_repeat\nfrom pandas.core.array_algos.putmask import setitem_datetimelike_compat\nfrom pandas.core.array_algos.putmask import validate_putmask\nfrom pandas.core.array_algos.quantile import quantile_compat\nfrom pandas.core.array_algos.replace import compare_or_regex_search\nfrom pandas.core.array_algos.replace import replace_regex\nfrom pandas.core.array_algos.replace import should_use_regex\nfrom pandas.core.array_algos.transforms import shift\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import ExtensionArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.computation import expressions\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import check_setitem_lengths\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterable\nfrom collections.abc import Sequence\nfrom pandas.core.api import Index\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\n\n\ndef new_block(values, placement: BlockPlacement, *, ndim: int, refs: (\n    BlockValuesRefs | None)=None) ->Block: [MASK]\n"}
{"method_name": "mgr", "full_method_name": "mgr.iget", "method_path": "../srcdata/Computation/pandas/pandas/tests/internals/test_internals.py", "method_code": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas.compat import IS64\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import period_range\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.internals import BlockManager\nfrom pandas.core.internals import SingleBlockManager\nfrom pandas.core.internals import make_block\nfrom pandas.core.internals.blocks import ensure_block_shape\nfrom pandas.core.internals.blocks import maybe_coerce_values\nfrom pandas.core.internals.blocks import new_block\n@pytest.fixture\ndef mgr():\n    return create_mgr(\n        'a: f8; b: object; c: f8; d: object; e: f8;f: bool; g: i8; h: complex; i: datetime-1; j: datetime-2;k: M8[ns, US/Eastern]; l: M8[ns, CET];'\n        )", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas.compat import IS64\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import period_range\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.internals import BlockManager\nfrom pandas.core.internals import SingleBlockManager\nfrom pandas.core.internals import make_block\nfrom pandas.core.internals.blocks import ensure_block_shape\nfrom pandas.core.internals.blocks import maybe_coerce_values\nfrom pandas.core.internals.blocks import new_block\n\nclass TestBlockManager():\n\tdef test_iget(self):\n\t    cols = Index(list('abc'))\n\t    values = np.random.default_rng(2).random((3, 3))\n\t    block = new_block(values=values.copy(), placement=BlockPlacement(np.\n\t        arange(3, dtype=np.intp)), ndim=values.ndim)\n\t    mgr = BlockManager(blocks=(block,), axes=[cols, Index(np.arange(3))])\n\t    tm.assert_almost_equal(mgr.iget(0).internal_values(), values[0])\n\t    tm.assert_almost_equal(mgr.iget(1).internal_values(), values[1])\n\t    tm.assert_almost_equal(mgr.iget(2).internal_values(), values[2])\n\t\nTestBlockManager().test_iget()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/internals/test_internals.py"}], "instruction": "# To retrieve the data block at the second position (index 1) by column\nresult = mgr.iget(1)\n\n# To retrieve the data block for the field 'e' assuming 'e' is a valid field name\nresult = mgr.iget('e', axis=0)", "method_code_mask": "from datetime import date\nfrom datetime import datetime\nimport itertools\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs.internals import BlockPlacement\nfrom pandas.compat import IS64\nfrom pandas.core.dtypes.common import is_scalar\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import period_range\nimport pandas._testing as tm\nimport pandas.core.algorithms as algos\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays import TimedeltaArray\nfrom pandas.core.internals import BlockManager\nfrom pandas.core.internals import SingleBlockManager\nfrom pandas.core.internals import make_block\nfrom pandas.core.internals.blocks import ensure_block_shape\nfrom pandas.core.internals.blocks import maybe_coerce_values\nfrom pandas.core.internals.blocks import new_block\n\n\n@pytest.fixture\ndef mgr(): [MASK]\n"}
{"method_name": "from_dataframe", "full_method_name": "from_dataframe", "method_path": "../srcdata/Computation/pandas/pandas/core/interchange/from_dataframe.py", "method_code": "from __future__ import annotations\nimport ctypes\nimport re\nfrom typing import Any\nfrom typing import overload\nimport numpy as np\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas.core.interchange.dataframe_protocol import Buffer\nfrom pandas.core.interchange.dataframe_protocol import Column\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pandas.core.interchange.utils import Endianness\ndef from_dataframe(df, allow_copy: bool=True) ->pd.DataFrame:\n    \"\"\"\n    Build a ``pd.DataFrame`` from any DataFrame supporting the interchange protocol.\n\n    Parameters\n    ----------\n    df : DataFrameXchg\n        Object supporting the interchange protocol, i.e. `__dataframe__` method.\n    allow_copy : bool, default: True\n        Whether to allow copying the memory to perform the conversion\n        (if false then zero-copy approach is requested).\n\n    Returns\n    -------\n    pd.DataFrame\n\n    Examples\n    --------\n    >>> df_not_necessarily_pandas = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n    >>> interchange_object = df_not_necessarily_pandas.__dataframe__()\n    >>> interchange_object.column_names()\n    Index(['A', 'B'], dtype='object')\n    >>> df_pandas = pd.api.interchange.from_dataframe(\n    ...     interchange_object.select_columns_by_name([\"A\"])\n    ... )\n    >>> df_pandas\n         A\n    0    1\n    1    2\n\n    These methods (``column_names``, ``select_columns_by_name``) should work\n    for any dataframe library which implements the interchange protocol.\n    \"\"\"\n    if isinstance(df, pd.DataFrame):\n        return df\n    if not hasattr(df, '__dataframe__'):\n        raise ValueError('`df` does not support __dataframe__')\n    return _from_dataframe(df.__dataframe__(allow_copy=allow_copy),\n        allow_copy=allow_copy)", "test_code_list": [{"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat import is_ci_environment\nfrom pandas.compat import is_platform_windows\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.interchange.column import PandasColumn\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.from_dataframe import from_dataframe\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pyarrow.interchange import from_dataframe as pa_from_dataframe\nimport pyarrow.compute as pc\nimport pyarrow.interchange as pai\ndef test_categorical_pyarrow():\n    pa = pytest.importorskip('pyarrow', '11.0.0')\n    arr = ['Mon', 'Tue', 'Mon', 'Wed', 'Mon', 'Thu', 'Fri', 'Sat', 'Sun']\n    table = pa.table({'weekday': pa.array(arr).dictionary_encode()})\n    exchange_df = table.__dataframe__()\n    result = from_dataframe(exchange_df)\n    weekday = pd.Categorical(arr, categories=['Mon', 'Tue', 'Wed', 'Thu',\n        'Fri', 'Sat', 'Sun'])\n    expected = pd.DataFrame({'weekday': weekday})\n    tm.assert_frame_equal(result, expected)\n\ntest_categorical_pyarrow()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/interchange/test_impl.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat import is_ci_environment\nfrom pandas.compat import is_platform_windows\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.interchange.column import PandasColumn\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.from_dataframe import from_dataframe\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pyarrow.interchange import from_dataframe as pa_from_dataframe\nimport pyarrow.compute as pc\nimport pyarrow.interchange as pai\ndef test_empty_categorical_pyarrow():\n    pa = pytest.importorskip('pyarrow', '11.0.0')\n    arr = [None]\n    table = pa.table({'arr': pa.array(arr, 'float64').dictionary_encode()})\n    exchange_df = table.__dataframe__()\n    result = from_dataframe(exchange_df)\n    expected = pd.DataFrame({'arr': pd.Categorical([np.nan])})\n    tm.assert_frame_equal(result, expected)\n\ntest_empty_categorical_pyarrow()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/interchange/test_impl.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat import is_ci_environment\nfrom pandas.compat import is_platform_windows\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.interchange.column import PandasColumn\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.from_dataframe import from_dataframe\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pyarrow.interchange import from_dataframe as pa_from_dataframe\nimport pyarrow.compute as pc\nimport pyarrow.interchange as pai\ndef test_large_string_pyarrow():\n    pa = pytest.importorskip('pyarrow', '11.0.0')\n    arr = ['Mon', 'Tue']\n    table = pa.table({'weekday': pa.array(arr, 'large_string')})\n    exchange_df = table.__dataframe__()\n    result = from_dataframe(exchange_df)\n    expected = pd.DataFrame({'weekday': ['Mon', 'Tue']})\n    tm.assert_frame_equal(result, expected)\n    assert pa.Table.equals(pa.interchange.from_dataframe(result), table)\n\ntest_large_string_pyarrow()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/interchange/test_impl.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat import is_ci_environment\nfrom pandas.compat import is_platform_windows\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.interchange.column import PandasColumn\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.from_dataframe import from_dataframe\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pyarrow.interchange import from_dataframe as pa_from_dataframe\nimport pyarrow.compute as pc\nimport pyarrow.interchange as pai\ndef test_datetime():\n    df = pd.DataFrame({'A': [pd.Timestamp('2022-01-01'), pd.NaT]})\n    col = df.__dataframe__().get_column_by_name('A')\n    assert col.size() == 2\n    assert col.null_count == 1\n    assert col.dtype[0] == DtypeKind.DATETIME\n    assert col.describe_null == (ColumnNullType.USE_SENTINEL, iNaT)\n    tm.assert_frame_equal(df, from_dataframe(df.__dataframe__()))\n\ntest_datetime()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/interchange/test_impl.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import iNaT\nfrom pandas.compat import is_ci_environment\nfrom pandas.compat import is_platform_windows\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.interchange.column import PandasColumn\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.from_dataframe import from_dataframe\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pyarrow.interchange import from_dataframe as pa_from_dataframe\nimport pyarrow.compute as pc\nimport pyarrow.interchange as pai\ndef test_empty_dataframe():\n    df = pd.DataFrame({'a': []}, dtype='int8')\n    dfi = df.__dataframe__()\n    result = from_dataframe(dfi, allow_copy=False)\n    expected = pd.DataFrame({'a': []}, dtype='int8')\n    tm.assert_frame_equal(result, expected)\n\ntest_empty_dataframe()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/interchange/test_impl.py"}], "instruction": "Functionality: The from_dataframe function is designed to convert a DataFrame object that supports the DataFrame interchange protocol into a pandas DataFrame. It can handle various DataFrame implementations from different libraries, as long as they adhere to the interchange protocol. The function ensures compatibility and data transfer between different DataFrame objects, facilitating a standardized approach for data manipulation and analysis across various Python libraries.\n\nInputs: \n1. df: DataFrameXchg - This input is a DataFrame object that supports the interchange protocol. It can be any DataFrame-like object from different libraries, as long as it has a __dataframe__ method that allows it to be converted and interacted with according to the protocol.\n2. allow_copy: bool, default: True - This argument specifies whether the function is allowed to copy the memory of the input DataFrame during the conversion process. If set to True, the function may copy the data to ensure a clean and independent pandas DataFrame is produced. If set to False, the function requests a zero-copy approach, where possible, to avoid unnecessary memory copying.\n\nOutputs: \n1. pd.DataFrame - The function returns a pandas DataFrame. This DataFrame is constructed from the input DataFrame object that supports the interchange protocol. The returned DataFrame is capable of being used with the full set of pandas functionalities, providing a seamless transition between the different implementations of DataFrame-like objects.", "method_code_mask": "from __future__ import annotations\nimport ctypes\nimport re\nfrom typing import Any\nfrom typing import overload\nimport numpy as np\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas.core.interchange.dataframe_protocol import Buffer\nfrom pandas.core.interchange.dataframe_protocol import Column\nfrom pandas.core.interchange.dataframe_protocol import ColumnNullType\nfrom pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\nfrom pandas.core.interchange.dataframe_protocol import DtypeKind\nfrom pandas.core.interchange.utils import ArrowCTypes\nfrom pandas.core.interchange.utils import Endianness\n\n\ndef from_dataframe(df, allow_copy: bool=True) ->pd.DataFrame: [MASK]\n"}
{"method_name": "length_of_indexer", "full_method_name": "length_of_indexer", "method_path": "../srcdata/Computation/pandas/pandas/core/indexers/utils.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.core.dtypes.common import is_array_like\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas._typing import AnyArrayLike\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.construction import array as pd_array\ndef length_of_indexer(indexer, target=None) ->int:\n    \"\"\"\n    Return the expected length of target[indexer]\n\n    Returns\n    -------\n    int\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        target_len = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += target_len\n        if stop is None or stop > target_len:\n            stop = target_len\n        elif stop < 0:\n            stop += target_len\n        if step is None:\n            step = 1\n        elif step < 0:\n            start, stop = stop + 1, start + 1\n            step = -step\n        return (stop - start + step - 1) // step\n    elif isinstance(indexer, (ABCSeries, ABCIndex, np.ndarray, list)):\n        if isinstance(indexer, list):\n            indexer = np.array(indexer)\n        if indexer.dtype == bool:\n            return indexer.sum()\n        return len(indexer)\n    elif isinstance(indexer, range):\n        return (indexer.stop - indexer.start) // indexer.step\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError('cannot find the length of the indexer')", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.indexers import is_scalar_indexer\nfrom pandas.core.indexers import length_of_indexer\nfrom pandas.core.indexers import validate_indices\ndef test_length_of_indexer():\n    arr = np.zeros(4, dtype=bool)\n    arr[0] = 1\n    result = length_of_indexer(arr)\n    assert result == 1\n\ntest_length_of_indexer()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexing/test_indexers.py"}], "instruction": "Functionality: The length_of_indexer function is designed to calculate the expected length of a target object when indexed by a given indexer. This function supports various types of indexers, such as slices, Series, Index, numpy arrays, lists, ranges, and single values. It can also work with a target object if provided, especially when dealing with slices.\n\nInputs: \n- indexer: This can be a slice object, a pandas Series, a pandas Index, a numpy array, a list, a range, or a single value. The indexer is used to determine the length of the subset that would be selected from the target.\n- target (optional): This is the object that the indexer would be applied to. It is only necessary when the indexer is a slice.\n\nOutputs:\n- int: The function returns an integer representing the expected length of the subset that would be selected from the target using the indexer.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.core.dtypes.common import is_array_like\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas._typing import AnyArrayLike\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.construction import array as pd_array\n\n\ndef length_of_indexer(indexer, target=None) ->int: [MASK]\n"}
{"method_name": "df", "full_method_name": "df.copy", "method_path": "../srcdata/Computation/pandas/pandas/tests/indexing/test_categorical.py", "method_code": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalDtype\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\n@pytest.fixture\ndef df():\n    return DataFrame({'A': np.arange(6, dtype='int64')}, index=\n        CategoricalIndex(list('aabbca'), dtype=CategoricalDtype(list('cab')\n        ), name='B'))", "test_code_list": [{"test_code": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalDtype\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\n\nclass TestCategoricalIndex():\n\tdef test_ix_categorical_index(self):\n\t    df = DataFrame(np.random.default_rng(2).standard_normal((3, 3)), index=\n\t        list('ABC'), columns=list('XYZ'))\n\t    cdf = df.copy()\n\t    cdf.index = CategoricalIndex(df.index)\n\t    cdf.columns = CategoricalIndex(df.columns)\n\t    expect = Series(df.loc['A', :], index=cdf.columns, name='A')\n\t    tm.assert_series_equal(cdf.loc['A', :], expect)\n\t    expect = Series(df.loc[:, 'X'], index=cdf.index, name='X')\n\t    tm.assert_series_equal(cdf.loc[:, 'X'], expect)\n\t    exp_index = CategoricalIndex(list('AB'), categories=['A', 'B', 'C'])\n\t    expect = DataFrame(df.loc[['A', 'B'], :], columns=cdf.columns, index=\n\t        exp_index)\n\t    tm.assert_frame_equal(cdf.loc[['A', 'B'], :], expect)\n\t    exp_columns = CategoricalIndex(list('XY'), categories=['X', 'Y', 'Z'])\n\t    expect = DataFrame(df.loc[:, ['X', 'Y']], index=cdf.index, columns=\n\t        exp_columns)\n\t    tm.assert_frame_equal(cdf.loc[:, ['X', 'Y']], expect)\n\t\nTestCategoricalIndex().test_ix_categorical_index()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexing/test_categorical.py"}], "instruction": "Functionality: The task is to implement a function to create a copy of a given DataFrame. The function should deeply copy the entire DataFrame, including the data, the index, and columns, such that any changes made to the copied DataFrame do not affect the original DataFrame.\n\nInputs: A DataFrame, which is a two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). The provided DataFrame contains a single column 'A' with integer values ranging from 0 to 5, and the index is a CategoricalIndex named 'B' with values 'a', 'b', and 'c'.\n\nOutputs: A new DataFrame that is a deep copy of the input DataFrame. This means that all elements, including data, index, and columns, are copied, and the copied DataFrame is independent of the original DataFrame. Any modifications to the copied DataFrame should not affect the original DataFrame.", "method_code_mask": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalDtype\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Interval\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\n\n\n@pytest.fixture\ndef df(): [MASK]\n"}
{"method_name": "reset_option", "full_method_name": "reset_option", "method_path": "../srcdata/Computation/pandas/pandas/_config/config.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\ndef reset_option(pat: str) ->None:\n    \"\"\"\n    Reset one or more options to their default value.\n\n    Parameters\n    ----------\n    pat : str/regex\n        If specified only options matching ``pat*`` will be reset.\n        Pass ``\"all\"`` as argument to reset all options.\n\n        .. warning::\n\n            Partial matches are supported for convenience, but unless you\n            use the full option name (e.g. x.y.z.option_name), your code may break\n            in future versions if new options with similar names are introduced.\n\n    Returns\n    -------\n    None\n        No return value.\n\n    See Also\n    --------\n    get_option : Retrieve the value of the specified option.\n    set_option : Set the value of the specified option or options.\n    describe_option : Print the description for one or more registered options.\n\n    Notes\n    -----\n    For all available options, please view the\n    :ref:`User Guide <options.available>`.\n\n    Examples\n    --------\n    >>> pd.reset_option(\"display.max_columns\")  # doctest: +SKIP\n    \"\"\"\n    keys = _select_options(pat)\n    if len(keys) == 0:\n        raise OptionError(f'No such keys(s) for pat={pat!r}')\n    if len(keys) > 1 and len(pat) < 4 and pat != 'all':\n        raise ValueError(\n            'You must specify at least 4 characters when resetting multiple keys, use the special keyword \"all\" to reset all the options to their default value'\n            )\n    for k in keys:\n        set_option(k, _registered_options[k].defval)", "test_code_list": [{"test_code": "from datetime import datetime\nfrom io import StringIO\nimport re\nfrom shutil import get_terminal_size\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import get_option\nfrom pandas import option_context\nfrom pandas import read_csv\nfrom pandas import reset_option\nfrom pandas.io.formats import printing\nimport pandas.io.formats.format as fmt\n\nclass TestDataFrameFormatting():\n\tdef test_repr_chop_threshold(self):\n\t    df = DataFrame([[0.1, 0.5], [0.5, -0.1]])\n\t    reset_option('display.chop_threshold')\n\t    assert repr(df) == '     0    1\\n0  0.1  0.5\\n1  0.5 -0.1'\n\t    with option_context('display.chop_threshold', 0.2):\n\t        assert repr(df) == '     0    1\\n0  0.0  0.5\\n1  0.5  0.0'\n\t    with option_context('display.chop_threshold', 0.6):\n\t        assert repr(df) == '     0    1\\n0  0.0  0.0\\n1  0.0  0.0'\n\t    with option_context('display.chop_threshold', None):\n\t        assert repr(df) == '     0    1\\n0  0.1  0.5\\n1  0.5 -0.1'\n\t\nTestDataFrameFormatting().test_repr_chop_threshold()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_format.py"}], "instruction": "Functionality: Reset one or more options to their default value in a pandas-like environment.\n\nInputs: \n- pat: str\n  A string representing the pattern to match for resetting options. If specified, only options matching \"pat*\" will be reset. Use \"all\" as an argument to reset all options. Partial matches are supported, but using full option names is recommended to prevent potential issues with future versions introducing new options with similar names.\n\nOutputs: \n- None: The function does not return a value; it performs the reset operation in place.\n\nAdditional Notes: \n- The function warns against using short patterns that may result in multiple key matches, unless the special keyword \"all\" is used. If no keys are found for the provided pattern, an OptionError is raised. If more than one key is matched with a pattern shorter than 4 characters (excluding \"all\"), a ValueError is raised.\n\nSee Also:\n- get_option: Retrieve the value of the specified option.\n- set_option: Set the value of the specified option or options.\n- describe_option: Print the description for one or more registered options.\n\nFor detailed information on all available options, refer to the User Guide documentation.", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import NamedTuple\nfrom typing import cast\nimport warnings\nfrom pandas._typing import F\nfrom pandas.util._exceptions import find_stack_level\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Sequence\nimport keyword\nimport tokenize\n\n\ndef reset_option(pat: str) ->None: [MASK]\n"}
{"method_name": "set_locale", "full_method_name": "set_locale", "method_path": "../srcdata/Computation/pandas/pandas/_config/localization.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport locale\nimport platform\nimport re\nimport subprocess\nfrom typing import TYPE_CHECKING\nfrom typing import cast\nfrom pandas._config.config import options\nfrom collections.abc import Generator\n@contextmanager\ndef set_locale(new_locale: (str | tuple[str, str]), lc_var: int=locale.LC_ALL\n    ) ->Generator[str | tuple[str, str], None, None]:\n    \"\"\"\n    Context manager for temporarily setting a locale.\n\n    Parameters\n    ----------\n    new_locale : str or tuple\n        A string of the form <language_country>.<encoding>. For example to set\n        the current locale to US English with a UTF8 encoding, you would pass\n        \"en_US.UTF-8\".\n    lc_var : int, default `locale.LC_ALL`\n        The category of the locale being set.\n\n    Notes\n    -----\n    This is useful when you want to run a particular block of code under a\n    particular locale, without globally setting the locale. This probably isn't\n    thread-safe.\n    \"\"\"\n    current_locale = locale.setlocale(lc_var)\n    try:\n        locale.setlocale(lc_var, new_locale)\n        normalized_code, normalized_encoding = locale.getlocale()\n        if normalized_code is not None and normalized_encoding is not None:\n            yield f'{normalized_code}.{normalized_encoding}'\n        else:\n            yield new_locale\n    finally:\n        locale.setlocale(lc_var, current_locale)", "test_code_list": [{"test_code": "import calendar\nimport datetime\nimport decimal\nimport json\nimport locale\nimport math\nimport re\nimport time\nimport dateutil\nimport numpy as np\nimport pytest\nimport pandas._libs.json as ujson\nfrom pandas.compat import IS64\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import Timedelta\nfrom pandas import Timestamp\nfrom pandas import date_range\nimport pandas._testing as tm\n\nclass TestUltraJSONTests():\n\tdef test_encode_non_c_locale(self):\n\t    lc_category = locale.LC_NUMERIC\n\t    for new_locale in ('it_IT.UTF-8', 'Italian_Italy'):\n\t        if tm.can_set_locale(new_locale, lc_category):\n\t            with set_locale(new_locale, lc_category):\n\t                assert ujson.ujson_loads(ujson.ujson_dumps(4.78e+60)\n\t                    ) == 4.78e+60\n\t                assert ujson.ujson_loads('4.78', precise_float=True) == 4.78\n\t            break\n\t\nTestUltraJSONTests().test_encode_non_c_locale()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_ujson.py"}], "instruction": "Functionality: \nThe set_locale function is a context manager designed to temporarily set a locale for a specified block of code. It allows for setting the locale to a specific language and encoding without affecting the global locale settings. This is particularly useful when running code that requires a specific locale for proper operation, ensuring that the original locale is restored once the code execution is completed.\n\nInputs: \n1. new_locale: str or tuple[str, str]\n   A string or tuple representing the desired locale. In string form, it should be in the format <language_country>.<encoding>, e.g., \"en_US.UTF-8\" for US English with UTF-8 encoding.\n2. lc_var: int, default=locale.LC_ALL\n   An integer constant that specifies the category of the locale being set. This parameter is optional and defaults to LC_ALL, which affects all locale categories.\n\nOutputs:\n1. Generator[str | tuple[str, str], None, None]\n   A generator that yields the actual locale settings after applying the new_locale. The yielded value is either a string in the format <language_code>.<encoding> if the locale was successfully normalized, or the original new_locale value if normalization failed. The generator ensures that the original locale is restored upon exiting the context managed by this function.", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nimport locale\nimport platform\nimport re\nimport subprocess\nfrom typing import TYPE_CHECKING\nfrom typing import cast\nfrom pandas._config.config import options\nfrom collections.abc import Generator\n\n\n@contextmanager\ndef set_locale(new_locale: (str | tuple[str, str]), lc_var: int=locale.LC_ALL\n    ) ->Generator[str | tuple[str, str], None, None]: [MASK]\n"}
{"method_name": "parallel_coordinates", "full_method_name": "parallel_coordinates", "method_path": "../srcdata/Computation/pandas/pandas/plotting/_misc.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom pandas.plotting._core import _get_plot_backend\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom matplotlib.axes import Axes\nfrom matplotlib.colors import Colormap\nfrom matplotlib.figure import Figure\nfrom matplotlib.table import Table\nimport numpy as np\nfrom pandas import DataFrame\nfrom pandas import Series\ndef parallel_coordinates(frame: DataFrame, class_column: str, cols: (list[\n    str] | None)=None, ax: (Axes | None)=None, color: (list[str] | tuple[\n    str, ...] | None)=None, use_columns: bool=False, xticks: (list | tuple |\n    None)=None, colormap: (Colormap | str | None)=None, axvlines: bool=True,\n    axvlines_kwds: (Mapping[str, Any] | None)=None, sort_labels: bool=False,\n    **kwargs) ->Axes:\n    \"\"\"\n    Parallel coordinates plotting.\n\n    Parameters\n    ----------\n    frame : DataFrame\n        The DataFrame to be plotted.\n    class_column : str\n        Column name containing class names.\n    cols : list, optional\n        A list of column names to use.\n    ax : matplotlib.axis, optional\n        Matplotlib axis object.\n    color : list or tuple, optional\n        Colors to use for the different classes.\n    use_columns : bool, optional\n        If true, columns will be used as xticks.\n    xticks : list or tuple, optional\n        A list of values to use for xticks.\n    colormap : str or matplotlib colormap, default None\n        Colormap to use for line colors.\n    axvlines : bool, optional\n        If true, vertical lines will be added at each xtick.\n    axvlines_kwds : keywords, optional\n        Options to be passed to axvline method for vertical lines.\n    sort_labels : bool, default False\n        Sort class_column labels, useful when assigning colors.\n    **kwargs\n        Options to pass to matplotlib plotting method.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The matplotlib axes containing the parallel coordinates plot.\n\n    See Also\n    --------\n    plotting.andrews_curves : Generate a matplotlib plot for visualizing clusters\n        of multivariate data.\n    plotting.radviz : Plot a multidimensional dataset in 2D.\n\n    Examples\n    --------\n\n    .. plot::\n        :context: close-figs\n\n        >>> df = pd.read_csv(\n        ...     \"https://raw.githubusercontent.com/pandas-dev/\"\n        ...     \"pandas/main/pandas/tests/io/data/csv/iris.csv\"\n        ... )\n        >>> pd.plotting.parallel_coordinates(\n        ...     df, \"Name\", color=(\"#556270\", \"#4ECDC4\", \"#C7F464\")\n        ... )  # doctest: +SKIP\n    \"\"\"\n    plot_backend = _get_plot_backend('matplotlib')\n    return plot_backend.parallel_coordinates(frame=frame, class_column=\n        class_column, cols=cols, ax=ax, color=color, use_columns=\n        use_columns, xticks=xticks, colormap=colormap, axvlines=axvlines,\n        axvlines_kwds=axvlines_kwds, sort_labels=sort_labels, **kwargs)", "test_code_list": [{"test_code": "import os\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import interval_range\nfrom pandas import period_range\nfrom pandas import plotting\nfrom pandas import read_csv\nimport pandas._testing as tm\nfrom pandas.tests.plotting.common import _check_plot_works\nfrom pandas.plotting._matplotlib.style import get_standard_colors\n\nclass TestDataFramePlots():\n\t@pytest.mark.filterwarnings('ignore:Attempting to set:UserWarning')\n\tdef test_parallel_coordinates_with_sorted_labels(self):\n\t    df = DataFrame({'feat': list(range(30)), 'class': [(2) for _ in range(\n\t        10)] + [(3) for _ in range(10)] + [(1) for _ in range(10)]})\n\t    ax = parallel_coordinates(df, 'class', sort_labels=True)\n\t    polylines, labels = ax.get_legend_handles_labels()\n\t    color_label_tuples = zip([polyline.get_color() for polyline in\n\t        polylines], labels)\n\t    ordered_color_label_tuples = sorted(color_label_tuples, key=lambda x: x[1])\n\t    prev_next_tupels = zip(list(ordered_color_label_tuples[0:-1]), list(\n\t        ordered_color_label_tuples[1:]))\n\t    for prev, nxt in prev_next_tupels:\n\t        assert prev[1] < nxt[1] and prev[0] < nxt[0]\n\t\nTestDataFramePlots().test_parallel_coordinates_with_sorted_labels()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/plotting/test_misc.py"}, {"test_code": "import os\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import date_range\nfrom pandas import interval_range\nfrom pandas import period_range\nfrom pandas import plotting\nfrom pandas import read_csv\nimport pandas._testing as tm\nfrom pandas.tests.plotting.common import _check_plot_works\nfrom pandas.plotting._matplotlib.style import get_standard_colors\n\nclass TestDataFramePlots():\n\tdef test_get_standard_colors_random_seed(self):\n\t    df = DataFrame(np.zeros((10, 10)))\n\t    parallel_coordinates(df, 0)\n\t    rand1 = np.random.default_rng(None).random()\n\t    parallel_coordinates(df, 0)\n\t    rand2 = np.random.default_rng(None).random()\n\t    assert rand1 != rand2\n\t\nTestDataFramePlots().test_get_standard_colors_random_seed()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/plotting/test_misc.py"}], "instruction": "Functionality: The function 'parallel_coordinates' creates a parallel coordinates plot for a given DataFrame. This type of plot is particularly useful for visualizing multivariate data, allowing for the comparison of multiple variables on parallel axes.\n\nInputs:\n    frame: DataFrame - The DataFrame containing the data to be plotted.\n    class_column: str - The name of the column in the DataFrame that contains class labels or categories.\n    cols: list[str] | None - Optional list of column names from the DataFrame to be used in the plot.\n    ax: Axes | None - An optional Matplotlib axis object on which to plot.\n    color: list[str] | tuple[str, ...] | None - Optional colors to use for different classes in the plot.\n    use_columns: bool - If True, column names will be used as xticks.\n    xticks: list | tuple | None - Optional list of values to use for the xticks.\n    colormap: Colormap | str | None - Optional colormap to use for line colors in the plot.\n    axvlines: bool - If True, vertical lines will be added at each xtick.\n    axvlines_kwds: Mapping[str, Any] | None - Optional keywords to be passed to the axvline method for customizing vertical lines.\n    sort_labels: bool - If True, class_column labels will be sorted, useful when assigning colors.\n    **kwargs: Additional keyword arguments to pass to the matplotlib plotting method.\n\nOutputs:\n    matplotlib.axes.Axes - The matplotlib axes object containing the parallel coordinates plot.", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom pandas.plotting._core import _get_plot_backend\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom matplotlib.axes import Axes\nfrom matplotlib.colors import Colormap\nfrom matplotlib.figure import Figure\nfrom matplotlib.table import Table\nimport numpy as np\nfrom pandas import DataFrame\nfrom pandas import Series\n\n\ndef parallel_coordinates(frame: DataFrame, class_column: str, cols: (list[\n    str] | None)=None, ax: (Axes | None)=None, color: (list[str] | tuple[\n    str, ...] | None)=None, use_columns: bool=False, xticks: (list | tuple |\n    None)=None, colormap: (Colormap | str | None)=None, axvlines: bool=True,\n    axvlines_kwds: (Mapping[str, Any] | None)=None, sort_labels: bool=False,\n    **kwargs) ->Axes: [MASK]\n"}
{"method_name": "get_datevalue", "full_method_name": "get_datevalue", "method_path": "../srcdata/Computation/pandas/pandas/plotting/_matplotlib/converter.py", "method_code": "from __future__ import annotations\nimport contextlib\nimport datetime as pydt\nfrom datetime import datetime\nfrom datetime import tzinfo\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport matplotlib as mpl\nimport matplotlib.dates as mdates\nimport matplotlib.units as munits\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs.dtypes import FreqGroup\nfrom pandas._libs.tslibs.dtypes import periods_per_day\nfrom pandas._typing import F\nfrom pandas._typing import npt\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_nested_list_like\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import get_option\nimport pandas.core.common as com\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nimport pandas.core.tools.datetimes as tools\nfrom collections.abc import Generator\nfrom matplotlib.axis import Axis\nfrom pandas._libs.tslibs.offsets import BaseOffset\ndef get_datevalue(date, freq):\n    if isinstance(date, Period):\n        return date.asfreq(freq).ordinal\n    elif isinstance(date, (str, datetime, pydt.date, pydt.time, np.datetime64)\n        ):\n        return Period(date, freq).ordinal\n    elif is_integer(date) or is_float(date) or isinstance(date, (np.ndarray,\n        Index)) and date.size == 1:\n        return date\n    elif date is None:\n        return None\n    raise ValueError(f\"Unrecognizable date '{date}'\")", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nimport pickle\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import to_offset\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import NaT\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import isna\nfrom pandas import to_datetime\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom pandas.core.indexes.datetimes import bdate_range\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.indexes.timedeltas import timedelta_range\nfrom pandas.tseries.offsets import WeekOfMonth\nimport pandas.plotting._matplotlib.converter as conv\n\nclass TestTSPlot():\n\tdef test_get_datevalue(self):\n\t    assert get_datevalue(None, 'D') is None\n\t    assert get_datevalue(1987, 'Y') == 1987\n\t    assert get_datevalue(Period(1987, 'Y'), 'M') == Period('1987-12', 'M'\n\t        ).ordinal\n\t    assert get_datevalue('1/1/1987', 'D') == Period('1987-1-1', 'D'\n\t        ).ordinal\n\t\nTestTSPlot().test_get_datevalue()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/plotting/test_datetimelike.py"}], "instruction": "Functionality: The get_datevalue function is designed to convert various date representations into an ordinal value, specifically tailored for the given frequency (freq). This function supports a wide range of input types including Period objects, strings representing dates, Python datetime objects, numpy datetime64 objects, integers, floats, single-element numpy arrays, single-element pandas Indexes, as well as None. The function will convert these inputs into an ordinal value based on the specified frequency. For Period objects, it will first adjust the period to the given frequency before converting. For integers, floats, or single-element arrays, the function assumes the input is already in the correct form and returns it as is. If the input is None, the function returns None. For unrecognized input types or formats, the function raises a ValueError.\n\nInputs: \n1. date: This is the input date or time representation. It can be a Period object, string, datetime object, date object, time object, numpy datetime64, integer, float, single-element numpy array, single-element pandas Index, or None.\n2. freq: This is the frequency at which the date ordinal should be calculated. It's expected to be a string or an object that pandas recognizes as a frequency.\n\nOutputs:\nThe function returns an ordinal value representing the date converted to the specified frequency. If the input date is None, the function returns None. If the input is already an integer, float, or single-element array, it is returned as is. If the input cannot be recognized or converted, the function raises a ValueError.", "method_code_mask": "from __future__ import annotations\nimport contextlib\nimport datetime as pydt\nfrom datetime import datetime\nfrom datetime import tzinfo\nimport functools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport matplotlib as mpl\nimport matplotlib.dates as mdates\nimport matplotlib.units as munits\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs.dtypes import FreqGroup\nfrom pandas._libs.tslibs.dtypes import periods_per_day\nfrom pandas._typing import F\nfrom pandas._typing import npt\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_float_dtype\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_nested_list_like\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import get_option\nimport pandas.core.common as com\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nimport pandas.core.tools.datetimes as tools\nfrom collections.abc import Generator\nfrom matplotlib.axis import Axis\nfrom pandas._libs.tslibs.offsets import BaseOffset\n\n\ndef get_datevalue(date, freq): [MASK]\n"}
{"method_name": "period_range", "full_method_name": "period_range", "method_path": "../srcdata/Computation/pandas/pandas/core/indexes/period.py", "method_code": "from __future__ import annotations\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs import index as libindex\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import Period\nfrom pandas._libs.tslibs import Resolution\nfrom pandas._libs.tslibs import Tick\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.arrays.period import PeriodArray\nfrom pandas.core.arrays.period import period_array\nfrom pandas.core.arrays.period import raise_on_incompatible\nfrom pandas.core.arrays.period import validate_dtype_freq\nimport pandas.core.common as com\nimport pandas.core.indexes.base as ibase\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.indexes.datetimelike import DatetimeIndexOpsMixin\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom pandas.core.indexes.datetimes import Index\nfrom pandas.core.indexes.extension import inherit_names\nfrom collections.abc import Hashable\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import npt\ndef period_range(start=None, end=None, periods: (int | None)=None, freq=\n    None, name: (Hashable | None)=None) ->PeriodIndex:\n    \"\"\"\n    Return a fixed frequency PeriodIndex.\n\n    The day (calendar) is the default frequency.\n\n    Parameters\n    ----------\n    start : str, datetime, date, pandas.Timestamp, or period-like, default None\n        Left bound for generating periods.\n    end : str, datetime, date, pandas.Timestamp, or period-like, default None\n        Right bound for generating periods.\n    periods : int, default None\n        Number of periods to generate.\n    freq : str or DateOffset, optional\n        Frequency alias. By default the freq is taken from `start` or `end`\n        if those are Period objects. Otherwise, the default is ``\"D\"`` for\n        daily frequency.\n    name : str, default None\n        Name of the resulting PeriodIndex.\n\n    Returns\n    -------\n    PeriodIndex\n\n    Notes\n    -----\n    Of the three parameters: ``start``, ``end``, and ``periods``, exactly two\n    must be specified.\n\n    To learn more about the frequency strings, please see\n    :ref:`this link<timeseries.offset_aliases>`.\n\n    Examples\n    --------\n    >>> pd.period_range(start=\"2017-01-01\", end=\"2018-01-01\", freq=\"M\")\n    PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',\n             '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',\n             '2018-01'],\n            dtype='period[M]')\n\n    If ``start`` or ``end`` are ``Period`` objects, they will be used as anchor\n    endpoints for a ``PeriodIndex`` with frequency matching that of the\n    ``period_range`` constructor.\n\n    >>> pd.period_range(\n    ...     start=pd.Period(\"2017Q1\", freq=\"Q\"),\n    ...     end=pd.Period(\"2017Q2\", freq=\"Q\"),\n    ...     freq=\"M\",\n    ... )\n    PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'],\n                dtype='period[M]')\n    \"\"\"\n    if com.count_not_none(start, end, periods) != 2:\n        raise ValueError(\n            'Of the three parameters: start, end, and periods, exactly two must be specified'\n            )\n    if freq is None and (not isinstance(start, Period) and not isinstance(\n        end, Period)):\n        freq = 'D'\n    data, freq = PeriodArray._generate_range(start, end, periods, freq)\n    dtype = PeriodDtype(freq)\n    data = PeriodArray(data, dtype=dtype)\n    return PeriodIndex(data, name=name)", "test_code_list": [{"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport re\nimport warnings\nimport zoneinfo\nimport dateutil\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.ccalendar import DAYS\nfrom pandas._libs.tslibs.ccalendar import MONTHS\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas.errors import InvalidIndexError\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.resample import _get_period_range_edges\nfrom pandas.tseries import offsets\n\nclass TestPeriodIndex():\n\tdef test_asfreq_fill_value(self):\n\t    index = period_range(datetime(2005, 1, 1), datetime(2005, 1, 10), freq='D')\n\t    s = Series(range(len(index)), index=index)\n\t    new_index = date_range(s.index[0].to_timestamp(how='start'), s.index[-1\n\t        ].to_timestamp(how='start'), freq='1h')\n\t    expected = s.to_timestamp().reindex(new_index, fill_value=4.0)\n\t    result = s.to_timestamp().resample('1h').asfreq(fill_value=4.0)\n\t    tm.assert_series_equal(result, expected)\n\t    frame = s.to_frame('value')\n\t    new_index = date_range(frame.index[0].to_timestamp(how='start'), frame.\n\t        index[-1].to_timestamp(how='start'), freq='1h')\n\t    expected = frame.to_timestamp().reindex(new_index, fill_value=3.0)\n\t    result = frame.to_timestamp().resample('1h').asfreq(fill_value=3.0)\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestPeriodIndex().test_asfreq_fill_value()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_period_index.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport re\nimport warnings\nimport zoneinfo\nimport dateutil\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.ccalendar import DAYS\nfrom pandas._libs.tslibs.ccalendar import MONTHS\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas.errors import InvalidIndexError\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.resample import _get_period_range_edges\nfrom pandas.tseries import offsets\n\nclass TestPeriodIndex():\n\tdef test_resample_5minute(self):\n\t    rng = period_range('1/1/2000', '1/5/2000', freq='min')\n\t    ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)\n\t    expected = ts.to_timestamp().resample('5min').mean()\n\t    result = ts.resample('5min').mean().to_timestamp()\n\t    tm.assert_series_equal(result, expected)\n\t    expected = expected.to_period('5min')\n\t    result = ts.resample('5min').mean()\n\t    tm.assert_series_equal(result, expected)\n\t    result = ts.resample('5min').mean().to_timestamp().to_period()\n\t    tm.assert_series_equal(result, expected)\n\t\nTestPeriodIndex().test_resample_5minute()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_period_index.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport re\nimport warnings\nimport zoneinfo\nimport dateutil\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.ccalendar import DAYS\nfrom pandas._libs.tslibs.ccalendar import MONTHS\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas.errors import InvalidIndexError\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.resample import _get_period_range_edges\nfrom pandas.tseries import offsets\n\nclass TestPeriodIndex():\n\tdef test_resample_tz_localized2(self):\n\t    idx = date_range('2001-09-20 15:59', '2001-09-20 16:00', freq='min', tz\n\t        ='Australia/Sydney')\n\t    s = Series([1, 2], index=idx)\n\t    result = s.resample('D', closed='right', label='right').mean()\n\t    ex_index = date_range('2001-09-21', periods=1, freq='D', tz=\n\t        'Australia/Sydney')\n\t    expected = Series([1.5], index=ex_index)\n\t    tm.assert_series_equal(result, expected)\n\t    msg = 'Converting to PeriodArray/Index representation will drop timezone '\n\t    with tm.assert_produces_warning(UserWarning, match=msg):\n\t        result = s.resample('D').mean().to_period()\n\t    ex_index = period_range('2001-09-20', periods=1, freq='D')\n\t    expected = Series([1.5], index=ex_index)\n\t    tm.assert_series_equal(result, expected)\n\t\nTestPeriodIndex().test_resample_tz_localized2()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_period_index.py"}, {"test_code": "from datetime import datetime\nfrom datetime import timezone\nimport re\nimport warnings\nimport zoneinfo\nimport dateutil\nimport numpy as np\nimport pytest\nfrom pandas._libs.tslibs.ccalendar import DAYS\nfrom pandas._libs.tslibs.ccalendar import MONTHS\nfrom pandas._libs.tslibs.period import IncompatibleFrequency\nfrom pandas.errors import InvalidIndexError\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nfrom pandas import Timestamp\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\nfrom pandas.core.indexes.period import Period\nfrom pandas.core.indexes.period import PeriodIndex\nfrom pandas.core.indexes.period import period_range\nfrom pandas.core.resample import _get_period_range_edges\nfrom pandas.tseries import offsets\n\nclass TestPeriodIndex():\n\tdef test_all_values_single_bin(self):\n\t    index = period_range(start='2012-01-01', end='2012-12-31', freq='M')\n\t    ser = Series(np.random.default_rng(2).standard_normal(len(index)),\n\t        index=index)\n\t    result = ser.resample('Y').mean()\n\t    tm.assert_almost_equal(result.iloc[0], ser.mean())\n\t\nTestPeriodIndex().test_all_values_single_bin()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_period_index.py"}], "instruction": "Functionality: The period_range function generates a fixed frequency PeriodIndex between a start and end date, or for a specified number of periods. It is particularly useful for time series analysis where a consistent frequency (like daily, monthly, quarterly, etc.) is required.\n\nInputs:\n- start : (str, datetime, date, pandas.Timestamp, or period-like) Left bound for generating periods. Optional.\n- end : (str, datetime, date, pandas.Timestamp, or period-like) Right bound for generating periods. Optional.\n- periods : (int) Number of periods to generate. Optional.\n- freq : (str or DateOffset) Frequency alias. By default, the freq is taken from 'start' or 'end' if those are Period objects. Otherwise, the default is \"D\" for daily frequency. Optional.\n- name : (Hashable) Name of the resulting PeriodIndex. Optional.\n\nOutputs:\n- A PeriodIndex object representing a range of time periods with a fixed frequency.\n\nNotes:\n- Exactly two of the three parameters 'start', 'end', and 'periods' must be specified.\n- For frequency strings, refer to the pandas documentation on offset aliases.", "method_code_mask": "from __future__ import annotations\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas._libs import index as libindex\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import Period\nfrom pandas._libs.tslibs import Resolution\nfrom pandas._libs.tslibs import Tick\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.arrays.period import PeriodArray\nfrom pandas.core.arrays.period import period_array\nfrom pandas.core.arrays.period import raise_on_incompatible\nfrom pandas.core.arrays.period import validate_dtype_freq\nimport pandas.core.common as com\nimport pandas.core.indexes.base as ibase\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.indexes.datetimelike import DatetimeIndexOpsMixin\nfrom pandas.core.indexes.datetimes import DatetimeIndex\nfrom pandas.core.indexes.datetimes import Index\nfrom pandas.core.indexes.extension import inherit_names\nfrom collections.abc import Hashable\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import npt\n\n\ndef period_range(start=None, end=None, periods: (int | None)=None, freq=\n    None, name: (Hashable | None)=None) ->PeriodIndex: [MASK]\n"}
{"method_name": "timedelta_range", "full_method_name": "timedelta_range", "method_path": "../srcdata/Computation/pandas/pandas/core/indexes/timedeltas.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom pandas._libs import index as libindex\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import Resolution\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import to_offset\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\nimport pandas.core.common as com\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.indexes.datetimelike import DatetimeTimedeltaMixin\nfrom pandas.core.indexes.extension import inherit_names\nfrom pandas._libs import NaTType\nfrom pandas._typing import DtypeObj\ndef timedelta_range(start=None, end=None, periods: (int | None)=None, freq=\n    None, name=None, closed=None, *, unit: (str | None)=None) ->TimedeltaIndex:\n    \"\"\"\n    Return a fixed frequency TimedeltaIndex with day as the default.\n\n    Parameters\n    ----------\n    start : str or timedelta-like, default None\n        Left bound for generating timedeltas.\n    end : str or timedelta-like, default None\n        Right bound for generating timedeltas.\n    periods : int, default None\n        Number of periods to generate.\n    freq : str, Timedelta, datetime.timedelta, or DateOffset, default 'D'\n        Frequency strings can have multiples, e.g. '5h'.\n    name : str, default None\n        Name of the resulting TimedeltaIndex.\n    closed : str, default None\n        Make the interval closed with respect to the given frequency to\n        the 'left', 'right', or both sides (None).\n    unit : str, default None\n        Specify the desired resolution of the result.\n\n        .. versionadded:: 2.0.0\n\n    Returns\n    -------\n    TimedeltaIndex\n        Fixed frequency, with day as the default.\n\n    See Also\n    --------\n    date_range : Return a fixed frequency DatetimeIndex.\n    period_range : Return a fixed frequency PeriodIndex.\n\n    Notes\n    -----\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\n    exactly three must be specified. If ``freq`` is omitted, the resulting\n    ``TimedeltaIndex`` will have ``periods`` linearly spaced elements between\n    ``start`` and ``end`` (closed on both sides).\n\n    To learn more about the frequency strings, please see\n    :ref:`this link<timeseries.offset_aliases>`.\n\n    Examples\n    --------\n    >>> pd.timedelta_range(start=\"1 day\", periods=4)\n    TimedeltaIndex(['1 days', '2 days', '3 days', '4 days'],\n                   dtype='timedelta64[ns]', freq='D')\n\n    The ``closed`` parameter specifies which endpoint is included.  The default\n    behavior is to include both endpoints.\n\n    >>> pd.timedelta_range(start=\"1 day\", periods=4, closed=\"right\")\n    TimedeltaIndex(['2 days', '3 days', '4 days'],\n                   dtype='timedelta64[ns]', freq='D')\n\n    The ``freq`` parameter specifies the frequency of the TimedeltaIndex.\n    Only fixed frequencies can be passed, non-fixed frequencies such as\n    'M' (month end) will raise.\n\n    >>> pd.timedelta_range(start=\"1 day\", end=\"2 days\", freq=\"6h\")\n    TimedeltaIndex(['1 days 00:00:00', '1 days 06:00:00', '1 days 12:00:00',\n                    '1 days 18:00:00', '2 days 00:00:00'],\n                   dtype='timedelta64[ns]', freq='6h')\n\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\n    automatically (linearly spaced).\n\n    >>> pd.timedelta_range(start=\"1 day\", end=\"5 days\", periods=4)\n    TimedeltaIndex(['1 days 00:00:00', '2 days 08:00:00', '3 days 16:00:00',\n                    '5 days 00:00:00'],\n                   dtype='timedelta64[ns]', freq=None)\n\n    **Specify a unit**\n\n    >>> pd.timedelta_range(\"1 Day\", periods=3, freq=\"100000D\", unit=\"s\")\n    TimedeltaIndex(['1 days', '100001 days', '200001 days'],\n                   dtype='timedelta64[s]', freq='100000D')\n    \"\"\"\n    if freq is None and com.any_none(periods, start, end):\n        freq = 'D'\n    freq = to_offset(freq)\n    tdarr = TimedeltaArray._generate_range(start, end, periods, freq,\n        closed=closed, unit=unit)\n    return TimedeltaIndex._simple_new(tdarr, name=name)", "test_code_list": [{"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_asfreq_bug():\n    df = DataFrame(data=[1, 3], index=[timedelta(), timedelta(minutes=3)])\n    result = df.resample('1min').asfreq()\n    expected = DataFrame(data=[1, np.nan, np.nan, 3], index=timedelta_range\n        ('0 day', periods=4, freq='1min'))\n    tm.assert_frame_equal(result, expected)\n\ntest_asfreq_bug()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_with_nat():\n    index = pd.to_timedelta(['0s', pd.NaT, '2s'])\n    result = DataFrame({'value': [2, 3, 5]}, index).resample('1s').mean()\n    expected = DataFrame({'value': [2.5, np.nan, 5.0]}, index=\n        timedelta_range('0 day', periods=3, freq='1s'))\n    tm.assert_frame_equal(result, expected)\n\ntest_resample_with_nat()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_as_freq_with_subperiod():\n    index = timedelta_range('00:00:00', '00:10:00', freq='5min')\n    df = DataFrame(data={'value': [1, 5, 10]}, index=index)\n    result = df.resample('2min').asfreq()\n    expected_data = {'value': [1, np.nan, np.nan, np.nan, np.nan, 10]}\n    expected = DataFrame(data=expected_data, index=timedelta_range(\n        '00:00:00', '00:10:00', freq='2min'))\n    tm.assert_frame_equal(result, expected)\n\ntest_resample_as_freq_with_subperiod()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_with_timedeltas():\n    expected = DataFrame({'A': np.arange(1480)})\n    expected = expected.groupby(expected.index // 30).sum()\n    expected.index = timedelta_range('0 days', freq='30min', periods=50)\n    df = DataFrame({'A': np.arange(1480)}, index=pd.to_timedelta(np.arange(\n        1480), unit='min'))\n    result = df.resample('30min').sum()\n    tm.assert_frame_equal(result, expected)\n    s = df['A']\n    result = s.resample('30min').sum()\n    tm.assert_series_equal(result, expected['A'])\n\ntest_resample_with_timedeltas()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_single_period_timedelta():\n    s = Series(list(range(5)), index=timedelta_range('1 day', freq='s',\n        periods=5))\n    result = s.resample('2s').sum()\n    expected = Series([1, 5, 4], index=timedelta_range('1 day', freq='2s',\n        periods=3))\n    tm.assert_series_equal(result, expected)\n\ntest_resample_single_period_timedelta()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_timedelta_idempotency():\n    index = timedelta_range('0', periods=9, freq='10ms')\n    series = Series(range(9), index=index)\n    result = series.resample('10ms').mean()\n    expected = series.astype(float)\n    tm.assert_series_equal(result, expected)\n\ntest_resample_timedelta_idempotency()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_offset_with_timedeltaindex():\n    rng = timedelta_range(start='0s', periods=25, freq='s')\n    ts = Series(np.random.default_rng(2).standard_normal(len(rng)), index=rng)\n    with_base = ts.resample('2s', offset='5s').mean()\n    without_base = ts.resample('2s').mean()\n    exp_without_base = timedelta_range(start='0s', end='25s', freq='2s')\n    exp_with_base = timedelta_range(start='5s', end='29s', freq='2s')\n    tm.assert_index_equal(without_base.index, exp_without_base)\n    tm.assert_index_equal(with_base.index, exp_with_base)\n\ntest_resample_offset_with_timedeltaindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}, {"test_code": "from datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.timedeltas import timedelta_range\ndef test_resample_timedelta_values():\n    times = timedelta_range('1 day', '6 day', freq='4D')\n    df = DataFrame({'time': times}, index=times)\n    times2 = timedelta_range('1 day', '6 day', freq='2D')\n    exp = Series(times2, index=times2, name='time')\n    exp.iloc[1] = pd.NaT\n    res = df.resample('2D').first()['time']\n    tm.assert_series_equal(res, exp)\n    res = df['time'].resample('2D').first()\n    tm.assert_series_equal(res, exp)\n\ntest_resample_timedelta_values()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_timedelta.py"}], "instruction": "Functionality: The timedelta_range function generates a fixed frequency TimedeltaIndex with a default frequency of day. It can generate a range of timedelta values based on start and end points, the number of periods, and a specified frequency.\n\nInputs: \n- start: str or timedelta-like, optional Left bound for generating timedeltas.\n- end: str or timedelta-like, optional Right bound for generating timedeltas.\n- periods: int, optional Number of periods to generate.\n- freq: str, Timedelta, datetime.timedelta, or DateOffset, optional Frequency of the timedeltas; 'D' by default.\n- name: str, optional Name of the resulting TimedeltaIndex.\n- closed: str, optional Indicates if the interval is closed on the left, right, or both sides (None).\n- unit: str, optional Specifies the resolution of the timedelta values.\n\nOutputs:\n- TimedeltaIndex: A fixed frequency TimedeltaIndex between the start and end points, with the specified number of periods and frequency. If freq is None, it defaults to 'D'. The 'closed' parameter affects which endpoints are included in the index.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom pandas._libs import index as libindex\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import Resolution\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import to_offset\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.arrays.timedeltas import TimedeltaArray\nimport pandas.core.common as com\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.indexes.datetimelike import DatetimeTimedeltaMixin\nfrom pandas.core.indexes.extension import inherit_names\nfrom pandas._libs import NaTType\nfrom pandas._typing import DtypeObj\n\n\ndef timedelta_range(start=None, end=None, periods: (int | None)=None, freq=\n    None, name=None, closed=None, *, unit: (str | None)=None\n    ) ->TimedeltaIndex: [MASK]\n"}
{"method_name": "pprint_thing", "full_method_name": "pprint_thing", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/printing.py", "method_code": "from __future__ import annotations\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport sys\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import Union\nfrom unicodedata import east_asian_width\nfrom pandas._config import get_option\nfrom pandas.core.dtypes.inference import is_sequence\nfrom pandas.io.formats.console import get_console_size\nfrom IPython import get_ipython\nfrom IPython.core.formatters import BaseFormatter\nfrom traitlets import ObjectName\ndef pprint_thing(thing: object, _nest_lvl: int=0, escape_chars: (\n    EscapeChars | None)=None, default_escapes: bool=False, quote_strings:\n    bool=False, max_seq_items: (int | None)=None) ->str:\n    \"\"\"\n    This function is the sanctioned way of converting objects\n    to a string representation and properly handles nested sequences.\n\n    Parameters\n    ----------\n    thing : anything to be formatted\n    _nest_lvl : internal use only. pprint_thing() is mutually-recursive\n        with pprint_sequence, this argument is used to keep track of the\n        current nesting level, and limit it.\n    escape_chars : list[str] or Mapping[str, str], optional\n        Characters to escape. If a Mapping is passed the values are the\n        replacements\n    default_escapes : bool, default False\n        Whether the input escape characters replaces or adds to the defaults\n    max_seq_items : int or None, default None\n        Pass through to other pretty printers to limit sequence printing\n\n    Returns\n    -------\n    str\n    \"\"\"\n\n    def as_escaped_string(thing: Any, escape_chars: (EscapeChars | None)=\n        escape_chars) ->str:\n        translate = {'\\t': '\\\\t', '\\n': '\\\\n', '\\r': '\\\\r'}\n        if isinstance(escape_chars, Mapping):\n            if default_escapes:\n                translate.update(escape_chars)\n            else:\n                translate = escape_chars\n            escape_chars = list(escape_chars.keys())\n        else:\n            escape_chars = escape_chars or ()\n        result = str(thing)\n        for c in escape_chars:\n            result = result.replace(c, translate[c])\n        return result\n    if hasattr(thing, '__next__'):\n        return str(thing)\n    elif isinstance(thing, Mapping) and _nest_lvl < get_option(\n        'display.pprint_nest_depth'):\n        result = _pprint_dict(thing, _nest_lvl, quote_strings=True,\n            max_seq_items=max_seq_items)\n    elif is_sequence(thing) and _nest_lvl < get_option(\n        'display.pprint_nest_depth'):\n        result = _pprint_seq(thing, _nest_lvl, escape_chars=escape_chars,\n            quote_strings=quote_strings, max_seq_items=max_seq_items)\n    elif isinstance(thing, str) and quote_strings:\n        result = f\"'{as_escaped_string(thing)}'\"\n    else:\n        result = as_escaped_string(thing)\n    return result", "test_code_list": [{"test_code": "from collections.abc import Mapping\nimport string\nimport pandas._config.config as cf\nfrom pandas.io.formats import printing\n\nclass TestPPrintThing():\n\tdef test_repr_binary_type(self):\n\t    letters = string.ascii_letters\n\t    try:\n\t        raw = bytes(letters, encoding=cf.get_option('display.encoding'))\n\t    except TypeError:\n\t        raw = bytes(letters)\n\t    b = str(raw.decode('utf-8'))\n\t    res = pprint_thing(b, quote_strings=True)\n\t    assert res == repr(b)\n\t    res = pprint_thing(b, quote_strings=False)\n\t    assert res == b\n\t\nTestPPrintThing().test_repr_binary_type()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/test_printing.py"}], "instruction": "Functionality: The pprint_thing function is designed to convert any given object into a string representation, with special handling for nested sequences. It ensures that the output is properly formatted, escaped, and quoted based on the parameters provided.\n\nInputs:\n- thing: The object to be formatted into a string.\n- _nest_LVL (int): An internal use parameter to track the current nesting level, used by pprint_thing() in mutual recursion with pprint_sequence. Default is 0.\n- escape_chars (Union[List[str], Mapping[str, str]]): Characters to escape. If a Mapping is passed, the values are used as replacements. Default is None.\n- default_escapes (bool): Whether the input escape characters replace or add to the defaults. Default is False.\n- quote_strings (bool): Whether to quote strings in the output. Default is False.\n- max_seq_items (Union[int, None]): A limit on the number of items to print for sequences. Pass-through to other pretty printers. Default is None.\n\nOutputs:\n- str: Returns a string representation of the input object, properly formatted, escaped, and quoted based on the provided parameters.", "method_code_mask": "from __future__ import annotations\nfrom collections.abc import Callable\nfrom collections.abc import Iterable\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nimport sys\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import TypeVar\nfrom typing import Union\nfrom unicodedata import east_asian_width\nfrom pandas._config import get_option\nfrom pandas.core.dtypes.inference import is_sequence\nfrom pandas.io.formats.console import get_console_size\nfrom IPython import get_ipython\nfrom IPython.core.formatters import BaseFormatter\nfrom traitlets import ObjectName\n\n\ndef pprint_thing(thing: object, _nest_lvl: int=0, escape_chars: (\n    EscapeChars | None)=None, default_escapes: bool=False, quote_strings:\n    bool=False, max_seq_items: (int | None)=None) ->str: [MASK]\n"}
{"method_name": "table", "full_method_name": "table", "method_path": "../srcdata/Computation/pandas/pandas/plotting/_misc.py", "method_code": "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom pandas.plotting._core import _get_plot_backend\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom matplotlib.axes import Axes\nfrom matplotlib.colors import Colormap\nfrom matplotlib.figure import Figure\nfrom matplotlib.table import Table\nimport numpy as np\nfrom pandas import DataFrame\nfrom pandas import Series\ndef table(ax: Axes, data: (DataFrame | Series), **kwargs) ->Table:\n    \"\"\"\n    Helper function to convert DataFrame and Series to matplotlib.table.\n\n    Parameters\n    ----------\n    ax : Matplotlib axes object\n        The axes on which to draw the table.\n    data : DataFrame or Series\n        Data for table contents.\n    **kwargs\n        Keyword arguments to be passed to matplotlib.table.table.\n        If `rowLabels` or `colLabels` is not specified, data index or column\n        name will be used.\n\n    Returns\n    -------\n    matplotlib table object\n        The created table as a matplotlib Table object.\n\n    See Also\n    --------\n    DataFrame.plot : Make plots of DataFrame using matplotlib.\n    matplotlib.pyplot.table : Create a table from data in a Matplotlib plot.\n\n    Examples\n    --------\n\n    .. plot::\n            :context: close-figs\n\n            >>> import matplotlib.pyplot as plt\n            >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n            >>> fix, ax = plt.subplots()\n            >>> ax.axis(\"off\")\n            (0.0, 1.0, 0.0, 1.0)\n            >>> table = pd.plotting.table(\n            ...     ax, df, loc=\"center\", cellLoc=\"center\", colWidths=list([0.2, 0.2])\n            ... )\n    \"\"\"\n    plot_backend = _get_plot_backend('matplotlib')\n    return plot_backend.table(ax=ax, data=data, rowLabels=None, colLabels=\n        None, **kwargs)", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nimport gc\nimport itertools\nimport re\nimport string\nimport weakref\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nfrom pandas.core.dtypes.api import is_list_like\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import Series\nfrom pandas import bdate_range\nfrom pandas import date_range\nfrom pandas import option_context\nfrom pandas import plotting\nimport pandas._testing as tm\nfrom pandas.tests.plotting.common import _check_plot_works\nfrom pandas.io.formats.printing import pprint_thing\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\nclass TestDataFramePlots():\n\tdef test_table(self):\n\t    df = DataFrame(np.random.default_rng(2).random((10, 3)), index=list(\n\t        string.ascii_letters[:10]))\n\t    _check_plot_works(df.plot, table=True)\n\t    _check_plot_works(df.plot, table=df)\n\t    with tm.assert_produces_warning(None):\n\t        ax = df.plot()\n\t        assert len(ax.tables) == 0\n\t        table(ax, df.T)\n\t        assert len(ax.tables) == 1\n\t\nTestDataFramePlots().test_table()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/plotting/frame/test_frame.py"}], "instruction": "Functionality: Converts a DataFrame or Series to a matplotlib table object on a specified Matplotlib axes.\nInputs: \n- ax: A Matplotlib axes object where the table will be drawn.\n- data: A DataFrame or Series containing the data for the table contents.\n- **kwargs: Optional keyword arguments to be passed to matplotlib.table.table. If 'rowLabels' or 'colLabels' is not specified, data index or column name will be used.\nOutputs: \n- Returns a matplotlib table object created from the provided data.", "method_code_mask": "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom pandas.plotting._core import _get_plot_backend\nfrom collections.abc import Generator\nfrom collections.abc import Mapping\nfrom matplotlib.axes import Axes\nfrom matplotlib.colors import Colormap\nfrom matplotlib.figure import Figure\nfrom matplotlib.table import Table\nimport numpy as np\nfrom pandas import DataFrame\nfrom pandas import Series\n\n\ndef table(ax: Axes, data: (DataFrame | Series), **kwargs) ->Table: [MASK]\n"}
{"method_name": "df", "full_method_name": "df.melt", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_melt.py", "method_code": "import re\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import date_range\nfrom pandas import lreshape\nfrom pandas import melt\nfrom pandas import wide_to_long\nimport pandas._testing as tm\n@pytest.fixture\ndef df():\n    res = DataFrame(np.random.default_rng(2).standard_normal((10, 4)),\n        columns=Index(list('ABCD'), dtype=object), index=date_range(\n        '2000-01-01', periods=10, freq='B'))\n    res['id1'] = (res['A'] > 0).astype(np.int64)\n    res['id2'] = (res['B'] > 0).astype(np.int64)\n    return res", "test_code_list": [{"test_code": "import re\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import date_range\nfrom pandas import lreshape\nfrom pandas import melt\nfrom pandas import wide_to_long\nimport pandas._testing as tm\n\nclass TestMelt():\n\tdef test_melt_with_duplicate_columns(self):\n\t    df = DataFrame([['id', 2, 3]], columns=['a', 'b', 'b'])\n\t    result = df.melt(id_vars=['a'], value_vars=['b'])\n\t    expected = DataFrame([['id', 'b', 2], ['id', 'b', 3]], columns=['a',\n\t        'variable', 'value'])\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMelt().test_melt_with_duplicate_columns()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_melt.py"}, {"test_code": "import re\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import date_range\nfrom pandas import lreshape\nfrom pandas import melt\nfrom pandas import wide_to_long\nimport pandas._testing as tm\n\nclass TestMelt():\n\tdef test_melt_multiindex_columns_var_name(self):\n\t    df = DataFrame({('A', 'a'): [1], ('A', 'b'): [2]})\n\t    expected = DataFrame([('A', 'a', 1), ('A', 'b', 2)], columns=['first',\n\t        'second', 'value'])\n\t    tm.assert_frame_equal(df.melt(var_name=['first', 'second']), expected)\n\t    tm.assert_frame_equal(df.melt(var_name=['first']), expected[['first',\n\t        'value']])\n\t\nTestMelt().test_melt_multiindex_columns_var_name()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_melt.py"}], "instruction": "Functionality: The df.melt function is a versatile tool used to unpivot a DataFrame from wide format to long format. This function allows transforming datasets by converting column headers into key-value pairs, which is particularly useful when preparing data for statistical analysis or visualization.\n\nInputs: \n1. frame: A DataFrame to be melted.\n2. id_vars: Optional, a column or list of columns to use as identifier variables.\n3. value_vars: Optional, a column or list of columns to unpivot. If None, all columns that are not set as id_vars are used.\n4. var_name: Optional, the name to use for the 'variable' column. If None, the existing names are used.\n5. value_name: Optional, the name to use for the 'value' column. If None, it defaults to 'value'.\n6. col_level: Optional, the index level to use when unstacking/pivoting the columns. This is useful when the DataFrame has a MultiIndex.\n\nOutputs:\n1. A DataFrame in long format. The output DataFrame will have the id_vars and the unpivoted columns as 'variable' and 'value' (or as specified by var_name and value_name).", "method_code_mask": "import re\nimport numpy as np\nimport pytest\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import date_range\nfrom pandas import lreshape\nfrom pandas import melt\nfrom pandas import wide_to_long\nimport pandas._testing as tm\n\n\n@pytest.fixture\ndef df(): [MASK]\n"}
{"method_name": "cartesian_product", "full_method_name": "cartesian_product", "method_path": "../srcdata/Computation/pandas/pandas/core/reshape/util.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas._typing import NumpyIndexT\ndef cartesian_product(X) ->list[np.ndarray]:\n    \"\"\"\n    Numpy version of itertools.product.\n    Sometimes faster (for large inputs)...\n\n    Parameters\n    ----------\n    X : list-like of list-likes\n\n    Returns\n    -------\n    product : list of ndarrays\n\n    Examples\n    --------\n    >>> cartesian_product([list(\"ABC\"), [1, 2]])\n    [array(['A', 'A', 'B', 'B', 'C', 'C'], dtype='<U1'), array([1, 2, 1, 2, 1, 2])]\n\n    See Also\n    --------\n    itertools.product : Cartesian product of input iterables.  Equivalent to\n        nested for-loops.\n    \"\"\"\n    msg = 'Input must be a list-like of list-likes'\n    if not is_list_like(X):\n        raise TypeError(msg)\n    for x in X:\n        if not is_list_like(x):\n            raise TypeError(msg)\n    if len(X) == 0:\n        return []\n    lenX = np.fromiter((len(x) for x in X), dtype=np.intp)\n    cumprodX = np.cumprod(lenX)\n    if np.any(cumprodX < 0):\n        raise ValueError('Product space too large to allocate arrays!')\n    a = np.roll(cumprodX, 1)\n    a[0] = 1\n    if cumprodX[-1] != 0:\n        b = cumprodX[-1] / cumprodX\n    else:\n        b = np.zeros_like(cumprodX)\n    return [tile_compat(np.repeat(x, b[i]), np.prod(a[i])) for i, x in\n        enumerate(X)]", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas import Index\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.reshape.util import cartesian_product\n\nclass TestCartesianProduct():\n\tdef test_simple(self):\n\t    x, y = list('ABC'), [1, 22]\n\t    result1, result2 = cartesian_product([x, y])\n\t    expected1 = np.array(['A', 'A', 'B', 'B', 'C', 'C'])\n\t    expected2 = np.array([1, 22, 1, 22, 1, 22])\n\t    tm.assert_numpy_array_equal(result1, expected1)\n\t    tm.assert_numpy_array_equal(result2, expected2)\n\t\nTestCartesianProduct().test_simple()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_util.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import Index\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.reshape.util import cartesian_product\n\nclass TestCartesianProduct():\n\tdef test_datetimeindex(self):\n\t    x = date_range('2000-01-01', periods=2)\n\t    result1, result2 = (Index(y).day for y in cartesian_product([x, x]))\n\t    expected1 = Index([1, 1, 2, 2], dtype=np.int32)\n\t    expected2 = Index([1, 2, 1, 2], dtype=np.int32)\n\t    tm.assert_index_equal(result1, expected1)\n\t    tm.assert_index_equal(result2, expected2)\n\t\nTestCartesianProduct().test_datetimeindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_util.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import Index\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.reshape.util import cartesian_product\n\nclass TestCartesianProduct():\n\tdef test_tzaware_retained(self):\n\t    x = date_range('2000-01-01', periods=2, tz='US/Pacific')\n\t    y = np.array([3, 4])\n\t    result1, result2 = cartesian_product([x, y])\n\t    expected = x.repeat(2)\n\t    tm.assert_index_equal(result1, expected)\n\t\nTestCartesianProduct().test_tzaware_retained()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_util.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import Index\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.reshape.util import cartesian_product\n\nclass TestCartesianProduct():\n\tdef test_tzaware_retained_categorical(self):\n\t    x = date_range('2000-01-01', periods=2, tz='US/Pacific').astype('category')\n\t    y = np.array([3, 4])\n\t    result1, result2 = cartesian_product([x, y])\n\t    expected = x.repeat(2)\n\t    tm.assert_index_equal(result1, expected)\n\t\nTestCartesianProduct().test_tzaware_retained_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_util.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import Index\nfrom pandas import date_range\nimport pandas._testing as tm\nfrom pandas.core.reshape.util import cartesian_product\n\nclass TestCartesianProduct():\n\tdef test_empty_input(self):\n\t    result = cartesian_product([])\n\t    expected = []\n\t    assert result == expected\n\t\nTestCartesianProduct().test_empty_input()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/test_util.py"}], "instruction": "Functionality: The cartesian_product function computes the Cartesian product of input iterables. It is a numpy version of itertools.product and can sometimes be faster for large inputs. The function takes a list-like of list-likes as an input and returns a list of ndarrays representing the Cartesian product.\n\nInputs: \nX: A list-like of list-likes. Each inner list-like represents a set of items from which the Cartesian product is to be computed. Each item within the inner list-likes can be of any hashable type.\n\nOutputs: \nA list of ndarrays, where each ndarray represents one of the dimensions of the Cartesian product. The number of ndarrays returned is equal to the number of list-likes in the input X. Each ndarray contains the elements from the respective input list-like, repeated as many times as necessary to complete the Cartesian product.\n\nThe function raises a TypeError if the input X is not a list-like of list-likes. It also raises a ValueError if the product space is too large to allocate arrays.\n\nNote: Do not include information on specific test cases that might be used during the interview. Focus on explaining the functionality, inputs, and outputs of the cartesian_product function clearly and concisely.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nimport numpy as np\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas._typing import NumpyIndexT\n\n\ndef cartesian_product(X) ->list[np.ndarray]: [MASK]\n"}
{"method_name": "left", "full_method_name": "left.join", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py", "method_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n@pytest.fixture\ndef left():\n    \"\"\"left dataframe (not multi-indexed) for multi-index join tests\"\"\"\n    key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux', 'qux',\n        'snap']\n    key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',\n        'three', 'one']\n    data = np.random.default_rng(2).standard_normal(len(key1))\n    return DataFrame({'key1': key1, 'key2': key2, 'data': data})", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_join_index_preserve_order(self):\n\t    on_cols = ['k1', 'k2']\n\t    left = DataFrame({'k1': [0, 1, 2] * 8, 'k2': ['foo', 'bar'] * 12, 'v':\n\t        np.array(np.arange(24), dtype=np.int64)})\n\t    index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n\t    right = DataFrame({'v2': [5, 7]}, index=index)\n\t    result = left.join(right, on=on_cols)\n\t    expected = left.copy()\n\t    expected['v2'] = np.nan\n\t    expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n\t    expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\t    tm.assert_frame_equal(result, expected)\n\t    result.sort_values(on_cols, kind='mergesort', inplace=True)\n\t    expected = left.join(right, on=on_cols, sort=True)\n\t    tm.assert_frame_equal(result, expected)\n\t    left = DataFrame({'k1': [0, 1, 2] * 8, 'k2': ['foo', 'bar'] * 12, 'k3':\n\t        np.array([0, 1, 2] * 8, dtype=np.float32), 'v': np.array(np.arange(\n\t        24), dtype=np.int32)})\n\t    index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n\t    right = DataFrame({'v2': [5, 7]}, index=index)\n\t    result = left.join(right, on=on_cols)\n\t    expected = left.copy()\n\t    expected['v2'] = np.nan\n\t    expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n\t    expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\t    tm.assert_frame_equal(result, expected)\n\t    result = result.sort_values(on_cols, kind='mergesort')\n\t    expected = left.join(right, on=on_cols, sort=True)\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_join_index_preserve_order()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_join_index_multi_match_multiindex(self):\n\t    left = DataFrame([['X', 'Y', 'C', 'a'], ['W', 'Y', 'C', 'e'], ['V', 'Q',\n\t        'A', 'h'], ['V', 'R', 'D', 'i'], ['X', 'Y', 'D', 'b'], ['X', 'Y',\n\t        'A', 'c'], ['W', 'Q', 'B', 'f'], ['W', 'R', 'C', 'g'], ['V', 'Y',\n\t        'C', 'j'], ['X', 'Y', 'B', 'd']], columns=['cola', 'colb', 'colc',\n\t        'tag'], index=[3, 2, 0, 1, 7, 6, 4, 5, 9, 8])\n\t    right = DataFrame([['W', 'R', 'C', 0], ['W', 'Q', 'B', 3], ['W', 'Q',\n\t        'B', 8], ['X', 'Y', 'A', 1], ['X', 'Y', 'A', 4], ['X', 'Y', 'B', 5],\n\t        ['X', 'Y', 'C', 6], ['X', 'Y', 'C', 9], ['X', 'Q', 'C', -6], ['X',\n\t        'R', 'C', -9], ['V', 'Y', 'C', 7], ['V', 'R', 'D', 2], ['V', 'R',\n\t        'D', -1], ['V', 'Q', 'A', -3]], columns=['col1', 'col2', 'col3', 'val']\n\t        ).set_index(['col1', 'col2', 'col3'])\n\t    result = left.join(right, on=['cola', 'colb', 'colc'], how='left')\n\t    expected = DataFrame([['X', 'Y', 'C', 'a', 6], ['X', 'Y', 'C', 'a', 9],\n\t        ['W', 'Y', 'C', 'e', np.nan], ['V', 'Q', 'A', 'h', -3], ['V', 'R',\n\t        'D', 'i', 2], ['V', 'R', 'D', 'i', -1], ['X', 'Y', 'D', 'b', np.nan\n\t        ], ['X', 'Y', 'A', 'c', 1], ['X', 'Y', 'A', 'c', 4], ['W', 'Q', 'B',\n\t        'f', 3], ['W', 'Q', 'B', 'f', 8], ['W', 'R', 'C', 'g', 0], ['V',\n\t        'Y', 'C', 'j', 7], ['X', 'Y', 'B', 'd', 5]], columns=['cola',\n\t        'colb', 'colc', 'tag', 'val'], index=[3, 3, 2, 0, 1, 1, 7, 6, 6, 4,\n\t        4, 5, 9, 8])\n\t    tm.assert_frame_equal(result, expected)\n\t    result = left.join(right, on=['cola', 'colb', 'colc'], how='left', sort\n\t        =True)\n\t    expected = expected.sort_values(['cola', 'colb', 'colc'], kind='mergesort')\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_join_index_multi_match_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_join_index_multi_match(self):\n\t    left = DataFrame([['c', 0], ['b', 1], ['a', 2], ['b', 3]], columns=[\n\t        'tag', 'val'], index=[2, 0, 1, 3])\n\t    right = DataFrame([['a', 'v'], ['c', 'w'], ['c', 'x'], ['d', 'y'], ['a',\n\t        'z'], ['c', 'r'], ['e', 'q'], ['c', 's']], columns=['tag', 'char']\n\t        ).set_index('tag')\n\t    result = left.join(right, on='tag', how='left')\n\t    expected = DataFrame([['c', 0, 'w'], ['c', 0, 'x'], ['c', 0, 'r'], ['c',\n\t        0, 's'], ['b', 1, np.nan], ['a', 2, 'v'], ['a', 2, 'z'], ['b', 3,\n\t        np.nan]], columns=['tag', 'val', 'char'], index=[2, 2, 2, 2, 0, 1, \n\t        1, 3])\n\t    tm.assert_frame_equal(result, expected)\n\t    result = left.join(right, on='tag', how='left', sort=True)\n\t    expected2 = expected.sort_values('tag', kind='mergesort')\n\t    tm.assert_frame_equal(result, expected2)\n\t    result = merge(left, right.reset_index(), how='left', on='tag')\n\t    expected.index = RangeIndex(len(expected))\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_join_index_multi_match()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_merge_na_buglet(self):\n\t    left = DataFrame({'id': list('abcde'), 'v1': np.random.default_rng(2).\n\t        standard_normal(5), 'v2': np.random.default_rng(2).standard_normal(\n\t        5), 'dummy': list('abcde'), 'v3': np.random.default_rng(2).\n\t        standard_normal(5)}, columns=['id', 'v1', 'v2', 'dummy', 'v3'])\n\t    right = DataFrame({'id': ['a', 'b', np.nan, np.nan, np.nan], 'sv3': [\n\t        1.234, 5.678, np.nan, np.nan, np.nan]})\n\t    result = merge(left, right, on='id', how='left')\n\t    rdf = right.drop(['id'], axis=1)\n\t    expected = left.join(rdf)\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_merge_na_buglet()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestJoinMultiMulti():\n\tdef test_single_common_level(self):\n\t    index_left = MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'), ('K1',\n\t        'X2')], names=['key', 'X'])\n\t    left = DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']},\n\t        index=index_left)\n\t    index_right = MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'), ('K2',\n\t        'Y2'), ('K2', 'Y3')], names=['key', 'Y'])\n\t    right = DataFrame({'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1',\n\t        'D2', 'D3']}, index=index_right)\n\t    result = left.join(right)\n\t    expected = merge(left.reset_index(), right.reset_index(), on=['key'],\n\t        how='inner').set_index(['key', 'X', 'Y'])\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestJoinMultiMulti().test_single_common_level()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestJoinMultiMulti():\n\tdef test_join_multi_wrong_order(self):\n\t    midx1 = MultiIndex.from_product([[1, 2], [3, 4]], names=['a', 'b'])\n\t    midx3 = MultiIndex.from_tuples([(4, 1), (3, 2), (3, 1)], names=['b', 'a'])\n\t    left = DataFrame(index=midx1, data={'x': [10, 20, 30, 40]})\n\t    right = DataFrame(index=midx3, data={'y': ['foo', 'bar', 'fing']})\n\t    result = left.join(right)\n\t    expected = DataFrame(index=midx1, data={'x': [10, 20, 30, 40], 'y': [\n\t        'fing', 'foo', 'bar', np.nan]})\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestJoinMultiMulti().test_join_multi_wrong_order()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_join_index_preserve_order(self):\n\t    on_cols = ['k1', 'k2']\n\t    left = DataFrame({'k1': [0, 1, 2] * 8, 'k2': ['foo', 'bar'] * 12, 'v':\n\t        np.array(np.arange(24), dtype=np.int64)})\n\t    index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n\t    right = DataFrame({'v2': [5, 7]}, index=index)\n\t    result = left.join(right, on=on_cols)\n\t    expected = left.copy()\n\t    expected['v2'] = np.nan\n\t    expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n\t    expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\t    tm.assert_frame_equal(result, expected)\n\t    result.sort_values(on_cols, kind='mergesort', inplace=True)\n\t    expected = left.join(right, on=on_cols, sort=True)\n\t    tm.assert_frame_equal(result, expected)\n\t    left = DataFrame({'k1': [0, 1, 2] * 8, 'k2': ['foo', 'bar'] * 12, 'k3':\n\t        np.array([0, 1, 2] * 8, dtype=np.float32), 'v': np.array(np.arange(\n\t        24), dtype=np.int32)})\n\t    index = MultiIndex.from_tuples([(2, 'bar'), (1, 'foo')])\n\t    right = DataFrame({'v2': [5, 7]}, index=index)\n\t    result = left.join(right, on=on_cols)\n\t    expected = left.copy()\n\t    expected['v2'] = np.nan\n\t    expected.loc[(expected.k1 == 2) & (expected.k2 == 'bar'), 'v2'] = 5\n\t    expected.loc[(expected.k1 == 1) & (expected.k2 == 'foo'), 'v2'] = 7\n\t    tm.assert_frame_equal(result, expected)\n\t    result = result.sort_values(on_cols, kind='mergesort')\n\t    expected = left.join(right, on=on_cols, sort=True)\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_join_index_preserve_order()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestJoinMultiMulti():\n\tdef test_single_common_level(self):\n\t    index_left = MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'), ('K1',\n\t        'X2')], names=['key', 'X'])\n\t    left = DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']},\n\t        index=index_left)\n\t    index_right = MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'), ('K2',\n\t        'Y2'), ('K2', 'Y3')], names=['key', 'Y'])\n\t    right = DataFrame({'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1',\n\t        'D2', 'D3']}, index=index_right)\n\t    result = left.join(right)\n\t    expected = merge(left.reset_index(), right.reset_index(), on=['key'],\n\t        how='inner').set_index(['key', 'X', 'Y'])\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestJoinMultiMulti().test_single_common_level()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}], "instruction": "Functionality: Implement a function left.join that replicates the functionality of the pandas DataFrame method .join for a non-multi-index DataFrame. This function should join the given DataFrame with another DataFrame on a specified key or keys. The join operation should be a left join, meaning all keys from the left DataFrame will be kept, and the keys in the right DataFrame that are not present in the left DataFrame will result in NaN values for the columns of the right DataFrame.\n\nInputs: \n- left: A pandas DataFrame to serve as the left operand in the join operation. This DataFrame should not have a MultiIndex structure and should include at least one column that can act as a key for the join operation.\n\nOutputs:\n- A pandas DataFrame that is the result of the left join operation. This DataFrame should contain all columns from the left DataFrame and all columns from the right DataFrame that can be joined on the specified key(s). If the right DataFrame has rows with keys not present in the left DataFrame, these rows will not appear in the result. For keys in the left DataFrame that do not have corresponding keys in the right DataFrame, the values from the right DataFrame's columns will be NaN.\n\nNote: The test cases will not be revealed to ensure the integrity of the assessment, but they will include scenarios to assess the correctness of the implementation under various conditions, including edge cases.", "method_code_mask": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\n\n@pytest.fixture\ndef left(): [MASK]\n"}
{"method_name": "right", "full_method_name": "right.reset_index", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py", "method_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n@pytest.fixture\ndef right(multiindex_dataframe_random_data):\n    \"\"\"right dataframe (multi-indexed) for multi-index join tests\"\"\"\n    df = multiindex_dataframe_random_data\n    df.index.names = ['key1', 'key2']\n    df.columns = ['j_one', 'j_two', 'j_three']\n    return df", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_join_index_multi_match(self):\n\t    left = DataFrame([['c', 0], ['b', 1], ['a', 2], ['b', 3]], columns=[\n\t        'tag', 'val'], index=[2, 0, 1, 3])\n\t    right = DataFrame([['a', 'v'], ['c', 'w'], ['c', 'x'], ['d', 'y'], ['a',\n\t        'z'], ['c', 'r'], ['e', 'q'], ['c', 's']], columns=['tag', 'char']\n\t        ).set_index('tag')\n\t    result = left.join(right, on='tag', how='left')\n\t    expected = DataFrame([['c', 0, 'w'], ['c', 0, 'x'], ['c', 0, 'r'], ['c',\n\t        0, 's'], ['b', 1, np.nan], ['a', 2, 'v'], ['a', 2, 'z'], ['b', 3,\n\t        np.nan]], columns=['tag', 'val', 'char'], index=[2, 2, 2, 2, 0, 1, \n\t        1, 3])\n\t    tm.assert_frame_equal(result, expected)\n\t    result = left.join(right, on='tag', how='left', sort=True)\n\t    expected2 = expected.sort_values('tag', kind='mergesort')\n\t    tm.assert_frame_equal(result, expected2)\n\t    result = merge(left, right.reset_index(), how='left', on='tag')\n\t    expected.index = RangeIndex(len(expected))\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_join_index_multi_match()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestJoinMultiMulti():\n\tdef test_single_common_level(self):\n\t    index_left = MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'), ('K1',\n\t        'X2')], names=['key', 'X'])\n\t    left = DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']},\n\t        index=index_left)\n\t    index_right = MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'), ('K2',\n\t        'Y2'), ('K2', 'Y3')], names=['key', 'Y'])\n\t    right = DataFrame({'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1',\n\t        'D2', 'D3']}, index=index_right)\n\t    result = left.join(right)\n\t    expected = merge(left.reset_index(), right.reset_index(), on=['key'],\n\t        how='inner').set_index(['key', 'X', 'Y'])\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestJoinMultiMulti().test_single_common_level()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeMulti():\n\tdef test_left_merge_na_buglet(self):\n\t    left = DataFrame({'id': list('abcde'), 'v1': np.random.default_rng(2).\n\t        standard_normal(5), 'v2': np.random.default_rng(2).standard_normal(\n\t        5), 'dummy': list('abcde'), 'v3': np.random.default_rng(2).\n\t        standard_normal(5)}, columns=['id', 'v1', 'v2', 'dummy', 'v3'])\n\t    right = DataFrame({'id': ['a', 'b', np.nan, np.nan, np.nan], 'sv3': [\n\t        1.234, 5.678, np.nan, np.nan, np.nan]})\n\t    result = merge(left, right, on='id', how='left')\n\t    rdf = right.drop(['id'], axis=1)\n\t    expected = left.join(rdf)\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeMulti().test_left_merge_na_buglet()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_multi.py"}], "instruction": "Functionality: The function right.reset_index is a method of a pandas DataFrame object which is used to reset the index of the DataFrame. This might be necessary when the index is no longer needed as an index but rather as a column, or when you want to concatenate DataFrames that have different indexes.\n\nInputs: \n1. The function accepts up to three arguments:\n   - level (optional): If the DataFrame has a MultiIndex, this parameter can be set to a level name or number to reset only the given level. By default, all levels are reset.\n   - drop (boolean, optional): If set to True, the index is dropped and replaced by a RangeIndex. The default is False, which keeps the index as a new column in the DataFrame.\n   - inplace (boolean, optional): If set to True, the operation is performed in-place on the DataFrame. If set to False, a new DataFrame is returned. The default is False.\n\nOutputs:\n   - When inplace is False (default), the function returns a new DataFrame with the index reset according to the parameters provided (level, drop).\n   - When inplace is True, the function does not return anything but modifies the DataFrame in place.", "method_code_mask": "import numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import merge\n\n\n@pytest.fixture\ndef right(multiindex_dataframe_random_data): [MASK]\n"}
{"method_name": "_join_by_hand", "full_method_name": "_join_by_hand", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_join.py", "method_code": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import bdate_range\nfrom pandas import concat\nfrom pandas import merge\nfrom pandas import option_context\nimport pandas._testing as tm\ndef _join_by_hand(a, b, how='left'):\n    join_index = a.index.join(b.index, how=how)\n    a_re = a.reindex(join_index)\n    b_re = b.reindex(join_index)\n    result_columns = a.columns.append(b.columns)\n    for col, s in b_re.items():\n        a_re[col] = s\n    return a_re.reindex(columns=result_columns)", "test_code_list": [{"test_code": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import bdate_range\nfrom pandas import concat\nfrom pandas import merge\nfrom pandas import option_context\nimport pandas._testing as tm\n\nclass TestJoin():\n\tdef test_join_index_mixed_overlap(self):\n\t    df1 = DataFrame({'A': 1.0, 'B': 2, 'C': 'foo', 'D': True}, index=np.\n\t        arange(10), columns=['A', 'B', 'C', 'D'])\n\t    assert df1['B'].dtype == np.int64\n\t    assert df1['D'].dtype == np.bool_\n\t    df2 = DataFrame({'A': 1.0, 'B': 2, 'C': 'foo', 'D': True}, index=np.\n\t        arange(0, 10, 2), columns=['A', 'B', 'C', 'D'])\n\t    joined = df1.join(df2, lsuffix='_one', rsuffix='_two')\n\t    expected_columns = ['A_one', 'B_one', 'C_one', 'D_one', 'A_two',\n\t        'B_two', 'C_two', 'D_two']\n\t    df1.columns = expected_columns[:4]\n\t    df2.columns = expected_columns[4:]\n\t    expected = _join_by_hand(df1, df2)\n\t    tm.assert_frame_equal(joined, expected)\n\t\nTestJoin().test_join_index_mixed_overlap()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_join.py"}], "instruction": "Functionality: The _join_by_hand function is designed to join two pandas Series or DataFrames based on their index, similar to merging tables in a database. It performs the join operation by first finding the join index based on the specified join type (how parameter), then reindexing both input Series or DataFrames to this join index, and finally concatenating the columns of both inputs into a single DataFrame.\n\nInputs: \n- a: The first input Series or DataFrame.\n- b: The second input Series or DataFrame.\n- how (optional): A string specifying the type of join to be performed. It can take one of the following values: 'left', 'right', 'outer', or 'inner'. The default value is 'left'.\n\nOutputs:\n- A DataFrame that results from joining the two input Series or DataFrames. The DataFrame will have the join_index as its index and will contain all columns from both input Series or DataFrames. If columns have the same name in both inputs, the column from the first input (a) will be used.", "method_code_mask": "import re\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import bdate_range\nfrom pandas import concat\nfrom pandas import merge\nfrom pandas import option_context\nimport pandas._testing as tm\n\n\ndef _join_by_hand(a, b, how='left'): [MASK]\n"}
{"method_name": "left", "full_method_name": "left.merge", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py", "method_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n@pytest.fixture\ndef left():\n    return DataFrame({'X': Series(np.random.default_rng(2).choice(['foo',\n        'bar'], size=(10,))).astype(CategoricalDtype(['foo', 'bar'])), 'Y':\n        np.random.default_rng(2).choice(['one', 'two', 'three'], size=(10,))})", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMerge():\n\tdef test_merge_different_column_key_names(self):\n\t    left = DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2,\n\t        3, 4]})\n\t    right = DataFrame({'rkey': ['foo', 'bar', 'qux', 'foo'], 'value': [5, 6,\n\t        7, 8]})\n\t    merged = left.merge(right, left_on='lkey', right_on='rkey', how='outer',\n\t        sort=True)\n\t    exp = Series(['bar', 'baz', 'foo', 'foo', 'foo', 'foo', np.nan], name=\n\t        'lkey')\n\t    tm.assert_series_equal(merged['lkey'], exp)\n\t    exp = Series(['bar', np.nan, 'foo', 'foo', 'foo', 'foo', 'qux'], name=\n\t        'rkey')\n\t    tm.assert_series_equal(merged['rkey'], exp)\n\t    exp = Series([2, 3, 1, 1, 4, 4, np.nan], name='value_x')\n\t    tm.assert_series_equal(merged['value_x'], exp)\n\t    exp = Series([6, np.nan, 5, 8, 5, 8, 7], name='value_y')\n\t    tm.assert_series_equal(merged['value_y'], exp)\n\t\nTestMerge().test_merge_different_column_key_names()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMerge():\n\tdef test_merge_right_index_right(self):\n\t    left = DataFrame({'a': [1, 2, 3], 'key': [0, 1, 1]})\n\t    right = DataFrame({'b': [1, 2, 3]})\n\t    expected = DataFrame({'a': [1, 2, 3, None], 'key': [0, 1, 1, 2], 'b': [\n\t        1, 2, 2, 3]}, columns=['a', 'key', 'b'], index=[0, 1, 2, np.nan])\n\t    result = left.merge(right, left_on='key', right_index=True, how='right')\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMerge().test_merge_right_index_right()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMerge():\n\tdef test_merge_take_missing_values_from_index_of_other_dtype(self):\n\t    left = DataFrame({'a': [1, 2, 3], 'key': Categorical(['a', 'a', 'b'],\n\t        categories=list('abc'))})\n\t    right = DataFrame({'b': [1, 2, 3]}, index=CategoricalIndex(['a', 'b', 'c'])\n\t        )\n\t    result = left.merge(right, left_on='key', right_index=True, how='right')\n\t    expected = DataFrame({'a': [1, 2, 3, None], 'key': Categorical(['a',\n\t        'a', 'b', 'c']), 'b': [1, 1, 2, 3]}, index=[0, 1, 2, np.nan])\n\t    expected = expected.reindex(columns=['a', 'key', 'b'])\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMerge().test_merge_take_missing_values_from_index_of_other_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMerge():\n\tdef test_merge_non_string_columns(self):\n\t    left = DataFrame({(0): [1, 0, 1, 0], (1): [0, 1, 0, 0], (2): [0, 0, 2, \n\t        0], (3): [1, 0, 0, 3]})\n\t    right = left.astype(float)\n\t    expected = left\n\t    result = merge(left, right)\n\t    tm.assert_frame_equal(expected, result)\n\t\nTestMerge().test_merge_non_string_columns()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMerge():\n\tdef test_merge_index_singlekey_inner(self):\n\t    left = DataFrame({'key': ['a', 'b', 'c', 'd', 'e', 'e', 'a'], 'v1': np.\n\t        random.default_rng(2).standard_normal(7)})\n\t    right = DataFrame({'v2': np.random.default_rng(2).standard_normal(4)},\n\t        index=['d', 'b', 'c', 'a'])\n\t    result = merge(left, right, left_on='key', right_index=True, how='inner')\n\t    expected = left.join(right, on='key').loc[result.index]\n\t    tm.assert_frame_equal(result, expected)\n\t    result = merge(right, left, right_on='key', left_index=True, how='inner')\n\t    expected = left.join(right, on='key').loc[result.index]\n\t    tm.assert_frame_equal(result, expected.loc[:, result.columns])\n\t\nTestMerge().test_merge_index_singlekey_inner()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeCategorical():\n\tdef test_merge_categorical(self):\n\t    right = DataFrame({'c': {(0): 'a', (1): 'b', (2): 'c', (3): 'd', (4):\n\t        'e'}, 'd': {(0): 'null', (1): 'null', (2): 'null', (3): 'null', (4):\n\t        'null'}})\n\t    left = DataFrame({'a': {(0): 'f', (1): 'f', (2): 'f', (3): 'f', (4):\n\t        'f'}, 'b': {(0): 'g', (1): 'g', (2): 'g', (3): 'g', (4): 'g'}})\n\t    df = merge(left, right, how='left', left_on='b', right_on='c')\n\t    expected = df.copy()\n\t    cright = right.copy()\n\t    cright['d'] = cright['d'].astype('category')\n\t    result = merge(left, cright, how='left', left_on='b', right_on='c')\n\t    expected['d'] = expected['d'].astype(CategoricalDtype(['null']))\n\t    tm.assert_frame_equal(result, expected)\n\t    cleft = left.copy()\n\t    cleft['b'] = cleft['b'].astype('category')\n\t    result = merge(cleft, cright, how='left', left_on='b', right_on='c')\n\t    tm.assert_frame_equal(result, expected)\n\t    cright = right.copy()\n\t    cright['d'] = cright['d'].astype('category')\n\t    cleft = left.copy()\n\t    cleft['b'] = cleft['b'].astype('category')\n\t    result = merge(cleft, cright, how='left', left_on='b', right_on='c')\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeCategorical().test_merge_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}], "instruction": "Functionality: The left.merge function is designed to perform a database-style join operation of two DataFrame objects on their common column(s). The specific type of join in this case is a left join, meaning that all observations from the left DataFrame are included in the resulting DataFrame, while only matching observations from the right DataFrame are included. Missing values from the right DataFrame are replaced with NaN.\n\nInputs: \n1. The left DataFrame, which is to be merged with another DataFrame. The DataFrame is expected to have categorical data type columns and may include various data types such as strings, integers, etc. An example of the left DataFrame is provided in the code snippet, where it includes a categorical 'X' column and a 'Y' column with randomly chosen elements.\n\nOutputs:\n1. The resulting DataFrame after the left join operation is performed. The result will include all rows from the left DataFrame, and only the matched rows from the right DataFrame. If there is no match, the result will contain NaN on the right DataFrame's side.", "method_code_mask": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\n\n@pytest.fixture\ndef left(): [MASK]\n"}
{"method_name": "right", "full_method_name": "right.copy", "method_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py", "method_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n@pytest.fixture\ndef right():\n    return DataFrame({'X': Series(['foo', 'bar']).astype(CategoricalDtype([\n        'foo', 'bar'])), 'Z': [1, 2]})", "test_code_list": [{"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\ndef test_merge_on_cat_and_ext_array():\n    right = DataFrame({'a': Series([pd.Interval(0, 1), pd.Interval(1, 2)],\n        dtype='interval')})\n    left = right.copy()\n    left['a'] = left['a'].astype('category')\n    result = merge(left, right, how='inner', on='a')\n    expected = right.copy()\n    tm.assert_frame_equal(result, expected)\n\ntest_merge_on_cat_and_ext_array()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}, {"test_code": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\nclass TestMergeCategorical():\n\tdef test_merge_categorical(self):\n\t    right = DataFrame({'c': {(0): 'a', (1): 'b', (2): 'c', (3): 'd', (4):\n\t        'e'}, 'd': {(0): 'null', (1): 'null', (2): 'null', (3): 'null', (4):\n\t        'null'}})\n\t    left = DataFrame({'a': {(0): 'f', (1): 'f', (2): 'f', (3): 'f', (4):\n\t        'f'}, 'b': {(0): 'g', (1): 'g', (2): 'g', (3): 'g', (4): 'g'}})\n\t    df = merge(left, right, how='left', left_on='b', right_on='c')\n\t    expected = df.copy()\n\t    cright = right.copy()\n\t    cright['d'] = cright['d'].astype('category')\n\t    result = merge(left, cright, how='left', left_on='b', right_on='c')\n\t    expected['d'] = expected['d'].astype(CategoricalDtype(['null']))\n\t    tm.assert_frame_equal(result, expected)\n\t    cleft = left.copy()\n\t    cleft['b'] = cleft['b'].astype('category')\n\t    result = merge(cleft, cright, how='left', left_on='b', right_on='c')\n\t    tm.assert_frame_equal(result, expected)\n\t    cright = right.copy()\n\t    cright['d'] = cright['d'].astype('category')\n\t    cleft = left.copy()\n\t    cleft['b'] = cleft['b'].astype('category')\n\t    result = merge(cleft, cright, how='left', left_on='b', right_on='c')\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestMergeCategorical().test_merge_categorical()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/reshape/merge/test_merge.py"}], "instruction": "Functionality: The function 'right.copy' is a method that enables the user to create a copy of a given DataFrame. This is essentially a deep copy operation, which means that changes to the copy will not affect the original DataFrame, and vice versa. This function provides an effective way to ensure that data operations are isolated and do not inadvertently alter the source data.\n\nInputs: \n- The function 'right.copy' does not explicitly require any input arguments when called on a DataFrame. However, it implicitly takes the DataFrame it is called upon as its primary input.\n\nOutputs:\n- The 'right.copy' function returns a new DataFrame that is a deep copy of the original DataFrame it is called upon. This means the returned DataFrame will have the same data, index, and columns as the original DataFrame, but it will be a separate object in memory, unaffected by any changes made to the original DataFrame.", "method_code_mask": "from datetime import date\nfrom datetime import datetime\nfrom datetime import timedelta\nimport re\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nimport pandas as pd\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import MultiIndex\nfrom pandas import PeriodIndex\nfrom pandas import RangeIndex\nfrom pandas import Series\nfrom pandas import TimedeltaIndex\nimport pandas._testing as tm\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.reshape.merge import MergeError\nfrom pandas.core.reshape.merge import merge\n\n\n@pytest.fixture\ndef right(): [MASK]\n"}
{"method_name": "coerce_to_array", "full_method_name": "coerce_to_array", "method_path": "../srcdata/Computation/pandas/pandas/core/arrays/boolean.py", "method_code": "from __future__ import annotations\nimport numbers\nfrom typing import TYPE_CHECKING\nfrom typing import ClassVar\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import register_extension_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core import ops\nfrom pandas.core.array_algos import masked_accumulations\nfrom pandas.core.arrays.masked import BaseMaskedArray\nfrom pandas.core.arrays.masked import BaseMaskedDtype\nimport pyarrow\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import npt\nfrom pandas._typing import type_t\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.arrays import IntegerArray\ndef coerce_to_array(values, mask=None, copy: bool=False) ->tuple[np.ndarray,\n    np.ndarray]:\n    \"\"\"\n    Coerce the input values array to numpy arrays with a mask.\n\n    Parameters\n    ----------\n    values : 1D list-like\n    mask : bool 1D array, optional\n    copy : bool, default False\n        if True, copy the input\n\n    Returns\n    -------\n    tuple of (values, mask)\n    \"\"\"\n    if isinstance(values, BooleanArray):\n        if mask is not None:\n            raise ValueError('cannot pass mask for BooleanArray input')\n        values, mask = values._data, values._mask\n        if copy:\n            values = values.copy()\n            mask = mask.copy()\n        return values, mask\n    mask_values = None\n    if isinstance(values, np.ndarray) and values.dtype == np.bool_:\n        if copy:\n            values = values.copy()\n    elif isinstance(values, np.ndarray) and values.dtype.kind in 'iufcb':\n        mask_values = isna(values)\n        values_bool = np.zeros(len(values), dtype=bool)\n        values_bool[~mask_values] = values[~mask_values].astype(bool)\n        if not np.all(values_bool[~mask_values].astype(values.dtype) ==\n            values[~mask_values]):\n            raise TypeError('Need to pass bool-like values')\n        values = values_bool\n    else:\n        values_object = np.asarray(values, dtype=object)\n        inferred_dtype = lib.infer_dtype(values_object, skipna=True)\n        integer_like = 'floating', 'integer', 'mixed-integer-float'\n        if inferred_dtype not in ('boolean', 'empty') + integer_like:\n            raise TypeError('Need to pass bool-like values')\n        mask_values = cast('npt.NDArray[np.bool_]', isna(values_object))\n        values = np.zeros(len(values), dtype=bool)\n        values[~mask_values] = values_object[~mask_values].astype(bool)\n        if inferred_dtype in integer_like and not np.all(values[~\n            mask_values].astype(float) == values_object[~mask_values].\n            astype(float)):\n            raise TypeError('Need to pass bool-like values')\n    if mask is None and mask_values is None:\n        mask = np.zeros(values.shape, dtype=bool)\n    elif mask is None:\n        mask = mask_values\n    elif isinstance(mask, np.ndarray) and mask.dtype == np.bool_:\n        if mask_values is not None:\n            mask = mask | mask_values\n        elif copy:\n            mask = mask.copy()\n    else:\n        mask = np.array(mask, dtype=bool)\n        if mask_values is not None:\n            mask = mask | mask_values\n    if values.shape != mask.shape:\n        raise ValueError('values.shape and mask.shape must match')\n    return values, mask", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.arrays import BooleanArray\nfrom pandas.core.arrays.boolean import coerce_to_array\ndef test_coerce_to_array():\n    values = np.array([True, False, True, False], dtype='bool')\n    mask = np.array([False, False, False, True], dtype='bool')\n    result = BooleanArray(*coerce_to_array(values, mask=mask))\n    expected = BooleanArray(values, mask)\n    tm.assert_extension_array_equal(result, expected)\n    assert result._data is values\n    assert result._mask is mask\n    result = BooleanArray(*coerce_to_array(values, mask=mask, copy=True))\n    expected = BooleanArray(values, mask)\n    tm.assert_extension_array_equal(result, expected)\n    assert result._data is not values\n    assert result._mask is not mask\n    values = [True, False, None, False]\n    mask = np.array([False, False, False, True], dtype='bool')\n    result = BooleanArray(*coerce_to_array(values, mask=mask))\n    expected = BooleanArray(np.array([True, False, True, True]), np.array([\n        False, False, True, True]))\n    tm.assert_extension_array_equal(result, expected)\n    result = BooleanArray(*coerce_to_array(np.array(values, dtype=object),\n        mask=mask))\n    tm.assert_extension_array_equal(result, expected)\n    result = BooleanArray(*coerce_to_array(values, mask=mask.tolist()))\n    tm.assert_extension_array_equal(result, expected)\n    values = np.array([True, False, True, False], dtype='bool')\n    mask = np.array([False, False, False, True], dtype='bool')\n    coerce_to_array(values.reshape(1, -1))\n    with pytest.raises(ValueError, match=\n        'values.shape and mask.shape must match'):\n        coerce_to_array(values.reshape(1, -1), mask=mask)\n    with pytest.raises(ValueError, match=\n        'values.shape and mask.shape must match'):\n        coerce_to_array(values, mask=mask.reshape(1, -1))\n\ntest_coerce_to_array()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/boolean/test_construction.py"}, {"test_code": "import numpy as np\nimport pytest\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.arrays import BooleanArray\nfrom pandas.core.arrays.boolean import coerce_to_array\ndef test_coerce_to_array_from_boolean_array():\n    values = np.array([True, False, True, False], dtype='bool')\n    mask = np.array([False, False, False, True], dtype='bool')\n    arr = BooleanArray(values, mask)\n    result = BooleanArray(*coerce_to_array(arr))\n    tm.assert_extension_array_equal(result, arr)\n    assert result._data is arr._data\n    assert result._mask is arr._mask\n    result = BooleanArray(*coerce_to_array(arr), copy=True)\n    tm.assert_extension_array_equal(result, arr)\n    assert result._data is not arr._data\n    assert result._mask is not arr._mask\n    with pytest.raises(ValueError, match=\n        'cannot pass mask for BooleanArray input'):\n        coerce_to_array(arr, mask=mask)\n\ntest_coerce_to_array_from_boolean_array()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/boolean/test_construction.py"}], "instruction": "Functionality: The function coerce_to_array coerces the input values array to numpy arrays with a mask. It handles various input types, ensuring they are converted to boolean values if necessary, and creates or updates a mask array based on the input values and an optional mask parameter.\n\nInputs: \n- values: A 1D list-like object that needs to be coerced into a numpy array.\n- mask: An optional 1D boolean array that represents the mask for the values array.\n- copy: A boolean parameter (default False) that indicates whether to copy the input values and mask.\n\nOutputs: \n- A tuple containing two numpy arrays:\n    - The first element is a numpy array representing the coerced values.\n    - The second element is a numpy array representing the mask for the coerced values.", "method_code_mask": "from __future__ import annotations\nimport numbers\nfrom typing import TYPE_CHECKING\nfrom typing import ClassVar\nfrom typing import cast\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import register_extension_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core import ops\nfrom pandas.core.array_algos import masked_accumulations\nfrom pandas.core.arrays.masked import BaseMaskedArray\nfrom pandas.core.arrays.masked import BaseMaskedDtype\nimport pyarrow\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import npt\nfrom pandas._typing import type_t\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.arrays import IntegerArray\n\n\ndef coerce_to_array(values, mask=None, copy: bool=False) ->tuple[np.ndarray,\n    np.ndarray]: [MASK]\n"}
{"method_name": "construct_from_string", "full_method_name": "NumpyEADtype.construct_from_string", "method_path": "../srcdata/Computation/pandas/pandas/core/dtypes/dtypes.py", "method_code": "from __future__ import annotations\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom decimal import Decimal\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport numpy as np\nimport pytz\nfrom pandas._config.config import get_option\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.interval import Interval\nfrom pandas._libs.properties import cache_readonly\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._libs.tslibs import Period\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import timezones\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs import tz_compare\nfrom pandas._libs.tslibs.dtypes import PeriodDtypeBase\nfrom pandas._libs.tslibs.dtypes import abbrev_to_npy_unit\nfrom pandas._libs.tslibs.offsets import BDay\nfrom pandas.errors import PerformanceWarning\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import ExtensionDtype\nfrom pandas.core.dtypes.base import StorageExtensionDtype\nfrom pandas.core.dtypes.base import register_extension_dtype\nfrom pandas.core.dtypes.generic import ABCCategoricalIndex\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCRangeIndex\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_list_like\nimport pyarrow as pa\nfrom collections.abc import MutableMapping\nfrom datetime import tzinfo\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import IntervalClosedType\nfrom pandas._typing import Ordered\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas._typing import type_t\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import PeriodIndex\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays.arrow import ArrowExtensionArray\nfrom pandas.core.util.hashing import combine_hash_arrays\nfrom pandas.core.util.hashing import hash_array\nfrom pandas.core.util.hashing import hash_tuples\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.cast import find_common_type\nimport pyarrow\nfrom pandas.core.arrays.arrow._arrow_utils import pyarrow_array_to_numpy_and_mask\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.arrays.boolean import BooleanDtype\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.cast import can_hold_element\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas import isna\nfrom pandas.core.arrays.sparse.array import SparseArray\nfrom pandas.core.dtypes.astype import astype_array\nfrom pandas.core.dtypes.cast import np_find_common_type\nclass NumpyEADtype(ExtensionDtype):\n    \"\"\"\n    A Pandas ExtensionDtype for NumPy dtypes.\n\n    This is mostly for internal compatibility, and is not especially\n    useful on its own.\n\n    Parameters\n    ----------\n    dtype : object\n        Object to be converted to a NumPy data type object.\n\n    See Also\n    --------\n    numpy.dtype\n    \"\"\"\n    _metadata = '_dtype',\n    _supports_2d = False\n    _can_fast_transpose = False\n\n    def __init__(self, dtype: (npt.DTypeLike | NumpyEADtype | None)) ->None:\n        if isinstance(dtype, NumpyEADtype):\n            dtype = dtype.numpy_dtype\n        self._dtype = np.dtype(dtype)\n\n    def __repr__(self) ->str:\n        return f'NumpyEADtype({self.name!r})'\n\n    @property\n    def numpy_dtype(self) ->np.dtype:\n        \"\"\"\n        The NumPy dtype this NumpyEADtype wraps.\n        \"\"\"\n        return self._dtype\n\n    @property\n    def name(self) ->str:\n        \"\"\"\n        A bit-width name for this data-type.\n        \"\"\"\n        return self._dtype.name\n\n    @property\n    def type(self) ->type[np.generic]:\n        \"\"\"\n        The type object used to instantiate a scalar of this NumPy data-type.\n        \"\"\"\n        return self._dtype.type\n\n    @property\n    def _is_numeric(self) ->bool:\n        return self.kind in set('biufc')\n\n    @property\n    def _is_boolean(self) ->bool:\n        return self.kind == 'b'\n\n    @classmethod\n    def construct_from_string(cls, string: str) ->NumpyEADtype:\n        try:\n            dtype = np.dtype(string)\n        except TypeError as err:\n            if not isinstance(string, str):\n                msg = (\n                    f\"'construct_from_string' expects a string, got {type(string)}\"\n                    )\n            else:\n                msg = f\"Cannot construct a 'NumpyEADtype' from '{string}'\"\n            raise TypeError(msg) from err\n        return cls(dtype)\n\n    @classmethod\n    def construct_array_type(cls) ->type_t[NumpyExtensionArray]:\n        \"\"\"\n        Return the array type associated with this dtype.\n\n        Returns\n        -------\n        type\n        \"\"\"\n        from pandas.core.arrays import NumpyExtensionArray\n        return NumpyExtensionArray\n\n    @property\n    def kind(self) ->str:\n        \"\"\"\n        A character code (one of 'biufcmMOSUV') identifying the general kind of data.\n        \"\"\"\n        return self._dtype.kind\n\n    @property\n    def itemsize(self) ->int:\n        \"\"\"\n        The element size of this data-type object.\n        \"\"\"\n        return self._dtype.itemsize", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nimport pandas as pd\nimport pandas._testing as tm\ndef test_constructor_from_string():\n    result = NumpyEADtype.construct_from_string('int64')\n    expected = NumpyEADtype(np.dtype('int64'))\n    assert result == expected\n\ntest_constructor_from_string()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/numpy_/test_numpy.py"}], "instruction": "Functionality: The NumpyEADtype.construct_from_string function is a class method that constructs a NumpyEADtype object from a string representation of a numpy dtype. This method attempts to parse the string and create a corresponding numpy dtype, which is then wrapped in a NumpyEADtype instance.\n\nInputs:\n- string: str\n  An input string that represents a numpy data type. The string should be in a format that numpy's dtype constructor can understand. Examples include 'int32', 'float64', 'datetime64[ns]', etc.\n\nOutputs:\n- NumpyEADtype\n  A NumpyEADtype object that wraps the numpy dtype created from the input string. This object provides compatibility with pandas' extension array dtype system.", "method_code_mask": "from __future__ import annotations\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom decimal import Decimal\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nimport numpy as np\nimport pytz\nfrom pandas._config.config import get_option\nfrom pandas._libs import lib\nfrom pandas._libs import missing as libmissing\nfrom pandas._libs.interval import Interval\nfrom pandas._libs.properties import cache_readonly\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import NaT\nfrom pandas._libs.tslibs import NaTType\nfrom pandas._libs.tslibs import Period\nfrom pandas._libs.tslibs import Timedelta\nfrom pandas._libs.tslibs import Timestamp\nfrom pandas._libs.tslibs import timezones\nfrom pandas._libs.tslibs import to_offset\nfrom pandas._libs.tslibs import tz_compare\nfrom pandas._libs.tslibs.dtypes import PeriodDtypeBase\nfrom pandas._libs.tslibs.dtypes import abbrev_to_npy_unit\nfrom pandas._libs.tslibs.offsets import BDay\nfrom pandas.errors import PerformanceWarning\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import ExtensionDtype\nfrom pandas.core.dtypes.base import StorageExtensionDtype\nfrom pandas.core.dtypes.base import register_extension_dtype\nfrom pandas.core.dtypes.generic import ABCCategoricalIndex\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCRangeIndex\nfrom pandas.core.dtypes.inference import is_bool\nfrom pandas.core.dtypes.inference import is_list_like\nimport pyarrow as pa\nfrom collections.abc import MutableMapping\nfrom datetime import tzinfo\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import IntervalClosedType\nfrom pandas._typing import Ordered\nfrom pandas._typing import Scalar\nfrom pandas._typing import npt\nfrom pandas._typing import type_t\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DatetimeIndex\nfrom pandas import Index\nfrom pandas import IntervalIndex\nfrom pandas import PeriodIndex\nfrom pandas.core.arrays import BaseMaskedArray\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import IntervalArray\nfrom pandas.core.arrays import PeriodArray\nfrom pandas.core.arrays import SparseArray\nfrom pandas.core.arrays.arrow import ArrowExtensionArray\nfrom pandas.core.util.hashing import combine_hash_arrays\nfrom pandas.core.util.hashing import hash_array\nfrom pandas.core.util.hashing import hash_tuples\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.cast import find_common_type\nimport pyarrow\nfrom pandas.core.arrays.arrow._arrow_utils import pyarrow_array_to_numpy_and_mask\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.arrays.boolean import BooleanDtype\nfrom pandas.core.dtypes.missing import na_value_for_dtype\nfrom pandas.core.dtypes.cast import can_hold_element\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas import isna\nfrom pandas.core.arrays.sparse.array import SparseArray\nfrom pandas.core.dtypes.astype import astype_array\nfrom pandas.core.dtypes.cast import np_find_common_type\n\n\nclass NumpyEADtype(ExtensionDtype):\n    \"\"\"\n    A Pandas ExtensionDtype for NumPy dtypes.\n\n    This is mostly for internal compatibility, and is not especially\n    useful on its own.\n\n    Parameters\n    ----------\n    dtype : object\n        Object to be converted to a NumPy data type object.\n\n    See Also\n    --------\n    numpy.dtype\n    \"\"\"\n    _metadata = '_dtype',\n    _supports_2d = False\n    _can_fast_transpose = False\n\n    def __init__(self, dtype: (npt.DTypeLike | NumpyEADtype | None)) ->None:\n        if isinstance(dtype, NumpyEADtype):\n            dtype = dtype.numpy_dtype\n        self._dtype = np.dtype(dtype)\n\n    def __repr__(self) ->str:\n        return f'NumpyEADtype({self.name!r})'\n\n    @property\n    def numpy_dtype(self) ->np.dtype:\n        \"\"\"\n        The NumPy dtype this NumpyEADtype wraps.\n        \"\"\"\n        return self._dtype\n\n    @property\n    def name(self) ->str:\n        \"\"\"\n        A bit-width name for this data-type.\n        \"\"\"\n        return self._dtype.name\n\n    @property\n    def type(self) ->type[np.generic]:\n        \"\"\"\n        The type object used to instantiate a scalar of this NumPy data-type.\n        \"\"\"\n        return self._dtype.type\n\n    @property\n    def _is_numeric(self) ->bool:\n        return self.kind in set('biufc')\n\n    @property\n    def _is_boolean(self) ->bool:\n        return self.kind == 'b'\n\n    @classmethod\n    def construct_from_string(cls, string: str) ->NumpyEADtype: [MASK]\n\n    @classmethod\n    def construct_array_type(cls) ->type_t[NumpyExtensionArray]:\n        \"\"\"\n        Return the array type associated with this dtype.\n\n        Returns\n        -------\n        type\n        \"\"\"\n        from pandas.core.arrays import NumpyExtensionArray\n        return NumpyExtensionArray\n\n    @property\n    def kind(self) ->str:\n        \"\"\"\n        A character code (one of 'biufcmMOSUV') identifying the general kind of data.\n        \"\"\"\n        return self._dtype.kind\n\n    @property\n    def itemsize(self) ->int:\n        \"\"\"\n        The element size of this data-type object.\n        \"\"\"\n        return self._dtype.itemsize\n"}
{"method_name": "recode_for_categories", "full_method_name": "recode_for_categories", "method_path": "../srcdata/Computation/pandas/pandas/core/arrays/categorical.py", "method_code": "from __future__ import annotations\nfrom csv import QUOTE_NONNUMERIC\nfrom functools import partial\nimport operator\nfrom shutil import get_terminal_size\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import NaT\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import lib\nfrom pandas._libs.arrays import NDArrayBacked\nfrom pandas.compat.numpy import function as nv\nfrom pandas.util._validators import validate_bool_kwarg\nfrom pandas.core.dtypes.cast import coerce_indexer_dtype\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_any_real_numeric_dtype\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_hashable\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core import algorithms\nfrom pandas.core import arraylike\nfrom pandas.core import ops\nfrom pandas.core.accessor import PandasDelegate\nfrom pandas.core.accessor import delegate_names\nfrom pandas.core.algorithms import factorize\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\nfrom pandas.core.arrays._mixins import ravel_compat\nfrom pandas.core.base import ExtensionArray\nfrom pandas.core.base import NoNewAttributesMixin\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.construction import extract_array\nfrom pandas.core.construction import sanitize_array\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\nfrom pandas.core.sorting import nargsort\nfrom pandas.core.strings.object_array import ObjectStringArrayMixin\nfrom pandas.io.formats import console\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AstypeArg\nfrom pandas._typing import AxisInt\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NpDtype\nfrom pandas._typing import Ordered\nfrom pandas._typing import Shape\nfrom pandas._typing import SortKind\nfrom pandas._typing import npt\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.indexes.range import RangeIndex\nfrom pandas import to_datetime\nfrom pandas import to_numeric\nfrom pandas import to_timedelta\nfrom pandas import CategoricalIndex\nfrom pandas.core.util.hashing import hash_array\nfrom pandas.io.formats import format as fmt\nfrom pandas.core.dtypes.concat import union_categoricals\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.groupby.ops import WrappedCythonOp\ndef recode_for_categories(codes: np.ndarray, old_categories, new_categories,\n    copy: bool=True) ->np.ndarray:\n    \"\"\"\n    Convert a set of codes for to a new set of categories\n\n    Parameters\n    ----------\n    codes : np.ndarray\n    old_categories, new_categories : Index\n    copy: bool, default True\n        Whether to copy if the codes are unchanged.\n\n    Returns\n    -------\n    new_codes : np.ndarray[np.int64]\n\n    Examples\n    --------\n    >>> old_cat = pd.Index([\"b\", \"a\", \"c\"])\n    >>> new_cat = pd.Index([\"a\", \"b\"])\n    >>> codes = np.array([0, 1, 1, 2])\n    >>> recode_for_categories(codes, old_cat, new_cat)\n    array([ 1,  0,  0, -1], dtype=int8)\n    \"\"\"\n    if len(old_categories) == 0:\n        if copy:\n            return codes.copy()\n        return codes\n    elif new_categories.equals(old_categories):\n        if copy:\n            return codes.copy()\n        return codes\n    indexer = coerce_indexer_dtype(new_categories.get_indexer_for(\n        old_categories), new_categories)\n    new_codes = take_nd(indexer, codes, fill_value=-1)\n    return new_codes", "test_code_list": [{"test_code": "import re\nimport numpy as np\nimport pytest\nfrom pandas.compat import PY311\nfrom pandas import Categorical\nfrom pandas import CategoricalIndex\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import StringDtype\nimport pandas._testing as tm\nfrom pandas.core.arrays.categorical import recode_for_categories\n\nclass TestPrivateCategoricalAPI():\n\tdef test_recode_to_categories_large(self):\n\t    N = 1000\n\t    codes = np.arange(N)\n\t    old = Index(codes)\n\t    expected = np.arange(N - 1, -1, -1, dtype=np.int16)\n\t    new = Index(expected)\n\t    result = recode_for_categories(codes, old, new)\n\t    tm.assert_numpy_array_equal(result, expected)\n\t\nTestPrivateCategoricalAPI().test_recode_to_categories_large()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arrays/categorical/test_api.py"}], "instruction": "Functionality: The function recode_for_categories is designed to convert a set of codes that refer to old categories to a new set of codes that refer to new categories. This is particularly useful when dealing with categorical data where category mappings need to be updated.\n\nInputs: \n- codes: An np.ndarray representing the codes that refer to old categories.\n- old_categories, new_categories: Both are Index objects. old_categories represent the current mapping that the codes are based on, and new_categories represent the new mapping that the codes should be converted to.\n- copy: A boolean, defaulting to True, indicating whether to copy the codes if they are unchanged.\n\nOutputs:\n- new_codes: An np.ndarray of np.int64 type, representing the converted codes based on the new_categories.\n\nExample usage:", "method_code_mask": "from __future__ import annotations\nfrom csv import QUOTE_NONNUMERIC\nfrom functools import partial\nimport operator\nfrom shutil import get_terminal_size\nfrom typing import TYPE_CHECKING\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import NaT\nfrom pandas._libs import algos as libalgos\nfrom pandas._libs import lib\nfrom pandas._libs.arrays import NDArrayBacked\nfrom pandas.compat.numpy import function as nv\nfrom pandas.util._validators import validate_bool_kwarg\nfrom pandas.core.dtypes.cast import coerce_indexer_dtype\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.common import ensure_int64\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import is_any_real_numeric_dtype\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_hashable\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import needs_i8_conversion\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtypeType\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core import algorithms\nfrom pandas.core import arraylike\nfrom pandas.core import ops\nfrom pandas.core.accessor import PandasDelegate\nfrom pandas.core.accessor import delegate_names\nfrom pandas.core.algorithms import factorize\nfrom pandas.core.algorithms import take_nd\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\nfrom pandas.core.arrays._mixins import ravel_compat\nfrom pandas.core.base import ExtensionArray\nfrom pandas.core.base import NoNewAttributesMixin\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.construction import extract_array\nfrom pandas.core.construction import sanitize_array\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\nfrom pandas.core.sorting import nargsort\nfrom pandas.core.strings.object_array import ObjectStringArrayMixin\nfrom pandas.io.formats import console\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom collections.abc import Iterator\nfrom collections.abc import Sequence\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import AstypeArg\nfrom pandas._typing import AxisInt\nfrom pandas._typing import Dtype\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import NpDtype\nfrom pandas._typing import Ordered\nfrom pandas._typing import Shape\nfrom pandas._typing import SortKind\nfrom pandas._typing import npt\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas.core.indexes.range import RangeIndex\nfrom pandas import to_datetime\nfrom pandas import to_numeric\nfrom pandas import to_timedelta\nfrom pandas import CategoricalIndex\nfrom pandas.core.util.hashing import hash_array\nfrom pandas.io.formats import format as fmt\nfrom pandas.core.dtypes.concat import union_categoricals\nfrom pandas.core.reshape.concat import concat\nfrom pandas.core.groupby.ops import WrappedCythonOp\n\n\ndef recode_for_categories(codes: np.ndarray, old_categories, new_categories,\n    copy: bool=True) ->np.ndarray: [MASK]\n"}
{"method_name": "index_view", "full_method_name": "index_view", "method_path": "../srcdata/Computation/pandas/pandas/tests/copy_view/index/test_index.py", "method_code": "import numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.tests.copy_view.util import get_array\ndef index_view(index_data):\n    df = DataFrame({'a': index_data, 'b': 1.5})\n    view = df[:]\n    df = df.set_index('a', drop=True)\n    idx = df.index\n    return idx, view", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.tests.copy_view.util import get_array\ndef test_infer_objects():\n    idx, view_ = index_view(['a', 'b'])\n    expected = idx.copy(deep=True)\n    idx = idx.infer_objects(copy=False)\n    view_.iloc[0, 0] = 'aaaa'\n    tm.assert_index_equal(idx, expected, check_names=False)\n\ntest_infer_objects()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/copy_view/index/test_index.py"}], "instruction": "Functionality: The 'index_view' function is designed to process a given array of data and return a specific view of the data as part of a DataFrame's index. This function first creates a DataFrame with the provided data and another column filled with a constant value. Then, it creates a copy of this DataFrame as a view. After that, it sets the index of the DataFrame to be the first column ('a') and returns the index of this DataFrame along with the previously created view.\n\nInputs: \n    index_data: A 1-dimensional array-like object. This could be a list, a numpy array, or any other iterable containing the data to be used as the 'a' column in the DataFrame.\n\nOutputs:\n    idx: The index of the DataFrame after setting the 'a' column as the index. This is a pandas Index object.\n    view: A copy of the DataFrame before the 'a' column is set as the index. This DataFrame contains the 'a' column with the provided data and the 'b' column filled with the value 1.5.", "method_code_mask": "import numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.tests.copy_view.util import get_array\n\n\ndef index_view(index_data): [MASK]\n"}
{"method_name": "round_trip_pathlib", "full_method_name": "round_trip_pathlib", "method_path": "../srcdata/Computation/pandas/pandas/_testing/_io.py", "method_code": "from __future__ import annotations\nimport gzip\nimport io\nimport pathlib\nimport tarfile\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport uuid\nimport zipfile\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas._testing.contexts import ensure_clean\nfrom collections.abc import Callable\nfrom pandas._typing import FilePath\nfrom pandas._typing import ReadPickleBuffer\nfrom pandas import DataFrame\nfrom pandas import Series\nimport bz2\nimport lzma\ndef round_trip_pathlib(writer, reader, path: (str | None)=None):\n    \"\"\"\n    Write an object to file specified by a pathlib.Path and read it back\n\n    Parameters\n    ----------\n    writer : callable bound to pandas object\n        IO writing function (e.g. DataFrame.to_csv )\n    reader : callable\n        IO reading function (e.g. pd.read_csv )\n    path : str, default None\n        The path where the object is written and then read.\n\n    Returns\n    -------\n    pandas object\n        The original object that was serialized and then re-read.\n    \"\"\"\n    Path = pathlib.Path\n    if path is None:\n        path = '___pathlib___'\n    with ensure_clean(path) as path:\n        writer(Path(path))\n        obj = reader(Path(path))\n    return obj", "test_code_list": [{"test_code": "import bz2\nimport datetime\nimport functools\nfrom functools import partial\nimport gzip\nimport io\nimport os\nfrom pathlib import Path\nimport pickle\nimport shutil\nimport tarfile\nfrom typing import Any\nimport uuid\nimport zipfile\nimport numpy as np\nimport pytest\nfrom pandas.compat import is_platform_little_endian\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import Series\nfrom pandas import period_range\nimport pandas._testing as tm\nfrom pandas.tests.io.generate_legacy_storage_files import create_pickle_data\nimport pandas.io.common as icom\nfrom pandas.tseries.offsets import Day\nfrom pandas.tseries.offsets import MonthEnd\nimport lzma\ndef test_pickle_path_pathlib():\n    df = DataFrame(1.1 * np.arange(120).reshape((30, 4)), columns=Index(\n        list('ABCD'), dtype=object), index=Index([f'i-{i}' for i in range(\n        30)], dtype=object))\n    result = round_trip_pathlib(df.to_pickle, pd.read_pickle)\n    tm.assert_frame_equal(df, result)\n\ntest_pickle_path_pathlib()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_pickle.py"}, {"test_code": "import zoneinfo\nimport numpy as np\nimport pytest\nimport pandas as pd\nimport pandas._testing as tm\nfrom pandas.core.arrays import ArrowStringArray\nfrom pandas.core.arrays import StringArray\nfrom pandas.io.feather_format import read_feather\nfrom pandas.io.feather_format import to_feather\nfrom pandas.arrays import ArrowExtensionArray\n\nclass TestFeather():\n\tdef test_path_pathlib(self):\n\t    df = pd.DataFrame(1.1 * np.arange(120).reshape((30, 4)), columns=pd.\n\t        Index(list('ABCD'), dtype=object), index=pd.Index([f'i-{i}' for i in\n\t        range(30)], dtype=object)).reset_index()\n\t    result = round_trip_pathlib(df.to_feather, read_feather)\n\t    tm.assert_frame_equal(df, result)\n\t\nTestFeather().test_path_pathlib()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_feather.py"}, {"test_code": "import bz2\nimport datetime as dt\nfrom datetime import datetime\nimport gzip\nimport io\nimport os\nimport struct\nimport tarfile\nimport zipfile\nimport numpy as np\nimport pytest\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import CategoricalDtype\nimport pandas._testing as tm\nfrom pandas.core.frame import DataFrame\nfrom pandas.core.frame import Series\nfrom pandas.io.parsers import read_csv\nfrom pandas.io.stata import CategoricalConversionWarning\nfrom pandas.io.stata import InvalidColumnName\nfrom pandas.io.stata import PossiblePrecisionLoss\nfrom pandas.io.stata import StataMissingValue\nfrom pandas.io.stata import StataReader\nfrom pandas.io.stata import StataWriter\nfrom pandas.io.stata import StataWriterUTF8\nfrom pandas.io.stata import ValueLabelTypeMismatch\nfrom pandas.io.stata import read_stata\n\nclass TestStata():\n\tdef test_path_pathlib(self):\n\t    df = DataFrame(1.1 * np.arange(120).reshape((30, 4)), columns=pd.Index(\n\t        list('ABCD'), dtype=object), index=pd.Index([f'i-{i}' for i in\n\t        range(30)], dtype=object))\n\t    df.index.name = 'index'\n\t    reader = lambda x: read_stata(x).set_index('index')\n\t    result = round_trip_pathlib(df.to_stata, reader)\n\t    tm.assert_frame_equal(df, result)\n\t\nTestStata().test_path_pathlib()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_stata.py"}], "instruction": "Functionality: The round_trip_pathlib function is designed to serialize a pandas object (like a DataFrame or a Series) to a file specified by a pathlib.Path object, and then deserialize it back into the original object. This function provides a way to test the round-trip behavior of writing and reading data using specified IO functions.\n\nInputs: \n- writer: A callable IO writing function bound to a pandas object (e.g., DataFrame.to_csv).\n- reader: A callable IO reading function (e.g., pd.read_csv).\n- path: A string representing the file path where the object will be written and then read. This is optional, and if not provided, a default path will be used.\n\nOutputs: \n- pandas object: The original pandas object (DataFrame or Series) that was written to the file and then read back, allowing for verification of data integrity after the round-trip process.", "method_code_mask": "from __future__ import annotations\nimport gzip\nimport io\nimport pathlib\nimport tarfile\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport uuid\nimport zipfile\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas as pd\nfrom pandas._testing.contexts import ensure_clean\nfrom collections.abc import Callable\nfrom pandas._typing import FilePath\nfrom pandas._typing import ReadPickleBuffer\nfrom pandas import DataFrame\nfrom pandas import Series\nimport bz2\nimport lzma\n\n\ndef round_trip_pathlib(writer, reader, path: (str | None)=None): [MASK]\n"}
{"method_name": "skip_if_installed", "full_method_name": "skip_if_installed", "method_path": "../srcdata/Computation/pandas/pandas/util/_test_decorators.py", "method_code": "from __future__ import annotations\nimport locale\nfrom typing import TYPE_CHECKING\nimport pytest\nfrom collections.abc import Callable\nfrom pandas._typing import F\nfrom pandas.compat import IS64\nfrom pandas.compat import is_platform_windows\nfrom pandas.compat._optional import import_optional_dependency\ndef skip_if_installed(package: str) ->pytest.MarkDecorator:\n    \"\"\"\n    Skip a test if a package is installed.\n\n    Parameters\n    ----------\n    package : str\n        The name of the package.\n\n    Returns\n    -------\n    pytest.MarkDecorator\n        a pytest.mark.skipif to use as either a test decorator or a\n        parametrization mark.\n    \"\"\"\n    return pytest.mark.skipif(bool(import_optional_dependency(package,\n        errors='ignore')), reason=f'Skipping because {package} is installed.')", "test_code_list": [{"test_code": "import contextlib\nfrom contextlib import closing\nimport csv\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom io import StringIO\nfrom pathlib import Path\nimport sqlite3\nfrom typing import TYPE_CHECKING\nimport uuid\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import concat\nfrom pandas import date_range\nfrom pandas import isna\nfrom pandas import to_datetime\nfrom pandas import to_timedelta\nimport pandas._testing as tm\nfrom pandas.core.arrays import ArrowStringArray\nfrom pandas.core.arrays import StringArray\nfrom pandas.util.version import Version\nfrom pandas.io import sql\nfrom pandas.io.sql import SQLAlchemyEngine\nfrom pandas.io.sql import SQLDatabase\nfrom pandas.io.sql import SQLiteDatabase\nfrom pandas.io.sql import get_engine\nfrom pandas.io.sql import pandasSQL_builder\nfrom pandas.io.sql import read_sql_query\nfrom pandas.io.sql import read_sql_table\nimport sqlalchemy\nfrom sqlalchemy import Column\nfrom sqlalchemy import Float\nfrom sqlalchemy import MetaData\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy import insert\nfrom sqlalchemy import text\nfrom sqlalchemy import TEXT\nfrom sqlalchemy import Boolean\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import Integer\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import inspect\nfrom sqlalchemy import select\nfrom sqlalchemy.dialects.postgresql import insert\nfrom sqlalchemy.sql import text\nfrom sqlalchemy.dialects.mysql import insert\nfrom sqlalchemy import TIMESTAMP\nfrom sqlalchemy import bindparam\nfrom sqlalchemy.schema import MetaData\nfrom sqlalchemy import BigInteger\nfrom sqlalchemy import Unicode\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.orm import declarative_base\nfrom pandas.arrays import ArrowExtensionArray\nfrom sqlalchemy.orm import sessionmaker\n@skip_if_installed('sqlalchemy')\ndef test_con_unknown_dbapi2_class_does_not_error_without_sql_alchemy_installed(\n    ):\n\n\n    class MockSqliteConnection:\n\n        def __init__(self, *args, **kwargs) ->None:\n            self.conn = sqlite3.Connection(*args, **kwargs)\n\n        def __getattr__(self, name):\n            return getattr(self.conn, name)\n\n        def close(self):\n            self.conn.close()\n    with contextlib.closing(MockSqliteConnection(':memory:')) as conn:\n        with tm.assert_produces_warning(UserWarning, match=\n            'only supports SQLAlchemy'):\n            sql.read_sql('SELECT 1', conn)\n\ntest_con_unknown_dbapi2_class_does_not_error_without_sql_alchemy_installed()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_sql.py"}], "instruction": "Functionality: The function \"skip_if_installed\" is designed to conditionally skip test cases in a testing framework based on whether a specified package is installed. It is useful when certain tests should only run in environments where a specific package is not present, typically to ensure compatibility or to avoid unnecessary test runs when an optional dependency is not required.\n\nInputs: \n- package (str): The name of the package to check for. This is a string that represents the name of the Python package that is being checked for installation.\n\nOutputs:\n- pytest.MarkDecorator: This function returns a pytest decorator, specifically a \"pytest.mark.skipif\" decorator, which can be used as either a test decorator or a parametrization mark. The decorator will skip the test if the specified package is installed in the test environment. The reason for skipping the test is provided in the decorator, indicating that the test is being skipped because the specified package is installed.", "method_code_mask": "from __future__ import annotations\nimport locale\nfrom typing import TYPE_CHECKING\nimport pytest\nfrom collections.abc import Callable\nfrom pandas._typing import F\nfrom pandas.compat import IS64\nfrom pandas.compat import is_platform_windows\nfrom pandas.compat._optional import import_optional_dependency\n\n\ndef skip_if_installed(package: str) ->pytest.MarkDecorator: [MASK]\n"}
{"method_name": "get_engine", "full_method_name": "get_engine", "method_path": "../srcdata/Computation/pandas/pandas/io/sql.py", "method_code": "from __future__ import annotations\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom contextlib import ExitStack\nfrom contextlib import contextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import AbstractMethodError\nfrom pandas.errors import DatabaseError\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.util._validators import check_dtype_backend\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas import get_option\nfrom pandas.core.api import DataFrame\nfrom pandas.core.api import Series\nfrom pandas.core.arrays import ArrowExtensionArray\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.common import maybe_make_list\nfrom pandas.core.internals.construction import convert_object_array\nfrom pandas.core.tools.datetimes import to_datetime\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom sqlalchemy import Table\nfrom sqlalchemy.sql.expression import Select\nfrom sqlalchemy.sql.expression import TextClause\nfrom pandas._typing import DtypeArg\nfrom pandas._typing import DtypeBackend\nfrom pandas._typing import IndexLabel\nfrom pandas import Index\nimport sqlite3\nfrom sqlalchemy.schema import CreateTable\nfrom sqlalchemy import insert\nimport pyarrow as pa\nfrom sqlalchemy import select\nfrom sqlalchemy import Column\nfrom sqlalchemy import PrimaryKeyConstraint\nfrom sqlalchemy.schema import MetaData\nfrom sqlalchemy.types import TIMESTAMP\nfrom sqlalchemy.types import BigInteger\nfrom sqlalchemy.types import Boolean\nfrom sqlalchemy.types import Date\nfrom sqlalchemy.types import DateTime\nfrom sqlalchemy.types import Float\nfrom sqlalchemy.types import Integer\nfrom sqlalchemy.types import SmallInteger\nfrom sqlalchemy.types import Text\nfrom sqlalchemy.types import Time\nfrom sqlalchemy import exc\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.types import TypeEngine\nfrom sqlalchemy import inspect as sqlalchemy_inspect\nfrom sqlalchemy import Numeric\nfrom pandas.io._util import _arrow_dtype_mapping\ndef get_engine(engine: str) ->BaseEngine:\n    \"\"\"return our implementation\"\"\"\n    if engine == 'auto':\n        engine = get_option('io.sql.engine')\n    if engine == 'auto':\n        engine_classes = [SQLAlchemyEngine]\n        error_msgs = ''\n        for engine_class in engine_classes:\n            try:\n                return engine_class()\n            except ImportError as err:\n                error_msgs += '\\n - ' + str(err)\n        raise ImportError(\n            f\"\"\"Unable to find a usable engine; tried using: 'sqlalchemy'.\nA suitable version of sqlalchemy is required for sql I/O support.\nTrying to import the above resulted in these errors:{error_msgs}\"\"\"\n            )\n    if engine == 'sqlalchemy':\n        return SQLAlchemyEngine()\n    raise ValueError(\"engine must be one of 'auto', 'sqlalchemy'\")", "test_code_list": [{"test_code": "import contextlib\nfrom contextlib import closing\nimport csv\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom datetime import timedelta\nfrom io import StringIO\nfrom pathlib import Path\nimport sqlite3\nfrom typing import TYPE_CHECKING\nimport uuid\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nimport pandas.util._test_decorators as td\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import Timestamp\nfrom pandas import concat\nfrom pandas import date_range\nfrom pandas import isna\nfrom pandas import to_datetime\nfrom pandas import to_timedelta\nimport pandas._testing as tm\nfrom pandas.core.arrays import ArrowStringArray\nfrom pandas.core.arrays import StringArray\nfrom pandas.util.version import Version\nfrom pandas.io import sql\nfrom pandas.io.sql import SQLAlchemyEngine\nfrom pandas.io.sql import SQLDatabase\nfrom pandas.io.sql import SQLiteDatabase\nfrom pandas.io.sql import get_engine\nfrom pandas.io.sql import pandasSQL_builder\nfrom pandas.io.sql import read_sql_query\nfrom pandas.io.sql import read_sql_table\nimport sqlalchemy\nfrom sqlalchemy import Column\nfrom sqlalchemy import Float\nfrom sqlalchemy import MetaData\nfrom sqlalchemy import String\nfrom sqlalchemy import Table\nfrom sqlalchemy import insert\nfrom sqlalchemy import text\nfrom sqlalchemy import TEXT\nfrom sqlalchemy import Boolean\nfrom sqlalchemy import DateTime\nfrom sqlalchemy import Integer\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import inspect\nfrom sqlalchemy import select\nfrom sqlalchemy.dialects.postgresql import insert\nfrom sqlalchemy.sql import text\nfrom sqlalchemy.dialects.mysql import insert\nfrom sqlalchemy import TIMESTAMP\nfrom sqlalchemy import bindparam\nfrom sqlalchemy.schema import MetaData\nfrom sqlalchemy import BigInteger\nfrom sqlalchemy import Unicode\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.orm import declarative_base\nfrom pandas.arrays import ArrowExtensionArray\nfrom sqlalchemy.orm import sessionmaker\ndef test_options_get_engine():\n    pytest.importorskip('sqlalchemy')\n    assert isinstance(get_engine('sqlalchemy'), SQLAlchemyEngine)\n    with pd.option_context('io.sql.engine', 'sqlalchemy'):\n        assert isinstance(get_engine('auto'), SQLAlchemyEngine)\n        assert isinstance(get_engine('sqlalchemy'), SQLAlchemyEngine)\n    with pd.option_context('io.sql.engine', 'auto'):\n        assert isinstance(get_engine('auto'), SQLAlchemyEngine)\n        assert isinstance(get_engine('sqlalchemy'), SQLAlchemyEngine)\n\ntest_options_get_engine()\n", "code_start": "from __future__ import annotations\n", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/test_sql.py"}], "instruction": "Functionality: The get_engine function is designed to return an instance of a database engine suitable for SQL I/O operations. It is capable of determining the appropriate engine based on the input argument or the default settings defined in the pandas library. This function is essential for establishing connections to databases and executing SQL queries.\n\nInputs: \n- engine: str\n    A string representing the type of database engine to be returned. The possible values include 'auto' (to automatically select based on the pandas default settings or installed libraries), 'sqlalchemy' (to explicitly use the SQLAlchemy engine).\n\nOutputs:\n- BaseEngine\n    Returns an instance of a database engine subclass (e.g., SQLAlchemyEngine) that can be used to interact with databases. If the input is 'auto', the function will attempt to create an engine based on available libraries, prioritizing 'sqlalchemy'. If 'sqlalchemy' is specified, a SQLAlchemyEngine instance is returned. If an unrecognized engine type is provided, or if the necessary library is not installed, a ValueError or ImportError will be raised.", "method_code_mask": "from __future__ import annotations\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom contextlib import ExitStack\nfrom contextlib import contextmanager\nfrom datetime import date\nfrom datetime import datetime\nfrom datetime import time\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import AbstractMethodError\nfrom pandas.errors import DatabaseError\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.util._validators import check_dtype_backend\nfrom pandas.core.dtypes.common import is_dict_like\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.missing import isna\nfrom pandas import get_option\nfrom pandas.core.api import DataFrame\nfrom pandas.core.api import Series\nfrom pandas.core.arrays import ArrowExtensionArray\nfrom pandas.core.base import PandasObject\nimport pandas.core.common as com\nfrom pandas.core.common import maybe_make_list\nfrom pandas.core.internals.construction import convert_object_array\nfrom pandas.core.tools.datetimes import to_datetime\nfrom collections.abc import Callable\nfrom collections.abc import Generator\nfrom collections.abc import Iterator\nfrom collections.abc import Mapping\nfrom sqlalchemy import Table\nfrom sqlalchemy.sql.expression import Select\nfrom sqlalchemy.sql.expression import TextClause\nfrom pandas._typing import DtypeArg\nfrom pandas._typing import DtypeBackend\nfrom pandas._typing import IndexLabel\nfrom pandas import Index\nimport sqlite3\nfrom sqlalchemy.schema import CreateTable\nfrom sqlalchemy import insert\nimport pyarrow as pa\nfrom sqlalchemy import select\nfrom sqlalchemy import Column\nfrom sqlalchemy import PrimaryKeyConstraint\nfrom sqlalchemy.schema import MetaData\nfrom sqlalchemy.types import TIMESTAMP\nfrom sqlalchemy.types import BigInteger\nfrom sqlalchemy.types import Boolean\nfrom sqlalchemy.types import Date\nfrom sqlalchemy.types import DateTime\nfrom sqlalchemy.types import Float\nfrom sqlalchemy.types import Integer\nfrom sqlalchemy.types import SmallInteger\nfrom sqlalchemy.types import Text\nfrom sqlalchemy.types import Time\nfrom sqlalchemy import exc\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.types import TypeEngine\nfrom sqlalchemy import inspect as sqlalchemy_inspect\nfrom sqlalchemy import Numeric\nfrom pandas.io._util import _arrow_dtype_mapping\n\n\ndef get_engine(engine: str) ->BaseEngine: [MASK]\n"}
{"method_name": "build_table_schema", "full_method_name": "build_table_schema", "method_path": "../srcdata/Computation/pandas/pandas/io/json/_table_schema.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import timezones\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas import DataFrame\nimport pandas.core.common as com\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import JSONSerializable\nfrom pandas import Series\nfrom pandas.core.indexes.multi import MultiIndex\ndef build_table_schema(data: (DataFrame | Series), index: bool=True,\n    primary_key: (bool | None)=None, version: bool=True) ->dict[str,\n    JSONSerializable]:\n    \"\"\"\n    Create a Table schema from ``data``.\n\n    Parameters\n    ----------\n    data : Series, DataFrame\n    index : bool, default True\n        Whether to include ``data.index`` in the schema.\n    primary_key : bool or None, default True\n        Column names to designate as the primary key.\n        The default `None` will set `'primaryKey'` to the index\n        level or levels if the index is unique.\n    version : bool, default True\n        Whether to include a field `pandas_version` with the version\n        of pandas that last revised the table schema. This version\n        can be different from the installed pandas version.\n\n    Returns\n    -------\n    dict\n\n    Notes\n    -----\n    See `Table Schema\n    <https://pandas.pydata.org/docs/user_guide/io.html#table-schema>`__ for\n    conversion types.\n    Timedeltas as converted to ISO8601 duration format with\n    9 decimal places after the seconds field for nanosecond precision.\n\n    Categoricals are converted to the `any` dtype, and use the `enum` field\n    constraint to list the allowed values. The `ordered` attribute is included\n    in an `ordered` field.\n\n    Examples\n    --------\n    >>> from pandas.io.json._table_schema import build_table_schema\n    >>> df = pd.DataFrame(\n    ...     {'A': [1, 2, 3],\n    ...      'B': ['a', 'b', 'c'],\n    ...      'C': pd.date_range('2016-01-01', freq='D', periods=3),\n    ...      }, index=pd.Index(range(3), name='idx'))\n    >>> build_table_schema(df)\n    {'fields': [{'name': 'idx', 'type': 'integer'}, {'name': 'A', 'type': 'integer'}, {'name': 'B', 'type': 'string'}, {'name': 'C', 'type': 'datetime'}], 'primaryKey': ['idx'], 'pandas_version': '1.4.0'}\n    \"\"\"\n    if index is True:\n        data = set_default_names(data)\n    schema: dict[str, Any] = {}\n    fields = []\n    if index:\n        if data.index.nlevels > 1:\n            data.index = cast('MultiIndex', data.index)\n            for level, name in zip(data.index.levels, data.index.names):\n                new_field = convert_pandas_type_to_json_field(level)\n                new_field['name'] = name\n                fields.append(new_field)\n        else:\n            fields.append(convert_pandas_type_to_json_field(data.index))\n    if data.ndim > 1:\n        for column, s in data.items():\n            fields.append(convert_pandas_type_to_json_field(s))\n    else:\n        fields.append(convert_pandas_type_to_json_field(data))\n    schema['fields'] = fields\n    if index and data.index.is_unique and primary_key is None:\n        if data.index.nlevels == 1:\n            schema['primaryKey'] = [data.index.name]\n        else:\n            schema['primaryKey'] = data.index.names\n    elif primary_key is not None:\n        schema['primaryKey'] = primary_key\n    if version:\n        schema['pandas_version'] = TABLE_SCHEMA_VERSION\n    return schema", "test_code_list": [{"test_code": "from collections import OrderedDict\nfrom io import StringIO\nimport json\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\nfrom pandas.io.json._table_schema import convert_json_field_to_pandas_type\nfrom pandas.io.json._table_schema import convert_pandas_type_to_json_field\nfrom pandas.io.json._table_schema import set_default_names\n\nclass TestBuildSchema():\n\tdef test_series(self):\n\t    s = pd.Series([1, 2, 3], name='foo')\n\t    result = build_table_schema(s, version=False)\n\t    expected = {'fields': [{'name': 'index', 'type': 'integer'}, {'name':\n\t        'foo', 'type': 'integer'}], 'primaryKey': ['index']}\n\t    assert result == expected\n\t    result = build_table_schema(s)\n\t    assert 'pandas_version' in result\n\t\nTestBuildSchema().test_series()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema.py"}, {"test_code": "from collections import OrderedDict\nfrom io import StringIO\nimport json\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\nfrom pandas.io.json._table_schema import convert_json_field_to_pandas_type\nfrom pandas.io.json._table_schema import convert_pandas_type_to_json_field\nfrom pandas.io.json._table_schema import set_default_names\n\nclass TestBuildSchema():\n\tdef test_series_unnamed(self):\n\t    result = build_table_schema(pd.Series([1, 2, 3]), version=False)\n\t    expected = {'fields': [{'name': 'index', 'type': 'integer'}, {'name':\n\t        'values', 'type': 'integer'}], 'primaryKey': ['index']}\n\t    assert result == expected\n\t\nTestBuildSchema().test_series_unnamed()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema.py"}, {"test_code": "from collections import OrderedDict\nfrom io import StringIO\nimport json\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\nfrom pandas.io.json._table_schema import convert_json_field_to_pandas_type\nfrom pandas.io.json._table_schema import convert_pandas_type_to_json_field\nfrom pandas.io.json._table_schema import set_default_names\n\nclass TestTableOrient():\n\tdef test_mi_falsey_name(self):\n\t    df = DataFrame(np.random.default_rng(2).standard_normal((4, 4)), index=\n\t        pd.MultiIndex.from_product([('A', 'B'), ('a', 'b')]))\n\t    result = [x['name'] for x in build_table_schema(df)['fields']]\n\t    assert result == ['level_0', 'level_1', 0, 1, 2, 3]\n\t\nTestTableOrient().test_mi_falsey_name()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema.py"}, {"test_code": "from collections import OrderedDict\nimport datetime as dt\nimport decimal\nfrom io import StringIO\nimport json\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import array\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays.integer import Int64Dtype\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.series import Series\nfrom pandas.tests.extension.date import DateArray\nfrom pandas.tests.extension.date import DateDtype\nfrom pandas.tests.extension.decimal.array import DecimalArray\nfrom pandas.tests.extension.decimal.array import DecimalDtype\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\n\nclass TestBuildSchema():\n\tdef test_build_table_schema(self):\n\t    df = DataFrame({'A': DateArray([dt.date(2021, 10, 10)]), 'B':\n\t        DecimalArray([decimal.Decimal(10)]), 'C': array(['pandas'], dtype=\n\t        'string'), 'D': array([10], dtype='Int64')})\n\t    result = build_table_schema(df, version=False)\n\t    expected = {'fields': [{'name': 'index', 'type': 'integer'}, {'name':\n\t        'A', 'type': 'any', 'extDtype': 'DateDtype'}, {'name': 'B', 'type':\n\t        'number', 'extDtype': 'decimal'}, {'name': 'C', 'type': 'any',\n\t        'extDtype': 'string'}, {'name': 'D', 'type': 'integer', 'extDtype':\n\t        'Int64'}], 'primaryKey': ['index']}\n\t    assert result == expected\n\t    result = build_table_schema(df)\n\t    assert 'pandas_version' in result\n\t\nTestBuildSchema().test_build_table_schema()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema_ext_dtype.py"}], "instruction": "Functionality: \nThe build_table_schema function is designed to create a JSON-serializable table schema from a given DataFrame or Series. This schema is useful for defining the structure of data for interoperability and data exchange purposes. The function can include index information, designate primary keys, and note the last revision version of pandas used on the schema.\n\nInputs: \n1. data: DataFrame | Series - The pandas DataFrame or Series from which the table schema will be created.\n2. index: bool = True - Determines whether the index of the data should be included in the schema.\n3. primary_key: bool | None = None - Specifies column names to be designated as the primary key. If None and the index is unique, the index is used as the primary key.\n4. version: bool = True - Determines whether to include a field 'pandas_version' with the version of pandas that last revised the table schema.\n\nOutputs: \n1. dict[str, JSONSerializable] - A dictionary representing the table schema that is JSON-serializable. The schema includes fields definitions, primary key information, and optionally, the pandas version.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import timezones\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas import DataFrame\nimport pandas.core.common as com\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import JSONSerializable\nfrom pandas import Series\nfrom pandas.core.indexes.multi import MultiIndex\n\n\ndef build_table_schema(data: (DataFrame | Series), index: bool=True,\n    primary_key: (bool | None)=None, version: bool=True) ->dict[str,\n    JSONSerializable]: [MASK]\n"}
{"method_name": "as_json_table_type", "full_method_name": "as_json_table_type", "method_path": "../srcdata/Computation/pandas/pandas/io/json/_table_schema.py", "method_code": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import timezones\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas import DataFrame\nimport pandas.core.common as com\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import JSONSerializable\nfrom pandas import Series\nfrom pandas.core.indexes.multi import MultiIndex\ndef as_json_table_type(x: DtypeObj) ->str:\n    \"\"\"\n    Convert a NumPy / pandas type to its corresponding json_table.\n\n    Parameters\n    ----------\n    x : np.dtype or ExtensionDtype\n\n    Returns\n    -------\n    str\n        the Table Schema data types\n\n    Notes\n    -----\n    This table shows the relationship between NumPy / pandas dtypes,\n    and Table Schema dtypes.\n\n    ==============  =================\n    Pandas type     Table Schema type\n    ==============  =================\n    int64           integer\n    float64         number\n    bool            boolean\n    datetime64[ns]  datetime\n    timedelta64[ns] duration\n    object          str\n    categorical     any\n    =============== =================\n    \"\"\"\n    if is_integer_dtype(x):\n        return 'integer'\n    elif is_bool_dtype(x):\n        return 'boolean'\n    elif is_numeric_dtype(x):\n        return 'number'\n    elif lib.is_np_dtype(x, 'M') or isinstance(x, (DatetimeTZDtype,\n        PeriodDtype)):\n        return 'datetime'\n    elif lib.is_np_dtype(x, 'm'):\n        return 'duration'\n    elif isinstance(x, ExtensionDtype):\n        return 'any'\n    elif is_string_dtype(x):\n        return 'string'\n    else:\n        return 'any'", "test_code_list": [{"test_code": "from collections import OrderedDict\nfrom io import StringIO\nimport json\nimport numpy as np\nimport pytest\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nimport pandas as pd\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\nfrom pandas.io.json._table_schema import convert_json_field_to_pandas_type\nfrom pandas.io.json._table_schema import convert_pandas_type_to_json_field\nfrom pandas.io.json._table_schema import set_default_names\n\nclass TestTableSchemaType():\n\tdef test_as_json_table_type_categorical_dtypes(self):\n\t    assert as_json_table_type(pd.Categorical(['a']).dtype) == 'any'\n\t    assert as_json_table_type(CategoricalDtype()) == 'any'\n\t\nTestTableSchemaType().test_as_json_table_type_categorical_dtypes()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema.py"}, {"test_code": "from collections import OrderedDict\nimport datetime as dt\nimport decimal\nfrom io import StringIO\nimport json\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import array\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays.integer import Int64Dtype\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.series import Series\nfrom pandas.tests.extension.date import DateArray\nfrom pandas.tests.extension.date import DateDtype\nfrom pandas.tests.extension.decimal.array import DecimalArray\nfrom pandas.tests.extension.decimal.array import DecimalDtype\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\n\nclass TestTableSchemaType():\n\tdef test_as_json_table_type_ext_date_dtype(self):\n\t    assert as_json_table_type(DateDtype()) == 'any'\n\t\nTestTableSchemaType().test_as_json_table_type_ext_date_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema_ext_dtype.py"}, {"test_code": "from collections import OrderedDict\nimport datetime as dt\nimport decimal\nfrom io import StringIO\nimport json\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import array\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays.integer import Int64Dtype\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.series import Series\nfrom pandas.tests.extension.date import DateArray\nfrom pandas.tests.extension.date import DateDtype\nfrom pandas.tests.extension.decimal.array import DecimalArray\nfrom pandas.tests.extension.decimal.array import DecimalDtype\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\n\nclass TestTableSchemaType():\n\tdef test_as_json_table_type_ext_decimal_dtype(self):\n\t    assert as_json_table_type(DecimalDtype()) == 'number'\n\t\nTestTableSchemaType().test_as_json_table_type_ext_decimal_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema_ext_dtype.py"}, {"test_code": "from collections import OrderedDict\nimport datetime as dt\nimport decimal\nfrom io import StringIO\nimport json\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import array\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays.integer import Int64Dtype\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.series import Series\nfrom pandas.tests.extension.date import DateArray\nfrom pandas.tests.extension.date import DateDtype\nfrom pandas.tests.extension.decimal.array import DecimalArray\nfrom pandas.tests.extension.decimal.array import DecimalDtype\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\n\nclass TestTableSchemaType():\n\tdef test_as_json_table_type_ext_string_dtype(self):\n\t    assert as_json_table_type(StringDtype()) == 'any'\n\t\nTestTableSchemaType().test_as_json_table_type_ext_string_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema_ext_dtype.py"}, {"test_code": "from collections import OrderedDict\nimport datetime as dt\nimport decimal\nfrom io import StringIO\nimport json\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import array\nfrom pandas import read_json\nimport pandas._testing as tm\nfrom pandas.core.arrays.integer import Int64Dtype\nfrom pandas.core.arrays.string_ import StringDtype\nfrom pandas.core.series import Series\nfrom pandas.tests.extension.date import DateArray\nfrom pandas.tests.extension.date import DateDtype\nfrom pandas.tests.extension.decimal.array import DecimalArray\nfrom pandas.tests.extension.decimal.array import DecimalDtype\nfrom pandas.io.json._table_schema import as_json_table_type\nfrom pandas.io.json._table_schema import build_table_schema\n\nclass TestTableSchemaType():\n\tdef test_as_json_table_type_ext_integer_dtype(self):\n\t    assert as_json_table_type(Int64Dtype()) == 'integer'\n\t\nTestTableSchemaType().test_as_json_table_type_ext_integer_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/json/test_json_table_schema_ext_dtype.py"}], "instruction": "Functionality: The function 'as_json_table_type' is designed to convert a given NumPy or pandas data type into its corresponding data type as recognized by the JSON Table Schema standard. This function serves as a bridge between the data types used in data analysis and those used in JSON-based data representation.\n\nInputs: \nx : DtypeObj\n    The input parameter 'x' is a data type object from either NumPy or pandas. This could be any of the following types: np.dtype or ExtensionDtype, which includes but is not limited to int64, float64, bool, datetime64[ns], timedelta64[ns], object, categorical.\n\nOutputs: \nstr\n    The function returns a string representing the JSON Table Schema data type corresponding to the input 'x'. The mapping includes 'integer' for int64, 'number' for float64, 'boolean' for bool, 'datetime' for datetime64[ns] and other datetime-related types, 'duration' for timedelta64[ns], 'any' for ExtensionDtypes, and 'string' for object types. If the input 'x' does not match any of these known mappings, the function will default to returning 'any'.", "method_code_mask": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import cast\nimport warnings\nfrom pandas._libs import lib\nfrom pandas._libs.tslibs import timezones\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.base import _registry as registry\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_integer_dtype\nfrom pandas.core.dtypes.common import is_numeric_dtype\nfrom pandas.core.dtypes.common import is_string_dtype\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.dtypes.dtypes import DatetimeTZDtype\nfrom pandas.core.dtypes.dtypes import ExtensionDtype\nfrom pandas.core.dtypes.dtypes import PeriodDtype\nfrom pandas import DataFrame\nimport pandas.core.common as com\nfrom pandas.tseries.frequencies import to_offset\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import JSONSerializable\nfrom pandas import Series\nfrom pandas.core.indexes.multi import MultiIndex\n\n\ndef as_json_table_type(x: DtypeObj) ->str: [MASK]\n"}
{"method_name": "df", "full_method_name": "df.style._translate", "method_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py", "method_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n@pytest.fixture\ndef df():\n    df = DataFrame({'A': [0, 1], 'B': np.random.default_rng(2).\n        standard_normal(2)})\n    return df", "test_code_list": [{"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_render_trimming_mi():\n    midx = MultiIndex.from_product([[1, 2], [1, 2, 3]])\n    df = DataFrame(np.arange(36).reshape(6, 6), columns=midx, index=midx)\n    with option_context('styler.render.max_elements', 4):\n        ctx = df.style._translate(True, True)\n    assert len(ctx['body'][0]) == 5\n    assert {'attributes': 'rowspan=\"2\"'}.items() <= ctx['body'][0][0].items()\n    assert {'class': 'data row0 col_trim'}.items() <= ctx['body'][0][4].items()\n    assert {'class': 'data row_trim col_trim'}.items() <= ctx['body'][2][4\n        ].items()\n    assert len(ctx['body']) == 3\n\ntest_render_trimming_mi()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_hiding_headers_over_index_no_sparsify():\n    midx = MultiIndex.from_product([[1, 2], ['a', 'a', 'b']])\n    df = DataFrame(9, index=midx, columns=[0])\n    ctx = df.style._translate(False, False)\n    assert len(ctx['body']) == 6\n    ctx = df.style.hide((1, 'a'), axis=0)._translate(False, False)\n    assert len(ctx['body']) == 4\n    assert 'row2' in ctx['body'][0][0]['class']\n\ntest_hiding_headers_over_index_no_sparsify()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_hiding_headers_over_columns_no_sparsify():\n    midx = MultiIndex.from_product([[1, 2], ['a', 'a', 'b']])\n    df = DataFrame(9, columns=midx, index=[0])\n    ctx = df.style._translate(False, False)\n    for ix in [(0, 1), (0, 2), (1, 1), (1, 2)]:\n        assert ctx['head'][ix[0]][ix[1]]['is_visible'] is True\n    ctx = df.style.hide((1, 'a'), axis='columns')._translate(False, False)\n    for ix in [(0, 1), (0, 2), (1, 1), (1, 2)]:\n        assert ctx['head'][ix[0]][ix[1]]['is_visible'] is False\n\ntest_hiding_headers_over_columns_no_sparsify()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_hide_multiindex(self):\n\t    df = DataFrame({'A': [1, 2], 'B': [1, 2]}, index=MultiIndex.from_arrays\n\t        ([['a', 'a'], [0, 1]], names=['idx_level_0', 'idx_level_1']))\n\t    ctx1 = df.style._translate(True, True)\n\t    assert ctx1['body'][0][0]['is_visible']\n\t    assert ctx1['body'][0][1]['is_visible']\n\t    assert len(ctx1['head'][0]) == 4\n\t    ctx2 = df.style.hide(axis='index')._translate(True, True)\n\t    assert not ctx2['body'][0][0]['is_visible']\n\t    assert not ctx2['body'][0][1]['is_visible']\n\t    assert len(ctx2['head'][0]) == 3\n\t    assert not ctx2['head'][0][0]['is_visible']\n\t\nTestStyler().test_hide_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_hide_columns_index_mult_levels(self):\n\t    i1 = MultiIndex.from_arrays([['a', 'a'], [0, 1]], names=['idx_level_0',\n\t        'idx_level_1'])\n\t    i2 = MultiIndex.from_arrays([['b', 'b'], [0, 1]], names=['col_level_0',\n\t        'col_level_1'])\n\t    df = DataFrame([[1, 2], [3, 4]], index=i1, columns=i2)\n\t    ctx = df.style._translate(True, True)\n\t    assert ctx['head'][0][2]['is_visible']\n\t    assert ctx['head'][1][2]['is_visible']\n\t    assert ctx['head'][1][3]['display_value'] == '1'\n\t    assert ctx['body'][0][0]['is_visible']\n\t    assert ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][2]['display_value'] == '3'\n\t    assert ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][3]['display_value'] == '4'\n\t    ctx = df.style.hide('b', axis='columns')._translate(True, True)\n\t    assert not ctx['head'][0][2]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][0][0]['is_visible']\n\t    ctx = df.style.hide([('b', 0)], axis='columns')._translate(True, True)\n\t    assert not ctx['head'][0][2]['is_visible']\n\t    assert ctx['head'][0][3]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][3]['display_value'] == '4'\n\t    ctx = df.style.hide([('b', 1)], axis=1).hide(axis=0)._translate(True, True)\n\t    assert not ctx['body'][0][0]['is_visible']\n\t    assert len(ctx['head'][0]) == 3\n\t    assert ctx['head'][0][1]['is_visible']\n\t    assert ctx['head'][1][1]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][2]['display_value'] == '3'\n\t    ctx = df.style.hide('a', axis='index')._translate(True, True)\n\t    assert ctx['body'] == []\n\t    ctx = df.style.hide(('a', 0), axis='index')._translate(True, True)\n\t    for i in [0, 1, 2, 3]:\n\t        assert 'row1' in ctx['body'][0][i]['class']\n\t        assert ctx['body'][0][i]['is_visible']\n\t\nTestStyler().test_hide_columns_index_mult_levels()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_render_empty_mi():\n    df = DataFrame(index=MultiIndex.from_product([['A'], [0, 1]], names=[\n        None, 'one']))\n    expected = dedent(\n        \"\"\"    >\n      <thead>\n        <tr>\n          <th class=\"index_name level0\" >&nbsp;</th>\n          <th class=\"index_name level1\" >one</th>\n        </tr>\n      </thead>\n    \"\"\"\n        )\n    assert expected in df.style.to_html()\n\ntest_render_empty_mi()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_unique_id(self):\n\t    df = DataFrame({'a': [1, 3, 5, 6], 'b': [2, 4, 12, 21]})\n\t    result = df.style.to_html(uuid='test')\n\t    assert 'test' in result\n\t    ids = re.findall('id=\"(.*?)\"', result)\n\t    assert np.unique(ids).size == len(ids)\n\t\nTestStyler().test_unique_id()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_hiding_headers_over_index_no_sparsify():\n    midx = MultiIndex.from_product([[1, 2], ['a', 'a', 'b']])\n    df = DataFrame(9, index=midx, columns=[0])\n    ctx = df.style._translate(False, False)\n    assert len(ctx['body']) == 6\n    ctx = df.style.hide((1, 'a'), axis=0)._translate(False, False)\n    assert len(ctx['body']) == 4\n    assert 'row2' in ctx['body'][0][0]['class']\n\ntest_hiding_headers_over_index_no_sparsify()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_hiding_headers_over_columns_no_sparsify():\n    midx = MultiIndex.from_product([[1, 2], ['a', 'a', 'b']])\n    df = DataFrame(9, columns=midx, index=[0])\n    ctx = df.style._translate(False, False)\n    for ix in [(0, 1), (0, 2), (1, 1), (1, 2)]:\n        assert ctx['head'][ix[0]][ix[1]]['is_visible'] is True\n    ctx = df.style.hide((1, 'a'), axis='columns')._translate(False, False)\n    for ix in [(0, 1), (0, 2), (1, 1), (1, 2)]:\n        assert ctx['head'][ix[0]][ix[1]]['is_visible'] is False\n\ntest_hiding_headers_over_columns_no_sparsify()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_row_trimming_hide_index():\n    df = DataFrame([[1], [2], [3], [4], [5]])\n    with option_context('styler.render.max_rows', 2):\n        ctx = df.style.hide([0, 1], axis='index')._translate(True, True)\n    assert len(ctx['body']) == 3\n    for r, val in enumerate(['3', '4', '...']):\n        assert ctx['body'][r][1]['display_value'] == val\n\ntest_row_trimming_hide_index()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_row_trimming_hide_index_mi():\n    df = DataFrame([[1], [2], [3], [4], [5]])\n    df.index = MultiIndex.from_product([[0], [0, 1, 2, 3, 4]])\n    with option_context('styler.render.max_rows', 2):\n        ctx = df.style.hide([(0, 0), (0, 1)], axis='index')._translate(True,\n            True)\n    assert len(ctx['body']) == 3\n    assert {'value': 0, 'attributes': 'rowspan=\"2\"', 'is_visible': True}.items(\n        ) <= ctx['body'][0][0].items()\n    assert {'value': 0, 'attributes': '', 'is_visible': False}.items() <= ctx[\n        'body'][1][0].items()\n    assert {'value': '...', 'is_visible': True}.items() <= ctx['body'][2][0\n        ].items()\n    for r, val in enumerate(['2', '3', '...']):\n        assert ctx['body'][r][1]['display_value'] == val\n    for r, val in enumerate(['3', '4', '...']):\n        assert ctx['body'][r][2]['display_value'] == val\n\ntest_row_trimming_hide_index_mi()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_col_trimming_hide_columns():\n    df = DataFrame([[1, 2, 3, 4, 5]])\n    with option_context('styler.render.max_columns', 2):\n        ctx = df.style.hide([0, 1], axis='columns')._translate(True, True)\n    assert len(ctx['head'][0]) == 6\n    for c, vals in enumerate([(1, False), (2, True), (3, True), ('...', True)]\n        ):\n        assert ctx['head'][0][c + 2]['value'] == vals[0]\n        assert ctx['head'][0][c + 2]['is_visible'] == vals[1]\n    assert len(ctx['body'][0]) == 6\n\ntest_col_trimming_hide_columns()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_hide_multiindex(self):\n\t    df = DataFrame({'A': [1, 2], 'B': [1, 2]}, index=MultiIndex.from_arrays\n\t        ([['a', 'a'], [0, 1]], names=['idx_level_0', 'idx_level_1']))\n\t    ctx1 = df.style._translate(True, True)\n\t    assert ctx1['body'][0][0]['is_visible']\n\t    assert ctx1['body'][0][1]['is_visible']\n\t    assert len(ctx1['head'][0]) == 4\n\t    ctx2 = df.style.hide(axis='index')._translate(True, True)\n\t    assert not ctx2['body'][0][0]['is_visible']\n\t    assert not ctx2['body'][0][1]['is_visible']\n\t    assert len(ctx2['head'][0]) == 3\n\t    assert not ctx2['head'][0][0]['is_visible']\n\t\nTestStyler().test_hide_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_hide_columns_index_mult_levels(self):\n\t    i1 = MultiIndex.from_arrays([['a', 'a'], [0, 1]], names=['idx_level_0',\n\t        'idx_level_1'])\n\t    i2 = MultiIndex.from_arrays([['b', 'b'], [0, 1]], names=['col_level_0',\n\t        'col_level_1'])\n\t    df = DataFrame([[1, 2], [3, 4]], index=i1, columns=i2)\n\t    ctx = df.style._translate(True, True)\n\t    assert ctx['head'][0][2]['is_visible']\n\t    assert ctx['head'][1][2]['is_visible']\n\t    assert ctx['head'][1][3]['display_value'] == '1'\n\t    assert ctx['body'][0][0]['is_visible']\n\t    assert ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][2]['display_value'] == '3'\n\t    assert ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][3]['display_value'] == '4'\n\t    ctx = df.style.hide('b', axis='columns')._translate(True, True)\n\t    assert not ctx['head'][0][2]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][0][0]['is_visible']\n\t    ctx = df.style.hide([('b', 0)], axis='columns')._translate(True, True)\n\t    assert not ctx['head'][0][2]['is_visible']\n\t    assert ctx['head'][0][3]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][3]['display_value'] == '4'\n\t    ctx = df.style.hide([('b', 1)], axis=1).hide(axis=0)._translate(True, True)\n\t    assert not ctx['body'][0][0]['is_visible']\n\t    assert len(ctx['head'][0]) == 3\n\t    assert ctx['head'][0][1]['is_visible']\n\t    assert ctx['head'][1][1]['is_visible']\n\t    assert not ctx['head'][1][2]['is_visible']\n\t    assert not ctx['body'][1][3]['is_visible']\n\t    assert ctx['body'][1][2]['is_visible']\n\t    assert ctx['body'][1][2]['display_value'] == '3'\n\t    ctx = df.style.hide('a', axis='index')._translate(True, True)\n\t    assert ctx['body'] == []\n\t    ctx = df.style.hide(('a', 0), axis='index')._translate(True, True)\n\t    for i in [0, 1, 2, 3]:\n\t        assert 'row1' in ctx['body'][0][i]['class']\n\t        assert ctx['body'][0][i]['is_visible']\n\t\nTestStyler().test_hide_columns_index_mult_levels()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_set_properties(self):\n\t    df = DataFrame({'A': [0, 1]})\n\t    result = df.style.set_properties(color='white', size='10px')._compute().ctx\n\t    v = [('color', 'white'), ('size', '10px')]\n\t    expected = {(0, 0): v, (1, 0): v}\n\t    assert result.keys() == expected.keys()\n\t    for v1, v2 in zip(result.values(), expected.values()):\n\t        assert sorted(v1) == sorted(v2)\n\t\nTestStyler().test_set_properties()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_set_properties_subset(self):\n\t    df = DataFrame({'A': [0, 1]})\n\t    result = df.style.set_properties(subset=IndexSlice[0, 'A'], color='white'\n\t        )._compute().ctx\n\t    expected = {(0, 0): [('color', 'white')]}\n\t    assert result == expected\n\t\nTestStyler().test_set_properties_subset()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_index_name(self):\n\t    df = DataFrame({'A': [1, 2], 'B': [3, 4], 'C': [5, 6]})\n\t    result = df.set_index('A').style._translate(True, True)\n\t    expected = {'class': 'index_name level0', 'type': 'th', 'value': 'A',\n\t        'is_visible': True, 'display_value': 'A'}\n\t    assert expected.items() <= result['head'][1][0].items()\n\t\nTestStyler().test_index_name()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_apply_axis(self):\n\t    df = DataFrame({'A': [0, 0], 'B': [1, 1]})\n\t    f = lambda x: [f'val: {x.max()}' for v in x]\n\t    result = df.style.apply(f, axis=1)\n\t    assert len(result._todo) == 1\n\t    assert len(result.ctx) == 0\n\t    result._compute()\n\t    expected = {(0, 0): [('val', '1')], (0, 1): [('val', '1')], (1, 0): [(\n\t        'val', '1')], (1, 1): [('val', '1')]}\n\t    assert result.ctx == expected\n\t    result = df.style.apply(f, axis=0)\n\t    expected = {(0, 0): [('val', '0')], (0, 1): [('val', '1')], (1, 0): [(\n\t        'val', '0')], (1, 1): [('val', '1')]}\n\t    result._compute()\n\t    assert result.ctx == expected\n\t    result = df.style.apply(f)\n\t    result._compute()\n\t    assert result.ctx == expected\n\t\nTestStyler().test_apply_axis()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_chaining_table_styles(self):\n\t    df = DataFrame(data=[[0, 1], [1, 2]], columns=['A', 'B'])\n\t    styler = df.style.set_table_styles([{'selector': '', 'props': [(\n\t        'background-color', 'yellow')]}]).set_table_styles([{'selector':\n\t        '.col0', 'props': [('background-color', 'blue')]}], overwrite=False)\n\t    assert len(styler.table_styles) == 2\n\t\nTestStyler().test_chaining_table_styles()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}], "instruction": "Functionality: The df.style._translate function is part of the pandas library and is responsible for applying styling to a DataFrame based on specified rules. This function takes the DataFrame and styling rules as input and outputs a styled representation of the DataFrame. It is an internal function that is typically not called directly by users but is used to generate styled outputs for display or export.\n\nInputs: \n- df: A pandas DataFrame instance that is to be styled. This DataFrame should contain the data that the styling rules will be applied to.\n- style_rules: An optional argument that can be a list of styling rules to apply to the DataFrame. These rules can include, but are not limited to, background color changes, text formatting, and conditional formatting.\n\nOutputs:\n- A Styler object: This is the output of the function, which is a styled representation of the input DataFrame. The Styler object contains the formatted DataFrame and information about how each cell should be displayed, such as colors, fonts, and other CSS styling attributes. This object can then be rendered to various formats, including HTML for web display or PDF for printing.", "method_code_mask": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\n\n@pytest.fixture\ndef df(): [MASK]\n"}
{"method_name": "styler", "full_method_name": "styler.to_html", "method_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py", "method_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n@pytest.fixture\ndef styler(df):\n    df = DataFrame({'A': [0, 1], 'B': np.random.default_rng(2).\n        standard_normal(2)})\n    return Styler(df)", "test_code_list": [{"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_no_cell_ids(self):\n\t    df = DataFrame(data=[[0]])\n\t    styler = Styler(df, uuid='_', cell_ids=False)\n\t    styler.to_html()\n\t    s = styler.to_html()\n\t    assert s.find('<td class=\"data row0 col0\" >') != -1\n\t\nTestStyler().test_no_cell_ids()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}], "instruction": "Functionality: The styler.to_html function generates an HTML representation of a pandas DataFrame, styled according to the properties and methods applied to a Styler object. This function is crucial for visualizing data in web applications or when sharing data analysis results in a web-based format.\n\nInputs: The function does not directly take any input arguments when called on a Styler object. However, the style and formatting of the DataFrame are determined by methods and properties applied prior to calling to_html. These may include methods like set_caption, set_table_styles, set_properties, and others that alter the appearance of the DataFrame.\n\nOutputs: The function returns a string containing the HTML code that represents the styled DataFrame. This HTML code can then be used in web pages or other HTML documents to display the DataFrame with the applied styles.", "method_code_mask": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\n\n@pytest.fixture\ndef styler(df): [MASK]\n"}
{"method_name": "_get_level_lengths", "full_method_name": "_get_level_lengths", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef _get_level_lengths(index: Index, sparsify: bool, max_index: int,\n    hidden_elements: (Sequence[int] | None)=None):\n    \"\"\"\n    Given an index, find the level length for each element.\n\n    Parameters\n    ----------\n    index : Index\n        Index or columns to determine lengths of each element\n    sparsify : bool\n        Whether to hide or show each distinct element in a MultiIndex\n    max_index : int\n        The maximum number of elements to analyse along the index due to trimming\n    hidden_elements : sequence of int\n        Index positions of elements hidden from display in the index affecting\n        length\n\n    Returns\n    -------\n    Dict :\n        Result is a dictionary of (level, initial_position): span\n    \"\"\"\n    if isinstance(index, MultiIndex):\n        levels = index._format_multi(sparsify=lib.no_default, include_names\n            =False)\n    else:\n        levels = index._format_flat(include_name=False)\n    if hidden_elements is None:\n        hidden_elements = []\n    lengths = {}\n    if not isinstance(index, MultiIndex):\n        for i, value in enumerate(levels):\n            if i not in hidden_elements:\n                lengths[0, i] = 1\n        return lengths\n    for i, lvl in enumerate(levels):\n        visible_row_count = 0\n        for j, row in enumerate(lvl):\n            if visible_row_count > max_index:\n                break\n            if not sparsify:\n                if j not in hidden_elements:\n                    lengths[i, j] = 1\n                    visible_row_count += 1\n            elif row is not lib.no_default and j not in hidden_elements:\n                last_label = j\n                lengths[i, last_label] = 1\n                visible_row_count += 1\n            elif row is not lib.no_default:\n                last_label = j\n                lengths[i, last_label] = 0\n            elif j not in hidden_elements:\n                visible_row_count += 1\n                if visible_row_count > max_index:\n                    break\n                if lengths[i, last_label] == 0:\n                    last_label = j\n                    lengths[i, last_label] = 1\n                else:\n                    lengths[i, last_label] += 1\n    non_zero_lengths = {element: length for element, length in lengths.\n        items() if length >= 1}\n    return non_zero_lengths", "test_code_list": [{"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\ndef test_get_level_lengths_mi_hidden():\n    index = MultiIndex.from_arrays([[1, 1, 1, 2, 2, 2], ['a', 'a', 'b', 'a',\n        'a', 'b']])\n    expected = {(0, 2): 1, (0, 3): 1, (0, 4): 1, (0, 5): 1, (1, 2): 1, (1, \n        3): 1, (1, 4): 1, (1, 5): 1}\n    result = _get_level_lengths(index, sparsify=False, max_index=100,\n        hidden_elements=[0, 1, 0, 1])\n    tm.assert_dict_equal(result, expected)\n\ntest_get_level_lengths_mi_hidden()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_get_level_lengths(self):\n\t    index = MultiIndex.from_product([['a', 'b'], [0, 1, 2]])\n\t    expected = {(0, 0): 3, (0, 3): 3, (1, 0): 1, (1, 1): 1, (1, 2): 1, (1, \n\t        3): 1, (1, 4): 1, (1, 5): 1}\n\t    result = _get_level_lengths(index, sparsify=True, max_index=100)\n\t    tm.assert_dict_equal(result, expected)\n\t    expected = {(0, 0): 1, (0, 1): 1, (0, 2): 1, (0, 3): 1, (0, 4): 1, (0, \n\t        5): 1, (1, 0): 1, (1, 1): 1, (1, 2): 1, (1, 3): 1, (1, 4): 1, (1, 5): 1\n\t        }\n\t    result = _get_level_lengths(index, sparsify=False, max_index=100)\n\t    tm.assert_dict_equal(result, expected)\n\t\nTestStyler().test_get_level_lengths()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}, {"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_get_level_lengths_un_sorted(self):\n\t    index = MultiIndex.from_arrays([[1, 1, 2, 1], ['a', 'b', 'b', 'd']])\n\t    expected = {(0, 0): 2, (0, 2): 1, (0, 3): 1, (1, 0): 1, (1, 1): 1, (1, \n\t        2): 1, (1, 3): 1}\n\t    result = _get_level_lengths(index, sparsify=True, max_index=100)\n\t    tm.assert_dict_equal(result, expected)\n\t    expected = {(0, 0): 1, (0, 1): 1, (0, 2): 1, (0, 3): 1, (1, 0): 1, (1, \n\t        1): 1, (1, 2): 1, (1, 3): 1}\n\t    result = _get_level_lengths(index, sparsify=False, max_index=100)\n\t    tm.assert_dict_equal(result, expected)\n\t\nTestStyler().test_get_level_lengths_un_sorted()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}], "instruction": "Functionality: The _get_level_lengths function is designed to determine the length of each level in a given index, considering whether to sparsify the index and any hidden elements, and ensuring the analysis is limited by a maximum number of elements.\n\nInputs:\nindex: Index\n    An Index or columns object from which the lengths of each element are determined.\nsparsify: bool\n    A boolean indicating whether to hide or show each distinct element in a MultiIndex.\nmax_index: int\n    The maximum number of elements to analyze along the index for trimming purposes.\nhidden_elements: Sequence[int] | None\n    A sequence of int representing the index positions of elements hidden from display in the index, affecting length.\n\nOutputs:\nDict :\n    A dictionary where each key is a tuple of (level, initial_position) and each value is the span (length) of the element at that position in the index. The dictionary only contains non-zero span values.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef _get_level_lengths(index: Index, sparsify: bool, max_index: int,\n    hidden_elements: (Sequence[int] | None)=None): [MASK]\n"}
{"method_name": "maybe_convert_css_to_tuples", "full_method_name": "maybe_convert_css_to_tuples", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef maybe_convert_css_to_tuples(style: CSSProperties) ->CSSList:\n    \"\"\"\n    Convert css-string to sequence of tuples format if needed.\n    'color:red; border:1px solid black;' -> [('color', 'red'),\n                                             ('border','1px solid red')]\n    \"\"\"\n    if isinstance(style, str):\n        s = style.split(';')\n        try:\n            return [(x.split(':')[0].strip(), x.split(':')[1].strip()) for\n                x in s if x.strip() != '']\n        except IndexError as err:\n            raise ValueError(\n                f\"Styles supplied as string must follow CSS rule formats, for example 'attr: val;'. '{style}' was given.\"\n                ) from err\n    return style", "test_code_list": [{"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_maybe_convert_css_to_tuples(self):\n\t    expected = [('a', 'b'), ('c', 'd e')]\n\t    assert maybe_convert_css_to_tuples('a:b;c:d e;') == expected\n\t    assert maybe_convert_css_to_tuples('a: b ;c:  d e  ') == expected\n\t    expected = []\n\t    assert maybe_convert_css_to_tuples('') == expected\n\t\nTestStyler().test_maybe_convert_css_to_tuples()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}], "instruction": "Functionality: The function 'maybe_convert_css_to_tuples' is designed to take a CSS style string or a sequence of tuples and convert the style string into a sequence of tuples if necessary. The tuples represent CSS rules, where the first element of each tuple is the CSS property (e.g., 'color') and the second element is the value of that property (e.g., 'red'). If the input is already in the tuple sequence format, it returns the input as is.\nInputs: \n- style: CSSProperties\n  Represents either a CSS style string (e.g., 'color:red; border:1px solid black;') or a sequence of tuples already in the desired output format.\nOutputs: \n- CSSList\n  Returns a sequence of tuples where each tuple represents a CSS rule with the property and its value. If the input was already in the desired format, it returns the input sequence of tuples without modification.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef maybe_convert_css_to_tuples(style: CSSProperties) ->CSSList: [MASK]\n"}
{"method_name": "non_reducing_slice", "full_method_name": "non_reducing_slice", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef non_reducing_slice(slice_: Subset):\n    \"\"\"\n    Ensure that a slice doesn't reduce to a Series or Scalar.\n\n    Any user-passed `subset` should have this called on it\n    to make sure we're always working with DataFrames.\n    \"\"\"\n    kinds = ABCSeries, np.ndarray, Index, list, str\n    if isinstance(slice_, kinds):\n        slice_ = IndexSlice[:, slice_]\n\n    def pred(part) ->bool:\n        \"\"\"\n        Returns\n        -------\n        bool\n            True if slice does *not* reduce,\n            False if `part` is a tuple.\n        \"\"\"\n        if isinstance(part, tuple):\n            return any(isinstance(s, slice) or is_list_like(s) for s in part)\n        else:\n            return isinstance(part, slice) or is_list_like(part)\n    if not is_list_like(slice_):\n        if not isinstance(slice_, slice):\n            slice_ = [[slice_]]\n        else:\n            slice_ = [slice_]\n    else:\n        slice_ = [(p if pred(p) else [p]) for p in slice_]\n    return tuple(slice_)", "test_code_list": [{"test_code": "import contextlib\nimport copy\nimport re\nfrom textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nimport pandas._testing as tm\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _get_level_lengths\nfrom pandas.io.formats.style_render import _get_trimming_maximums\nfrom pandas.io.formats.style_render import maybe_convert_css_to_tuples\nfrom pandas.io.formats.style_render import non_reducing_slice\n\nclass TestStyler():\n\tdef test_non_reducing_slice_on_multiindex(self):\n\t    dic = {('a', 'd'): [1, 4], ('a', 'c'): [2, 3], ('b', 'c'): [3, 2], ('b',\n\t        'd'): [4, 1]}\n\t    df = DataFrame(dic, index=[0, 1])\n\t    idx = IndexSlice\n\t    slice_ = idx[:, idx['b', 'd']]\n\t    tslice_ = non_reducing_slice(slice_)\n\t    result = df.loc[tslice_]\n\t    expected = DataFrame({('b', 'd'): [4, 1]})\n\t    tm.assert_frame_equal(result, expected)\n\t\nTestStyler().test_non_reducing_slice_on_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_style.py"}], "instruction": "Functionality: The non_reducing_slice function is designed to ensure that a slicing operation on a DataFrame does not reduce the result to a Series or a scalar value. It is particularly useful when a user-provided subset could potentially result in a reduction of dimensions. This function modifies the slice to keep the result as a DataFrame by ensuring that at least one dimension is preserved.\n\nInputs: \n- slice_: This is the input subset/slice which might be a single element, a list, a slice, a numpy array, a pandas Series, or an Index object. The input can be of various types, including but not limited to: ABCSeries, np.ndarray, Index, list, str.\n\nOutputs:\n- tuple: The function returns a tuple of slices or indexers. This tuple will be structured in such a way that, when applied to a DataFrame, the result will not be reduced to a Series or scalar, but will remain a DataFrame. The returned structure ensures that at least one dimension of the original DataFrame is preserved, even if the slice would otherwise result in a smaller DataFrame, Series, or scalar.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef non_reducing_slice(slice_: Subset): [MASK]\n"}
{"method_name": "df", "full_method_name": "df.style.format", "method_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_to_latex.py", "method_code": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\n@pytest.fixture\ndef df():\n    return DataFrame({'A': [0, 1], 'B': [-0.61, -1.22], 'C': Series(['ab',\n        'cd'], dtype=object)})", "test_code_list": [{"test_code": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\ndef test_rendered_links():\n    df = DataFrame(['text www.domain.com text'])\n    result = df.style.format(hyperlinks='latex').to_latex()\n    assert 'text \\\\href{www.domain.com}{www.domain.com} text' in result\n\ntest_rendered_links()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_to_latex.py"}], "instruction": "Functionality: The df.style.format function is designed to provide a powerful and flexible way to format the values of a DataFrame in a variety of ways. This function allows you to apply custom formatting to individual cells, entire columns, or entire rows. It's particularly useful for presenting data in a more readable and interpretable format, such as formatting numbers, dates, or special values.\n\nInputs: The function accepts the following main arguments:\n- fmt: A dictionary that maps column names to formatting strings or functions. Alternatively, it can be a single formatting string or function that will be applied to all columns.\n- subset: An optional argument that allows you to specify a subset of the DataFrame to format. It can be a list of column names or a boolean array of the same length as the DataFrame.\n\nOutputs: The function returns a Styler object, which is a class that encapsulates the formatted DataFrame. This Styler object can then be rendered in various formats, such as HTML, or displayed in a Jupyter notebook with enhanced formatting capabilities. The Styler object also supports additional methods for applying styles, hiding indices, and exporting to different formats.", "method_code_mask": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\n\n\n@pytest.fixture\ndef df(): [MASK]\n"}
{"method_name": "_parse_latex_cell_styles", "full_method_name": "_parse_latex_cell_styles", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef _parse_latex_cell_styles(latex_styles: CSSList, display_value: str,\n    convert_css: bool=False) ->str:\n    \"\"\"\n    Mutate the ``display_value`` string including LaTeX commands from ``latex_styles``.\n\n    This method builds a recursive latex chain of commands based on the\n    CSSList input, nested around ``display_value``.\n\n    If a CSS style is given as ('<command>', '<options>') this is translated to\n    '\\\\<command><options>{display_value}', and this value is treated as the\n    display value for the next iteration.\n\n    The most recent style forms the inner component, for example for styles:\n    `[('c1', 'o1'), ('c2', 'o2')]` this returns: `\\\\c1o1{\\\\c2o2{display_value}}`\n\n    Sometimes latex commands have to be wrapped with curly braces in different ways:\n    We create some parsing flags to identify the different behaviours:\n\n     - `--rwrap`        : `\\\\<command><options>{<display_value>}`\n     - `--wrap`         : `{\\\\<command><options> <display_value>}`\n     - `--nowrap`       : `\\\\<command><options> <display_value>`\n     - `--lwrap`        : `{\\\\<command><options>} <display_value>`\n     - `--dwrap`        : `{\\\\<command><options>}{<display_value>}`\n\n    For example for styles:\n    `[('c1', 'o1--wrap'), ('c2', 'o2')]` this returns: `{\\\\c1o1 \\\\c2o2{display_value}}\n    \"\"\"\n    if convert_css:\n        latex_styles = _parse_latex_css_conversion(latex_styles)\n    for command, options in latex_styles[::-1]:\n        formatter = {'--wrap': f'{{\\\\{command}--to_parse {display_value}}}',\n            '--nowrap': f'\\\\{command}--to_parse {display_value}', '--lwrap':\n            f'{{\\\\{command}--to_parse}} {display_value}', '--rwrap':\n            f'\\\\{command}--to_parse{{{display_value}}}', '--dwrap':\n            f'{{\\\\{command}--to_parse}}{{{display_value}}}'}\n        display_value = f'\\\\{command}{options} {display_value}'\n        for arg in ['--nowrap', '--wrap', '--lwrap', '--rwrap', '--dwrap']:\n            if arg in str(options):\n                display_value = formatter[arg].replace('--to_parse',\n                    _parse_latex_options_strip(value=options, arg=arg))\n                break\n    return display_value", "test_code_list": [{"test_code": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\ndef test_parse_latex_cell_styles_basic():\n    cell_style = [('itshape', '--rwrap'), ('cellcolor', '[rgb]{0,1,1}--rwrap')]\n    expected = '\\\\itshape{\\\\cellcolor[rgb]{0,1,1}{text}}'\n    assert _parse_latex_cell_styles(cell_style, 'text') == expected\n\ntest_parse_latex_cell_styles_basic()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_to_latex.py"}], "instruction": "Functionality: \nThe _parse_latex_cell_styles function is designed to mutate a given string, `display_value`, by wrapping it with LaTeX commands derived from the `latex_styles` list. Each style in the list is a tuple consisting of a command and its options. The function processes the styles in reverse order, applying each command to the string, potentially with additional formatting depending on the options.\n\nInputs: \n- latex_styles: A list of tuples, where each tuple represents a LaTeX command and its associated options.\n- display_value: A string value that is to be wrapped with LaTeX commands.\n- convert_css: A boolean parameter indicating whether to convert CSS styles to LaTeX commands before processing (default is False).\n\nOutputs: \n- A string that represents the original `display_value` wrapped with LaTeX commands according to the `latex_styles` list. The final string includes the LaTeX commands and formatting as specified by the options.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef _parse_latex_cell_styles(latex_styles: CSSList, display_value: str,\n    convert_css: bool=False) ->str: [MASK]\n"}
{"method_name": "_parse_latex_header_span", "full_method_name": "_parse_latex_header_span", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef _parse_latex_header_span(cell: dict[str, Any], multirow_align: str,\n    multicol_align: str, wrap: bool=False, convert_css: bool=False) ->str:\n    \"\"\"\n    Refactor the cell `display_value` if a 'colspan' or 'rowspan' attribute is present.\n\n    'rowspan' and 'colspan' do not occur simultaneouly. If they are detected then\n    the `display_value` is altered to a LaTeX `multirow` or `multicol` command\n    respectively, with the appropriate cell-span.\n\n    ``wrap`` is used to enclose the `display_value` in braces which is needed for\n    column headers using an siunitx package.\n\n    Requires the package {multirow}, whereas multicol support is usually built in\n    to the {tabular} environment.\n\n    Examples\n    --------\n    >>> cell = {\"cellstyle\": \"\", \"display_value\": \"text\", \"attributes\": 'colspan=\"3\"'}\n    >>> _parse_latex_header_span(cell, \"t\", \"c\")\n    '\\\\\\\\multicolumn{3}{c}{text}'\n    \"\"\"\n    display_val = _parse_latex_cell_styles(cell['cellstyle'], cell[\n        'display_value'], convert_css)\n    if 'attributes' in cell:\n        attrs = cell['attributes']\n        if 'colspan=\"' in attrs:\n            colspan = attrs[attrs.find('colspan=\"') + 9:]\n            colspan = int(colspan[:colspan.find('\"')])\n            if 'naive-l' == multicol_align:\n                out = f'{{{display_val}}}' if wrap else f'{display_val}'\n                blanks = ' & {}' if wrap else ' &'\n                return out + blanks * (colspan - 1)\n            elif 'naive-r' == multicol_align:\n                out = f'{{{display_val}}}' if wrap else f'{display_val}'\n                blanks = '{} & ' if wrap else '& '\n                return blanks * (colspan - 1) + out\n            return (\n                f'\\\\multicolumn{{{colspan}}}{{{multicol_align}}}{{{display_val}}}'\n                )\n        elif 'rowspan=\"' in attrs:\n            if multirow_align == 'naive':\n                return display_val\n            rowspan = attrs[attrs.find('rowspan=\"') + 9:]\n            rowspan = int(rowspan[:rowspan.find('\"')])\n            return (\n                f'\\\\multirow[{multirow_align}]{{{rowspan}}}{{*}}{{{display_val}}}'\n                )\n    if wrap:\n        return f'{{{display_val}}}'\n    else:\n        return display_val", "test_code_list": [{"test_code": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\ndef test_parse_latex_header_span():\n    cell = {'attributes': 'colspan=\"3\"', 'display_value': 'text',\n        'cellstyle': []}\n    expected = '\\\\multicolumn{3}{Y}{text}'\n    assert _parse_latex_header_span(cell, 'X', 'Y') == expected\n    cell = {'attributes': 'rowspan=\"5\"', 'display_value': 'text',\n        'cellstyle': []}\n    expected = '\\\\multirow[X]{5}{*}{text}'\n    assert _parse_latex_header_span(cell, 'X', 'Y') == expected\n    cell = {'display_value': 'text', 'cellstyle': []}\n    assert _parse_latex_header_span(cell, 'X', 'Y') == 'text'\n    cell = {'display_value': 'text', 'cellstyle': [('bfseries', '--rwrap')]}\n    assert _parse_latex_header_span(cell, 'X', 'Y') == '\\\\bfseries{text}'\n\ntest_parse_latex_header_span()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_to_latex.py"}], "instruction": "Functionality: The _parse_latex_header_span function processes a cell from a table to generate LaTeX markup for headers that span multiple rows or columns. It checks if the cell has 'rowspan' or 'colspan' attributes, and if so, it modifies the cell's 'display_value' to include the appropriate LaTeX command for 'multirow' or 'multicol' to span cells as specified. The function also supports wrapping the 'display_value' in braces if required, typically for column headers using the siunitx package.\n\nInputs: \n- cell: A dictionary containing the cell data to be processed. It must include keys:\n  - 'cellstyle': A string representing the cell style.\n  - 'display_value': The value to be displayed in the cell.\n  - 'attributes' (optional): A string containing the attributes of the cell, like 'colspan' or 'rowspan'.\n- multirow_align: A string specifying the alignment for multirow cells (e.g., 't' for top).\n- multicol_align: A string specifying the alignment for multicolumn cells (e.g., 'c' for center).\n- wrap: A boolean indicating whether to wrap the 'display_value' in braces.\n- convert_css: A boolean indicating whether to convert CSS properties in the cell style.\n\nOutputs:\n- Returns a string that represents the modified 'display_value' for the cell, incorporating LaTeX 'multirow' or 'multicol' commands if 'rowspan' or 'colspan' attributes are detected, respectively. The string also reflects the specified alignment and wrapping.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef _parse_latex_header_span(cell: dict[str, Any], multirow_align: str,\n    multicol_align: str, wrap: bool=False, convert_css: bool=False) ->str: [M\n    ASK]\n"}
{"method_name": "_parse_latex_css_conversion", "full_method_name": "_parse_latex_css_conversion", "method_path": "../srcdata/Computation/pandas/pandas/io/formats/style_render.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\ndef _parse_latex_css_conversion(styles: CSSList) ->CSSList:\n    \"\"\"\n    Convert CSS (attribute,value) pairs to equivalent LaTeX (command,options) pairs.\n\n    Ignore conversion if tagged with `--latex` option, skipped if no conversion found.\n    \"\"\"\n\n    def font_weight(value, arg) ->(tuple[str, str] | None):\n        if value in ('bold', 'bolder'):\n            return 'bfseries', f'{arg}'\n        return None\n\n    def font_style(value, arg) ->(tuple[str, str] | None):\n        if value == 'italic':\n            return 'itshape', f'{arg}'\n        if value == 'oblique':\n            return 'slshape', f'{arg}'\n        return None\n\n    def color(value, user_arg, command, comm_arg):\n        \"\"\"\n        CSS colors have 5 formats to process:\n\n         - 6 digit hex code: \"#ff23ee\"     --> [HTML]{FF23EE}\n         - 3 digit hex code: \"#f0e\"        --> [HTML]{FF00EE}\n         - rgba: rgba(128, 255, 0, 0.5)    --> [rgb]{0.502, 1.000, 0.000}\n         - rgb: rgb(128, 255, 0,)          --> [rbg]{0.502, 1.000, 0.000}\n         - string: red                     --> {red}\n\n        Additionally rgb or rgba can be expressed in % which is also parsed.\n        \"\"\"\n        arg = user_arg if user_arg != '' else comm_arg\n        if value[0] == '#' and len(value) == 7:\n            return command, f'[HTML]{{{value[1:].upper()}}}{arg}'\n        if value[0] == '#' and len(value) == 4:\n            val = (\n                f'{value[1].upper() * 2}{value[2].upper() * 2}{value[3].upper() * 2}'\n                )\n            return command, f'[HTML]{{{val}}}{arg}'\n        elif value[:3] == 'rgb':\n            r = re.findall('(?<=\\\\()[0-9\\\\s%]+(?=,)', value)[0].strip()\n            r = float(r[:-1]) / 100 if '%' in r else int(r) / 255\n            g = re.findall('(?<=,)[0-9\\\\s%]+(?=,)', value)[0].strip()\n            g = float(g[:-1]) / 100 if '%' in g else int(g) / 255\n            if value[3] == 'a':\n                b = re.findall('(?<=,)[0-9\\\\s%]+(?=,)', value)[1].strip()\n            else:\n                b = re.findall('(?<=,)[0-9\\\\s%]+(?=\\\\))', value)[0].strip()\n            b = float(b[:-1]) / 100 if '%' in b else int(b) / 255\n            return command, f'[rgb]{{{r:.3f}, {g:.3f}, {b:.3f}}}{arg}'\n        else:\n            return command, f'{{{value}}}{arg}'\n    CONVERTED_ATTRIBUTES: dict[str, Callable] = {'font-weight': font_weight,\n        'background-color': partial(color, command='cellcolor', comm_arg=\n        '--lwrap'), 'color': partial(color, command='color', comm_arg=''),\n        'font-style': font_style}\n    latex_styles: CSSList = []\n    for attribute, value in styles:\n        if isinstance(value, str) and '--latex' in value:\n            latex_styles.append((attribute, value.replace('--latex', '')))\n        if attribute in CONVERTED_ATTRIBUTES:\n            arg = ''\n            for x in ['--wrap', '--nowrap', '--lwrap', '--dwrap', '--rwrap']:\n                if x in str(value):\n                    arg, value = x, _parse_latex_options_strip(value, x)\n                    break\n            latex_style = CONVERTED_ATTRIBUTES[attribute](value, arg)\n            if latex_style is not None:\n                latex_styles.extend([latex_style])\n    return latex_styles", "test_code_list": [{"test_code": "from textwrap import dedent\nimport numpy as np\nimport pytest\nfrom pandas import DataFrame\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _parse_latex_cell_styles\nfrom pandas.io.formats.style_render import _parse_latex_css_conversion\nfrom pandas.io.formats.style_render import _parse_latex_header_span\nfrom pandas.io.formats.style_render import _parse_latex_table_styles\nfrom pandas.io.formats.style_render import _parse_latex_table_wrapping\ndef test_parse_latex_css_conversion_option():\n    css = [('command', 'option--latex--wrap')]\n    expected = [('command', 'option--wrap')]\n    result = _parse_latex_css_conversion(css)\n    assert result == expected\n\ntest_parse_latex_css_conversion_option()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_to_latex.py"}], "instruction": "Functionality: The function _parse_latex_css_conversion is designed to convert CSS (attribute, value) pairs into equivalent LaTeX (command, options) pairs. This conversion enables the styling attributes used in web content to be compatible with LaTeX formatting rules. The function skips any CSS attributes tagged with `--latex` and leaves them unchanged. If no conversion is found for a given CSS attribute, it is ignored.\n\nInputs: \n- styles: A list of tuples where each tuple represents a (CSS attribute, value) pair. The CSS attribute is a string, and the value can be a string or another data type, although the function specifically processes string values.\n\nOutputs: \n- A list of tuples representing the equivalent LaTeX (command, options) pairs. If the conversion is successful, each tuple in the output list corresponds to a converted CSS pair from the input. If a CSS attribute is tagged with `--latex`, it is included in the output list without conversion, but with the `--latex` tag removed. If a CSS attribute cannot be converted, it is not included in the output list.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom collections.abc import Callable\nfrom collections.abc import Sequence\nfrom functools import partial\nimport re\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import DefaultDict\nfrom typing import Optional\nfrom typing import TypedDict\nfrom typing import Union\nfrom uuid import uuid4\nimport numpy as np\nfrom pandas._config import get_option\nfrom pandas._libs import lib\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.core.dtypes.common import is_complex\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas import DataFrame\nfrom pandas import Index\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import Series\nfrom pandas import isna\nfrom pandas.api.types import is_list_like\nimport pandas.core.common as com\nfrom pandas._typing import Axis\nfrom pandas._typing import Level\nfrom markupsafe import escape as escape_html\n\n\ndef _parse_latex_css_conversion(styles: CSSList) ->CSSList: [MASK]\n"}
{"method_name": "df", "full_method_name": "df.style.format", "method_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py", "method_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\n@pytest.fixture\ndef df():\n    return DataFrame(data=[[0, -0.609], [1, -1.228]], columns=['A', 'B'],\n        index=['x', 'y'])", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_format_with_na_rep():\n    df = DataFrame([[None, None], [1.1, 1.2]], columns=['A', 'B'])\n    ctx = df.style.format(None, na_rep='-')._translate(True, True)\n    assert ctx['body'][0][1]['display_value'] == '-'\n    assert ctx['body'][0][2]['display_value'] == '-'\n    ctx = df.style.format('{:.2%}', na_rep='-')._translate(True, True)\n    assert ctx['body'][0][1]['display_value'] == '-'\n    assert ctx['body'][0][2]['display_value'] == '-'\n    assert ctx['body'][1][1]['display_value'] == '110.00%'\n    assert ctx['body'][1][2]['display_value'] == '120.00%'\n    ctx = df.style.format('{:.2%}', na_rep='-', subset=['B'])._translate(\n        True, True)\n    assert ctx['body'][0][2]['display_value'] == '-'\n    assert ctx['body'][1][2]['display_value'] == '120.00%'\n\ntest_format_with_na_rep()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_format_non_numeric_na():\n    df = DataFrame({'object': [None, np.nan, 'foo'], 'datetime': [None, NaT,\n        Timestamp('20120101')]})\n    ctx = df.style.format(None, na_rep='-')._translate(True, True)\n    assert ctx['body'][0][1]['display_value'] == '-'\n    assert ctx['body'][0][2]['display_value'] == '-'\n    assert ctx['body'][1][1]['display_value'] == '-'\n    assert ctx['body'][1][2]['display_value'] == '-'\n\ntest_format_non_numeric_na()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_format_subset():\n    df = DataFrame([[0.1234, 0.1234], [1.1234, 1.1234]], columns=['a', 'b'])\n    ctx = df.style.format({'a': '{:0.1f}', 'b': '{0:.2%}'}, subset=\n        IndexSlice[0, :])._translate(True, True)\n    expected = '0.1'\n    raw_11 = '1.123400'\n    assert ctx['body'][0][1]['display_value'] == expected\n    assert ctx['body'][1][1]['display_value'] == raw_11\n    assert ctx['body'][0][2]['display_value'] == '12.34%'\n    ctx = df.style.format('{:0.1f}', subset=IndexSlice[0, :])._translate(\n        True, True)\n    assert ctx['body'][0][1]['display_value'] == expected\n    assert ctx['body'][1][1]['display_value'] == raw_11\n    ctx = df.style.format('{:0.1f}', subset=IndexSlice['a'])._translate(\n        True, True)\n    assert ctx['body'][0][1]['display_value'] == expected\n    assert ctx['body'][0][2]['display_value'] == '0.123400'\n    ctx = df.style.format('{:0.1f}', subset=IndexSlice[0, 'a'])._translate(\n        True, True)\n    assert ctx['body'][0][1]['display_value'] == expected\n    assert ctx['body'][1][1]['display_value'] == raw_11\n    ctx = df.style.format('{:0.1f}', subset=IndexSlice[[0, 1], ['a']]\n        )._translate(True, True)\n    assert ctx['body'][0][1]['display_value'] == expected\n    assert ctx['body'][1][1]['display_value'] == '1.1'\n    assert ctx['body'][0][2]['display_value'] == '0.123400'\n    assert ctx['body'][1][2]['display_value'] == raw_11\n\ntest_format_subset()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_format_index_with_na_rep():\n    df = DataFrame([[1, 2, 3, 4, 5]], columns=['A', None, np.nan, NaT, NA])\n    ctx = df.style.format_index(None, na_rep='--', axis=1)._translate(True,\n        True)\n    assert ctx['head'][0][1]['display_value'] == 'A'\n    for i in [2, 3, 4, 5]:\n        assert ctx['head'][0][i]['display_value'] == '--'\n\ntest_format_index_with_na_rep()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_1level_multiindex():\n    midx = MultiIndex.from_product([[1, 2]], names=[''])\n    df = DataFrame(-1, index=midx, columns=[0, 1])\n    ctx = df.style._translate(True, True)\n    assert ctx['body'][0][0]['display_value'] == '1'\n    assert ctx['body'][0][0]['is_visible'] is True\n    assert ctx['body'][1][0]['display_value'] == '2'\n    assert ctx['body'][1][0]['is_visible'] is True\n\ntest_1level_multiindex()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}, {"test_code": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\ndef test_boolean_format():\n    df = DataFrame([[True, False]])\n    ctx = df.style._translate(True, True)\n    assert ctx['body'][0][1]['display_value'] is True\n    assert ctx['body'][0][2]['display_value'] is False\n\ntest_boolean_format()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/formats/style/test_format.py"}], "instruction": "Functionality: The df.style.format function is a part of the pandas Styler class which is used to format the elements of a DataFrame into a more readable string format. This function allows you to apply various formatting techniques to the DataFrame, which can include precision control for floating-point numbers, custom formatting for specific columns or rows, or handling of missing values.\n\nInputs: The function takes the DataFrame as the primary input. Additionally, it accepts several optional arguments such as:\n- subset: A valid indexer for selecting a sub-selection of columns and rows.\n- na_rep: A string representation for missing values.\n- precision: The number of decimal places to use when formatting numbers.\n- thousands: The character to use as the thousands separator.\n\nOutputs: The function returns a Styler object, which is a pandas object that holds the formatted DataFrame. This object can then be displayed in various formats such as HTML, LaTeX, or plain text. The Styler object can also be further customized with additional methods to apply colors, borders, or other visual styles.", "method_code_mask": "import numpy as np\nimport pytest\nfrom pandas import NA\nfrom pandas import DataFrame\nfrom pandas import IndexSlice\nfrom pandas import MultiIndex\nfrom pandas import NaT\nfrom pandas import Timestamp\nfrom pandas import option_context\nfrom pandas.io.formats.style import Styler\nfrom pandas.io.formats.style_render import _str_escape\n\n\n@pytest.fixture\ndef df(): [MASK]\n"}
{"method_name": "ensure_dtype_objs", "full_method_name": "ensure_dtype_objs", "method_path": "../srcdata/Computation/pandas/pandas/io/parsers/c_parser_wrapper.py", "method_code": "from __future__ import annotations\nfrom collections import defaultdict\nfrom typing import TYPE_CHECKING\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import parsers\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import DtypeWarning\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.concat import union_categoricals\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.indexes.api import ensure_index_from_sequences\nfrom pandas.io.common import dedup_names\nfrom pandas.io.common import is_potential_multi_index\nfrom pandas.io.parsers.base_parser import ParserBase\nfrom pandas.io.parsers.base_parser import ParserError\nfrom pandas.io.parsers.base_parser import is_index_col\nfrom collections.abc import Hashable\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeArg\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import ReadCsvBuffer\nfrom pandas import Index\nfrom pandas import MultiIndex\ndef ensure_dtype_objs(dtype: (DtypeArg | dict[Hashable, DtypeArg] | None)) ->(\n    DtypeObj | dict[Hashable, DtypeObj] | None):\n    \"\"\"\n    Ensure we have either None, a dtype object, or a dictionary mapping to\n    dtype objects.\n    \"\"\"\n    if isinstance(dtype, defaultdict):\n        default_dtype = pandas_dtype(dtype.default_factory())\n        dtype_converted: defaultdict = defaultdict(lambda : default_dtype)\n        for key in dtype.keys():\n            dtype_converted[key] = pandas_dtype(dtype[key])\n        return dtype_converted\n    elif isinstance(dtype, dict):\n        return {k: pandas_dtype(dtype[k]) for k in dtype}\n    elif dtype is not None:\n        return pandas_dtype(dtype)\n    return dtype", "test_code_list": [{"test_code": "from io import BytesIO\nfrom io import StringIO\nimport numpy as np\nimport pytest\nimport pandas._libs.parsers as parser\nfrom pandas._libs.parsers import TextReader\nfrom pandas.errors import ParserWarning\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.parsers import TextFileReader\nfrom pandas.io.parsers import read_csv\nfrom pandas.io.parsers.c_parser_wrapper import ensure_dtype_objs\n\nclass TestTextReader():\n\tdef test_numpy_string_dtype(self):\n\t    data = 'a,1\\naa,2\\naaa,3\\naaaa,4\\naaaaa,5'\n\t\n\t    def _make_reader(**kwds):\n\t        if 'dtype' in kwds:\n\t            kwds['dtype'] = ensure_dtype_objs(kwds['dtype'])\n\t        return TextReader(StringIO(data), delimiter=',', header=None, **kwds)\n\t    reader = _make_reader(dtype='S5,i4')\n\t    result = reader.read()\n\t    assert result[0].dtype == 'S5'\n\t    ex_values = np.array(['a', 'aa', 'aaa', 'aaaa', 'aaaaa'], dtype='S5')\n\t    assert (result[0] == ex_values).all()\n\t    assert result[1].dtype == 'i4'\n\t    reader = _make_reader(dtype='S4')\n\t    result = reader.read()\n\t    assert result[0].dtype == 'S4'\n\t    ex_values = np.array(['a', 'aa', 'aaa', 'aaaa', 'aaaa'], dtype='S4')\n\t    assert (result[0] == ex_values).all()\n\t    assert result[1].dtype == 'S4'\n\t\nTestTextReader().test_numpy_string_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/parser/test_textreader.py"}, {"test_code": "from io import BytesIO\nfrom io import StringIO\nimport numpy as np\nimport pytest\nimport pandas._libs.parsers as parser\nfrom pandas._libs.parsers import TextReader\nfrom pandas.errors import ParserWarning\nfrom pandas import DataFrame\nimport pandas._testing as tm\nfrom pandas.io.parsers import TextFileReader\nfrom pandas.io.parsers import read_csv\nfrom pandas.io.parsers.c_parser_wrapper import ensure_dtype_objs\n\nclass TestTextReader():\n\tdef test_pass_dtype(self):\n\t    data = 'one,two\\n1,a\\n2,b\\n3,c\\n4,d'\n\t\n\t    def _make_reader(**kwds):\n\t        if 'dtype' in kwds:\n\t            kwds['dtype'] = ensure_dtype_objs(kwds['dtype'])\n\t        return TextReader(StringIO(data), delimiter=',', **kwds)\n\t    reader = _make_reader(dtype={'one': 'u1', (1): 'S1'})\n\t    result = reader.read()\n\t    assert result[0].dtype == 'u1'\n\t    assert result[1].dtype == 'S1'\n\t    reader = _make_reader(dtype={'one': np.uint8, (1): object})\n\t    result = reader.read()\n\t    assert result[0].dtype == 'u1'\n\t    assert result[1].dtype == 'O'\n\t    reader = _make_reader(dtype={'one': np.dtype('u1'), (1): np.dtype('O')})\n\t    result = reader.read()\n\t    assert result[0].dtype == 'u1'\n\t    assert result[1].dtype == 'O'\n\t\nTestTextReader().test_pass_dtype()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/io/parser/test_textreader.py"}], "instruction": "Functionality: The function 'ensure_dtype_objs' is designed to ensure that the input dtype argument is either None, a dtype object, or a dictionary mapping to dtype objects. It converts any given dtype information into an appropriate dtype object or a dictionary of dtype objects.\n\nInputs: \n- dtype: This is a DtypeArg or a dictionary with Hashable keys and DtypeArg values, or None. It represents the data type(s) to be ensured as DtypeObj(s) or a defaultdict of DtypeObj(s).\n\nOutputs: \n- If the input is a defaultdict, the function returns a defaultdict with the same keys, and values converted to DtypeObj.\n- If the input is a dict, the function returns a dict with the same keys, and values converted to DtypeObj.\n- If the input is a DtypeArg (and not None), the function returns the input converted to a DtypeObj.\n- If the input is None, the function returns None.", "method_code_mask": "from __future__ import annotations\nfrom collections import defaultdict\nfrom typing import TYPE_CHECKING\nimport warnings\nimport numpy as np\nfrom pandas._libs import lib\nfrom pandas._libs import parsers\nfrom pandas.compat._optional import import_optional_dependency\nfrom pandas.errors import DtypeWarning\nfrom pandas.util._exceptions import find_stack_level\nfrom pandas.core.dtypes.common import pandas_dtype\nfrom pandas.core.dtypes.concat import concat_compat\nfrom pandas.core.dtypes.concat import union_categoricals\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\nfrom pandas.core.indexes.api import ensure_index_from_sequences\nfrom pandas.io.common import dedup_names\nfrom pandas.io.common import is_potential_multi_index\nfrom pandas.io.parsers.base_parser import ParserBase\nfrom pandas.io.parsers.base_parser import ParserError\nfrom pandas.io.parsers.base_parser import is_index_col\nfrom collections.abc import Hashable\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom pandas._typing import AnyArrayLike\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import DtypeArg\nfrom pandas._typing import DtypeObj\nfrom pandas._typing import ReadCsvBuffer\nfrom pandas import Index\nfrom pandas import MultiIndex\n\n\ndef ensure_dtype_objs(dtype: (DtypeArg | dict[Hashable, DtypeArg] | None)) ->(\n    DtypeObj | dict[Hashable, DtypeObj] | None): [MASK]\n"}
{"method_name": "comparison_op", "full_method_name": "comparison_op", "method_path": "../srcdata/Computation/pandas/pandas/core/ops/array_ops.py", "method_code": "from __future__ import annotations\nimport datetime\nfrom functools import partial\nimport operator\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport numpy as np\nfrom pandas._libs import NaT\nfrom pandas._libs import Timedelta\nfrom pandas._libs import Timestamp\nfrom pandas._libs import lib\nfrom pandas._libs import ops as libops\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import is_unitless\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_v_string_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core import roperator\nfrom pandas.core.computation import expressions\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.ops import missing\nfrom pandas.core.ops.dispatch import should_extension_dispatch\nfrom pandas.core.ops.invalid import invalid_comparison\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Shape\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\ndef comparison_op(left: ArrayLike, right: Any, op) ->ArrayLike:\n    \"\"\"\n    Evaluate a comparison operation `=`, `!=`, `>=`, `>`, `<=`, or `<`.\n\n    Note: the caller is responsible for ensuring that numpy warnings are\n    suppressed (with np.errstate(all=\"ignore\")) if needed.\n\n    Parameters\n    ----------\n    left : np.ndarray or ExtensionArray\n    right : object\n        Cannot be a DataFrame, Series, or Index.\n    op : {operator.eq, operator.ne, operator.gt, operator.ge, operator.lt, operator.le}\n\n    Returns\n    -------\n    ndarray or ExtensionArray\n    \"\"\"\n    lvalues = ensure_wrapped_if_datetimelike(left)\n    rvalues = ensure_wrapped_if_datetimelike(right)\n    rvalues = lib.item_from_zerodim(rvalues)\n    if isinstance(rvalues, list):\n        rvalues = np.asarray(rvalues)\n    if isinstance(rvalues, (np.ndarray, ABCExtensionArray)):\n        if len(lvalues) != len(rvalues):\n            raise ValueError('Lengths must match to compare', lvalues.shape,\n                rvalues.shape)\n    if should_extension_dispatch(lvalues, rvalues) or (isinstance(rvalues,\n        (Timedelta, BaseOffset, Timestamp)) or right is NaT\n        ) and lvalues.dtype != object:\n        res_values = op(lvalues, rvalues)\n    elif is_scalar(rvalues) and isna(rvalues):\n        if op is operator.ne:\n            res_values = np.ones(lvalues.shape, dtype=bool)\n        else:\n            res_values = np.zeros(lvalues.shape, dtype=bool)\n    elif is_numeric_v_string_like(lvalues, rvalues):\n        return invalid_comparison(lvalues, rvalues, op)\n    elif lvalues.dtype == object or isinstance(rvalues, str):\n        res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n    else:\n        res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=True)\n    return res_values", "test_code_list": [{"test_code": "import operator\nimport numpy as np\nimport pytest\nimport pandas._testing as tm\nfrom pandas.core.ops.array_ops import comparison_op\nfrom pandas.core.ops.array_ops import na_logical_op\ndef test_object_comparison_2d():\n    left = np.arange(9).reshape(3, 3).astype(object)\n    right = left.T\n    result = comparison_op(left, right, operator.eq)\n    expected = np.eye(3).astype(bool)\n    tm.assert_numpy_array_equal(result, expected)\n    right.flags.writeable = False\n    result = comparison_op(left, right, operator.ne)\n    tm.assert_numpy_array_equal(result, ~expected)\n\ntest_object_comparison_2d()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/arithmetic/test_array_ops.py"}], "instruction": "Functionality: \nThe function `comparison_op` evaluates a comparison operation between two given operands using one of the comparison operators: `==`, `!=`, `>=`, `>`, `<=`, or `<`. It is designed to handle various types of inputs, including numpy arrays and pandas ExtensionArrays, and ensures that the comparison is performed accurately based on the data types of the operands.\n\nInputs: \n- left: ArrayLike - The left operand for the comparison, which can be a numpy array or a pandas ExtensionArray.\n- right: Any - The right operand for the comparison. It can be any object except for a DataFrame, Series, or Index.\n- op: Callable - A comparison operator from the `operator` module, such as `operator.eq` for equality, `operator.ne` for inequality, etc.\n\nOutputs: \n- ArrayLike: The result of the comparison operation. It is returned as a numpy array or an ExtensionArray, depending on the types of the input operands.\n\nNote: It is the responsibility of the caller to ensure that numpy warnings are suppressed if necessary by using `np.errstate(all=\"ignore\")`.", "method_code_mask": "from __future__ import annotations\nimport datetime\nfrom functools import partial\nimport operator\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nimport numpy as np\nfrom pandas._libs import NaT\nfrom pandas._libs import Timedelta\nfrom pandas._libs import Timestamp\nfrom pandas._libs import lib\nfrom pandas._libs import ops as libops\nfrom pandas._libs.tslibs import BaseOffset\nfrom pandas._libs.tslibs import is_unitless\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\nfrom pandas.core.dtypes.cast import find_common_type\nfrom pandas.core.dtypes.common import ensure_object\nfrom pandas.core.dtypes.common import is_bool_dtype\nfrom pandas.core.dtypes.common import is_list_like\nfrom pandas.core.dtypes.common import is_numeric_v_string_like\nfrom pandas.core.dtypes.common import is_object_dtype\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.generic import ABCExtensionArray\nfrom pandas.core.dtypes.generic import ABCIndex\nfrom pandas.core.dtypes.generic import ABCSeries\nfrom pandas.core.dtypes.missing import isna\nfrom pandas.core.dtypes.missing import notna\nfrom pandas.core import roperator\nfrom pandas.core.computation import expressions\nfrom pandas.core.construction import ensure_wrapped_if_datetimelike\nfrom pandas.core.ops import missing\nfrom pandas.core.ops.dispatch import should_extension_dispatch\nfrom pandas.core.ops.invalid import invalid_comparison\nfrom pandas._typing import ArrayLike\nfrom pandas._typing import Shape\nfrom pandas.core.arrays import DatetimeArray\nfrom pandas.core.arrays import TimedeltaArray\n\n\ndef comparison_op(left: ArrayLike, right: Any, op) ->ArrayLike: [MASK]\n"}
{"method_name": "index_large", "full_method_name": "index_large.intersection", "method_path": "../srcdata/Computation/pandas/pandas/tests/indexes/numeric/test_setops.py", "method_code": "from datetime import datetime\nfrom datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas._testing as tm\nfrom pandas.core.indexes.api import Index\nfrom pandas.core.indexes.api import RangeIndex\n@pytest.fixture\ndef index_large():\n    large = [2 ** 63, 2 ** 63 + 10, 2 ** 63 + 15, 2 ** 63 + 20, 2 ** 63 + 25]\n    return Index(large, dtype=np.uint64)", "test_code_list": [{"test_code": "from datetime import datetime\nfrom datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas._testing as tm\nfrom pandas.core.indexes.api import Index\nfrom pandas.core.indexes.api import RangeIndex\n\nclass TestSetOps():\n\tdef test_intersection_uint64_outside_int64_range(self):\n\t    index_large = Index([2 ** 63, 2 ** 63 + 10, 2 ** 63 + 15, 2 ** 63 + 20,\n\t        2 ** 63 + 25], dtype=np.uint64)\n\t    other = Index([2 ** 63, 2 ** 63 + 5, 2 ** 63 + 10, 2 ** 63 + 15, 2 ** \n\t        63 + 20])\n\t    result = index_large.intersection(other)\n\t    expected = Index(np.sort(np.intersect1d(index_large.values, other.values)))\n\t    tm.assert_index_equal(result, expected)\n\t    result = other.intersection(index_large)\n\t    expected = Index(np.sort(np.asarray(np.intersect1d(index_large.values,\n\t        other.values))))\n\t    tm.assert_index_equal(result, expected)\n\t\nTestSetOps().test_intersection_uint64_outside_int64_range()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/numeric/test_setops.py"}], "instruction": "Functionality: Implement the .intersection() function for the Index object 'index_large'. This function should return a new Index containing elements that are present in 'index_large' and another Index or array-like object that will be provided as an argument during the function call. In case of duplicate elements in the resulting Index, only the first occurrence should be included.\n\nInputs: \n- other: This is the Index or array-like object to intersect with 'index_large'. This is a mandatory argument.\n\nOutputs:\n- A new Index object containing the sorted, unique elements that are common to 'index_large' and 'other'. The resulting Index should maintain the dtype (data type) of 'index_large'.", "method_code_mask": "from datetime import datetime\nfrom datetime import timedelta\nimport numpy as np\nimport pytest\nimport pandas._testing as tm\nfrom pandas.core.indexes.api import Index\nfrom pandas.core.indexes.api import RangeIndex\n\n\n@pytest.fixture\ndef index_large(): [MASK]\n"}
{"method_name": "min_fitting_element", "full_method_name": "min_fitting_element", "method_path": "../srcdata/Computation/pandas/pandas/core/indexes/range.py", "method_code": "from __future__ import annotations\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom collections.abc import Iterator\nfrom datetime import timedelta\nimport operator\nfrom sys import getsizeof\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport numpy as np\nfrom pandas._libs import index as libindex\nfrom pandas._libs import lib\nfrom pandas._libs.lib import no_default\nfrom pandas.compat.numpy import function as nv\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.base import ExtensionDtype\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import ensure_python_int\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.generic import ABCTimedeltaIndex\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import check_array_indexer\nimport pandas.core.indexes.base as ibase\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\nfrom pandas._typing import Axis\nfrom pandas._typing import Dtype\nfrom pandas._typing import JoinHow\nfrom pandas._typing import NaPosition\nfrom pandas._typing import npt\nfrom pandas import Series\ndef min_fitting_element(start: int, step: int, lower_limit: int) ->int:\n    \"\"\"Returns the smallest element greater than or equal to the limit\"\"\"\n    no_steps = -(-(lower_limit - start) // abs(step))\n    return start + abs(step) * no_steps", "test_code_list": [{"test_code": "import numpy as np\nimport pytest\nfrom pandas.core.dtypes.common import ensure_platform_int\nimport pandas as pd\nfrom pandas import Index\nfrom pandas import RangeIndex\nimport pandas._testing as tm\n\nclass TestRangeIndex():\n\tdef test_min_fitting_element(self):\n\t    result = min_fitting_element(0, 2, 1)\n\t    assert 2 == result\n\t    result = min_fitting_element(1, 1, 1)\n\t    assert 1 == result\n\t    result = min_fitting_element(18, -2, 1)\n\t    assert 2 == result\n\t    result = min_fitting_element(5, -1, 1)\n\t    assert 1 == result\n\t    big_num = 500000000000000000000000\n\t    result = min_fitting_element(5, 1, big_num)\n\t    assert big_num == result\n\t\nTestRangeIndex().test_min_fitting_element()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/indexes/ranges/test_range.py"}], "instruction": "Functionality: The min_fitting_element function is designed to calculate the smallest element that is greater than or equal to a specified lower limit, given a starting point and a step value. This function is particularly useful for determining the next value in a sequence that meets a certain threshold.\n\nInputs:\n- start: An integer representing the starting point of the sequence.\n- step: An integer indicating the step size between elements in the sequence.\n- lower_limit: An integer that serves as the lower limit, with the goal to find the smallest element in the sequence that is greater than or equal to this limit.\n\nOutputs:\n- The function returns an integer which is the smallest element in the sequence (defined by start and step) that is greater than or equal to the specified lower limit.", "method_code_mask": "from __future__ import annotations\nfrom collections.abc import Callable\nfrom collections.abc import Hashable\nfrom collections.abc import Iterator\nfrom datetime import timedelta\nimport operator\nfrom sys import getsizeof\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Literal\nfrom typing import cast\nfrom typing import overload\nimport numpy as np\nfrom pandas._libs import index as libindex\nfrom pandas._libs import lib\nfrom pandas._libs.lib import no_default\nfrom pandas.compat.numpy import function as nv\nfrom pandas.util._decorators import cache_readonly\nfrom pandas.util._decorators import doc\nfrom pandas.core.dtypes.base import ExtensionDtype\nfrom pandas.core.dtypes.common import ensure_platform_int\nfrom pandas.core.dtypes.common import ensure_python_int\nfrom pandas.core.dtypes.common import is_float\nfrom pandas.core.dtypes.common import is_integer\nfrom pandas.core.dtypes.common import is_scalar\nfrom pandas.core.dtypes.common import is_signed_integer_dtype\nfrom pandas.core.dtypes.generic import ABCTimedeltaIndex\nfrom pandas.core import ops\nimport pandas.core.common as com\nfrom pandas.core.construction import extract_array\nfrom pandas.core.indexers import check_array_indexer\nimport pandas.core.indexes.base as ibase\nfrom pandas.core.indexes.base import Index\nfrom pandas.core.indexes.base import maybe_extract_name\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\nfrom pandas._typing import Axis\nfrom pandas._typing import Dtype\nfrom pandas._typing import JoinHow\nfrom pandas._typing import NaPosition\nfrom pandas._typing import npt\nfrom pandas import Series\n\n\ndef min_fitting_element(start: int, step: int, lower_limit: int) ->int: [MASK]\n"}
{"method_name": "df", "full_method_name": "df.groupby", "method_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py", "method_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\n@pytest.fixture\ndef df(index):\n    frame = DataFrame(np.random.default_rng(2).random((10, 2)), columns=\n        list('AB'), index=index)\n    return frame", "test_code_list": [{"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_groupby_resample_on_api():\n    df = DataFrame({'key': ['A', 'B'] * 5, 'dates': date_range('2016-01-01',\n        periods=10), 'values': np.random.default_rng(2).standard_normal(10)})\n    expected = df.set_index('dates').groupby('key').resample('D').mean()\n    result = df.groupby('key').resample('D', on='dates').mean()\n    tm.assert_frame_equal(result, expected)\n\ntest_groupby_resample_on_api()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}, {"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_groupby_resample_on_api():\n    df = DataFrame({'key': ['A', 'B'] * 5, 'dates': date_range('2016-01-01',\n        periods=10), 'values': np.random.default_rng(2).standard_normal(10)})\n    expected = df.set_index('dates').groupby('key').resample('D').mean()\n    result = df.groupby('key').resample('D', on='dates').mean()\n    tm.assert_frame_equal(result, expected)\n\ntest_groupby_resample_on_api()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}, {"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_resample_group_keys():\n    df = DataFrame({'A': 1, 'B': 2}, index=date_range('2000', periods=10))\n    expected = df.copy()\n    g = df.resample('5D', group_keys=False)\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n    g = df.resample('5D')\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n    expected.index = pd.MultiIndex.from_arrays([pd.to_datetime([\n        '2000-01-01', '2000-01-06']).as_unit('ns').repeat(5), expected.index])\n    g = df.resample('5D', group_keys=True)\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n\ntest_resample_group_keys()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}, {"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_agg_list_like_func_with_args():\n    df = DataFrame({'x': [1, 2, 3]}, index=date_range('2020-01-01', periods\n        =3, freq='D'))\n\n    def foo1(x, a=1, c=0):\n        return x + a + c\n\n    def foo2(x, b=2, c=0):\n        return x + b + c\n    msg = \"foo1\\\\(\\\\) got an unexpected keyword argument 'b'\"\n    with pytest.raises(TypeError, match=msg):\n        df.resample('D').agg([foo1, foo2], 3, b=3, c=4)\n    result = df.resample('D').agg([foo1, foo2], 3, c=4)\n    expected = DataFrame([[8, 8], [9, 9], [10, 10]], index=date_range(\n        '2020-01-01', periods=3, freq='D'), columns=pd.MultiIndex.\n        from_tuples([('x', 'foo1'), ('x', 'foo2')]))\n    tm.assert_frame_equal(result, expected)\n\ntest_agg_list_like_func_with_args()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}, {"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_resample_empty():\n    df = DataFrame(index=pd.to_datetime(['2018-01-01 00:00:00',\n        '2018-01-01 12:00:00', '2018-01-02 00:00:00']))\n    expected = DataFrame(index=pd.to_datetime(['2018-01-01 00:00:00',\n        '2018-01-01 08:00:00', '2018-01-01 16:00:00', '2018-01-02 00:00:00']))\n    result = df.resample('8h').mean()\n    tm.assert_frame_equal(result, expected)\n\ntest_resample_empty()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}, {"test_code": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\ndef test_resample_group_keys():\n    df = DataFrame({'A': 1, 'B': 2}, index=date_range('2000', periods=10))\n    expected = df.copy()\n    g = df.resample('5D', group_keys=False)\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n    g = df.resample('5D')\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n    expected.index = pd.MultiIndex.from_arrays([pd.to_datetime([\n        '2000-01-01', '2000-01-06']).as_unit('ns').repeat(5), expected.index])\n    g = df.resample('5D', group_keys=True)\n    result = g.apply(lambda x: x)\n    tm.assert_frame_equal(result, expected)\n\ntest_resample_group_keys()\n", "code_start": "", "test_path": "../srcdata/Computation/pandas/pandas/tests/resample/test_resample_api.py"}], "instruction": "Functionality: The groupby function in a DataFrame is a powerful tool utilized for data analysis and manipulation. It allows the grouping of data based on one or more columns of the DataFrame. The primary use of this function is to split the data into groups, apply some operations to each group independently, and then combine the results back into a DataFrame or a Series.\n\nInputs: \n1. `by`: A column name, an array, or a list of columns by which the DataFrame should be grouped.\n2. `axis`: Determines the axis along which the grouping will be performed. By default, it is 0 (rows). For grouping columns, use axis=1.\n3. `sort`: A boolean value (default is True). If set to True, the result will be sorted by the grouping keys.\n4. `as_index`: A boolean value (default is True). Determines if the keys should be treated as an index in the resulting DataFrame or Series.\n5. Additional parameters can be specified depending on the requirements of the operation (e.g., level, squeeze, etc.).\n\nOutputs:\n- If `as_index` is True, the function returns a GroupBy object that can be further processed with the .agg, .mean, .sum, etc., methods.\n- If `as_index` is False, the function returns a DataFrame where the grouping columns are included as normal columns, and the resulting columns depend on the operation applied (e.g., mean, sum).\n- The exact output type (DataFrame or Series) depends on the nature of the data and the operations applied after the groupby function.", "method_code_mask": "from datetime import datetime\nimport re\nimport numpy as np\nimport pytest\nfrom pandas._libs import lib\nimport pandas as pd\nfrom pandas import DataFrame\nfrom pandas import NamedAgg\nfrom pandas import Series\nimport pandas._testing as tm\nfrom pandas.core.indexes.datetimes import date_range\n\n\n@pytest.fixture\ndef df(index): [MASK]\n"}
